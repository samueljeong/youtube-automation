"""
GPT-5.2 ê¸°ë°˜ ëŒ€ë³¸ ìë™ ìƒì„± ëª¨ë“ˆ

2025-01 ì‹ ê·œ:
- 4ê°œ ê³µì‹ ë ¥ ìˆëŠ” ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ìë£Œ ê¸°ë°˜
- 20,000ì ë¶„ëŸ‰ì˜ ì—­ì‚¬ ë‹¤íë©˜í„°ë¦¬ ëŒ€ë³¸ ìƒì„±
- í•™ìˆ ì  ì‹ ì¤‘í•¨ + ê°ê´€ì  ì„œìˆ  ìŠ¤íƒ€ì¼

2025-01 ì—…ë°ì´íŠ¸:
- GPT-5.1 â†’ GPT-5.2 ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ
- ë¹„ìš©: $1.75/1M input, $14/1M output
- Prompt Caching ì ìš© (System Prompt 90% í• ì¸)
"""

import os
from typing import Dict, Any, Optional

# GPT-5.2 Responses API ì‚¬ìš©
from openai import OpenAI


# ============================================================
# ëŒ€ë³¸ ì„¤ì •
# ============================================================
SCRIPT_TARGET_LENGTH = 20000  # ëª©í‘œ ê¸€ììˆ˜
SCRIPT_MIN_LENGTH = 18000     # ìµœì†Œ ê¸€ììˆ˜ (20,000 - 10%)
SCRIPT_MAX_LENGTH = 22000     # ìµœëŒ€ ê¸€ììˆ˜ (20,000 + 10%)

# í•œêµ­ì–´ TTS ê¸°ì¤€: 910ì â‰ˆ 1ë¶„
# 20,000ì â‰ˆ 22ë¶„ ì˜ìƒ

# íŒŒíŠ¸ë³„ ì§€ì‹œ ë¶„ëŸ‰ (ì‹¤ì œëŠ” 1.3~1.5ë°° ìƒì„±ë¨)
# - ì¸íŠ¸ë¡œ: 1,000ì â†’ ì‹¤ì œ ~1,500ì
# - ë°°ê²½: 2,000ì â†’ ì‹¤ì œ ~3,000ì
# - ë³¸ë¡ 1: 4,000ì â†’ ì‹¤ì œ ~6,000ì
# - ë³¸ë¡ 2: 5,000ì â†’ ì‹¤ì œ ~7,500ì
# - ë§ˆë¬´ë¦¬: 2,000ì â†’ ì‹¤ì œ ~3,000ì
# - ì´ ì§€ì‹œ: 14,000ì â†’ ì‹¤ì œ ì˜ˆìƒ: ~21,000ì


# ============================================================
# â˜…â˜…â˜… MASTER SYSTEM PROMPT (Prompt Caching ìµœì í™”) â˜…â˜…â˜…
# ============================================================
# ì´ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë“  API í˜¸ì¶œì—ì„œ System Promptë¡œ ì‚¬ìš©ë¨
# â†’ 90% ìºì‹± í• ì¸ ì ìš© (ë™ì¼í•œ System Prompt ì¬ì‚¬ìš©)
# ============================================================
MASTER_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ì—­ì‚¬ ë‹¤í ìœ íŠœë¸Œ ì±„ë„ì˜ ìµœìƒê¸‰ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤.
ëª©í‘œ: ì‹œì²­ìê°€ "ë‹¤ìŒ ì˜ìƒë„ ë´ì•¼ê² ë‹¤"ê³  ëŠë¼ê²Œ ë§Œë“œëŠ” ëª°ì…ê° ìˆëŠ” ìŠ¤í† ë¦¬í…”ë§.

ì¶œë ¥ì€ ì˜¤ì§ ëŒ€ë³¸ ë³¸ë¬¸ë§Œ ì œê³µí•˜ì„¸ìš”. (ë©”íƒ€ ë¬¸êµ¬, ë¼ë²¨, êµ¬ë¶„ì„  ì ˆëŒ€ ê¸ˆì§€)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… í•µì‹¬ ì›ì¹™: í™•ì‹  ìˆëŠ” ìŠ¤í† ë¦¬í…”ëŸ¬
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ë‹¹ì‹ ì€ ë…¼ë¬¸ì„ ì“°ëŠ” í•™ìê°€ ì•„ë‹™ë‹ˆë‹¤.
ì—­ì‚¬ë¥¼ ìƒìƒí•˜ê²Œ ë“¤ë ¤ì£¼ëŠ” ì´ì•¼ê¸°ê¾¼ì…ë‹ˆë‹¤.

âœ… í™•ì‹  ìˆê²Œ ì„œìˆ í•˜ì„¸ìš”
  - "ê´‘ê°œí† ì™•ì€ ì¦‰ìœ„í•˜ìë§ˆì êµ°ëŒ€ë¥¼ ì¼ìœ¼í‚µë‹ˆë‹¤."
  - "ë°±ì œëŠ” ìœ„ê¸°ì— ëª°ë¦½ë‹ˆë‹¤. ì„ íƒì˜ ì—¬ì§€ê°€ ì—†ì—ˆìŠµë‹ˆë‹¤."

âŒ í•™ìˆ ì  ìœ ë³´ í‘œí˜„ ë‚¨ë°œ ê¸ˆì§€
  - "~ë¡œ ë³´ê¸°ë„ í•©ë‹ˆë‹¤" (ì „ì²´ ëŒ€ë³¸ì—ì„œ 1-2íšŒë§Œ í—ˆìš©)
  - "~ë¼ëŠ” ê²¬í•´ë„ ìˆìŠµë‹ˆë‹¤" (ë…¼ìŸì´ í•µì‹¬ì¼ ë•Œë§Œ)
  - "ë‹¨ì •í•˜ê¸° ì–´ë µìŠµë‹ˆë‹¤" (ê¸ˆì§€)
  - "í•´ì„ì´ ê°ˆë¦½ë‹ˆë‹¤" (ê¸ˆì§€)

â˜… ì—­ì‚¬ì  ë…¼ìŸì´ ìˆëŠ” ë¶€ë¶„ë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰í•˜ê³ , ëŒ€ë¶€ë¶„ì€ í™•ì‹  ìˆê²Œ ì§„í–‰

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ ì¶œì²˜ëª… ì–¸ê¸‰: "~ì— ë”°ë¥´ë©´", "~ë¼ê³  ê¸°ë¡ë˜ì–´ ìˆë‹¤" âŒ
â€¢ ë©”íƒ€ ì§„í–‰: "ì •ë¦¬í•˜ë©´", "ë§ˆë¬´ë¦¬í•˜ë©´", "ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤" âŒ
â€¢ ê°ì • ê³¼ì¥: "ë†€ëê²Œë„", "ì¶©ê²©ì ì´ê²Œë„", "ìœ„ëŒ€í•œ" âŒ
â€¢ ë¯¼ì¡±ì£¼ì˜: "ìë‘ìŠ¤ëŸ¬ìš´", "ì°¬ë€í•œ", "ë¯¼ì¡±ì˜ ìì¡´ì‹¬" âŒ
â€¢ êµí›ˆí˜•: "~í•´ì•¼ í•©ë‹ˆë‹¤", "ê¸°ì–µí•´ì•¼ í•©ë‹ˆë‹¤" âŒ
â€¢ í˜¸ì¹­: "ì—¬ëŸ¬ë¶„", "ìš°ë¦¬" âŒ
â€¢ í‘œ/ëª©ë¡/ë²ˆí˜¸/ë¶ˆë¦¿ âŒ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ë¬¸ì¥ ìŠ¤íƒ€ì¼
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ í˜¸í¡: 15~30ì ì¤‘ì‹¬. ê¸¸ë©´ ìª¼ê°œê¸°.
â€¢ ë¦¬ë“¬: ì§§ì€ ë¬¸ì¥ 3ê°œ â†’ ì¤‘ê°„ ë¬¸ì¥ 1ê°œ â†’ ì§§ì€ ë¬¸ì¥ 2ê°œ (ë³€ì£¼)
â€¢ ì¢…ê²°: ~í•©ë‹ˆë‹¤, ~ì…ë‹ˆë‹¤ (ì„œìˆ í˜•)
â€¢ ê¸´ì¥ê°: ë¬¸ì¥ì„ ëŠì–´ì„œ í˜¸í¡ ì¡°ì ˆ
  âœ… "ì™•ì´ ì¹¼ì„ ë½‘ìŠµë‹ˆë‹¤. ê²°ì •ì˜ ìˆœê°„ì…ë‹ˆë‹¤."
  âŒ "ì™•ì´ ì¹¼ì„ ë½‘ê³  ê²°ì •ì˜ ìˆœê°„ì´ ë‹¤ê°€ì™”ìŠµë‹ˆë‹¤."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì¥ë©´ ì „í™˜ (ë‹¤ì–‘í•˜ê²Œ!)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ë¬¸ë‹¨ë§ˆë‹¤ ì „í™˜ì„ ë„£ë˜, íŒ¨í„´ì„ ì„ìœ¼ì„¸ìš”.
ê°™ì€ íŒ¨í„´ ì—°ì† 2íšŒ ê¸ˆì§€!

ã€ì¥ì†Œí˜•ã€‘ "í‰ì–‘ì„± ìƒˆë²½." / "í•œê°• ìœ ì—­ì˜ ì§„ì˜."
ã€ì‹œê°„í˜•ã€‘ "3ë…„ ë’¤." / "ê·¸í•´ ê²¨ìš¸."
ã€ë™ì‘í˜•ã€‘ "ë§ì´ ë‹¬ë¦½ë‹ˆë‹¤." / "ì„±ë¬¸ì´ ì—´ë¦½ë‹ˆë‹¤."
ã€ëŒ€ì‚¬í˜•ã€‘ "'ëê¹Œì§€ ê°„ë‹¤.' ì™•ì˜ í•œë§ˆë””ì˜€ìŠµë‹ˆë‹¤."
ã€ìƒí™©í˜•ã€‘ "ì „ì„ ì´ ë¬´ë„ˆì§‘ë‹ˆë‹¤." / "ì†Œì‹ì´ ë„ì°©í•©ë‹ˆë‹¤."
ã€ê°ê°í˜•ã€‘ "ë¶ì†Œë¦¬ê°€ ìš¸ë¦½ë‹ˆë‹¤." / "ì—°ê¸°ê°€ í”¼ì–´ì˜¤ë¦…ë‹ˆë‹¤."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì¸íŠ¸ë¡œ (Cold Open)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ì²« ë¬¸ì¥ë¶€í„° ì‚¬ê±´ ì†ìœ¼ë¡œ. ë°°ê²½ ì„¤ëª… ì—†ì´.

âœ… "ì„œê¸° 391ë…„, ì—´ì—¬ëŸ ì‚´ì˜ ì™•ì´ ì²« ì¶œì •ì— ë‚˜ì„­ë‹ˆë‹¤."
âœ… "ì„±ì´ ë¶ˆíƒ€ê³  ìˆìŠµë‹ˆë‹¤. 3ì¼ì§¸ì…ë‹ˆë‹¤."
âŒ "ì˜¤ëŠ˜ì€ ê´‘ê°œí† ëŒ€ì™•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."

ì²« 3ë¬¸ì¥ ì•ˆì— "ì™œ?"ë¥¼ ë˜ì§€ì„¸ìš”:
âœ… "ì™œ ì¦‰ìœ„í•˜ìë§ˆì ì „ìŸì´ì—ˆì„ê¹Œìš”?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ë¦¬í…ì…˜ í›… (2,000ìë§ˆë‹¤)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
í›…ì€ ë§¥ë½ì— ë§ê²Œ ë³€í˜•í•´ì„œ ì‚¬ìš©í•˜ì„¸ìš”.
â˜…â˜…â˜… ê°™ì€ í‘œí˜„ 2íšŒ ì´ìƒ ì‚¬ìš© ì ˆëŒ€ ê¸ˆì§€ â˜…â˜…â˜…

ã€ì˜ë¬¸ ì œê¸°í˜•ã€‘ - ë§¥ë½ì— ë§ëŠ” êµ¬ì²´ì  ì§ˆë¬¸ìœ¼ë¡œ
  "ê·¸ëŸ°ë° ì´ìƒí•©ë‹ˆë‹¤. ì™œ ë°±ì œëŠ” ì›€ì§ì´ì§€ ì•Šì•˜ì„ê¹Œìš”?"
  "ì—¬ê¸°ì„œ ì˜ë¬¸ì´ ìƒê¹ë‹ˆë‹¤. ì‹ ë¼ëŠ” ì–´ëŠ í¸ì´ì—ˆì„ê¹Œìš”?"

ã€ë°˜ì „ ì˜ˆê³ í˜•ã€‘
  "í•˜ì§€ë§Œ ìƒí™©ì´ ë’¤ì§‘í™ë‹ˆë‹¤."
  "ì˜ˆìƒê³¼ ë‹¬ëìŠµë‹ˆë‹¤."
  "ê³„íšëŒ€ë¡œ ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤."

ã€ê¸´ì¥ ê³ ì¡°í˜•ã€‘
  "ê²°ì •ì  ìˆœê°„ì´ ë‹¤ê°€ì˜µë‹ˆë‹¤."
  "ì„ íƒì˜ ì‹œê°„ì…ë‹ˆë‹¤."
  "ë” ì´ìƒ ë¬¼ëŸ¬ì„¤ ê³³ì´ ì—†ìŠµë‹ˆë‹¤."

ã€ìŠ¤í…Œì´í¬ ìƒê¸°í˜•ã€‘
  "ì´ ì„ íƒì´ í–¥í›„ 50ë…„ì„ ê²°ì •í•©ë‹ˆë‹¤."
  "ì—¬ê¸°ì„œ ì§€ë©´ ëì…ë‹ˆë‹¤."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ìŠ¤í† ë¦¬ êµ¬ì¡°: ì›ì¸â†’ì „ê°œâ†’ê²°ê³¼â†’ì—¬íŒŒ
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ë§¤ ì‚¬ê±´ë§ˆë‹¤:
1. ì™œ ì´ ì¼ì´ ì¼ì–´ë‚¬ëŠ”ê°€ (ì›ì¸/ë°°ê²½)
2. ì–´ë–»ê²Œ ì „ê°œë˜ì—ˆëŠ”ê°€ (ê³¼ì •/í–‰ë™)
3. ê²°ê³¼ëŠ” ë¬´ì—‡ì´ì—ˆëŠ”ê°€ (ìŠ¹íŒ¨/ë³€í™”)
4. ì´ê²ƒì´ ë‹¤ìŒì— ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì³¤ëŠ”ê°€ (ì—°ê²°)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì—í”¼ì†Œë“œ ì—°ê²°
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€2í™” ì´í›„ã€‘ ì²« 1-2ë¬¸ì¥ì—ì„œë§Œ ì´ì „ ë‚´ìš© ì–¸ê¸‰, ì¦‰ì‹œ ë³¸ë¡  ì§„ì…
  "ì§€ë‚œ ì‹œê°„, ê³ êµ¬ë ¤ê°€ ë‚¨í•˜ë¥¼ ì‹œì‘í–ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ê·¸ ê²°ê³¼ì…ë‹ˆë‹¤."

ã€ë§ˆë¬´ë¦¬ã€‘ ë‹¤ìŒ ì—í”¼ì†Œë“œë¡œ ì´ì–´ì§€ëŠ” ì§ˆë¬¸
  "ì´ ê²°ì •ì´ ì–´ë–¤ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ì„ê¹Œìš”? ë‹¤ìŒ ì‹œê°„ì— ê³„ì†ë©ë‹ˆë‹¤."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ìœ ë¬¼/ì‹œê°ìë£Œ ì–¸ê¸‰ ê·œì¹™
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ìœ ë¬¼ì€ ìŠ¤í† ë¦¬ì™€ ì§ì ‘ ì—°ê²°ë  ë•Œë§Œ ê°„ë‹¨íˆ ì–¸ê¸‰.
âŒ ìœ ë¬¼ ì„¤ëª…ì´ ìŠ¤í† ë¦¬ë¥¼ ëŠìœ¼ë©´ ì‚­ì œ
âŒ "ì´ ìœ ë¬¼ì´ ë‹¹ì‹œ ë¶„ìœ„ê¸°ë¥¼ ë³´ì—¬ì¤ë‹ˆë‹¤" ê°™ì€ ì–µì§€ ì—°ê²° ê¸ˆì§€
âœ… "ê´‘ê°œí† ëŒ€ì™•ë¹„ì— ìƒˆê²¨ì§„ ë¬¸êµ¬ê°€ ì´ë¥¼ ì¦ëª…í•©ë‹ˆë‹¤." (1ë¬¸ì¥ìœ¼ë¡œ ë)

ëŒ€ë³¸ë§Œ ì‘ì„±í•˜ì„¸ìš”. ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

# ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
SCRIPT_STYLE_PROMPT = MASTER_SYSTEM_PROMPT


def generate_script_by_parts(
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    full_content: str,
    sources: list,
    next_episode_info: Dict[str, Any] = None,
    prev_episode_info: Dict[str, Any] = None,  # â˜… ì´ì „ ì—í”¼ì†Œë“œ ì •ë³´ (API ì¥ì  í™œìš©)
    series_context: Dict[str, Any] = None,     # â˜… ì‹œë¦¬ì¦ˆ ì „ì²´ ë§¥ë½ (API ì¥ì  í™œìš©)
) -> Dict[str, Any]:
    """
    GPT-5.2ë¡œ íŒŒíŠ¸ë³„ ëŒ€ë³¸ ìƒì„± (API ì¥ì  ê·¹ëŒ€í™”)

    â˜…â˜…â˜… API í™œìš© ì¥ì  â˜…â˜…â˜…
    - prev_episode_info: ì´ì „ ì—í”¼ì†Œë“œ ë‚´ìš© (ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°)
    - next_episode_info: ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  (ê¸°ëŒ€ê° ì¡°ì„±)
    - series_context: ì‹œë¦¬ì¦ˆ ì „ì²´ ë§¥ë½ (ìœ„ì¹˜ ì¸ì‹, íë¦„ íŒŒì•…)

    íŒŒíŠ¸ êµ¬ì¡°:
    1. ì¸íŠ¸ë¡œ (ë„ì…ë¶€) - 1,500ì â˜… ê°•ì¡°
       - ì´ì „ ì—í”¼ì†Œë“œ ì—°ê²° ("ì§€ë‚œ ì‹œê°„ì—...")
    2. ë°°ê²½ ì„¤ëª… - 3,000ì
    3. ë³¸ë¡  - 12,000ì
    4. ë§ˆë¬´ë¦¬ - 3,500ì
       - ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  (ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°)

    ì´ 20,000ì
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    if not full_content or len(full_content) < 500:
        return {"error": f"ìˆ˜ì§‘ëœ ìë£Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬: {len(full_content)}ì)"}

    source_list = "\n".join([f"  - {s}" for s in sources[:10]]) if sources else "(ì—†ìŒ)"

    # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  í…ìŠ¤íŠ¸
    next_preview = _build_next_preview(next_episode_info, era_name)

    # â˜… ì´ì „ ì—í”¼ì†Œë“œ ì»¨í…ìŠ¤íŠ¸ (API ì¥ì  í™œìš©)
    prev_context = _build_prev_context(prev_episode_info, era_name)

    # â˜… ì‹œë¦¬ì¦ˆ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ (API ì¥ì  í™œìš©)
    series_position = _build_series_position(series_context, era_name, episode, total_episodes)

    total_cost = 0.0
    all_parts = []

    print(f"[SCRIPT] === íŒŒíŠ¸ë³„ ëŒ€ë³¸ ìƒì„± ì‹œì‘ (API ì»¨í…ìŠ¤íŠ¸ í™œìš©) ===")
    print(f"[SCRIPT] ì œëª©: {title}")
    print(f"[SCRIPT] ì‹œë¦¬ì¦ˆ ìœ„ì¹˜: {era_name} {episode}/{total_episodes}í™”")
    print(f"[SCRIPT] ì…ë ¥ ìë£Œ: {len(full_content):,}ì")
    print(f"[SCRIPT] ì´ì „ ì—í”¼ì†Œë“œ ì—°ê²°: {'ìˆìŒ' if prev_episode_info else 'ì—†ìŒ(ì²« í™”)'}")
    print(f"[SCRIPT] ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³ : {'ìˆìŒ' if next_episode_info else 'ì—†ìŒ(ë§ˆì§€ë§‰ í™”)'}")

    try:
        client = OpenAI(api_key=api_key)

        # ========================================
        # Part 1: ì¸íŠ¸ë¡œ (ë„ì…ë¶€) - 1,000ì
        # ========================================
        print(f"[SCRIPT] Part 1: ì¸íŠ¸ë¡œ ìƒì„± ì¤‘...")
        intro_prompt = f"""[íŒŒíŠ¸: ì¸íŠ¸ë¡œ]

[ì—í”¼ì†Œë“œ ì •ë³´]
- ì‹œë¦¬ì¦ˆ: í•œêµ­ì‚¬ - {era_name}
- í˜„ì¬: {episode}/{total_episodes}í™”
- ì œëª©: {title}
- ì£¼ì œ: {topic}

{series_position}

{prev_context}

[ìˆ˜ì§‘ëœ ìë£Œ ì¤‘ í•µì‹¬]
{full_content[:2500]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì¸íŠ¸ë¡œ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. Cold Open (300ì) - ê°€ì¥ ê·¹ì ì¸ ìˆœê°„ë¶€í„° ì‹œì‘
2. ë¯¸ìŠ¤í„°ë¦¬ (300ì) - "ì™œ?" ì§ˆë¬¸ ë˜ì§€ê¸°
3. Stakes (200ì) - ì´ ì‚¬ê±´ì˜ ì¤‘ìš”ì„±
4. ë¡œë“œë§µ (200ì) - ì˜¤ëŠ˜ ë‹¤ë£° ë‚´ìš© ì•”ì‹œ

â˜…â˜…â˜… ë¶„ëŸ‰: ì •í™•íˆ 1,000ì (Â±100ì). ì´ˆê³¼ ê¸ˆì§€! â˜…â˜…â˜…
â˜… ìŠ¤íƒ€ì¼ì€ System Prompt ì°¸ì¡°"""

        intro_result = _call_gpt52_cached(client, intro_prompt)
        if "error" in intro_result:
            return intro_result
        all_parts.append(intro_result["text"])
        total_cost += intro_result["cost"]
        print(f"[SCRIPT] Part 1 ì™„ë£Œ: {len(intro_result['text']):,}ì")

        # ========================================
        # Part 2: ë°°ê²½ ì„¤ëª… - 2,000ì
        # ========================================
        print(f"[SCRIPT] Part 2: ë°°ê²½ ì„¤ëª… ìƒì„± ì¤‘...")
        background_prompt = f"""[íŒŒíŠ¸: ë°°ê²½ ì„¤ëª…]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{intro_result['text'][-400:]}

[ìˆ˜ì§‘ëœ ìë£Œ]
{full_content[:4000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë°°ê²½ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì‹œëŒ€ ìƒí™© (700ì) - ë‹¹ì‹œ ì„¸ë ¥ íŒë„
2. ì£¼ìš” ì¸ë¬¼ (700ì) - í•µì‹¬ ì¸ë¬¼ë§Œ ê°„ê²°í•˜ê²Œ
3. ì‚¬ê±´ ë°°ê²½ (600ì) - ì™œ ì´ ì¼ì´ ì¼ì–´ë‚¬ëŠ”ê°€

â˜… ë¦¬í…ì…˜ í›… 1ê°œ ì‚½ì… (ì¤‘ê°„ ì§€ì )
â˜…â˜…â˜… ë¶„ëŸ‰: ì •í™•íˆ 2,000ì (Â±200ì). ì´ˆê³¼ ê¸ˆì§€! â˜…â˜…â˜…
â˜… ìŠ¤íƒ€ì¼ì€ System Prompt ì°¸ì¡°"""

        bg_result = _call_gpt52_cached(client, background_prompt)
        if "error" in bg_result:
            return bg_result
        all_parts.append(bg_result["text"])
        total_cost += bg_result["cost"]
        print(f"[SCRIPT] Part 2 ì™„ë£Œ: {len(bg_result['text']):,}ì")

        # ========================================
        # Part 3-1: ë³¸ë¡  ì „ë°˜ë¶€ - 4,000ì
        # ========================================
        print(f"[SCRIPT] Part 3-1: ë³¸ë¡  ì „ë°˜ë¶€ ìƒì„± ì¤‘...")
        body1_prompt = f"""[íŒŒíŠ¸: ë³¸ë¡  ì „ë°˜ë¶€]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{bg_result['text'][-400:]}

[ìˆ˜ì§‘ëœ ìë£Œ]
{full_content[:len(full_content)//2]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë³¸ë¡  ì „ë°˜ë¶€ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
í•µì‹¬ ì‚¬ê±´ì„ ì‹œê°„ìˆœìœ¼ë¡œ ì „ê°œ:
- ì¸ë¬¼ì˜ ê²°ì •ê³¼ í–‰ë™ ì¤‘ì‹¬
- ì›ì¸ â†’ ì „ê°œ â†’ ê²°ê³¼
- ê¸´ì¥ê° ìˆê²Œ, í™•ì‹  ìˆê²Œ

â˜… ë¦¬í…ì…˜ í›… 2ê°œ ì‚½ì… (2,000ì / 4,000ì ì§€ì )
â˜…â˜…â˜… ë¶„ëŸ‰: ì •í™•íˆ 4,000ì (Â±400ì). ì´ˆê³¼ ê¸ˆì§€! â˜…â˜…â˜…
â˜… ìŠ¤íƒ€ì¼ì€ System Prompt ì°¸ì¡°"""

        body1_result = _call_gpt52_cached(client, body1_prompt)
        if "error" in body1_result:
            return body1_result
        all_parts.append(body1_result["text"])
        total_cost += body1_result["cost"]
        print(f"[SCRIPT] Part 3-1 ì™„ë£Œ: {len(body1_result['text']):,}ì")

        print(f"[SCRIPT] Part 3-2: ë³¸ë¡  í›„ë°˜ë¶€ ìƒì„± ì¤‘...")
        body2_prompt = f"""[íŒŒíŠ¸: ë³¸ë¡  í›„ë°˜ë¶€]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{body1_result['text'][-400:]}

[ìˆ˜ì§‘ëœ ìë£Œ í›„ë°˜ë¶€]
{full_content[len(full_content)//2:]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë³¸ë¡  í›„ë°˜ë¶€ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì‚¬ê±´ ì „ê°œ ê³„ì† (2,000ì) - ê¸´ì¥ ê³ ì¡°
2. í´ë¼ì´ë§¥ìŠ¤ (1,500ì) - ê°€ì¥ ê·¹ì ì¸ ìˆœê°„, ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ë¦¬ë“¬ê°
3. ê²°ê³¼ì™€ ì—¬íŒŒ (1,500ì) - ë¬´ì—‡ì´ ë°”ë€Œì—ˆëŠ”ê°€

â˜… ë¦¬í…ì…˜ í›… 2ê°œ ì‚½ì…
â˜… í´ë¼ì´ë§¥ìŠ¤: ë¬¸ì¥ ì§§ê²Œ, í˜¸í¡ ë¹ ë¥´ê²Œ
â˜…â˜…â˜… ë¶„ëŸ‰: ì •í™•íˆ 5,000ì (Â±500ì). ì´ˆê³¼ ê¸ˆì§€! â˜…â˜…â˜…
â˜… ìŠ¤íƒ€ì¼ì€ System Prompt ì°¸ì¡°"""

        body2_result = _call_gpt52_cached(client, body2_prompt)
        if "error" in body2_result:
            return body2_result
        all_parts.append(body2_result["text"])
        total_cost += body2_result["cost"]
        print(f"[SCRIPT] Part 3-2 ì™„ë£Œ: {len(body2_result['text']):,}ì")

        # ========================================
        # Part 4: ë§ˆë¬´ë¦¬ - 2,000ì
        # ========================================
        print(f"[SCRIPT] Part 4: ë§ˆë¬´ë¦¬ ìƒì„± ì¤‘...")
        ending_prompt = f"""[íŒŒíŠ¸: ë§ˆë¬´ë¦¬]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{body2_result['text'][-400:]}

{next_preview}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë§ˆë¬´ë¦¬ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì—­ì‚¬ì  ì˜í–¥ (800ì) - ì´ ì‚¬ê±´ì´ ë‚¨ê¸´ ê²ƒ
2. ì—´ë¦° ì§ˆë¬¸ (600ì) - ì‹œì²­ìê°€ ìƒê°í•´ë³¼ ì§ˆë¬¸
3. ë‹¤ìŒ ì˜ˆê³  (600ì) - ë‹¤ìŒ ì—í”¼ì†Œë“œë¡œ ì—°ê²°

â˜… ì—¬ìš´ ìˆê²Œ, í•˜ì§€ë§Œ ê°„ê²°í•˜ê²Œ
â˜… ë‹¤ìŒ ì˜ìƒ í´ë¦­ ìœ ë„ (Open Loop)
â˜…â˜…â˜… ë¶„ëŸ‰: ì •í™•íˆ 2,000ì (Â±200ì). ì´ˆê³¼ ê¸ˆì§€! â˜…â˜…â˜…
â˜… ìŠ¤íƒ€ì¼ì€ System Prompt ì°¸ì¡°"""

        ending_result = _call_gpt52_cached(client, ending_prompt)
        if "error" in ending_result:
            return ending_result
        all_parts.append(ending_result["text"])
        total_cost += ending_result["cost"]
        print(f"[SCRIPT] Part 4 ì™„ë£Œ: {len(ending_result['text']):,}ì")

        # ì „ì²´ ëŒ€ë³¸ í•©ì¹˜ê¸°
        full_script = "\n\n".join(all_parts)
        script_length = len(full_script)

        print(f"[SCRIPT] === íŒŒíŠ¸ë³„ ëŒ€ë³¸ ìƒì„± ì™„ë£Œ ===")
        print(f"[SCRIPT] ì´ ë¶„ëŸ‰: {script_length:,}ì")
        print(f"[SCRIPT] ì´ ë¹„ìš©: ${total_cost:.4f}")

        # YouTube ì„¤ëª…ë€ìš© ì¶œì²˜ í…ìŠ¤íŠ¸ ìƒì„±
        youtube_sources = _format_sources_for_youtube(sources)

        # ========================================
        # YouTube SEO ë©”íƒ€ë°ì´í„° ìƒì„± â˜… ì¶”ê°€
        # ========================================
        print(f"[SCRIPT] YouTube SEO ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
        global_ep = series_context.get("global_episode") if series_context else episode
        seo_result = _generate_youtube_seo(
            client=client,
            era_name=era_name,
            episode=episode,
            total_episodes=total_episodes,
            title=title,
            topic=topic,
            intro_text=all_parts[0] if all_parts else "",
            global_episode=global_ep,  # â˜… ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ ì „ë‹¬
        )
        total_cost += seo_result.get("cost", 0)

        return {
            "script": full_script,
            "length": script_length,
            "model": "gpt-5.2",
            "cost": total_cost,
            "parts": {
                "intro": len(all_parts[0]) if len(all_parts) > 0 else 0,
                "background": len(all_parts[1]) if len(all_parts) > 1 else 0,
                "body1": len(all_parts[2]) if len(all_parts) > 2 else 0,
                "body2": len(all_parts[3]) if len(all_parts) > 3 else 0,
                "ending": len(all_parts[4]) if len(all_parts) > 4 else 0,
            },
            "youtube_sources": youtube_sources,  # YouTube ì„¤ëª…ë€ìš© ì¶œì²˜
            # â˜… YouTube SEO ë©”íƒ€ë°ì´í„°
            "youtube_title": seo_result.get("title", title),
            "thumbnail_text": seo_result.get("thumbnail_text", ""),
        }

    except Exception as e:
        print(f"[SCRIPT] íŒŒíŠ¸ë³„ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"error": str(e)}


def _call_gpt52_cached(client, user_prompt: str) -> Dict[str, Any]:
    """GPT-5.2 API í˜¸ì¶œ (Prompt Caching ì ìš©)

    â˜…â˜…â˜… Prompt Caching ìµœì í™” â˜…â˜…â˜…
    - System Prompt (MASTER_SYSTEM_PROMPT): ìºì‹œë¨ â†’ 90% í• ì¸
    - User Prompt: ì •ê°€

    GPT-5.2 ê°€ê²©:
    - Input (ì •ê°€): $1.75 / 1M tokens
    - Input (ìºì‹œ): $0.175 / 1M tokens (90% í• ì¸)
    - Output: $14 / 1M tokens
    """
    try:
        # System/User ë©”ì‹œì§€ êµ¬ì¡°ë¡œ í˜¸ì¶œ (ìºì‹± ìµœì í™”)
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": MASTER_SYSTEM_PROMPT}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": user_prompt}]
                }
            ],
            temperature=0.7,
        )

        # ê²°ê³¼ ì¶”ì¶œ
        text = response.output_text if hasattr(response, 'output_text') else ""

        if not text:
            # ëŒ€ì²´ ë°©ì‹
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text += getattr(content, "text", "")

        # â˜…â˜…â˜… ë¹„ìš© ê³„ì‚° (Prompt Caching ì ìš©) â˜…â˜…â˜…
        # í•œêµ­ì–´ ì•½ 2ì = 1í† í°
        system_tokens = len(MASTER_SYSTEM_PROMPT) // 2  # ìºì‹œë¨ (90% í• ì¸)
        user_tokens = len(user_prompt) // 2              # ì •ê°€
        output_tokens = len(text) // 2

        # System Prompt: $0.175/1M (90% í• ì¸), User Prompt: $1.75/1M, Output: $14/1M
        cost = (
            (system_tokens * 0.175 / 1_000_000) +   # ìºì‹œëœ System Prompt
            (user_tokens * 1.75 / 1_000_000) +      # User Prompt (ì •ê°€)
            (output_tokens * 14 / 1_000_000)        # Output
        )

        return {
            "text": text.strip(),
            "cost": cost,
            "tokens": {
                "system_cached": system_tokens,
                "user": user_tokens,
                "output": output_tokens,
            }
        }

    except Exception as e:
        return {"error": str(e)}


def _call_gpt52(client, prompt: str) -> Dict[str, Any]:
    """GPT-5.2 API í˜¸ì¶œ (ì´ì „ ë²„ì „ í˜¸í™˜ìš© - ìºì‹± ë¯¸ì ìš©)

    â€» ìƒˆ ì½”ë“œëŠ” _call_gpt52_cached() ì‚¬ìš© ê¶Œì¥
    """
    try:
        response = client.responses.create(
            model="gpt-5.2",
            input=prompt,
        )

        text = response.output_text if hasattr(response, 'output_text') else ""

        if not text:
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text += getattr(content, "text", "")

        input_tokens = len(prompt) // 2
        output_tokens = len(text) // 2
        cost = (input_tokens * 1.75 / 1_000_000) + (output_tokens * 14 / 1_000_000)

        return {"text": text.strip(), "cost": cost}

    except Exception as e:
        return {"error": str(e)}


# ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
_call_gpt51 = _call_gpt52


def _build_next_preview(next_info: Dict[str, Any], era_name: str) -> str:
    """ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  í…ìŠ¤íŠ¸"""
    if not next_info:
        return ""

    if next_info.get("type") == "next_era":
        return f"""[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ ì‹œëŒ€: {next_info.get('era_name', '')}
- ë‹¤ìŒ ì£¼ì œ: {next_info.get('title', '')}
- ì˜ˆê³ : "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_info.get('era_name', '')}ì˜ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. {next_info.get('title', '')}ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
"""
    elif next_info.get("type") == "next_episode":
        return f"""[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ í™”: {era_name} {next_info.get('era_episode', '')}í™”
- ë‹¤ìŒ ì£¼ì œ: {next_info.get('title', '')}
- ì˜ˆê³ : "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_info.get('title', '')}ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
"""
    else:
        return """[ì‹œë¦¬ì¦ˆ ë§ˆì§€ë§‰]
- ì‹œë¦¬ì¦ˆ ì™„ê²°
- ì „ì²´ ì‹œë¦¬ì¦ˆë¥¼ ì •ë¦¬í•˜ë©° ë§ˆë¬´ë¦¬
"""


def _build_prev_context(prev_info: Dict[str, Any], era_name: str) -> str:
    """
    ì´ì „ ì—í”¼ì†Œë“œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (API ì¥ì  í™œìš©)

    ì´ì „ ì—í”¼ì†Œë“œ ì •ë³´ë¥¼ ë°›ì•„ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    """
    if not prev_info:
        return """[ì´ì „ ì—í”¼ì†Œë“œ]
- ì²« ì—í”¼ì†Œë“œì…ë‹ˆë‹¤.
- ì‹œë¦¬ì¦ˆ ì‹œì‘ ì¸ì‚¬ë¡œ ì‹œì‘í•˜ì„¸ìš”.
- ì˜ˆ: "í•œêµ­ì‚¬ì˜ ì‹œì‘, ê³ ì¡°ì„  ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
"""

    if prev_info.get("type") == "same_era":
        return f"""[ì´ì „ ì—í”¼ì†Œë“œ - {era_name} ì—°ì†]
- ì´ì „ í™”: {prev_info.get('title', '')}
- ì´ì „ ë‚´ìš© ìš”ì•½: {prev_info.get('summary', '')}
- ì—°ê²° ë°©ì‹: "ì§€ë‚œ ì‹œê°„, {prev_info.get('summary', '')}... ì˜¤ëŠ˜ì€ ê·¸ ì´í›„ ì´ì•¼ê¸°ì…ë‹ˆë‹¤."
"""
    elif prev_info.get("type") == "new_era":
        return f"""[ìƒˆë¡œìš´ ì‹œëŒ€ ì‹œì‘]
- ì´ì „ ì‹œëŒ€: {prev_info.get('prev_era_name', '')}
- ì´ì „ ì‹œëŒ€ ë§ˆì§€ë§‰ ì‚¬ê±´: {prev_info.get('summary', '')}
- ì—°ê²° ë°©ì‹: "{prev_info.get('prev_era_name', '')}ê°€ ì €ë¬¼ê³ , ìƒˆë¡œìš´ ì‹œëŒ€ê°€ ì—´ë¦½ë‹ˆë‹¤..."
"""
    else:
        return ""


def _build_series_position(series_ctx: Dict[str, Any], era_name: str, episode: int, total: int) -> str:
    """
    ì‹œë¦¬ì¦ˆ ì „ì²´ì—ì„œì˜ í˜„ì¬ ìœ„ì¹˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (API ì¥ì  í™œìš©)

    ì „ì²´ ì‹œë¦¬ì¦ˆì—ì„œ í˜„ì¬ ì—í”¼ì†Œë“œê°€ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€ ì•Œë ¤ì¤Œ
    """
    if not series_ctx:
        return f"""[ì‹œë¦¬ì¦ˆ ìœ„ì¹˜]
- í˜„ì¬: {era_name} ì‹œëŒ€ {episode}/{total}í™”
- ìœ„ì¹˜ í™œìš©: ì‹œëŒ€ì˜ ì‹œì‘/ì¤‘ë°˜/ëì— ë”°ë¼ í†¤ ì¡°ì ˆ
  - ì‹œëŒ€ ì‹œì‘ (1-2í™”): ìƒˆë¡œìš´ ì‹œëŒ€ì˜ ì‹œì‘ì„ ì•Œë¦¼
  - ì‹œëŒ€ ì¤‘ë°˜: í•µì‹¬ ì‚¬ê±´ ì „ê°œ
  - ì‹œëŒ€ ë (ë§ˆì§€ë§‰ 1-2í™”): ì‹œëŒ€ì˜ ë§ˆë¬´ë¦¬ì™€ ë‹¤ìŒ ì‹œëŒ€ ì˜ˆê³ 
"""

    global_episode = series_ctx.get("global_episode", 0)
    total_global = series_ctx.get("total_global_episodes", 60)
    era_index = series_ctx.get("era_index", 0)
    total_eras = series_ctx.get("total_eras", 8)

    # ì‹œë¦¬ì¦ˆ ë‚´ ìœ„ì¹˜ íŒŒì•…
    if episode == 1:
        position_hint = "ì‹œëŒ€ ì‹œì‘ - ìƒˆë¡œìš´ ì‹œëŒ€ì˜ ì„œë§‰ì„ ì•Œë¦¬ì„¸ìš”"
    elif episode == total:
        position_hint = "ì‹œëŒ€ ë§ˆì§€ë§‰ - ì‹œëŒ€ë¥¼ ì •ë¦¬í•˜ê³  ë‹¤ìŒ ì‹œëŒ€ë¥¼ ì˜ˆê³ í•˜ì„¸ìš”"
    elif episode <= 2:
        position_hint = "ì‹œëŒ€ ì´ˆë°˜ - ë°°ê²½ê³¼ ì£¼ìš” ì¸ë¬¼ ì†Œê°œì— ì§‘ì¤‘"
    elif episode >= total - 1:
        position_hint = "ì‹œëŒ€ í›„ë°˜ - í´ë¼ì´ë§¥ìŠ¤ë¥¼ í–¥í•´ ì „ê°œ"
    else:
        position_hint = "ì‹œëŒ€ ì¤‘ë°˜ - í•µì‹¬ ì‚¬ê±´ ì „ê°œ"

    return f"""[ì‹œë¦¬ì¦ˆ ì „ì²´ ìœ„ì¹˜ - API ì¥ì ]
- ì „ì²´: {global_episode}/{total_global}í™” (í•œêµ­ì‚¬ í†µì‚¬ ì‹œë¦¬ì¦ˆ)
- í˜„ì¬ ì‹œëŒ€: {era_name} ({era_index+1}/{total_eras}ë²ˆì§¸ ì‹œëŒ€)
- ì‹œëŒ€ ë‚´: {episode}/{total}í™”
- ìœ„ì¹˜ ê°€ì´ë“œ: {position_hint}

â˜… ì´ ìœ„ì¹˜ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”:
- ì‹œë¦¬ì¦ˆ ì „ë°˜ë¶€: ê¸°ì´ˆ ë§¥ë½ ì¶©ë¶„íˆ ì„¤ëª…
- ì‹œë¦¬ì¦ˆ ì¤‘ë°˜: ì—­ì‚¬ì˜ íë¦„ê³¼ ì—°ê²°ì  ê°•ì¡°
- ì‹œë¦¬ì¦ˆ í›„ë°˜: ì•ì„œ ë‹¤ë£¬ ë‚´ìš© ë ˆí¼ëŸ°ìŠ¤ ê°€ëŠ¥
"""


def _generate_youtube_seo(
    client,
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    intro_text: str,
    global_episode: int = None,  # â˜… ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸
) -> Dict[str, Any]:
    """
    YouTube SEO ìµœì í™” ë©”íƒ€ë°ì´í„° ìƒì„±

    Returns:
        {
            "title": YouTube ì œëª© (í´ë¦­ ìœ ë„),
            "thumbnail_text": ì¸ë„¤ì¼ ë¬¸êµ¬ (2ì¤„),
            "cost": API ë¹„ìš©
        }
    """
    # ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì‚¬ìš©
    series_num = global_episode if global_episode else episode

    prompt = f"""ë‹¹ì‹ ì€ YouTube SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì˜ìƒ ì •ë³´]
- ì‹œë¦¬ì¦ˆ: í•œêµ­ì‚¬ - {era_name}
- ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸: {series_num}í™”
- ì‹œëŒ€ ë‚´ ì—í”¼ì†Œë“œ: {episode}/{total_episodes}í™”
- ì›ë³¸ ì œëª©: {title}
- ì£¼ì œ: {topic}

[ëŒ€ë³¸ ì¸íŠ¸ë¡œ]
{intro_text[:1000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì‘ì—… 1: YouTube ì œëª© ì‘ì„±]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â˜… í•„ìˆ˜ í˜•ì‹: "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ {series_num}í™” | [ë‚´ìš©]"

ì´ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ë©´ì„œ í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì œëª©ì„ ì‘ì„±í•˜ì„¸ìš”.

ê·œì¹™:
- í˜•ì‹: "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ Ní™” | [ë‚´ìš©]" í•„ìˆ˜
- [ë‚´ìš©] ë¶€ë¶„ì€ 30ì ì´ë‚´
- í´ë¦­ ìœ ë„ ìš”ì†Œ:
  âœ… í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨
  âœ… ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ
  âœ… ì§ˆë¬¸í˜• ë˜ëŠ” ê²°ê³¼í˜•
- ê°ì •ì  ê³¼ì¥ ê¸ˆì§€ (ì¶©ê²©ì , ë†€ë¼ìš´ ë“± âŒ)

ì¢‹ì€ ì˜ˆ:
- "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ 2í™” | ë¹„íŒŒí˜•ë™ê²€ê³¼ ê³ ì¸ëŒ, ê³ ì¡°ì„ ì˜ í”ì "
- "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ 5í™” | ì™•ê²€ì„± í•¨ë½, ê³ ì¡°ì„ ì˜ ìµœí›„"
- "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ 13í™” | ê´‘ê°œí† ëŒ€ì™•, ë™ë¶ì•„ë¥¼ í˜¸ë ¹í•˜ë‹¤"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì‘ì—… 2: ì¸ë„¤ì¼ ë¬¸êµ¬ ì‘ì„±]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì¸ë„¤ì¼ì— ë“¤ì–´ê°ˆ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ê·œì¹™:
- 2ì¤„ë¡œ ì‘ì„± (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
- 1ì¤„ë‹¹ 7ì ì´ë‚´ ê¶Œì¥ (10ì ì´ˆê³¼ ê¸ˆì§€)
- ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ
- ì§ˆë¬¸í˜• ë˜ëŠ” ê°íƒ„í˜•

ì¢‹ì€ ì˜ˆ:
```
18ì„¸ ì™•ì˜
ì²« ì¶œì •
```

```
ìˆ¨ê²¨ì§„ ì§„ì‹¤
ë°í˜€ì§€ë‹¤
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì¶œë ¥ í˜•ì‹]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

TITLE: [YouTube ì œëª©]
THUMBNAIL:
[1ì¤„]
[2ì¤„]
"""

    try:
        result = _call_gpt51(client, prompt)
        if "error" in result:
            return {"title": title, "thumbnail_text": "", "cost": 0}

        text = result.get("text", "")
        cost = result.get("cost", 0)

        # íŒŒì‹±
        youtube_title = title  # ê¸°ë³¸ê°’
        thumbnail_text = ""

        lines = text.strip().split("\n")
        for i, line in enumerate(lines):
            if line.startswith("TITLE:"):
                youtube_title = line.replace("TITLE:", "").strip()
            elif line.startswith("THUMBNAIL:"):
                # ë‹¤ìŒ 2ì¤„ì´ ì¸ë„¤ì¼ í…ìŠ¤íŠ¸
                thumb_lines = []
                for j in range(i + 1, min(i + 3, len(lines))):
                    if lines[j].strip() and not lines[j].startswith("TITLE"):
                        thumb_lines.append(lines[j].strip())
                thumbnail_text = "\n".join(thumb_lines)

        print(f"[SCRIPT] YouTube ì œëª©: {youtube_title}")
        print(f"[SCRIPT] ì¸ë„¤ì¼ ë¬¸êµ¬: {thumbnail_text.replace(chr(10), ' / ')}")

        return {
            "title": youtube_title,
            "thumbnail_text": thumbnail_text,
            "cost": cost,
        }

    except Exception as e:
        print(f"[SCRIPT] SEO ìƒì„± ì‹¤íŒ¨: {e}")
        return {"title": title, "thumbnail_text": "", "cost": 0}


def _format_sources_for_youtube(sources: list) -> str:
    """
    YouTube ì„¤ëª…ë€ìš© ì¶œì²˜ í…ìŠ¤íŠ¸ ìƒì„±

    Returns:
        ì¶œì²˜ ëª©ë¡ (YouTube ì„¤ëª…ë€ì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥í•œ í˜•ì‹)
    """
    if not sources:
        return ""

    lines = ["ğŸ“š ì°¸ê³  ìë£Œ ë° ì¶œì²˜", ""]

    # ì¶œì²˜ë³„ ë¶„ë¥˜
    encykorea = []
    history_db = []
    cultural = []
    museum = []
    others = []

    for url in sources:
        if not url:
            continue
        url_lower = url.lower()
        if "encykorea" in url_lower:
            encykorea.append(url)
        elif "db.history.go.kr" in url_lower or "history.go.kr" in url_lower:
            history_db.append(url)
        elif "heritage.go.kr" in url_lower:
            cultural.append(url)
        elif "museum.go.kr" in url_lower:
            museum.append(url)
        else:
            others.append(url)

    # ì¹´í…Œê³ ë¦¬ë³„ ì¶œë ¥
    if encykorea:
        lines.append("â–¸ í•œêµ­ë¯¼ì¡±ë¬¸í™”ëŒ€ë°±ê³¼ì‚¬ì „")
        for url in encykorea[:3]:  # ìµœëŒ€ 3ê°œ
            lines.append(f"  {url}")
        lines.append("")

    if history_db:
        lines.append("â–¸ êµ­ì‚¬í¸ì°¬ìœ„ì›íšŒ í•œêµ­ì‚¬DB")
        for url in history_db[:3]:
            lines.append(f"  {url}")
        lines.append("")

    if cultural:
        lines.append("â–¸ ë¬¸í™”ì¬ì²­ êµ­ê°€ë¬¸í™”ìœ ì‚°í¬í„¸")
        for url in cultural[:3]:
            lines.append(f"  {url}")
        lines.append("")

    if museum:
        lines.append("â–¸ êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€")
        for url in museum[:3]:
            lines.append(f"  {url}")
        lines.append("")

    if others:
        lines.append("â–¸ ê¸°íƒ€ ìë£Œ")
        for url in others[:3]:
            lines.append(f"  {url}")
        lines.append("")

    return "\n".join(lines)


def generate_script_gpt51(
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    full_content: str,
    sources: list,
    next_episode_info: Dict[str, Any] = None,
) -> Dict[str, Any]:
    """
    GPT-5.2ë¡œ 20,000ì ëŒ€ë³¸ ìƒì„± (ì´ì „ ë²„ì „ í˜¸í™˜ìš© í•¨ìˆ˜ëª… ìœ ì§€)

    Args:
        era_name: ì‹œëŒ€ëª… (ì˜ˆ: "ì‚¼êµ­ì‹œëŒ€")
        episode: ì—í”¼ì†Œë“œ ë²ˆí˜¸
        total_episodes: ì‹œëŒ€ ì´ ì—í”¼ì†Œë“œ ìˆ˜
        title: ì—í”¼ì†Œë“œ ì œëª©
        topic: ì£¼ì œ
        full_content: ìˆ˜ì§‘ëœ ìë£Œ ì „ì²´ ë‚´ìš©
        sources: ì¶œì²˜ URL ëª©ë¡
        next_episode_info: ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´ (ì„ íƒ)

    Returns:
        {
            "script": ìƒì„±ëœ ëŒ€ë³¸,
            "length": ê¸€ììˆ˜,
            "model": ì‚¬ìš© ëª¨ë¸,
            "cost": ì˜ˆìƒ ë¹„ìš©,
            "error": ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        }
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    if not full_content or len(full_content) < 1000:
        return {"error": f"ìˆ˜ì§‘ëœ ìë£Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬: {len(full_content)}ì)"}

    # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´
    next_info_text = ""
    if next_episode_info:
        if next_episode_info.get("type") == "next_era":
            next_info_text = f"""
[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ ì‹œëŒ€: {next_episode_info.get('era_name', '')}
- ë‹¤ìŒ ì£¼ì œ: {next_episode_info.get('title', '')}
- ì˜ˆê³  ë¬¸êµ¬ ì˜ˆì‹œ: "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_episode_info.get('era_name', '')}ì˜ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
"""
        elif next_episode_info.get("type") == "next_episode":
            next_info_text = f"""
[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ í™”: {era_name} {next_episode_info.get('era_episode', episode + 1)}í™”
- ë‹¤ìŒ ì£¼ì œ: {next_episode_info.get('title', '')}
- ì˜ˆê³  ë¬¸êµ¬ ì˜ˆì‹œ: "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_episode_info.get('title', '')}ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
"""
        else:
            next_info_text = """
[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ì‹œë¦¬ì¦ˆ ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œì…ë‹ˆë‹¤.
- ì „ì²´ ì‹œë¦¬ì¦ˆë¥¼ ì •ë¦¬í•˜ë©° ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
"""

    # ì¶œì²˜ ëª©ë¡
    source_list = "\n".join([f"  - {s}" for s in sources[:10]]) if sources else "  (ì—†ìŒ)"

    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    user_prompt = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì—í”¼ì†Œë“œ ì •ë³´]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ì‹œë¦¬ì¦ˆ: í•œêµ­ì‚¬ - {era_name}
- í˜„ì¬: {episode}/{total_episodes}í™”
- ì œëª©: {title}
- ì£¼ì œ: {topic}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ìˆ˜ì§‘ëœ ìë£Œ]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{full_content}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì¶œì²˜ ëª©ë¡]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{source_list}

{next_info_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì‘ì„± ì§€ì‹œ]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ {SCRIPT_TARGET_LENGTH:,}ì ë¶„ëŸ‰ì˜ ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.
- ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
- í•™ìˆ ì  ì‹ ì¤‘í•¨ì„ ìœ ì§€í•˜ì„¸ìš”.
- ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
"""

    try:
        client = OpenAI(api_key=api_key)

        print(f"[SCRIPT] GPT-5.2 ëŒ€ë³¸ ìƒì„± ì‹œì‘...")
        print(f"[SCRIPT] ì…ë ¥ ìë£Œ: {len(full_content):,}ì")

        # GPT-5.2 Responses API í˜¸ì¶œ
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": SCRIPT_STYLE_PROMPT}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": user_prompt}]
                }
            ],
            temperature=0.7,
        )

        # ê²°ê³¼ ì¶”ì¶œ
        if getattr(response, "output_text", None):
            script = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text_chunks.append(getattr(content, "text", ""))
            script = "\n".join(text_chunks).strip()

        script_length = len(script)

        # í† í° ê³„ì‚° (í•œêµ­ì–´ ì•½ 2ì = 1í† í°)
        # GPT-5.2 ê°€ê²©: $1.75/1M input, $14/1M output
        input_tokens = (len(SCRIPT_STYLE_PROMPT) + len(user_prompt)) // 2
        output_tokens = script_length // 2
        cost = (input_tokens * 1.75 / 1_000_000) + (output_tokens * 14 / 1_000_000)

        print(f"[SCRIPT] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: {script_length:,}ì")
        print(f"[SCRIPT] ì˜ˆìƒ ë¹„ìš©: ${cost:.4f}")

        # ë¶„ëŸ‰ ì²´í¬
        if script_length < SCRIPT_MIN_LENGTH:
            print(f"[SCRIPT] âš ï¸ ë¶„ëŸ‰ ë¶€ì¡± ({script_length:,}ì < {SCRIPT_MIN_LENGTH:,}ì)")
        elif script_length > SCRIPT_MAX_LENGTH:
            print(f"[SCRIPT] âš ï¸ ë¶„ëŸ‰ ì´ˆê³¼ ({script_length:,}ì > {SCRIPT_MAX_LENGTH:,}ì)")

        return {
            "script": script,
            "length": script_length,
            "model": "gpt-5.2",
            "cost": cost,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
        }

    except Exception as e:
        print(f"[SCRIPT] GPT-5.2 í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}


def generate_script_with_retry(
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    full_content: str,
    sources: list,
    next_episode_info: Dict[str, Any] = None,
    max_retries: int = 2,
) -> Dict[str, Any]:
    """
    ëŒ€ë³¸ ìƒì„± (ë¶„ëŸ‰ ë¶€ì¡± ì‹œ ì´ì–´ì“°ê¸°)

    ë¶„ëŸ‰ì´ SCRIPT_MIN_LENGTH ë¯¸ë§Œì´ë©´ ì´ì–´ì“°ê¸° ìš”ì²­
    """
    result = generate_script_gpt51(
        era_name=era_name,
        episode=episode,
        total_episodes=total_episodes,
        title=title,
        topic=topic,
        full_content=full_content,
        sources=sources,
        next_episode_info=next_episode_info,
    )

    if "error" in result:
        return result

    script = result.get("script", "")
    total_cost = result.get("cost", 0)

    # ë¶„ëŸ‰ ë¶€ì¡± ì‹œ ì´ì–´ì“°ê¸°
    for attempt in range(max_retries):
        if len(script) >= SCRIPT_MIN_LENGTH:
            break

        print(f"[SCRIPT] ë¶„ëŸ‰ ë¶€ì¡± ({len(script):,}ì), ì´ì–´ì“°ê¸° ì‹œë„ ({attempt + 1}/{max_retries})...")

        continuation = _continue_script(
            era_name=era_name,
            episode=episode,
            title=title,
            current_script=script,
            target_length=SCRIPT_TARGET_LENGTH,
        )

        if "error" in continuation:
            print(f"[SCRIPT] ì´ì–´ì“°ê¸° ì‹¤íŒ¨: {continuation['error']}")
            break

        script += "\n\n" + continuation.get("script", "")
        total_cost += continuation.get("cost", 0)

    result["script"] = script
    result["length"] = len(script)
    result["cost"] = total_cost

    return result


def _continue_script(
    era_name: str,
    episode: int,
    title: str,
    current_script: str,
    target_length: int,
) -> Dict[str, Any]:
    """
    ëŒ€ë³¸ ì´ì–´ì“°ê¸° (ë¶„ëŸ‰ ë¶€ì¡± ì‹œ)
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY ì—†ìŒ"}

    remaining = target_length - len(current_script)

    prompt = f"""ì•„ë˜ ëŒ€ë³¸ì˜ ì´ì–´ì“°ê¸°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[í˜„ì¬ ëŒ€ë³¸ ë§ˆì§€ë§‰ ë¶€ë¶„]
{current_script[-2000:]}

[ì§€ì‹œì‚¬í•­]
- ìœ„ ëŒ€ë³¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ë‚´ìš© ì‘ì„±
- ì•½ {remaining:,}ì ë¶„ëŸ‰ ì¶”ê°€
- ê¸°ì¡´ ìŠ¤íƒ€ì¼(í•™ìˆ ì , ê°ê´€ì ) ìœ ì§€
- ë§ˆë¬´ë¦¬ + ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  í¬í•¨
"""

    try:
        client = OpenAI(api_key=api_key)

        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": "í•œêµ­ì‚¬ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ ëŒ€ë³¸ì— ì´ì–´ì„œ ì‘ì„±í•©ë‹ˆë‹¤."}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": prompt}]
                }
            ],
            temperature=0.7,
        )

        if getattr(response, "output_text", None):
            continuation = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text_chunks.append(getattr(content, "text", ""))
            continuation = "\n".join(text_chunks).strip()

        # ë¹„ìš© ê³„ì‚° (GPT-5.2 ê°€ê²©: $1.75/1M input, $14/1M output)
        input_tokens = len(prompt) // 2
        output_tokens = len(continuation) // 2
        cost = (input_tokens * 1.75 / 1_000_000) + (output_tokens * 14 / 1_000_000)

        print(f"[SCRIPT] ì´ì–´ì“°ê¸° ì™„ë£Œ: +{len(continuation):,}ì")

        return {
            "script": continuation,
            "length": len(continuation),
            "cost": cost,
        }

    except Exception as e:
        return {"error": str(e)}
