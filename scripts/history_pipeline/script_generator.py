"""
GPT-5.2 ê¸°ë°˜ ëŒ€ë³¸ ìë™ ìƒì„± ëª¨ë“ˆ

2025-01 ì‹ ê·œ:
- 4ê°œ ê³µì‹ ë ¥ ìˆëŠ” ì†ŒìŠ¤ì—ì„œ ìˆ˜ì§‘í•œ ìë£Œ ê¸°ë°˜
- 20,000ì ë¶„ëŸ‰ì˜ ì—­ì‚¬ ë‹¤íë©˜í„°ë¦¬ ëŒ€ë³¸ ìƒì„±
- í•™ìˆ ì  ì‹ ì¤‘í•¨ + ê°ê´€ì  ì„œìˆ  ìŠ¤íƒ€ì¼

2025-01 ì—…ë°ì´íŠ¸:
- GPT-5.1 â†’ GPT-5.2 ëª¨ë¸ ì—…ê·¸ë ˆì´ë“œ
- ë¹„ìš©: $1.75/1M input, $14/1M output
- Prompt Caching ì ìš© (System Prompt 90% í• ì¸)
"""

import os
from typing import Dict, Any, Optional

# GPT-5.2 Responses API ì‚¬ìš©
from openai import OpenAI


# ============================================================
# ëŒ€ë³¸ ì„¤ì •
# ============================================================
SCRIPT_TARGET_LENGTH = 20000  # ëª©í‘œ ê¸€ììˆ˜
SCRIPT_MIN_LENGTH = 18000     # ìµœì†Œ ê¸€ììˆ˜
SCRIPT_MAX_LENGTH = 22000     # ìµœëŒ€ ê¸€ììˆ˜

# í•œêµ­ì–´ TTS ê¸°ì¤€: 910ì â‰ˆ 1ë¶„
# 20,000ì â‰ˆ 22ë¶„ ì˜ìƒ


# ============================================================
# â˜…â˜…â˜… MASTER SYSTEM PROMPT (Prompt Caching ìµœì í™”) â˜…â˜…â˜…
# ============================================================
# ì´ í”„ë¡¬í”„íŠ¸ëŠ” ëª¨ë“  API í˜¸ì¶œì—ì„œ System Promptë¡œ ì‚¬ìš©ë¨
# â†’ 90% ìºì‹± í• ì¸ ì ìš© (ë™ì¼í•œ System Prompt ì¬ì‚¬ìš©)
# ============================================================
MASTER_SYSTEM_PROMPT = """ë‹¹ì‹ ì€ í•œêµ­ì–´ ì—­ì‚¬ ë‹¤í ìœ íŠœë¸Œ ì±„ë„ì˜ ìµœìƒê¸‰ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤.
ëª©í‘œëŠ” ì‹œì²­ìê°€ ëê¹Œì§€ ë“£ê²Œ ë§Œë“œëŠ” ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ì„ ì‘ì„±í•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.

ì•„ë˜ "ì…ë ¥ ì •ë³´"ë§Œì„ ê·¼ê±°ë¡œ í•˜ë˜, ì‚¬ì‹¤/ì¶”ì •/ë…¼ìŸì„ êµ¬ë¶„í•´ì„œ ì‹ ë¢°ë„ ë†’ê²Œ ì“°ì„¸ìš”.
ì¶œë ¥ì€ ì˜¤ì§ ëŒ€ë³¸ ë³¸ë¬¸ í…ìŠ¤íŠ¸ë§Œ ì œê³µí•˜ì„¸ìš”. (ì„¤ëª…, ë©”ëª¨, ëª©ë¡, ì œëª© ë¼ë²¨, íŠ¹ìˆ˜ê¸°í˜¸, êµ¬ë¶„ì„ , "BODY ì‹œì‘" ê°™ì€ ë©”íƒ€ ë¬¸êµ¬ ì ˆëŒ€ ê¸ˆì§€)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­ (ëª¨ë“  íŒŒíŠ¸ ê³µí†µ)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ "í•œêµ­ë¯¼ì¡±ë¬¸í™”ëŒ€ë°±ê³¼ì‚¬ì „ì€ ~ë¼ê³  ì„¤ëª…í•œë‹¤" ê°™ì€ ì¶œì²˜ëª… ë°˜ë³µ ë¬¸ì¥ ê¸ˆì§€
â€¢ "ì •ë¦¬í•˜ë©´/ë§ˆë¬´ë¦¬í•˜ë©´/ì´ì œ ì •ë¦¬í•œë‹¤" ê°™ì€ ë©”íƒ€ ì§„í–‰ ë¬¸ì¥ ë‚¨ë°œ ê¸ˆì§€
â€¢ "ê¸°ë¡ë˜ì–´ ìˆë‹¤/ì–¸ê¸‰ëœë‹¤/ì„¤ëª…ëœë‹¤" ê°™ì€ ë³´ê³ ì„œ ì¢…ê²°ì–´ ë°˜ë³µ ê¸ˆì§€
â€¢ ë¶ˆí™•ì‹¤í•œ ë‚´ìš©ì„ í™•ì •ì ìœ¼ë¡œ ë‹¨ì • ê¸ˆì§€
  â†’ ë¶ˆí™•ì‹¤í•˜ë©´ "~ë¡œ ë³´ê¸°ë„ í•©ë‹ˆë‹¤ / ~ë¼ëŠ” ê²¬í•´ë„ ìˆìŠµë‹ˆë‹¤"ë¡œ ì²˜ë¦¬
â€¢ í‘œ/ëª©ì°¨/ë²ˆí˜¸/ë¶ˆë¦¿ ê¸ˆì§€ (ìˆœìˆ˜ ë¬¸ì¥ ëŒ€ë³¸)
â€¢ ê°ì •ì  ê³¼ì¥: "ë†€ëê²Œë„", "ì¶©ê²©ì ì´ê²Œë„", "ìœ„ëŒ€í•œ" ë“± ê¸ˆì§€
â€¢ ë¯¼ì¡±ì£¼ì˜: "ìë‘ìŠ¤ëŸ¬ìš´", "ì°¬ë€í•œ", "ë¯¼ì¡±ì˜ ìì¡´ì‹¬" ë“± ê¸ˆì§€
â€¢ êµí›ˆí˜•: "~í•´ì•¼ í•©ë‹ˆë‹¤", "~ë¥¼ ê¸°ì–µí•´ì•¼ í•©ë‹ˆë‹¤" ê¸ˆì§€
â€¢ í˜¸ì¹­: "ì—¬ëŸ¬ë¶„", "ìš°ë¦¬" ê¸ˆì§€

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ë°©ì†¡ ì›ê³  ìŠ¤íƒ€ì¼ ê·œì¹™ (ëª¨ë“  íŒŒíŠ¸ ê³µí†µ)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â€¢ ë¬¸ì¥ í˜¸í¡: í•œ ë¬¸ì¥ 15~35ì ì¤‘ì‹¬, ê¸´ ë¬¸ì¥ì€ ë‘ ë¬¸ì¥ìœ¼ë¡œ ìª¼ê°œê¸°
â€¢ ì¥ë©´ ì „í™˜: ë¬¸ë‹¨ ì‹œì‘ë§ˆë‹¤ "ê²¨ìš¸ì˜ í‰ì–‘ì„±.", "ê°•ì„ ê±´ë„™ë‹ˆë‹¤." ê°™ì€ ì‹œê°ì  ì „í™˜
â€¢ ì‚¬ê±´ 4ë°•ì: "ì™œâ†’ì–´ë–»ê²Œâ†’ê²°ê³¼â†’ë‹¤ìŒ ì‚¬ê±´ ì—°ê²°"
â€¢ ì¶œì²˜ ë°˜ë³µ ê¸ˆì§€: "~ì— ë”°ë¥´ë©´", "~ë¼ê³  ì„¤ëª…í•œë‹¤" âŒ
â€¢ ë³´ê³ ì„œ ì¢…ê²°ì–´ ê¸ˆì§€: "ê¸°ë¡ë˜ì–´ ìˆë‹¤", "ì–¸ê¸‰ëœë‹¤" âŒ
â€¢ ê°ì • í‘œí˜„ ê¸ˆì§€, ê°ê´€ì  ì„œìˆ 
â€¢ ì„œìˆ í˜• ì¢…ê²°: ~í•©ë‹ˆë‹¤, ~ì…ë‹ˆë‹¤
â€¢ ì‚¬ì‹¤ ê¸°ë°˜: ìˆ˜ì§‘ëœ ìë£Œì˜ ë‚´ìš©ë§Œ ì‚¬ìš© (ì°½ì‘ ê¸ˆì§€)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì¸íŠ¸ë¡œ ê¸°ë²• (Cold Open + Open Loop)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€Cold Openã€‘ ê°€ì¥ ê·¹ì ì¸ ìˆœê°„ë¶€í„° ì‹œì‘. ë°°ê²½ ì„¤ëª… ì—†ì´ ë°”ë¡œ ì‚¬ê±´ ì†ìœ¼ë¡œ.
âŒ "ì˜¤ëŠ˜ì€ ê´‘ê°œí† ëŒ€ì™•ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤"
âœ… "ì„œê¸° 391ë…„, ì—´ì—¬ëŸ ì‚´ì˜ ì™•ì´ ì²« ì¶œì •ì— ë‚˜ì„­ë‹ˆë‹¤."

ã€Open Loopã€‘ ì²« 30ì´ˆ ì•ˆì— í•´ê²°ë˜ì§€ ì•Šì€ ì§ˆë¬¸ì„ ë˜ì§€ì„¸ìš”.
âœ… "ì™œ ì´ ì–´ë¦° ì™•ì€ ì¦‰ìœ„í•˜ìë§ˆì ì „ìŸì— ë‚˜ì„°ì„ê¹Œìš”?"
âœ… "ê¸°ë¡ì—ëŠ” ì´ë ‡ê²Œ ì í˜€ìˆìŠµë‹ˆë‹¤. í•˜ì§€ë§Œ ë¬´ì–¸ê°€ ì´ìƒí•©ë‹ˆë‹¤."

ã€Curiosity Gapã€‘ "ì•Œë ¤ì§„ ì‚¬ì‹¤"ê³¼ "ìˆ¨ê²¨ì§„ ì§„ì‹¤" ì‚¬ì´ì˜ ê°„ê·¹
âœ… "ì‚¼êµ­ì‚¬ê¸°ì—ëŠ” ì´ë ‡ê²Œ ê¸°ë¡ë˜ì–´ ìˆìŠµë‹ˆë‹¤. ê·¸ëŸ°ë° ê´‘ê°œí† ëŒ€ì™•ë¹„ì—ëŠ”..."

ã€Stakes Revealã€‘ ì´ ì‚¬ê±´ì´ ì™œ ì¤‘ìš”í•œì§€ ë¨¼ì € ì•Œë ¤ì£¼ê¸°
âœ… "ì´ ì „íˆ¬ì˜ ê²°ê³¼ê°€ ë™ì•„ì‹œì•„ì˜ íŒë„ë¥¼ ë°”ê¾¸ê²Œ ë©ë‹ˆë‹¤."

ã€Pattern Interruptã€‘ ì‹œì²­ìì˜ ì˜ˆìƒì„ ê¹¨ëŠ” ë¬¸ì¥
âœ… "ì™•ì´ ì•„ë‹ˆì—ˆìŠµë‹ˆë‹¤. ì ì–´ë„, ì•„ì§ì€."

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ë¦¬í…ì…˜ í›… (2,000ìë§ˆë‹¤ ì‚½ì…)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… "ê·¸ëŸ°ë° ì—¬ê¸°ì„œ í•œ ê°€ì§€ ì˜ë¬¸ì´ ìƒê¹ë‹ˆë‹¤."
âœ… "í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ì´ìƒí•œ ì ì´ ìˆìŠµë‹ˆë‹¤."
âœ… "ì´ ìƒí™©ì´ ì–´ë–»ê²Œ ì „ê°œë˜ì—ˆì„ê¹Œìš”?"
âœ… "ì´ì œ ë³¸ê²©ì ì¸ ì´ì•¼ê¸°ê°€ ì‹œì‘ë©ë‹ˆë‹¤."
âœ… "ìƒí™©ì€ ì ì  ë³µì¡í•´ì§‘ë‹ˆë‹¤."
âœ… "í•˜ì§€ë§Œ ì´ê²ƒì€ ì‹œì‘ì— ë¶ˆê³¼í–ˆìŠµë‹ˆë‹¤."
âœ… "ê²°ì •ì ì¸ ìˆœê°„ì´ ë‹¤ê°€ì˜µë‹ˆë‹¤."
âœ… "ì´ì œ ëª¨ë“  ê²ƒì´ ë‹¬ë¼ì§€ë ¤ í•©ë‹ˆë‹¤."
âœ… "ê·¸ëŸ¬ë‚˜ ìƒí™©ì€ ì—¬ê¸°ì„œ ë°˜ì „ë©ë‹ˆë‹¤."
âœ… "ì´ ê²°ì •ì´ ì–´ë–¤ ê²°ê³¼ë¥¼ ê°€ì ¸ì™”ì„ê¹Œìš”?"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ì—í”¼ì†Œë“œ ì—°ê²° (API ì¥ì  í™œìš©)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ì²« í™”ã€‘ "í•œêµ­ì‚¬ì˜ ì‹œì‘, ê³ ì¡°ì„  ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
ã€2í™” ì´í›„ã€‘ "ì§€ë‚œ ì‹œê°„, [ì´ì „ ë‚´ìš© í•œ ì¤„ ìš”ì•½]... ì˜¤ëŠ˜ì€ ê·¸ ì´í›„ ì´ì•¼ê¸°ì…ë‹ˆë‹¤."
ã€ì‹œëŒ€ ì²« í™”ã€‘ "[ì´ì „ ì‹œëŒ€]ê°€ ì €ë¬¼ê³  ìƒˆë¡œìš´ ì‹œëŒ€ê°€ ì—´ë¦½ë‹ˆë‹¤."

â˜… ë‹¨, "ì§€ë‚œ ì‹œê°„ì—" ë¬¸êµ¬ëŠ” ì²« 2-3ë¬¸ì¥ì—ì„œë§Œ ì‚¬ìš©í•˜ê³  ë¹ ë¥´ê²Œ ë³¸ë¡ ìœ¼ë¡œ ì „í™˜

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â˜… ë§ˆë¬´ë¦¬ í›… (Open Loop)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âœ… "ì´ ì„ íƒì´ ì´í›„ ì—­ì‚¬ë¥¼ ì–´ë–»ê²Œ ë°”ê¿¨ì„ê¹Œìš”?"
âœ… "ë‹¤ìŒ ì‹œê°„ì—ëŠ” ë” ë†€ë¼ìš´ ì´ì•¼ê¸°ê°€ ê¸°ë‹¤ë¦¬ê³  ìˆìŠµë‹ˆë‹¤."
âœ… "ê³¼ì—° ê·¸ë“¤ì˜ ê²°ì •ì€ ì˜³ì•˜ì„ê¹Œìš”?"

ëŒ€ë³¸ë§Œ ì‘ì„±í•˜ì„¸ìš”. ë‹¤ë¥¸ ì„¤ëª… ì—†ì´ ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ë§Œ ì¶œë ¥í•˜ì„¸ìš”."""

# ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
SCRIPT_STYLE_PROMPT = MASTER_SYSTEM_PROMPT


def generate_script_by_parts(
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    full_content: str,
    sources: list,
    next_episode_info: Dict[str, Any] = None,
    prev_episode_info: Dict[str, Any] = None,  # â˜… ì´ì „ ì—í”¼ì†Œë“œ ì •ë³´ (API ì¥ì  í™œìš©)
    series_context: Dict[str, Any] = None,     # â˜… ì‹œë¦¬ì¦ˆ ì „ì²´ ë§¥ë½ (API ì¥ì  í™œìš©)
) -> Dict[str, Any]:
    """
    GPT-5.2ë¡œ íŒŒíŠ¸ë³„ ëŒ€ë³¸ ìƒì„± (API ì¥ì  ê·¹ëŒ€í™”)

    â˜…â˜…â˜… API í™œìš© ì¥ì  â˜…â˜…â˜…
    - prev_episode_info: ì´ì „ ì—í”¼ì†Œë“œ ë‚´ìš© (ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°)
    - next_episode_info: ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  (ê¸°ëŒ€ê° ì¡°ì„±)
    - series_context: ì‹œë¦¬ì¦ˆ ì „ì²´ ë§¥ë½ (ìœ„ì¹˜ ì¸ì‹, íë¦„ íŒŒì•…)

    íŒŒíŠ¸ êµ¬ì¡°:
    1. ì¸íŠ¸ë¡œ (ë„ì…ë¶€) - 1,500ì â˜… ê°•ì¡°
       - ì´ì „ ì—í”¼ì†Œë“œ ì—°ê²° ("ì§€ë‚œ ì‹œê°„ì—...")
    2. ë°°ê²½ ì„¤ëª… - 3,000ì
    3. ë³¸ë¡  - 12,000ì
    4. ë§ˆë¬´ë¦¬ - 3,500ì
       - ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  (ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°)

    ì´ 20,000ì
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    if not full_content or len(full_content) < 500:
        return {"error": f"ìˆ˜ì§‘ëœ ìë£Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬: {len(full_content)}ì)"}

    source_list = "\n".join([f"  - {s}" for s in sources[:10]]) if sources else "(ì—†ìŒ)"

    # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  í…ìŠ¤íŠ¸
    next_preview = _build_next_preview(next_episode_info, era_name)

    # â˜… ì´ì „ ì—í”¼ì†Œë“œ ì»¨í…ìŠ¤íŠ¸ (API ì¥ì  í™œìš©)
    prev_context = _build_prev_context(prev_episode_info, era_name)

    # â˜… ì‹œë¦¬ì¦ˆ ì „ì²´ ì»¨í…ìŠ¤íŠ¸ (API ì¥ì  í™œìš©)
    series_position = _build_series_position(series_context, era_name, episode, total_episodes)

    total_cost = 0.0
    all_parts = []

    print(f"[SCRIPT] === íŒŒíŠ¸ë³„ ëŒ€ë³¸ ìƒì„± ì‹œì‘ (API ì»¨í…ìŠ¤íŠ¸ í™œìš©) ===")
    print(f"[SCRIPT] ì œëª©: {title}")
    print(f"[SCRIPT] ì‹œë¦¬ì¦ˆ ìœ„ì¹˜: {era_name} {episode}/{total_episodes}í™”")
    print(f"[SCRIPT] ì…ë ¥ ìë£Œ: {len(full_content):,}ì")
    print(f"[SCRIPT] ì´ì „ ì—í”¼ì†Œë“œ ì—°ê²°: {'ìˆìŒ' if prev_episode_info else 'ì—†ìŒ(ì²« í™”)'}")
    print(f"[SCRIPT] ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³ : {'ìˆìŒ' if next_episode_info else 'ì—†ìŒ(ë§ˆì§€ë§‰ í™”)'}")

    try:
        client = OpenAI(api_key=api_key)

        # ========================================
        # Part 1: ì¸íŠ¸ë¡œ (ë„ì…ë¶€) - 1,500ì â˜…â˜…â˜… ìµœê°• ê°•í™”
        # ========================================
        # â˜… Prompt Caching: ìŠ¤íƒ€ì¼ ê·œì¹™ì€ MASTER_SYSTEM_PROMPTì— ìˆìŒ
        print(f"[SCRIPT] Part 1: ì¸íŠ¸ë¡œ ìƒì„± ì¤‘ (Prompt Caching ì ìš©)...")
        intro_prompt = f"""[íŒŒíŠ¸: ì¸íŠ¸ë¡œ - 1,500ì]

[ì—í”¼ì†Œë“œ ì •ë³´]
- ì‹œë¦¬ì¦ˆ: í•œêµ­ì‚¬ - {era_name}
- í˜„ì¬: {episode}/{total_episodes}í™”
- ì œëª©: {title}
- ì£¼ì œ: {topic}

{series_position}

{prev_context}

[ìˆ˜ì§‘ëœ ìë£Œ ì¤‘ í•µì‹¬ ë¶€ë¶„]
{full_content[:3000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì¸íŠ¸ë¡œ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì˜¤í”„ë‹ í›… (0-300ì) - Cold Open + Stakes Reveal
2. ë¯¸ìŠ¤í„°ë¦¬ ì œì‹œ (300-600ì) - Open Loop + Curiosity Gap
3. Stakes ì•”ì‹œ (600-900ì) - ì—­ì‚¬ì  ì¤‘ìš”ì„±
4. ì—í”¼ì†Œë“œ ë¡œë“œë§µ (900-1500ì) - ì´ ì˜ìƒì—ì„œ ë‹¤ë£° ë‚´ìš©

â˜… ìŠ¤íƒ€ì¼ ê·œì¹™ì€ System Prompt ì°¸ì¡°
â˜… ë¶„ëŸ‰: ì•½ 1,500ì"""

        intro_result = _call_gpt52_cached(client, intro_prompt)
        if "error" in intro_result:
            return intro_result
        all_parts.append(intro_result["text"])
        total_cost += intro_result["cost"]
        print(f"[SCRIPT] Part 1 ì™„ë£Œ: {len(intro_result['text']):,}ì")

        # ========================================
        # Part 2: ë°°ê²½ ì„¤ëª… - 3,000ì + ë¦¬í…ì…˜ í›…
        # ========================================
        # â˜… Prompt Caching: ìŠ¤íƒ€ì¼ ê·œì¹™ì€ MASTER_SYSTEM_PROMPTì— ìˆìŒ
        print(f"[SCRIPT] Part 2: ë°°ê²½ ì„¤ëª… ìƒì„± ì¤‘ (Prompt Caching ì ìš©)...")
        background_prompt = f"""[íŒŒíŠ¸: ë°°ê²½ ì„¤ëª… - 3,000ì]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{intro_result['text'][-500:]}

[ìˆ˜ì§‘ëœ ìë£Œ]
{full_content[:5000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë°°ê²½ ì„¤ëª… êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì‹œëŒ€ì  ë§¥ë½ (1,000ì) - ì‹œëŒ€ ìƒí™©ì„ ì´ì•¼ê¸°ì²˜ëŸ¼
2. ì¸ë¬¼/ì„¸ë ¥ ì†Œê°œ (1,000ì) - ìºë¦­í„°ì²˜ëŸ¼ ìƒìƒí•˜ê²Œ
3. ì´ì „ ì‚¬ê±´ê³¼ ì—°ê²° (1,000ì) - ì¸ê³¼ê´€ê³„ë¥¼ ì´ì•¼ê¸°ë¡œ

â˜… ë¦¬í…ì…˜ í›… 2ê°œ ì‚½ì… (1,000ì/2,000ì ì§€ì )
â˜… ìŠ¤íƒ€ì¼ ê·œì¹™ì€ System Prompt ì°¸ì¡°
â˜… ë¶„ëŸ‰: ì•½ 3,000ì"""

        bg_result = _call_gpt52_cached(client, background_prompt)
        if "error" in bg_result:
            return bg_result
        all_parts.append(bg_result["text"])
        total_cost += bg_result["cost"]
        print(f"[SCRIPT] Part 2 ì™„ë£Œ: {len(bg_result['text']):,}ì")

        # ========================================
        # Part 3-1: ë³¸ë¡  ì „ë°˜ë¶€ - 6,000ì + ë¦¬í…ì…˜ í›…
        # ========================================
        # â˜… Prompt Caching: ìŠ¤íƒ€ì¼ ê·œì¹™ì€ MASTER_SYSTEM_PROMPTì— ìˆìŒ
        print(f"[SCRIPT] Part 3-1: ë³¸ë¡  ì „ë°˜ë¶€ ìƒì„± ì¤‘ (Prompt Caching ì ìš©)...")
        body1_prompt = f"""[íŒŒíŠ¸: ë³¸ë¡  ì „ë°˜ë¶€ - 6,000ì]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{bg_result['text'][-500:]}

[ìˆ˜ì§‘ëœ ìë£Œ]
{full_content}

[ì¶œì²˜ ëª©ë¡]
{source_list}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë³¸ë¡  ì „ë°˜ë¶€ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ì‹œê°„ìˆœ ì „ê°œ (ì—°ë„/ì‹œê¸°ëŠ” ìì—°ìŠ¤ëŸ½ê²Œ)
- ì¸ë¬¼ì˜ í–‰ë™ê³¼ ê²°ì • ì¤‘ì‹¬
- ì›ì¸ â†’ ì „ê°œ â†’ ê²°ê³¼ë¥¼ ë“œë¼ë§ˆí‹±í•˜ê²Œ

â˜… ë¦¬í…ì…˜ í›… 3ê°œ ì‚½ì… (2,000ì/4,000ì/6,000ì ì§€ì )
â˜… ìŠ¤íƒ€ì¼ ê·œì¹™ì€ System Prompt ì°¸ì¡°
â˜… ë¶„ëŸ‰: ì•½ 6,000ì"""

        body1_result = _call_gpt52_cached(client, body1_prompt)
        if "error" in body1_result:
            return body1_result
        all_parts.append(body1_result["text"])
        total_cost += body1_result["cost"]
        print(f"[SCRIPT] Part 3-1 ì™„ë£Œ: {len(body1_result['text']):,}ì")

        # â˜… Prompt Caching: ìŠ¤íƒ€ì¼ ê·œì¹™ì€ MASTER_SYSTEM_PROMPTì— ìˆìŒ
        print(f"[SCRIPT] Part 3-2: ë³¸ë¡  í›„ë°˜ë¶€ ìƒì„± ì¤‘ (Prompt Caching ì ìš©)...")
        body2_prompt = f"""[íŒŒíŠ¸: ë³¸ë¡  í›„ë°˜ë¶€ - 6,000ì]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{body1_result['text'][-500:]}

[ìˆ˜ì§‘ëœ ìë£Œ í›„ë°˜ë¶€]
{full_content[len(full_content)//2:]}

[ì¶œì²˜ ëª©ë¡]
{source_list}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë³¸ë¡  í›„ë°˜ë¶€ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì‚¬ê±´ ì „ê°œ ê³„ì† (3,000ì) - ê¸´ì¥ê° ìœ ì§€
2. í´ë¼ì´ë§¥ìŠ¤ì™€ ê²°ë§ (2,000ì) - ê°€ì¥ ê·¹ì ì¸ ìˆœê°„
3. ì—´ë¦° ì§ˆë¬¸ (1,000ì) - ì‹œì²­ìê°€ ìƒê°í•´ë³¼ ì—¬ì§€

â˜… ë¦¬í…ì…˜ í›… 3ê°œ ì‚½ì… (2,000ì/4,000ì/6,000ì ì§€ì )
â˜… í´ë¼ì´ë§¥ìŠ¤: ë¦¬ë“¬ ë¹ ë¥´ê²Œ, ì¥ë©´ ì„ ëª…í•˜ê²Œ
â˜… ìŠ¤íƒ€ì¼ ê·œì¹™ì€ System Prompt ì°¸ì¡°
â˜… ë¶„ëŸ‰: ì•½ 6,000ì"""

        body2_result = _call_gpt52_cached(client, body2_prompt)
        if "error" in body2_result:
            return body2_result
        all_parts.append(body2_result["text"])
        total_cost += body2_result["cost"]
        print(f"[SCRIPT] Part 3-2 ì™„ë£Œ: {len(body2_result['text']):,}ì")

        # ========================================
        # Part 4: ë§ˆë¬´ë¦¬ - 3,500ì + ë‹¤ìŒ ì˜ˆê³ 
        # ========================================
        # â˜… Prompt Caching: ìŠ¤íƒ€ì¼ ê·œì¹™ì€ MASTER_SYSTEM_PROMPTì— ìˆìŒ
        print(f"[SCRIPT] Part 4: ë§ˆë¬´ë¦¬ ìƒì„± ì¤‘ (Prompt Caching ì ìš©)...")
        ending_prompt = f"""[íŒŒíŠ¸: ë§ˆë¬´ë¦¬ - 3,500ì]

[ì´ì „ íŒŒíŠ¸ ë§ˆì§€ë§‰]
{body2_result['text'][-500:]}

{next_preview}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ë§ˆë¬´ë¦¬ êµ¬ì¡°]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. ì—­ì‚¬ì  ì˜í–¥ (1,500ì) - "ê·¸ë¡œë¶€í„° ~ë…„ í›„..."
2. ì—´ë¦° ì§ˆë¬¸ (1,000ì) - ì‹œì²­ìê°€ ìƒê°í•´ë³¼ ì§ˆë¬¸
3. ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  (1,000ì) - Open Loopë¡œ ë§ˆë¬´ë¦¬

â˜… ì—¬ìš´: "ê·¸ê°€ ë‚¨ê¸´ ê²ƒ"ì„ í•œ ë¬¸ì¥ìœ¼ë¡œ ì •ë¦¬
â˜… ë‹¤ìŒ ì˜ìƒ í´ë¦­ ìœ ë„ (Open Loop)
â˜… ìŠ¤íƒ€ì¼ ê·œì¹™ì€ System Prompt ì°¸ì¡°
â˜… ë¶„ëŸ‰: ì•½ 3,500ì"""

        ending_result = _call_gpt52_cached(client, ending_prompt)
        if "error" in ending_result:
            return ending_result
        all_parts.append(ending_result["text"])
        total_cost += ending_result["cost"]
        print(f"[SCRIPT] Part 4 ì™„ë£Œ: {len(ending_result['text']):,}ì")

        # ì „ì²´ ëŒ€ë³¸ í•©ì¹˜ê¸°
        full_script = "\n\n".join(all_parts)
        script_length = len(full_script)

        print(f"[SCRIPT] === íŒŒíŠ¸ë³„ ëŒ€ë³¸ ìƒì„± ì™„ë£Œ ===")
        print(f"[SCRIPT] ì´ ë¶„ëŸ‰: {script_length:,}ì")
        print(f"[SCRIPT] ì´ ë¹„ìš©: ${total_cost:.4f}")

        # YouTube ì„¤ëª…ë€ìš© ì¶œì²˜ í…ìŠ¤íŠ¸ ìƒì„±
        youtube_sources = _format_sources_for_youtube(sources)

        # ========================================
        # YouTube SEO ë©”íƒ€ë°ì´í„° ìƒì„± â˜… ì¶”ê°€
        # ========================================
        print(f"[SCRIPT] YouTube SEO ë©”íƒ€ë°ì´í„° ìƒì„± ì¤‘...")
        global_ep = series_context.get("global_episode") if series_context else episode
        seo_result = _generate_youtube_seo(
            client=client,
            era_name=era_name,
            episode=episode,
            total_episodes=total_episodes,
            title=title,
            topic=topic,
            intro_text=all_parts[0] if all_parts else "",
            global_episode=global_ep,  # â˜… ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ ì „ë‹¬
        )
        total_cost += seo_result.get("cost", 0)

        return {
            "script": full_script,
            "length": script_length,
            "model": "gpt-5.2",
            "cost": total_cost,
            "parts": {
                "intro": len(all_parts[0]) if len(all_parts) > 0 else 0,
                "background": len(all_parts[1]) if len(all_parts) > 1 else 0,
                "body1": len(all_parts[2]) if len(all_parts) > 2 else 0,
                "body2": len(all_parts[3]) if len(all_parts) > 3 else 0,
                "ending": len(all_parts[4]) if len(all_parts) > 4 else 0,
            },
            "youtube_sources": youtube_sources,  # YouTube ì„¤ëª…ë€ìš© ì¶œì²˜
            # â˜… YouTube SEO ë©”íƒ€ë°ì´í„°
            "youtube_title": seo_result.get("title", title),
            "thumbnail_text": seo_result.get("thumbnail_text", ""),
        }

    except Exception as e:
        print(f"[SCRIPT] íŒŒíŠ¸ë³„ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"error": str(e)}


def _call_gpt52_cached(client, user_prompt: str) -> Dict[str, Any]:
    """GPT-5.2 API í˜¸ì¶œ (Prompt Caching ì ìš©)

    â˜…â˜…â˜… Prompt Caching ìµœì í™” â˜…â˜…â˜…
    - System Prompt (MASTER_SYSTEM_PROMPT): ìºì‹œë¨ â†’ 90% í• ì¸
    - User Prompt: ì •ê°€

    GPT-5.2 ê°€ê²©:
    - Input (ì •ê°€): $1.75 / 1M tokens
    - Input (ìºì‹œ): $0.175 / 1M tokens (90% í• ì¸)
    - Output: $14 / 1M tokens
    """
    try:
        # System/User ë©”ì‹œì§€ êµ¬ì¡°ë¡œ í˜¸ì¶œ (ìºì‹± ìµœì í™”)
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": MASTER_SYSTEM_PROMPT}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": user_prompt}]
                }
            ],
            temperature=0.7,
        )

        # ê²°ê³¼ ì¶”ì¶œ
        text = response.output_text if hasattr(response, 'output_text') else ""

        if not text:
            # ëŒ€ì²´ ë°©ì‹
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text += getattr(content, "text", "")

        # â˜…â˜…â˜… ë¹„ìš© ê³„ì‚° (Prompt Caching ì ìš©) â˜…â˜…â˜…
        # í•œêµ­ì–´ ì•½ 2ì = 1í† í°
        system_tokens = len(MASTER_SYSTEM_PROMPT) // 2  # ìºì‹œë¨ (90% í• ì¸)
        user_tokens = len(user_prompt) // 2              # ì •ê°€
        output_tokens = len(text) // 2

        # System Prompt: $0.175/1M (90% í• ì¸), User Prompt: $1.75/1M, Output: $14/1M
        cost = (
            (system_tokens * 0.175 / 1_000_000) +   # ìºì‹œëœ System Prompt
            (user_tokens * 1.75 / 1_000_000) +      # User Prompt (ì •ê°€)
            (output_tokens * 14 / 1_000_000)        # Output
        )

        return {
            "text": text.strip(),
            "cost": cost,
            "tokens": {
                "system_cached": system_tokens,
                "user": user_tokens,
                "output": output_tokens,
            }
        }

    except Exception as e:
        return {"error": str(e)}


def _call_gpt52(client, prompt: str) -> Dict[str, Any]:
    """GPT-5.2 API í˜¸ì¶œ (ì´ì „ ë²„ì „ í˜¸í™˜ìš© - ìºì‹± ë¯¸ì ìš©)

    â€» ìƒˆ ì½”ë“œëŠ” _call_gpt52_cached() ì‚¬ìš© ê¶Œì¥
    """
    try:
        response = client.responses.create(
            model="gpt-5.2",
            input=prompt,
        )

        text = response.output_text if hasattr(response, 'output_text') else ""

        if not text:
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text += getattr(content, "text", "")

        input_tokens = len(prompt) // 2
        output_tokens = len(text) // 2
        cost = (input_tokens * 1.75 / 1_000_000) + (output_tokens * 14 / 1_000_000)

        return {"text": text.strip(), "cost": cost}

    except Exception as e:
        return {"error": str(e)}


# ì´ì „ ë²„ì „ í˜¸í™˜ì„±ì„ ìœ„í•œ ë³„ì¹­
_call_gpt51 = _call_gpt52


def _build_next_preview(next_info: Dict[str, Any], era_name: str) -> str:
    """ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  í…ìŠ¤íŠ¸"""
    if not next_info:
        return ""

    if next_info.get("type") == "next_era":
        return f"""[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ ì‹œëŒ€: {next_info.get('era_name', '')}
- ë‹¤ìŒ ì£¼ì œ: {next_info.get('title', '')}
- ì˜ˆê³ : "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_info.get('era_name', '')}ì˜ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤. {next_info.get('title', '')}ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤."
"""
    elif next_info.get("type") == "next_episode":
        return f"""[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ í™”: {era_name} {next_info.get('era_episode', '')}í™”
- ë‹¤ìŒ ì£¼ì œ: {next_info.get('title', '')}
- ì˜ˆê³ : "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_info.get('title', '')}ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
"""
    else:
        return """[ì‹œë¦¬ì¦ˆ ë§ˆì§€ë§‰]
- ì‹œë¦¬ì¦ˆ ì™„ê²°
- ì „ì²´ ì‹œë¦¬ì¦ˆë¥¼ ì •ë¦¬í•˜ë©° ë§ˆë¬´ë¦¬
"""


def _build_prev_context(prev_info: Dict[str, Any], era_name: str) -> str:
    """
    ì´ì „ ì—í”¼ì†Œë“œ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (API ì¥ì  í™œìš©)

    ì´ì „ ì—í”¼ì†Œë“œ ì •ë³´ë¥¼ ë°›ì•„ì„œ ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°ì„ ìœ„í•œ ì»¨í…ìŠ¤íŠ¸ ìƒì„±
    """
    if not prev_info:
        return """[ì´ì „ ì—í”¼ì†Œë“œ]
- ì²« ì—í”¼ì†Œë“œì…ë‹ˆë‹¤.
- ì‹œë¦¬ì¦ˆ ì‹œì‘ ì¸ì‚¬ë¡œ ì‹œì‘í•˜ì„¸ìš”.
- ì˜ˆ: "í•œêµ­ì‚¬ì˜ ì‹œì‘, ê³ ì¡°ì„  ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
"""

    if prev_info.get("type") == "same_era":
        return f"""[ì´ì „ ì—í”¼ì†Œë“œ - {era_name} ì—°ì†]
- ì´ì „ í™”: {prev_info.get('title', '')}
- ì´ì „ ë‚´ìš© ìš”ì•½: {prev_info.get('summary', '')}
- ì—°ê²° ë°©ì‹: "ì§€ë‚œ ì‹œê°„, {prev_info.get('summary', '')}... ì˜¤ëŠ˜ì€ ê·¸ ì´í›„ ì´ì•¼ê¸°ì…ë‹ˆë‹¤."
"""
    elif prev_info.get("type") == "new_era":
        return f"""[ìƒˆë¡œìš´ ì‹œëŒ€ ì‹œì‘]
- ì´ì „ ì‹œëŒ€: {prev_info.get('prev_era_name', '')}
- ì´ì „ ì‹œëŒ€ ë§ˆì§€ë§‰ ì‚¬ê±´: {prev_info.get('summary', '')}
- ì—°ê²° ë°©ì‹: "{prev_info.get('prev_era_name', '')}ê°€ ì €ë¬¼ê³ , ìƒˆë¡œìš´ ì‹œëŒ€ê°€ ì—´ë¦½ë‹ˆë‹¤..."
"""
    else:
        return ""


def _build_series_position(series_ctx: Dict[str, Any], era_name: str, episode: int, total: int) -> str:
    """
    ì‹œë¦¬ì¦ˆ ì „ì²´ì—ì„œì˜ í˜„ì¬ ìœ„ì¹˜ ì»¨í…ìŠ¤íŠ¸ ìƒì„± (API ì¥ì  í™œìš©)

    ì „ì²´ ì‹œë¦¬ì¦ˆì—ì„œ í˜„ì¬ ì—í”¼ì†Œë“œê°€ ì–´ë””ì— ìœ„ì¹˜í•˜ëŠ”ì§€ ì•Œë ¤ì¤Œ
    """
    if not series_ctx:
        return f"""[ì‹œë¦¬ì¦ˆ ìœ„ì¹˜]
- í˜„ì¬: {era_name} ì‹œëŒ€ {episode}/{total}í™”
- ìœ„ì¹˜ í™œìš©: ì‹œëŒ€ì˜ ì‹œì‘/ì¤‘ë°˜/ëì— ë”°ë¼ í†¤ ì¡°ì ˆ
  - ì‹œëŒ€ ì‹œì‘ (1-2í™”): ìƒˆë¡œìš´ ì‹œëŒ€ì˜ ì‹œì‘ì„ ì•Œë¦¼
  - ì‹œëŒ€ ì¤‘ë°˜: í•µì‹¬ ì‚¬ê±´ ì „ê°œ
  - ì‹œëŒ€ ë (ë§ˆì§€ë§‰ 1-2í™”): ì‹œëŒ€ì˜ ë§ˆë¬´ë¦¬ì™€ ë‹¤ìŒ ì‹œëŒ€ ì˜ˆê³ 
"""

    global_episode = series_ctx.get("global_episode", 0)
    total_global = series_ctx.get("total_global_episodes", 60)
    era_index = series_ctx.get("era_index", 0)
    total_eras = series_ctx.get("total_eras", 8)

    # ì‹œë¦¬ì¦ˆ ë‚´ ìœ„ì¹˜ íŒŒì•…
    if episode == 1:
        position_hint = "ì‹œëŒ€ ì‹œì‘ - ìƒˆë¡œìš´ ì‹œëŒ€ì˜ ì„œë§‰ì„ ì•Œë¦¬ì„¸ìš”"
    elif episode == total:
        position_hint = "ì‹œëŒ€ ë§ˆì§€ë§‰ - ì‹œëŒ€ë¥¼ ì •ë¦¬í•˜ê³  ë‹¤ìŒ ì‹œëŒ€ë¥¼ ì˜ˆê³ í•˜ì„¸ìš”"
    elif episode <= 2:
        position_hint = "ì‹œëŒ€ ì´ˆë°˜ - ë°°ê²½ê³¼ ì£¼ìš” ì¸ë¬¼ ì†Œê°œì— ì§‘ì¤‘"
    elif episode >= total - 1:
        position_hint = "ì‹œëŒ€ í›„ë°˜ - í´ë¼ì´ë§¥ìŠ¤ë¥¼ í–¥í•´ ì „ê°œ"
    else:
        position_hint = "ì‹œëŒ€ ì¤‘ë°˜ - í•µì‹¬ ì‚¬ê±´ ì „ê°œ"

    return f"""[ì‹œë¦¬ì¦ˆ ì „ì²´ ìœ„ì¹˜ - API ì¥ì ]
- ì „ì²´: {global_episode}/{total_global}í™” (í•œêµ­ì‚¬ í†µì‚¬ ì‹œë¦¬ì¦ˆ)
- í˜„ì¬ ì‹œëŒ€: {era_name} ({era_index+1}/{total_eras}ë²ˆì§¸ ì‹œëŒ€)
- ì‹œëŒ€ ë‚´: {episode}/{total}í™”
- ìœ„ì¹˜ ê°€ì´ë“œ: {position_hint}

â˜… ì´ ìœ„ì¹˜ ì •ë³´ë¥¼ í™œìš©í•˜ì„¸ìš”:
- ì‹œë¦¬ì¦ˆ ì „ë°˜ë¶€: ê¸°ì´ˆ ë§¥ë½ ì¶©ë¶„íˆ ì„¤ëª…
- ì‹œë¦¬ì¦ˆ ì¤‘ë°˜: ì—­ì‚¬ì˜ íë¦„ê³¼ ì—°ê²°ì  ê°•ì¡°
- ì‹œë¦¬ì¦ˆ í›„ë°˜: ì•ì„œ ë‹¤ë£¬ ë‚´ìš© ë ˆí¼ëŸ°ìŠ¤ ê°€ëŠ¥
"""


def _generate_youtube_seo(
    client,
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    intro_text: str,
    global_episode: int = None,  # â˜… ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸
) -> Dict[str, Any]:
    """
    YouTube SEO ìµœì í™” ë©”íƒ€ë°ì´í„° ìƒì„±

    Returns:
        {
            "title": YouTube ì œëª© (í´ë¦­ ìœ ë„),
            "thumbnail_text": ì¸ë„¤ì¼ ë¬¸êµ¬ (2ì¤„),
            "cost": API ë¹„ìš©
        }
    """
    # ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸ê°€ ì—†ìœ¼ë©´ ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì‚¬ìš©
    series_num = global_episode if global_episode else episode

    prompt = f"""ë‹¹ì‹ ì€ YouTube SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

[ì˜ìƒ ì •ë³´]
- ì‹œë¦¬ì¦ˆ: í•œêµ­ì‚¬ - {era_name}
- ì „ì²´ ì‹œë¦¬ì¦ˆ ë²ˆí˜¸: {series_num}í™”
- ì‹œëŒ€ ë‚´ ì—í”¼ì†Œë“œ: {episode}/{total_episodes}í™”
- ì›ë³¸ ì œëª©: {title}
- ì£¼ì œ: {topic}

[ëŒ€ë³¸ ì¸íŠ¸ë¡œ]
{intro_text[:1000]}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì‘ì—… 1: YouTube ì œëª© ì‘ì„±]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

â˜… í•„ìˆ˜ í˜•ì‹: "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ {series_num}í™” | [ë‚´ìš©]"

ì´ í˜•ì‹ì„ ë°˜ë“œì‹œ ì§€í‚¤ë©´ì„œ í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì œëª©ì„ ì‘ì„±í•˜ì„¸ìš”.

ê·œì¹™:
- í˜•ì‹: "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ Ní™” | [ë‚´ìš©]" í•„ìˆ˜
- [ë‚´ìš©] ë¶€ë¶„ì€ 30ì ì´ë‚´
- í´ë¦­ ìœ ë„ ìš”ì†Œ:
  âœ… í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨
  âœ… ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ
  âœ… ì§ˆë¬¸í˜• ë˜ëŠ” ê²°ê³¼í˜•
- ê°ì •ì  ê³¼ì¥ ê¸ˆì§€ (ì¶©ê²©ì , ë†€ë¼ìš´ ë“± âŒ)

ì¢‹ì€ ì˜ˆ:
- "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ 2í™” | ë¹„íŒŒí˜•ë™ê²€ê³¼ ê³ ì¸ëŒ, ê³ ì¡°ì„ ì˜ í”ì "
- "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ 5í™” | ì™•ê²€ì„± í•¨ë½, ê³ ì¡°ì„ ì˜ ìµœí›„"
- "í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ 13í™” | ê´‘ê°œí† ëŒ€ì™•, ë™ë¶ì•„ë¥¼ í˜¸ë ¹í•˜ë‹¤"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì‘ì—… 2: ì¸ë„¤ì¼ ë¬¸êµ¬ ì‘ì„±]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì¸ë„¤ì¼ì— ë“¤ì–´ê°ˆ í…ìŠ¤íŠ¸ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

ê·œì¹™:
- 2ì¤„ë¡œ ì‘ì„± (ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)
- 1ì¤„ë‹¹ 7ì ì´ë‚´ ê¶Œì¥ (10ì ì´ˆê³¼ ê¸ˆì§€)
- ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ
- ì§ˆë¬¸í˜• ë˜ëŠ” ê°íƒ„í˜•

ì¢‹ì€ ì˜ˆ:
```
18ì„¸ ì™•ì˜
ì²« ì¶œì •
```

```
ìˆ¨ê²¨ì§„ ì§„ì‹¤
ë°í˜€ì§€ë‹¤
```

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì¶œë ¥ í˜•ì‹]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

ì•„ë˜ í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•˜ì„¸ìš”:

TITLE: [YouTube ì œëª©]
THUMBNAIL:
[1ì¤„]
[2ì¤„]
"""

    try:
        result = _call_gpt51(client, prompt)
        if "error" in result:
            return {"title": title, "thumbnail_text": "", "cost": 0}

        text = result.get("text", "")
        cost = result.get("cost", 0)

        # íŒŒì‹±
        youtube_title = title  # ê¸°ë³¸ê°’
        thumbnail_text = ""

        lines = text.strip().split("\n")
        for i, line in enumerate(lines):
            if line.startswith("TITLE:"):
                youtube_title = line.replace("TITLE:", "").strip()
            elif line.startswith("THUMBNAIL:"):
                # ë‹¤ìŒ 2ì¤„ì´ ì¸ë„¤ì¼ í…ìŠ¤íŠ¸
                thumb_lines = []
                for j in range(i + 1, min(i + 3, len(lines))):
                    if lines[j].strip() and not lines[j].startswith("TITLE"):
                        thumb_lines.append(lines[j].strip())
                thumbnail_text = "\n".join(thumb_lines)

        print(f"[SCRIPT] YouTube ì œëª©: {youtube_title}")
        print(f"[SCRIPT] ì¸ë„¤ì¼ ë¬¸êµ¬: {thumbnail_text.replace(chr(10), ' / ')}")

        return {
            "title": youtube_title,
            "thumbnail_text": thumbnail_text,
            "cost": cost,
        }

    except Exception as e:
        print(f"[SCRIPT] SEO ìƒì„± ì‹¤íŒ¨: {e}")
        return {"title": title, "thumbnail_text": "", "cost": 0}


def _format_sources_for_youtube(sources: list) -> str:
    """
    YouTube ì„¤ëª…ë€ìš© ì¶œì²˜ í…ìŠ¤íŠ¸ ìƒì„±

    Returns:
        ì¶œì²˜ ëª©ë¡ (YouTube ì„¤ëª…ë€ì— ë³µì‚¬-ë¶™ì—¬ë„£ê¸° ê°€ëŠ¥í•œ í˜•ì‹)
    """
    if not sources:
        return ""

    lines = ["ğŸ“š ì°¸ê³  ìë£Œ ë° ì¶œì²˜", ""]

    # ì¶œì²˜ë³„ ë¶„ë¥˜
    encykorea = []
    history_db = []
    cultural = []
    museum = []
    others = []

    for url in sources:
        if not url:
            continue
        url_lower = url.lower()
        if "encykorea" in url_lower:
            encykorea.append(url)
        elif "db.history.go.kr" in url_lower or "history.go.kr" in url_lower:
            history_db.append(url)
        elif "heritage.go.kr" in url_lower:
            cultural.append(url)
        elif "museum.go.kr" in url_lower:
            museum.append(url)
        else:
            others.append(url)

    # ì¹´í…Œê³ ë¦¬ë³„ ì¶œë ¥
    if encykorea:
        lines.append("â–¸ í•œêµ­ë¯¼ì¡±ë¬¸í™”ëŒ€ë°±ê³¼ì‚¬ì „")
        for url in encykorea[:3]:  # ìµœëŒ€ 3ê°œ
            lines.append(f"  {url}")
        lines.append("")

    if history_db:
        lines.append("â–¸ êµ­ì‚¬í¸ì°¬ìœ„ì›íšŒ í•œêµ­ì‚¬DB")
        for url in history_db[:3]:
            lines.append(f"  {url}")
        lines.append("")

    if cultural:
        lines.append("â–¸ ë¬¸í™”ì¬ì²­ êµ­ê°€ë¬¸í™”ìœ ì‚°í¬í„¸")
        for url in cultural[:3]:
            lines.append(f"  {url}")
        lines.append("")

    if museum:
        lines.append("â–¸ êµ­ë¦½ì¤‘ì•™ë°•ë¬¼ê´€")
        for url in museum[:3]:
            lines.append(f"  {url}")
        lines.append("")

    if others:
        lines.append("â–¸ ê¸°íƒ€ ìë£Œ")
        for url in others[:3]:
            lines.append(f"  {url}")
        lines.append("")

    return "\n".join(lines)


def generate_script_gpt51(
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    full_content: str,
    sources: list,
    next_episode_info: Dict[str, Any] = None,
) -> Dict[str, Any]:
    """
    GPT-5.2ë¡œ 20,000ì ëŒ€ë³¸ ìƒì„± (ì´ì „ ë²„ì „ í˜¸í™˜ìš© í•¨ìˆ˜ëª… ìœ ì§€)

    Args:
        era_name: ì‹œëŒ€ëª… (ì˜ˆ: "ì‚¼êµ­ì‹œëŒ€")
        episode: ì—í”¼ì†Œë“œ ë²ˆí˜¸
        total_episodes: ì‹œëŒ€ ì´ ì—í”¼ì†Œë“œ ìˆ˜
        title: ì—í”¼ì†Œë“œ ì œëª©
        topic: ì£¼ì œ
        full_content: ìˆ˜ì§‘ëœ ìë£Œ ì „ì²´ ë‚´ìš©
        sources: ì¶œì²˜ URL ëª©ë¡
        next_episode_info: ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´ (ì„ íƒ)

    Returns:
        {
            "script": ìƒì„±ëœ ëŒ€ë³¸,
            "length": ê¸€ììˆ˜,
            "model": ì‚¬ìš© ëª¨ë¸,
            "cost": ì˜ˆìƒ ë¹„ìš©,
            "error": ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
        }
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}

    if not full_content or len(full_content) < 1000:
        return {"error": f"ìˆ˜ì§‘ëœ ìë£Œê°€ ë¶€ì¡±í•©ë‹ˆë‹¤. (í˜„ì¬: {len(full_content)}ì)"}

    # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´
    next_info_text = ""
    if next_episode_info:
        if next_episode_info.get("type") == "next_era":
            next_info_text = f"""
[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ ì‹œëŒ€: {next_episode_info.get('era_name', '')}
- ë‹¤ìŒ ì£¼ì œ: {next_episode_info.get('title', '')}
- ì˜ˆê³  ë¬¸êµ¬ ì˜ˆì‹œ: "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_episode_info.get('era_name', '')}ì˜ ì´ì•¼ê¸°ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤."
"""
        elif next_episode_info.get("type") == "next_episode":
            next_info_text = f"""
[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ë‹¤ìŒ í™”: {era_name} {next_episode_info.get('era_episode', episode + 1)}í™”
- ë‹¤ìŒ ì£¼ì œ: {next_episode_info.get('title', '')}
- ì˜ˆê³  ë¬¸êµ¬ ì˜ˆì‹œ: "ë‹¤ìŒ ì‹œê°„ì—ëŠ” {next_episode_info.get('title', '')}ì— ëŒ€í•´ ì‚´í´ë³´ê² ìŠµë‹ˆë‹¤."
"""
        else:
            next_info_text = """
[ë‹¤ìŒ ì—í”¼ì†Œë“œ ì •ë³´]
- ì‹œë¦¬ì¦ˆ ë§ˆì§€ë§‰ ì—í”¼ì†Œë“œì…ë‹ˆë‹¤.
- ì „ì²´ ì‹œë¦¬ì¦ˆë¥¼ ì •ë¦¬í•˜ë©° ë§ˆë¬´ë¦¬í•˜ì„¸ìš”.
"""

    # ì¶œì²˜ ëª©ë¡
    source_list = "\n".join([f"  - {s}" for s in sources[:10]]) if sources else "  (ì—†ìŒ)"

    # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ êµ¬ì„±
    user_prompt = f"""
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì—í”¼ì†Œë“œ ì •ë³´]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ì‹œë¦¬ì¦ˆ: í•œêµ­ì‚¬ - {era_name}
- í˜„ì¬: {episode}/{total_episodes}í™”
- ì œëª©: {title}
- ì£¼ì œ: {topic}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ìˆ˜ì§‘ëœ ìë£Œ]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{full_content}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì¶œì²˜ ëª©ë¡]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{source_list}

{next_info_text}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ì‘ì„± ì§€ì‹œ]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ {SCRIPT_TARGET_LENGTH:,}ì ë¶„ëŸ‰ì˜ ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.
- ìë£Œì— ì—†ëŠ” ë‚´ìš©ì€ ì¶”ê°€í•˜ì§€ ë§ˆì„¸ìš”.
- í•™ìˆ ì  ì‹ ì¤‘í•¨ì„ ìœ ì§€í•˜ì„¸ìš”.
- ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”.
"""

    try:
        client = OpenAI(api_key=api_key)

        print(f"[SCRIPT] GPT-5.2 ëŒ€ë³¸ ìƒì„± ì‹œì‘...")
        print(f"[SCRIPT] ì…ë ¥ ìë£Œ: {len(full_content):,}ì")

        # GPT-5.2 Responses API í˜¸ì¶œ
        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": SCRIPT_STYLE_PROMPT}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": user_prompt}]
                }
            ],
            temperature=0.7,
        )

        # ê²°ê³¼ ì¶”ì¶œ
        if getattr(response, "output_text", None):
            script = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text_chunks.append(getattr(content, "text", ""))
            script = "\n".join(text_chunks).strip()

        script_length = len(script)

        # í† í° ê³„ì‚° (í•œêµ­ì–´ ì•½ 2ì = 1í† í°)
        # GPT-5.2 ê°€ê²©: $1.75/1M input, $14/1M output
        input_tokens = (len(SCRIPT_STYLE_PROMPT) + len(user_prompt)) // 2
        output_tokens = script_length // 2
        cost = (input_tokens * 1.75 / 1_000_000) + (output_tokens * 14 / 1_000_000)

        print(f"[SCRIPT] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: {script_length:,}ì")
        print(f"[SCRIPT] ì˜ˆìƒ ë¹„ìš©: ${cost:.4f}")

        # ë¶„ëŸ‰ ì²´í¬
        if script_length < SCRIPT_MIN_LENGTH:
            print(f"[SCRIPT] âš ï¸ ë¶„ëŸ‰ ë¶€ì¡± ({script_length:,}ì < {SCRIPT_MIN_LENGTH:,}ì)")
        elif script_length > SCRIPT_MAX_LENGTH:
            print(f"[SCRIPT] âš ï¸ ë¶„ëŸ‰ ì´ˆê³¼ ({script_length:,}ì > {SCRIPT_MAX_LENGTH:,}ì)")

        return {
            "script": script,
            "length": script_length,
            "model": "gpt-5.2",
            "cost": cost,
            "input_tokens": input_tokens,
            "output_tokens": output_tokens,
        }

    except Exception as e:
        print(f"[SCRIPT] GPT-5.2 í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return {"error": str(e)}


def generate_script_with_retry(
    era_name: str,
    episode: int,
    total_episodes: int,
    title: str,
    topic: str,
    full_content: str,
    sources: list,
    next_episode_info: Dict[str, Any] = None,
    max_retries: int = 2,
) -> Dict[str, Any]:
    """
    ëŒ€ë³¸ ìƒì„± (ë¶„ëŸ‰ ë¶€ì¡± ì‹œ ì´ì–´ì“°ê¸°)

    ë¶„ëŸ‰ì´ SCRIPT_MIN_LENGTH ë¯¸ë§Œì´ë©´ ì´ì–´ì“°ê¸° ìš”ì²­
    """
    result = generate_script_gpt51(
        era_name=era_name,
        episode=episode,
        total_episodes=total_episodes,
        title=title,
        topic=topic,
        full_content=full_content,
        sources=sources,
        next_episode_info=next_episode_info,
    )

    if "error" in result:
        return result

    script = result.get("script", "")
    total_cost = result.get("cost", 0)

    # ë¶„ëŸ‰ ë¶€ì¡± ì‹œ ì´ì–´ì“°ê¸°
    for attempt in range(max_retries):
        if len(script) >= SCRIPT_MIN_LENGTH:
            break

        print(f"[SCRIPT] ë¶„ëŸ‰ ë¶€ì¡± ({len(script):,}ì), ì´ì–´ì“°ê¸° ì‹œë„ ({attempt + 1}/{max_retries})...")

        continuation = _continue_script(
            era_name=era_name,
            episode=episode,
            title=title,
            current_script=script,
            target_length=SCRIPT_TARGET_LENGTH,
        )

        if "error" in continuation:
            print(f"[SCRIPT] ì´ì–´ì“°ê¸° ì‹¤íŒ¨: {continuation['error']}")
            break

        script += "\n\n" + continuation.get("script", "")
        total_cost += continuation.get("cost", 0)

    result["script"] = script
    result["length"] = len(script)
    result["cost"] = total_cost

    return result


def _continue_script(
    era_name: str,
    episode: int,
    title: str,
    current_script: str,
    target_length: int,
) -> Dict[str, Any]:
    """
    ëŒ€ë³¸ ì´ì–´ì“°ê¸° (ë¶„ëŸ‰ ë¶€ì¡± ì‹œ)
    """
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        return {"error": "OPENAI_API_KEY ì—†ìŒ"}

    remaining = target_length - len(current_script)

    prompt = f"""ì•„ë˜ ëŒ€ë³¸ì˜ ì´ì–´ì“°ê¸°ë¥¼ ì‘ì„±í•˜ì„¸ìš”.

[í˜„ì¬ ëŒ€ë³¸ ë§ˆì§€ë§‰ ë¶€ë¶„]
{current_script[-2000:]}

[ì§€ì‹œì‚¬í•­]
- ìœ„ ëŒ€ë³¸ì— ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ë‚´ìš© ì‘ì„±
- ì•½ {remaining:,}ì ë¶„ëŸ‰ ì¶”ê°€
- ê¸°ì¡´ ìŠ¤íƒ€ì¼(í•™ìˆ ì , ê°ê´€ì ) ìœ ì§€
- ë§ˆë¬´ë¦¬ + ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³  í¬í•¨
"""

    try:
        client = OpenAI(api_key=api_key)

        response = client.responses.create(
            model="gpt-5.2",
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": "í•œêµ­ì‚¬ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤. ê¸°ì¡´ ëŒ€ë³¸ì— ì´ì–´ì„œ ì‘ì„±í•©ë‹ˆë‹¤."}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": prompt}]
                }
            ],
            temperature=0.7,
        )

        if getattr(response, "output_text", None):
            continuation = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text_chunks.append(getattr(content, "text", ""))
            continuation = "\n".join(text_chunks).strip()

        # ë¹„ìš© ê³„ì‚° (GPT-5.2 ê°€ê²©: $1.75/1M input, $14/1M output)
        input_tokens = len(prompt) // 2
        output_tokens = len(continuation) // 2
        cost = (input_tokens * 1.75 / 1_000_000) + (output_tokens * 14 / 1_000_000)

        print(f"[SCRIPT] ì´ì–´ì“°ê¸° ì™„ë£Œ: +{len(continuation):,}ì")

        return {
            "script": continuation,
            "length": len(continuation),
            "cost": cost,
        }

    except Exception as e:
        return {"error": str(e)}
