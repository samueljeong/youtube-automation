"""
OPUS ì…ë ¥ ìƒì„± ëª¨ë“ˆ

ë°˜ìë™ ìš´ì˜ ìµœì í™”:
- materials_pack: ìë£Œ ë°œì·Œ/ìš”ì•½/í•µì‹¬í¬ì¸íŠ¸
- opus_prompt_pack: Opusì— í•œ ë²ˆì— ë¶™ì—¬ë„£ì„ ì™„ì œí’ˆ

ë³µë¶™ íë¦„:
1. OPUS_INPUT ì‹œíŠ¸ì—ì„œ opus_prompt_pack ì…€ ë³µì‚¬
2. Opusì— ë¶™ì—¬ë„£ê¸°
3. ëŒ€ë³¸ ìƒì„± ì™„ë£Œ
"""

import os
from datetime import datetime, timezone
from typing import List, Dict, Any, Tuple

from .config import (
    ERAS,
    SCRIPT_BRIEF_TEMPLATE,
    LLM_ENABLED_DEFAULT,
    LLM_MIN_SCORE_DEFAULT,
    LLM_MODEL_DEFAULT,
)
from .utils import (
    get_run_id,
    get_era_display_name,
    get_era_period,
)


def generate_opus_input(
    candidate_rows: List[List[Any]],
    era: str,
    llm_enabled: bool = LLM_ENABLED_DEFAULT,
    llm_min_score: float = LLM_MIN_SCORE_DEFAULT
) -> List[List[Any]]:
    """
    OPUS ì…ë ¥ ìƒì„± (TOP 1ë§Œ ì²˜ë¦¬)

    ë°˜ìë™ ìš´ì˜ì— ìµœì í™”:
    - materials_pack: ìë£Œ ë°œì·Œ/ìš”ì•½/í•µì‹¬í¬ì¸íŠ¸
    - opus_prompt_pack: Opusì— í•œ ë²ˆì— ë¶™ì—¬ë„£ì„ ì™„ì œí’ˆ

    Args:
        candidate_rows: CANDIDATES í–‰ ë°ì´í„°
        era: ì‹œëŒ€ í‚¤
        llm_enabled: LLM ì‚¬ìš© ì—¬ë¶€
        llm_min_score: LLM í˜¸ì¶œ ìµœì†Œ ì ìˆ˜

    Returns:
        OPUS_INPUT ì‹œíŠ¸ìš© í–‰ ë°ì´í„° ë¦¬ìŠ¤íŠ¸
    """
    if not candidate_rows:
        print("[HISTORY] í›„ë³´ ì—†ìŒ, OPUS_INPUT ìƒì„± ìŠ¤í‚µ")
        return []

    top1 = candidate_rows[0]
    run_date = top1[0]
    topic = top1[3]
    score_total = float(top1[4]) if top1[4] else 0
    title = top1[8]
    url = top1[9]
    summary = top1[10]

    era_name = get_era_display_name(era)
    period = get_era_period(era)

    # LLM í˜¸ì¶œ ì¡°ê±´
    should_call_llm = llm_enabled and (llm_min_score == 0 or score_total >= llm_min_score)

    if should_call_llm:
        print(f"[HISTORY] LLM í˜¸ì¶œ (ì ìˆ˜ {score_total} >= ìµœì†Œ {llm_min_score})")
        core_facts, thumbnail_copy = _llm_generate_core_facts(
            era, era_name, period, topic, title, summary, url
        )
    else:
        if llm_enabled and score_total < llm_min_score:
            print(f"[HISTORY] LLM ìŠ¤í‚µ (ì ìˆ˜ {score_total} < ìµœì†Œ {llm_min_score})")
        core_facts = _generate_default_core_facts(era_name, topic, title, summary)
        thumbnail_copy = _generate_default_thumbnail(era_name, topic, title)

    # ========================================
    # materials_pack: ìë£Œ ë°œì·Œ/ìš”ì•½ ë¬¶ìŒ
    # ========================================
    materials_pack = _build_materials_pack(
        era_name, period, topic, title, url, summary, core_facts
    )

    # ========================================
    # opus_prompt_pack: Opusì— ë¶™ì—¬ë„£ì„ ì™„ì œí’ˆ (í•œ ì…€)
    # ========================================
    opus_prompt_pack = _build_opus_prompt_pack(
        era_name, period, topic, title, url, core_facts
    )

    # ìƒì„± ì‹œê°„
    created_at = datetime.now(timezone.utc).isoformat()

    # ì‹œíŠ¸ í–‰ ìƒì„± (HISTORY_OPUS_INPUT ì»¬ëŸ¼ êµ¬ì¡°)
    opus_row = [[
        run_date,         # run_date
        era,              # era â˜… Idempotency ì²´í¬ìš©
        era_name,         # era_name
        title[:100],      # title
        url,              # source_url
        materials_pack,   # materials_pack
        opus_prompt_pack, # opus_prompt_pack â˜… ì´ê²ƒë§Œ ë³µë¶™
        thumbnail_copy,   # thumbnail_copy (ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì²œ)
        "PENDING",        # status
        created_at,       # created_at
    ]]

    print(f"[HISTORY] OPUS_INPUT ìƒì„± ì™„ë£Œ: {title[:30]}...")
    return opus_row


def _build_materials_pack(
    era_name: str,
    period: str,
    topic: str,
    title: str,
    url: str,
    summary: str,
    core_facts: str
) -> str:
    """ìë£Œ ë°œì·Œ/ìš”ì•½ ë¬¶ìŒ ìƒì„± (ì°¸ê³ ìš©)"""

    return f"""â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“š ìë£Œ ì •ë³´
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ì‹œëŒ€: {era_name} ({period})
ì£¼ì œ: {topic}
ì œëª©: {title}
ì¶œì²˜: {url}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ“ ìë£Œ ìš”ì•½
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{summary[:500]}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ğŸ¯ í•µì‹¬í¬ì¸íŠ¸ (íŒŒì´í”„ë¼ì¸ ìƒì„±)
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
{core_facts}
"""


def _build_opus_prompt_pack(
    era_name: str,
    period: str,
    topic: str,
    title: str,
    url: str,
    core_facts: str
) -> str:
    """
    Opusì— ë¶™ì—¬ë„£ì„ ì™„ì œí’ˆ í”„ë¡¬í”„íŠ¸ ìƒì„±

    ì´ ì…€ í•˜ë‚˜ë§Œ ë³µì‚¬í•´ì„œ Opusì— ë¶™ì—¬ë„£ìœ¼ë©´ ë¨
    ë§ˆì»¤ êµ¬ì¡°: [CONTEXT] / [STRUCTURE POINTS] / [OPUS SCRIPT BRIEF] / [ENDING PROMISE]
    """

    return f"""ë‹¹ì‹ ì€ í•œêµ­ì‚¬ ì „ë¬¸ ìœ íŠœë¸Œ ì±„ë„ì˜ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ **15~20ë¶„ ë¶„ëŸ‰(6,000~8,000ì)**ì˜ ë‚˜ë ˆì´ì…˜ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[CONTEXT]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ì±„ë„/ì‹œëŒ€: í•œêµ­ì‚¬ / {era_name} ({period})
- ìë£Œ ì¶œì²˜: {title}
- URL: {url}
- ì˜¤ëŠ˜ì˜ í•µì‹¬ ì§ˆë¬¸: ì™œ {era_name}ì´ í•œêµ­ ì—­ì‚¬ì˜ ì‹œì‘ì ìœ¼ë¡œ ì¤‘ìš”í•œê°€?

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[STRUCTURE POINTS] (5~7ê°œ, êµ¬ì¡° ì¤‘ì‹¬)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{core_facts}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
{SCRIPT_BRIEF_TEMPLATE}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
[ENDING PROMISE]
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ë‹¤ìŒ ì‹œëŒ€ ì—°ê²°: {era_name} ì´í›„ì˜ ì—­ì‚¬ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°
- ë‹¤ìŒ ì˜ìƒ ì˜ˆê³  í•œ ì¤„: "ë‹¤ìŒ ì‹œê°„ì—ëŠ” ___ì— ëŒ€í•´ ì•Œì•„ë³´ê² ìŠµë‹ˆë‹¤"

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ ìµœì¢… ì²´í¬ë¦¬ìŠ¤íŠ¸ (ì‘ì„± í›„ ë°˜ë“œì‹œ í™•ì¸)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
â–¡ ì´ ê¸€ììˆ˜ 6,000~8,000ì ì‚¬ì´ì¸ê°€?
â–¡ ì „ë°˜ë¶€(0~60%)ì— ê°ì •/í–‰ë™/ê³µê° í‘œí˜„ì´ ì—†ëŠ”ê°€?
â–¡ "ì •ë¦¬í•˜ë©´/í•µì‹¬ì€/ê²°ë¡ ì ìœ¼ë¡œ" ë“± ì¤‘ê°„ìš”ì•½ í‘œí˜„ì´ ì—†ëŠ”ê°€?
â–¡ ë§ˆì§€ë§‰ ë¬¸ì¥ì´ ë‹¤ìŒ ì‹œëŒ€ë¡œ ì—°ê²°ë˜ëŠ” ì§ˆë¬¸ì¸ê°€?
â–¡ "~í•´ì•¼ í•©ë‹ˆë‹¤/~ë¥¼ ê¸°ì–µí•©ì‹œë‹¤" ê°™ì€ í›ˆê³„í˜• í‘œí˜„ì´ ì—†ëŠ”ê°€?
â–¡ ê°‘ìê¸° í›ˆí›ˆí•´ì§€ê±°ë‚˜ ì°©í•´ì§€ëŠ” ê²°ë¡ ì´ ì•„ë‹Œê°€?
"""


def _generate_default_core_facts(
    era_name: str,
    topic: str,
    title: str,
    summary: str
) -> str:
    """LLM ì—†ì´ ê¸°ë³¸ í•µì‹¬í¬ì¸íŠ¸ í…œí”Œë¦¿ ìƒì„±"""

    return f"""[í•µì‹¬í¬ì¸íŠ¸ - {era_name}]

â–¶ ì£¼ì œ: {topic}
â–¶ ì¶œì²˜: {title}

[#OPEN] ì˜¤í”„ë‹ ì§ˆë¬¸
- ì´ ì‹œëŒ€ëŠ” ì–´ë–¤ ì‹œëŒ€ì˜€ë‚˜?
- ì™œ ì´ ì£¼ì œê°€ ì˜¤ëŠ˜ë‚ ì—ë„ ì¤‘ìš”í•œê°€?

[#BODY1_FACTS_ONLY] í•µì‹¬ ì‚¬ì‹¤ (5ê°œ)
1. (ì‚¬ì‹¤ 1 - ì‹œê°„/ì¥ì†Œ/ì¸ë¬¼ ì¤‘ì‹¬)
2. (ì‚¬ì‹¤ 2)
3. (ì‚¬ì‹¤ 3)
4. (ì‚¬ì‹¤ 4)
5. (ì‚¬ì‹¤ 5)

[#TURN] ì „í™˜ì 
- ê²°ì •ì  ìˆœê°„ì€ ì–¸ì œì˜€ë‚˜?
- ì–´ë–¤ ì„ íƒì˜ ê°ˆë¦¼ê¸¸ì´ ìˆì—ˆë‚˜?

[#BODY2_HUMAN_ALLOWED] ìŠ¤í† ë¦¬ ì „ê°œ
- ì£¼ìš” ì¸ë¬¼ì˜ í–‰ë™ê³¼ ì‹¬ë¦¬
- ì‚¬ê±´ì˜ ë“œë¼ë§ˆí‹±í•œ ì „ê°œ

[#IMPACT] ì—­ì‚¬ì  ì˜ì˜
- ì´í›„ ì—­ì‚¬ì— ë¯¸ì¹œ ì˜í–¥

[#NEXT] ë‹¤ìŒ ì‹œëŒ€ ì—°ê²°
- ë‹¤ìŒ ì‹œëŒ€ë¡œ ì´ì–´ì§€ëŠ” ì§ˆë¬¸

â–¶ ì°¸ê³  ìš”ì•½:
{summary[:400]}
"""


def _generate_default_thumbnail(
    era_name: str,
    topic: str,
    title: str
) -> str:
    """ê¸°ë³¸ ì¸ë„¤ì¼ ë¬¸êµ¬ í…œí”Œë¦¿"""
    return f"""[ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì²œ]

1. {era_name}ì˜ ë¹„ë°€
2. {topic} - ì—­ì‚¬ê°€ ìˆ¨ê¸´ ì§„ì‹¤
3. {title[:20]}...ì˜ ì¶©ê²©ì  ê²°ë§"""


def _llm_generate_core_facts(
    era: str,
    era_name: str,
    period: str,
    topic: str,
    title: str,
    summary: str,
    url: str
) -> Tuple[str, str]:
    """
    LLMìœ¼ë¡œ í•µì‹¬í¬ì¸íŠ¸ ìƒì„± (êµ¬ì¡° ë§ˆì»¤ í¬í•¨)

    Returns:
        (core_facts, thumbnail_copy)
    """

    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        print("[HISTORY] OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ ì—†ìŒ, ê¸°ë³¸ í…œí”Œë¦¿ ì‚¬ìš©")
        return (
            _generate_default_core_facts(era_name, topic, title, summary),
            _generate_default_thumbnail(era_name, topic, title)
        )

    try:
        from openai import OpenAI
        client = OpenAI(api_key=api_key)

        prompt = f"""ë‹¹ì‹ ì€ í•œêµ­ì‚¬ êµìœ¡ ì½˜í…ì¸  ê¸°íšìì…ë‹ˆë‹¤.
ì•„ë˜ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ YouTube ì—­ì‚¬ ì˜ìƒì˜ ëŒ€ë³¸ ì‘ì„±ì„ ìœ„í•œ 'êµ¬ì¡°ì  í•µì‹¬í¬ì¸íŠ¸'ë¥¼ ìƒì„±í•˜ì„¸ìš”.

[ì‹œëŒ€ ì •ë³´]
- ì‹œëŒ€: {era_name}
- ê¸°ê°„: {period}
- ì£¼ì œ ë¶„ë¥˜: {topic}

[ìë£Œ ì •ë³´]
- ì œëª©: {title}
- ìš”ì•½: {summary}
- ì¶œì²˜: {url}

[í•µì‹¬í¬ì¸íŠ¸ì˜ ì •ì²´ì„±]
ì´ ë‹¨ê³„ëŠ” 'ëŒ€ë³¸ì„ ì“°ê¸° ìœ„í•œ ì¬ë£Œ'ë¥¼ ì œê³µí•˜ëŠ” ê²ƒì…ë‹ˆë‹¤.
ì‹œì²­ìë¥¼ ì„¤ë“í•˜ê±°ë‚˜ ê°ì •ì„ ìœ ë„í•˜ëŠ” ë¬¸ì¥ì´ ì•„ë‹™ë‹ˆë‹¤.

[ì ˆëŒ€ ê¸ˆì§€]
âŒ ê°ì • í‘œí˜„ (í¥ë¯¸ë¡­ë‹¤, ë†€ëë‹¤, ì•ˆíƒ€ê¹ë‹¤)
âŒ í‰ê°€/íŒë‹¨ (ìœ„ëŒ€í•˜ë‹¤, ì¤‘ìš”í•˜ë‹¤, ~í•´ì•¼ í•œë‹¤)
âŒ ì¶”ì¸¡ (ì•„ë§ˆë„, ~í–ˆì„ ê²ƒì´ë‹¤)

[í—ˆìš© ìš”ì†Œ]
â­• ì‹œê°„/ì¥ì†Œ/ì¸ë¬¼ ì •ë³´
â­• ì‚¬ê±´ì˜ ì›ì¸ê³¼ ê²°ê³¼
â­• ì—­ì‚¬ì  ë§¥ë½

[ì¶œë ¥ í˜•ì‹ - ë°˜ë“œì‹œ ì•„ë˜ êµ¬ì¡° ë§ˆì»¤ë¥¼ í¬í•¨í•  ê²ƒ]

[#OPEN] ì˜¤í”„ë‹ ì§ˆë¬¸
- (ì‹œì²­ìì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•  ì§ˆë¬¸ 1~2ê°œ)

[#BODY1_FACTS_ONLY] í•µì‹¬ ì‚¬ì‹¤ (5ê°œ)
1. (ì—­ì‚¬ì  ì‚¬ì‹¤ - ì‹œê°„/ì¥ì†Œ/ì¸ë¬¼ ì¤‘ì‹¬, 25~40ì)
2. (ì—­ì‚¬ì  ì‚¬ì‹¤)
3. (ì—­ì‚¬ì  ì‚¬ì‹¤)
4. (ì—­ì‚¬ì  ì‚¬ì‹¤)
5. (ì—­ì‚¬ì  ì‚¬ì‹¤)

[#TURN] ì „í™˜ì 
- (ê²°ì •ì  ìˆœê°„/ì„ íƒì˜ ê°ˆë¦¼ê¸¸)

[#BODY2_HUMAN_ALLOWED] ìŠ¤í† ë¦¬ ì „ê°œ íŒíŠ¸
- (ì—¬ê¸°ì„œë¶€í„° ì¸ë¬¼ ì‹¬ë¦¬/í–‰ë™ ë¬˜ì‚¬ ê°€ëŠ¥)
- (ë“œë¼ë§ˆí‹±í•œ ì „ê°œ í¬ì¸íŠ¸)

[#IMPACT] ì—­ì‚¬ì  ì˜ì˜
- (ì´í›„ ì—­ì‚¬ì— ë¯¸ì¹œ ì˜í–¥)

[#NEXT] ë‹¤ìŒ ì‹œëŒ€ ì—°ê²°
- (ë‹¤ìŒ ì‹œëŒ€ë¡œ ì´ì–´ì§€ëŠ” ì§ˆë¬¸ 1ê°œ)

[ì¸ë„¤ì¼ ë¬¸êµ¬ 3ì•ˆ]
1. (í´ë¦­ ìœ ë„ ë¬¸êµ¬ - ì§§ê³  ì„íŒ©íŠ¸ ìˆê²Œ)
2. (í˜¸ê¸°ì‹¬ ìê·¹ ë¬¸êµ¬)
3. (ë°˜ì „/ë†€ë¼ì›€ ë¬¸êµ¬)
"""

        model = os.environ.get("OPENAI_MODEL", LLM_MODEL_DEFAULT)

        if "gpt-5" in model:
            response = client.responses.create(
                model=model,
                input=[
                    {"role": "system", "content": [{"type": "input_text", "text": "í•œêµ­ì‚¬ êµìœ¡ ì½˜í…ì¸  ê¸°íšì"}]},
                    {"role": "user", "content": [{"type": "input_text", "text": prompt}]}
                ],
                temperature=0.7
            )
            if getattr(response, "output_text", None):
                text = response.output_text.strip()
            else:
                text_chunks = []
                for item in getattr(response, "output", []) or []:
                    for content in getattr(item, "content", []) or []:
                        if getattr(content, "type", "") == "text":
                            text_chunks.append(getattr(content, "text", ""))
                text = "\n".join(text_chunks).strip()
        else:
            response = client.chat.completions.create(
                model=model,
                messages=[
                    {"role": "system", "content": "í•œêµ­ì‚¬ êµìœ¡ ì½˜í…ì¸  ê¸°íšì"},
                    {"role": "user", "content": prompt}
                ],
                temperature=0.7
            )
            text = response.choices[0].message.content.strip()

        # ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì¶œ
        core_facts, thumbnail_copy = _parse_llm_response_with_thumbnail(text)

        print(f"[HISTORY] LLM í•µì‹¬í¬ì¸íŠ¸ ìƒì„± ì™„ë£Œ (ëª¨ë¸: {model})")
        return core_facts, thumbnail_copy

    except Exception as e:
        print(f"[HISTORY] LLM í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return (
            _generate_default_core_facts(era_name, topic, title, summary),
            _generate_default_thumbnail(era_name, topic, title)
        )


def _parse_llm_response_with_thumbnail(text: str) -> Tuple[str, str]:
    """
    LLM ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ í•µì‹¬í¬ì¸íŠ¸ì™€ ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì¶œ

    Returns:
        (core_facts, thumbnail_copy)
    """
    import re

    # ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì¶œ (ì¸ë„¤ì¼ ì´í›„ ë¶€ë¶„)
    thumb_match = re.search(
        r'ì¸ë„¤ì¼.*',
        text,
        re.DOTALL | re.IGNORECASE
    )
    thumbnail_copy = thumb_match.group(0).strip() if thumb_match else ""

    # í•µì‹¬í¬ì¸íŠ¸ = ì¸ë„¤ì¼ ì „ê¹Œì§€ ì „ì²´
    if thumb_match:
        core_facts = text[:thumb_match.start()].strip()
    else:
        core_facts = text.strip()

    return core_facts, thumbnail_copy


def _parse_llm_response(text: str) -> Tuple[str, str, str]:
    """LLM ì‘ë‹µì„ ì„¹ì…˜ë³„ë¡œ íŒŒì‹± (ë ˆê±°ì‹œ, ë¯¸ì‚¬ìš©)"""
    import re

    core_facts = ""
    narrative_arc = ""
    thumbnail_ideas = ""

    # í•µì‹¬ ì‚¬ì‹¤ ì¶”ì¶œ
    core_match = re.search(
        r'í•µì‹¬\s*ì‚¬ì‹¤.*?(?=ìŠ¤í† ë¦¬|$)',
        text,
        re.DOTALL | re.IGNORECASE
    )
    if core_match:
        core_facts = core_match.group(0).strip()

    # ìŠ¤í† ë¦¬ ì•„í¬ ì¶”ì¶œ
    arc_match = re.search(
        r'ìŠ¤í† ë¦¬\s*ì•„í¬.*?(?=ì¸ë„¤ì¼|$)',
        text,
        re.DOTALL | re.IGNORECASE
    )
    if arc_match:
        narrative_arc = arc_match.group(0).strip()

    # ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì¶œ
    thumb_match = re.search(
        r'ì¸ë„¤ì¼.*',
        text,
        re.DOTALL | re.IGNORECASE
    )
    if thumb_match:
        thumbnail_ideas = thumb_match.group(0).strip()

    # í•µì‹¬ ì‚¬ì‹¤ì´ ë¹„ì–´ìˆìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ ì‚¬ìš©
    if not core_facts:
        core_facts = text

    return core_facts, narrative_arc, thumbnail_ideas
