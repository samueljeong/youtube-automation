"""
ì‡¼ì¸  íŒŒì´í”„ë¼ì¸ - YouTube íŠ¸ë Œë”© ê²€ìƒ‰

YouTube Data APIë¥¼ ì‚¬ìš©í•˜ì—¬ íŠ¸ë Œë”© ì‡¼ì¸  ê²€ìƒ‰ ë° ë¶„ì„
"""

import os
import re
from datetime import datetime, timedelta, timezone
from typing import List, Dict, Any, Optional
from googleapiclient.discovery import build
from googleapiclient.errors import HttpError


def get_youtube_client():
    """YouTube Data API í´ë¼ì´ì–¸íŠ¸ ìƒì„±"""
    api_key = os.environ.get("YOUTUBE_API_KEY")
    if not api_key:
        raise ValueError("YOUTUBE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")

    return build("youtube", "v3", developerKey=api_key)


def search_trending_shorts(
    query: str = "ì—°ì˜ˆ ë‰´ìŠ¤",
    max_results: int = 20,
    hours_ago: int = 24,
    order: str = "viewCount",
    region_code: str = "KR",
) -> List[Dict[str, Any]]:
    """
    YouTubeì—ì„œ íŠ¸ë Œë”© ì‡¼ì¸  ê²€ìƒ‰

    Args:
        query: ê²€ìƒ‰ì–´
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜
        hours_ago: ëª‡ ì‹œê°„ ì´ë‚´ ì˜ìƒ
        order: ì •ë ¬ ê¸°ì¤€ (viewCount, date, rating, relevance)
        region_code: ì§€ì—­ ì½”ë“œ

    Returns:
        [
            {
                "video_id": "...",
                "title": "...",
                "channel_title": "...",
                "published_at": "...",
                "view_count": 123456,
                "like_count": 1234,
                "comment_count": 56,
                "duration_seconds": 45,
                "thumbnail_url": "...",
            },
            ...
        ]
    """
    try:
        youtube = get_youtube_client()

        # ê²€ìƒ‰ ì‹œê°„ ë²”ìœ„ ì„¤ì •
        published_after = (datetime.now(timezone.utc) - timedelta(hours=hours_ago)).isoformat()

        print(f"[YouTube] ê²€ìƒ‰ ì¤‘: '{query}' (ìµœê·¼ {hours_ago}ì‹œê°„, {order}ìˆœ)")

        # 1ë‹¨ê³„: ê²€ìƒ‰
        search_response = youtube.search().list(
            q=query,
            part="snippet",
            type="video",
            videoDuration="short",  # Shorts (60ì´ˆ ì´í•˜)
            order=order,
            publishedAfter=published_after,
            regionCode=region_code,
            maxResults=max_results,
            relevanceLanguage="ko",
        ).execute()

        video_ids = [item["id"]["videoId"] for item in search_response.get("items", [])]

        if not video_ids:
            print("[YouTube] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return []

        # 2ë‹¨ê³„: ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ì¡°íšŒ
        videos_response = youtube.videos().list(
            part="snippet,statistics,contentDetails",
            id=",".join(video_ids),
        ).execute()

        results = []
        for item in videos_response.get("items", []):
            video_id = item["id"]
            snippet = item.get("snippet", {})
            statistics = item.get("statistics", {})
            content_details = item.get("contentDetails", {})

            # ì˜ìƒ ê¸¸ì´ íŒŒì‹± (PT45S â†’ 45ì´ˆ)
            duration_str = content_details.get("duration", "PT0S")
            duration_seconds = parse_duration(duration_str)

            # ShortsëŠ” 60ì´ˆ ì´í•˜ë§Œ
            if duration_seconds > 60:
                continue

            results.append({
                "video_id": video_id,
                "title": snippet.get("title", ""),
                "channel_title": snippet.get("channelTitle", ""),
                "channel_id": snippet.get("channelId", ""),
                "published_at": snippet.get("publishedAt", ""),
                "description": snippet.get("description", ""),
                "view_count": int(statistics.get("viewCount", 0)),
                "like_count": int(statistics.get("likeCount", 0)),
                "comment_count": int(statistics.get("commentCount", 0)),
                "duration_seconds": duration_seconds,
                "thumbnail_url": snippet.get("thumbnails", {}).get("high", {}).get("url", ""),
            })

        # ì¡°íšŒìˆ˜ìˆœ ì •ë ¬
        results.sort(key=lambda x: x["view_count"], reverse=True)

        print(f"[YouTube] {len(results)}ê°œ ì‡¼ì¸  ë°œê²¬")
        return results

    except HttpError as e:
        print(f"[YouTube] API ì˜¤ë¥˜: {e}")
        return []
    except Exception as e:
        print(f"[YouTube] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


def parse_duration(duration_str: str) -> int:
    """
    ISO 8601 durationì„ ì´ˆë¡œ ë³€í™˜
    PT45S â†’ 45, PT1M30S â†’ 90
    """
    match = re.match(r'PT(?:(\d+)M)?(?:(\d+)S)?', duration_str)
    if match:
        minutes = int(match.group(1) or 0)
        seconds = int(match.group(2) or 0)
        return minutes * 60 + seconds
    return 0


def calculate_engagement_score(video: Dict[str, Any]) -> float:
    """
    ì˜ìƒ ì°¸ì—¬ë„ ì ìˆ˜ ê³„ì‚°

    - ì¡°íšŒìˆ˜ (40%): 0~100ë§Œ â†’ 0~100ì 
    - ì¢‹ì•„ìš”ìœ¨ (30%): ì¢‹ì•„ìš”/ì¡°íšŒìˆ˜ ë¹„ìœ¨
    - ëŒ“ê¸€ìˆ˜ (20%): 0~1000 â†’ 0~100ì 
    - ì‹ ì„ ë„ (10%): ìµœê·¼ì¼ìˆ˜ë¡ ë†’ìŒ
    """
    views = video.get("view_count", 0)
    likes = video.get("like_count", 0)
    comments = video.get("comment_count", 0)
    published_at = video.get("published_at", "")

    # ì¡°íšŒìˆ˜ ì ìˆ˜ (0~100)
    view_score = min(views / 10000, 100)  # 100ë§Œ = 100ì 

    # ì¢‹ì•„ìš”ìœ¨ ì ìˆ˜ (0~100)
    like_ratio = (likes / views * 100) if views > 0 else 0
    like_score = min(like_ratio * 10, 100)  # 10% = 100ì 

    # ëŒ“ê¸€ìˆ˜ ì ìˆ˜ (0~100)
    comment_score = min(comments / 10, 100)  # 1000ê°œ = 100ì 

    # ì‹ ì„ ë„ ì ìˆ˜ (0~100)
    recency_score = 100
    if published_at:
        try:
            pub_time = datetime.fromisoformat(published_at.replace("Z", "+00:00"))
            hours_old = (datetime.now(timezone.utc) - pub_time).total_seconds() / 3600
            recency_score = max(0, 100 - hours_old * 4)  # 24ì‹œê°„ í›„ 0ì 
        except:
            pass

    # ê°€ì¤‘ í‰ê· 
    total = (
        view_score * 0.4 +
        like_score * 0.3 +
        comment_score * 0.2 +
        recency_score * 0.1
    )

    return round(total, 1)


def get_video_comments(
    video_id: str,
    max_results: int = 50,
) -> List[Dict[str, Any]]:
    """
    ì˜ìƒ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°

    Returns:
        [{"text": "...", "likes": 10, "author": "..."}, ...]
    """
    try:
        youtube = get_youtube_client()

        response = youtube.commentThreads().list(
            part="snippet",
            videoId=video_id,
            order="relevance",  # ì¸ê¸° ëŒ“ê¸€ ìš°ì„ 
            maxResults=max_results,
            textFormat="plainText",
        ).execute()

        comments = []
        for item in response.get("items", []):
            snippet = item.get("snippet", {}).get("topLevelComment", {}).get("snippet", {})
            comments.append({
                "text": snippet.get("textDisplay", ""),
                "likes": snippet.get("likeCount", 0),
                "author": snippet.get("authorDisplayName", ""),
                "published_at": snippet.get("publishedAt", ""),
            })

        return comments

    except HttpError as e:
        # ëŒ“ê¸€ ë¹„í™œì„±í™”ëœ ì˜ìƒ
        if "commentsDisabled" in str(e):
            print(f"[YouTube] ëŒ“ê¸€ ë¹„í™œì„±í™”: {video_id}")
        else:
            print(f"[YouTube] ëŒ“ê¸€ ì¡°íšŒ ì‹¤íŒ¨: {e}")
        return []
    except Exception as e:
        print(f"[YouTube] ëŒ“ê¸€ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return []


def extract_trending_topics(videos: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
    """
    íŠ¸ë Œë”© ì‡¼ì¸ ì—ì„œ ì£¼ì œ ì¶”ì¶œ

    Returns:
        [
            {
                "topic": "ë°•ë‚˜ë˜ ê°‘ì§ˆ",
                "video_count": 5,
                "total_views": 1234567,
                "sample_videos": [...],
                "keywords": ["ê°‘ì§ˆ", "ë…¼ë€"],
            },
            ...
        ]
    """
    from collections import defaultdict

    # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
    keyword_videos = defaultdict(list)

    # ì—°ì˜ˆì¸ ì´ë¦„ íŒ¨í„´
    name_pattern = r'([ê°€-í£]{2,4})(?:ê°€|ì´|ëŠ”|ì˜|ë¥¼|ì—ê²Œ|ì¸¡|ì”¨|,|\s)'

    # ì´ìŠˆ í‚¤ì›Œë“œ
    issue_keywords = [
        "ë…¼ë€", "ê°‘ì§ˆ", "í­ë¡œ", "ê³ ë°±", "ê²°í˜¼", "ì´í˜¼", "ì—´ì• ", "íŒŒí˜¼",
        "ì»´ë°±", "ì‚¬ê³¼", "í•´ëª…", "ì¶©ê²©", "ê·¼í™©", "ë³µê·€", "ì€í‡´", "íƒˆí‡´",
    ]

    for video in videos:
        title = video.get("title", "")

        # ì—°ì˜ˆì¸ ì´ë¦„ ì¶”ì¶œ
        names = re.findall(name_pattern, title)

        # ì´ìŠˆ í‚¤ì›Œë“œ ì¶”ì¶œ
        found_issues = [kw for kw in issue_keywords if kw in title]

        # ì¡°í•© (ì´ë¦„ + ì´ìŠˆ)
        for name in names:
            if len(name) >= 2:
                for issue in found_issues:
                    topic = f"{name} {issue}"
                    keyword_videos[topic].append(video)

                # ì´ë¦„ë§Œë„ ì¶”ê°€
                keyword_videos[name].append(video)

    # ì£¼ì œë³„ ì§‘ê³„
    topics = []
    for topic, vids in keyword_videos.items():
        if len(vids) >= 1:  # 1ê°œ ì´ìƒì´ë©´ í¬í•¨ (ê¸°ì¡´: 2ê°œ)
            topics.append({
                "topic": topic,
                "video_count": len(vids),
                "total_views": sum(v.get("view_count", 0) for v in vids),
                "avg_engagement": sum(calculate_engagement_score(v) for v in vids) / len(vids),
                "sample_videos": vids[:3],
            })

    # ì£¼ì œê°€ ì—†ìœ¼ë©´ ìƒìœ„ ì˜ìƒì„ ê°œë³„ ì£¼ì œë¡œ ì¶”ê°€
    if not topics and videos:
        for video in videos[:5]:
            title = video.get("title", "")
            # ì œëª©ì—ì„œ ì²« ë²ˆì§¸ í•œê¸€ ì´ë¦„ ì¶”ì¶œ ì‹œë„
            names = re.findall(r'([ê°€-í£]{2,4})', title)
            topic_name = names[0] if names else title[:20]

            topics.append({
                "topic": topic_name,
                "video_count": 1,
                "total_views": video.get("view_count", 0),
                "avg_engagement": calculate_engagement_score(video),
                "sample_videos": [video],
            })

    # ì¡°íšŒìˆ˜ìˆœ ì •ë ¬
    topics.sort(key=lambda x: x["total_views"], reverse=True)

    return topics[:10]  # ìƒìœ„ 10ê°œ


def search_shorts_by_category(
    category: str = "ì—°ì˜ˆì¸",
    hours_ago: int = 24,
    max_results: int = 30,
) -> Dict[str, Any]:
    """
    ì¹´í…Œê³ ë¦¬ë³„ íŠ¸ë Œë”© ì‡¼ì¸  ê²€ìƒ‰ + ì£¼ì œ ë¶„ì„

    Args:
        category: ì—°ì˜ˆì¸ / ìš´ë™ì„ ìˆ˜ / êµ­ë½•
        hours_ago: ê²€ìƒ‰ ì‹œê°„ ë²”ìœ„
        max_results: ìµœëŒ€ ê²°ê³¼ ìˆ˜

    Returns:
        {
            "videos": [...],
            "topics": [...],
            "best_topic": {...},
        }
    """
    # ì¹´í…Œê³ ë¦¬ë³„ ê²€ìƒ‰ì–´
    queries = {
        "ì—°ì˜ˆì¸": ["ì—°ì˜ˆ ë‰´ìŠ¤ ì‡¼ì¸ ", "ì•„ì´ëŒ ê·¼í™©", "ì—°ì˜ˆì¸ ë…¼ë€"],
        "ìš´ë™ì„ ìˆ˜": ["ìŠ¤í¬ì¸  ë‰´ìŠ¤ ì‡¼ì¸ ", "ì¶•êµ¬ ì„ ìˆ˜", "ì•¼êµ¬ ì„ ìˆ˜"],
        "êµ­ë½•": ["í•œêµ­ ìë‘", "K-ë¬¸í™”", "ì™¸êµ­ì¸ ë°˜ì‘"],
    }

    category_queries = queries.get(category, queries["ì—°ì˜ˆì¸"])

    all_videos = []
    seen_ids = set()

    for query in category_queries:
        videos = search_trending_shorts(
            query=query,
            max_results=max_results // len(category_queries),
            hours_ago=hours_ago,
        )

        for v in videos:
            if v["video_id"] not in seen_ids:
                v["engagement_score"] = calculate_engagement_score(v)
                all_videos.append(v)
                seen_ids.add(v["video_id"])

    # ì°¸ì—¬ë„ìˆœ ì •ë ¬
    all_videos.sort(key=lambda x: x["engagement_score"], reverse=True)

    # ì£¼ì œ ì¶”ì¶œ
    topics = extract_trending_topics(all_videos)

    return {
        "videos": all_videos,
        "topics": topics,
        "best_topic": topics[0] if topics else None,
        "category": category,
        "search_time": datetime.now(timezone.utc).isoformat(),
    }


def get_best_shorts_topic(
    categories: List[str] = None,
    min_engagement: float = 30,
) -> Optional[Dict[str, Any]]:
    """
    ì‡¼ì¸  ì œì‘ì— ê°€ì¥ ì í•©í•œ íŠ¸ë Œë”© ì£¼ì œ ì°¾ê¸°

    Args:
        categories: ê²€ìƒ‰í•  ì¹´í…Œê³ ë¦¬ (Noneì´ë©´ ì „ì²´)
        min_engagement: ìµœì†Œ ì°¸ì—¬ë„ ì ìˆ˜

    Returns:
        {
            "topic": "ë°•ë‚˜ë˜ ê°‘ì§ˆ",
            "category": "ì—°ì˜ˆì¸",
            "video_count": 5,
            "total_views": 1234567,
            "sample_videos": [...],
            "top_comments": [...],
        }
    """
    if categories is None:
        categories = ["ì—°ì˜ˆì¸"]

    best_topic = None
    best_score = 0

    for category in categories:
        print(f"[YouTube] === {category} ì¹´í…Œê³ ë¦¬ ê²€ìƒ‰ ===")

        result = search_shorts_by_category(category=category)

        if result["best_topic"]:
            topic = result["best_topic"]
            score = topic["avg_engagement"]

            print(f"  ğŸ”¥ {topic['topic']}: {topic['video_count']}ê°œ ì˜ìƒ, {topic['total_views']:,}íšŒ ì¡°íšŒ")

            if score > best_score and score >= min_engagement:
                best_score = score
                best_topic = topic
                best_topic["category"] = category

                # ìƒìœ„ ì˜ìƒì˜ ëŒ“ê¸€ ìˆ˜ì§‘
                if topic["sample_videos"]:
                    top_video = topic["sample_videos"][0]
                    comments = get_video_comments(top_video["video_id"], max_results=20)
                    best_topic["top_comments"] = comments[:10]

    if best_topic:
        print(f"[YouTube] âœ… ìµœì  ì£¼ì œ: {best_topic['topic']} (ì°¸ì—¬ë„ {best_score:.1f})")
    else:
        print(f"[YouTube] âŒ ì í•©í•œ ì£¼ì œ ì—†ìŒ (ìµœì†Œ ì°¸ì—¬ë„ {min_engagement} ë¯¸ë‹¬)")

    return best_topic


def youtube_to_news_format(topic: Dict[str, Any]) -> Dict[str, Any]:
    """
    YouTube ì£¼ì œë¥¼ ê¸°ì¡´ ë‰´ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    (ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ê³¼ í˜¸í™˜)
    """
    from datetime import datetime, timezone

    # ì¸ë¬¼ ì´ë¦„ ì¶”ì¶œ
    person = topic.get("topic", "").split()[0] if topic.get("topic") else "ì—°ì˜ˆì¸"

    # ì´ìŠˆ íƒ€ì… ì¶”ì¶œ
    issue_keywords = {
        "ë…¼ë€": "ë…¼ë€", "ê°‘ì§ˆ": "ë…¼ë€", "í­ë¡œ": "ë…¼ë€",
        "ì—´ì• ": "ì—´ì• ", "ê²°í˜¼": "ì—´ì• ", "ì´í˜¼": "ì—´ì• ",
        "ì»´ë°±": "ì»´ë°±", "ì‹ ê³¡": "ì»´ë°±",
        "ê·¼í™©": "ê·¼í™©", "ë³µê·€": "ê·¼í™©",
    }

    issue_type = "ê·¼í™©"
    topic_text = topic.get("topic", "")
    for kw, issue in issue_keywords.items():
        if kw in topic_text:
            issue_type = issue
            break

    # ìƒ˜í”Œ ì˜ìƒì—ì„œ ì •ë³´ ì¶”ì¶œ
    sample_videos = topic.get("sample_videos", [])
    best_video = sample_videos[0] if sample_videos else {}

    return {
        "run_id": datetime.now(timezone.utc).strftime("%Y-%m-%d"),
        "category": topic.get("category", "ì—°ì˜ˆì¸"),
        "person": person,
        "issue_type": issue_type,
        "news_title": topic.get("topic", "íŠ¸ë Œë”© ì£¼ì œ"),
        "news_url": f"https://youtube.com/watch?v={best_video.get('video_id', '')}" if best_video else "",
        "news_summary": f"{topic.get('video_count', 0)}ê°œ ì‡¼ì¸ , {topic.get('total_views', 0):,}íšŒ ì¡°íšŒ",
        "viral_score": {
            "total_score": topic.get("avg_engagement", 0),
            "grade": get_grade(topic.get("avg_engagement", 0)),
            "view_score": topic.get("total_views", 0) / 10000,
            "comment_score": 0,
            "controversy_score": 0,
            "recency_score": 100,
        },
        "script_hints": {
            "debate_topic": f"{person} ê´€ë ¨ ë…¼ìŸ",
            "hot_phrases": [c.get("text", "")[:30] for c in topic.get("top_comments", [])[:5]],
            "pro_comments": [],
            "con_comments": [],
        },
        "youtube_source": {
            "topic": topic.get("topic"),
            "video_count": topic.get("video_count", 0),
            "total_views": topic.get("total_views", 0),
            "sample_videos": sample_videos,
        },
        "ìƒíƒœ": "ì¤€ë¹„",
    }


def get_grade(score: float) -> str:
    """ì ìˆ˜ë¥¼ ë“±ê¸‰ìœ¼ë¡œ ë³€í™˜"""
    if score >= 80:
        return "S"
    elif score >= 60:
        return "A"
    elif score >= 40:
        return "B"
    elif score >= 20:
        return "C"
    return "D"


# CLI í…ŒìŠ¤íŠ¸
if __name__ == "__main__":
    import json

    print("=== YouTube íŠ¸ë Œë”© ì‡¼ì¸  ê²€ìƒ‰ í…ŒìŠ¤íŠ¸ ===\n")

    # ì—°ì˜ˆ ë‰´ìŠ¤ ê²€ìƒ‰
    result = search_shorts_by_category(category="ì—°ì˜ˆì¸", hours_ago=48)

    print(f"\nğŸ“Š ê²€ìƒ‰ ê²°ê³¼: {len(result['videos'])}ê°œ ì˜ìƒ")
    print(f"ğŸ“ˆ ì¶”ì¶œëœ ì£¼ì œ: {len(result['topics'])}ê°œ")

    if result["topics"]:
        print("\nğŸ”¥ ìƒìœ„ íŠ¸ë Œë”© ì£¼ì œ:")
        for i, topic in enumerate(result["topics"][:5], 1):
            print(f"  {i}. {topic['topic']}: {topic['video_count']}ê°œ ì˜ìƒ, {topic['total_views']:,}íšŒ")

    # ìµœì  ì£¼ì œ ì°¾ê¸°
    print("\n" + "="*50)
    best = get_best_shorts_topic(categories=["ì—°ì˜ˆì¸"])

    if best:
        # ë‰´ìŠ¤ í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        news_format = youtube_to_news_format(best)
        print(f"\nğŸ“‹ ë‰´ìŠ¤ í˜•ì‹ ë³€í™˜:")
        print(json.dumps(news_format, ensure_ascii=False, indent=2))
