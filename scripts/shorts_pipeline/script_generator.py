"""
ì‡¼ì¸  íŒŒì´í”„ë¼ì¸ - ëŒ€ë³¸ ë° ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±

GPT-5.1 Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬:
1. 60ì´ˆ ì‡¼ì¸  ëŒ€ë³¸ ìƒì„± (9ê°œ ì”¬)
2. ì”¬ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‹¤ë£¨ì—£ í¬í•¨)
"""

import os
import re
import json
from typing import Dict, Any, List, Optional

from openai import OpenAI


def repair_json(text: str) -> str:
    """
    ë¶ˆì™„ì „í•œ JSON ìˆ˜ì • ì‹œë„
    - ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
    - í›„í–‰ ì½¤ë§ˆ ì œê±°
    - ëˆ„ë½ëœ ì½¤ë§ˆ ì¶”ê°€
    """
    # 1) ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°
    if "```" in text:
        match = re.search(r'```(?:json)?\s*([\s\S]*?)\s*```', text)
        if match:
            text = match.group(1)
        else:
            # ì‹œì‘ë§Œ ìˆê³  ëì´ ì—†ëŠ” ê²½ìš°
            text = re.sub(r'^```(?:json)?\s*', '', text)
            text = re.sub(r'\s*```$', '', text)

    # 2) í›„í–‰ ì½¤ë§ˆ ì œê±° (ë°°ì—´/ê°ì²´ ëì˜ ì½¤ë§ˆ)
    text = re.sub(r',\s*([}\]])', r'\1', text)

    # 3) ì¤„ë°”ê¿ˆ í›„ ë”°ì˜´í‘œê°€ ì˜¤ëŠ”ë° ì½¤ë§ˆê°€ ì—†ëŠ” ê²½ìš° ìˆ˜ì •
    # "value"\n"key" â†’ "value",\n"key"
    text = re.sub(r'"\s*\n\s*"(?=[a-zA-Z_ê°€-í£])', '",\n"', text)

    # 4) ê°ì²´/ë°°ì—´ ë í›„ ì½¤ë§ˆ ì—†ì´ ë‹¤ìŒ ìš”ì†Œê°€ ì˜¤ëŠ” ê²½ìš°
    # }\n{ â†’ },\n{
    text = re.sub(r'}\s*\n\s*{', '},\n{', text)
    # ]\n[ â†’ ],\n[
    text = re.sub(r']\s*\n\s*\[', '],\n[', text)

    return text.strip()


def safe_json_parse(text: str) -> Dict[str, Any]:
    """
    ì•ˆì „í•œ JSON íŒŒì‹± (ìˆ˜ì • ì‹œë„ í¬í•¨)
    """
    # 1ì°¨ ì‹œë„: ì§ì ‘ íŒŒì‹±
    try:
        return json.loads(text)
    except json.JSONDecodeError:
        pass

    # 2ì°¨ ì‹œë„: ìˆ˜ì • í›„ íŒŒì‹±
    repaired = repair_json(text)
    try:
        return json.loads(repaired)
    except json.JSONDecodeError as e:
        # ìµœì¢… ì‹¤íŒ¨ ì‹œ ìƒì„¸ ì—ëŸ¬ ì¶œë ¥
        print(f"[SHORTS] JSON ìˆ˜ì • í›„ì—ë„ íŒŒì‹± ì‹¤íŒ¨")
        print(f"[SHORTS] ì—ëŸ¬ ìœ„ì¹˜: line {e.lineno}, col {e.colno}")
        print(f"[SHORTS] ìˆ˜ì •ëœ JSON ì• 500ì:\n{repaired[:500]}")
        raise

from .config import (
    DEFAULT_SCENE_COUNT,
    TARGET_SCRIPT_LENGTH,
    BACKGROUND_STYLES,
    SILHOUETTE_TEMPLATE,
    BACKGROUND_ONLY_TEMPLATE,
    VIDEO_WIDTH,
    VIDEO_HEIGHT,
)


# ê¸°ë³¸ ëª¨ë¸
DEFAULT_MODEL = "gpt-5.1"

# GPT-5.1 ë¹„ìš© (USD per 1K tokens)
GPT51_COSTS = {
    "input": 0.01,   # $0.01 per 1K input tokens
    "output": 0.03,  # $0.03 per 1K output tokens
}


def get_openai_client() -> OpenAI:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return OpenAI(api_key=api_key)


def extract_gpt51_response(response) -> str:
    """
    GPT-5.1 Responses API ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

    Args:
        response: client.responses.create() ì‘ë‹µ ê°ì²´

    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    # ë°©ë²• 1: output_text ì§ì ‘ ì ‘ê·¼
    if getattr(response, "output_text", None):
        return response.output_text.strip()

    # ë°©ë²• 2: output ë°°ì—´ì—ì„œ ì¶”ì¶œ
    text_chunks = []
    for item in getattr(response, "output", []) or []:
        for content in getattr(item, "content", []) or []:
            if getattr(content, "type", "") == "text":
                text_chunks.append(getattr(content, "text", ""))

    return "\n".join(text_chunks).strip()


SCRIPT_GENERATION_PROMPT = """
ë‹¹ì‹ ì€ ì¡°íšŒìˆ˜ 1000ë§Œì„ ë§Œë“œëŠ” ì—°ì˜ˆ ë‰´ìŠ¤ ì‡¼ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë‰´ìŠ¤ ì •ë³´ë¥¼ 30-40ì´ˆ YouTube Shorts ëŒ€ë³¸ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

## ë‰´ìŠ¤ ì •ë³´
- ì—°ì˜ˆì¸: {celebrity}
- ì´ìŠˆ ìœ í˜•: {issue_type}
- ë‰´ìŠ¤ ì œëª©: {news_title}
- ë‰´ìŠ¤ ìš”ì•½: {news_summary}
- í›… ë¬¸ì¥ (ì°¸ê³ ): {hook_text}

## ì‹¤ë£¨ì—£ íŠ¹ì§• (ì´ë¯¸ì§€ìš©)
{silhouette_desc}

## âš ï¸ ê°€ì¥ ì¤‘ìš”: ì²« 3ì´ˆ í›…

ì²« 3ì´ˆê°€ ì „ë¶€ì…ë‹ˆë‹¤. ì‹œì²­ìê°€ ìŠ¤í¬ë¡¤ì„ ë©ˆì¶”ê³  "ë­ì§€?" í•˜ê³  ë³´ê²Œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

### í›… ì‘ì„± ê³µì‹
1. **ê¶ê¸ˆì¦ ìœ ë°œ**: "ì´ê²Œ ì‚¬ì‹¤ì´ë¼ë©´..." / "ì•„ë¬´ë„ ëª°ëë˜..."
2. **ì¶©ê²© ì˜ˆê³ **: "ê²°êµ­ ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤" / "ëª¨ë‘ê°€ ì¶©ê²©ë°›ì•˜ìŠµë‹ˆë‹¤"
3. **ê°ì • ìê·¹**: "íŒ¬ë“¤ì´ ìš¸ì—ˆìŠµë‹ˆë‹¤" / "ì—…ê³„ê°€ ë°œì¹µ ë’¤ì§‘í˜”ìŠµë‹ˆë‹¤"
4. **ìˆ«ì í™œìš©**: "24ì‹œê°„ ë§Œì—..." / "10ë…„ ë§Œì— ì²˜ìŒ..."
5. **ëŒ€ë¹„ í™œìš©**: "ì›ƒìœ¼ë©° ë§í–ˆì§€ë§Œ..." / "ëª¨ë‘ê°€ ì¶•í•˜í–ˆëŠ”ë°..."

### í›… ê¸ˆì§€ í‘œí˜„
- "ì•ˆë…•í•˜ì„¸ìš”", "ì˜¤ëŠ˜ì€", "ì—¬ëŸ¬ë¶„" (ì§€ë£¨í•¨)
- ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘ (ì•½í•¨)
- ì„¤ëª…ìœ¼ë¡œ ì‹œì‘ (ì´íƒˆ)

## ğŸ”„ ìŠ¤í† ë¦¬ êµ¬ì¡° (í•µì‹¬!)

ì‹œì²­ìê°€ ëê¹Œì§€ ë³´ê³  "ì´ ê²°ë§ì´êµ¬ë‚˜!" í•˜ê³  ë§Œì¡±í•˜ê²Œ ë§Œë“œì„¸ìš”.
**ì ˆëŒ€ ë°˜ë³µ ê¸ˆì§€!** ê° ì”¬ì€ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë‹´ì•„ì•¼ í•©ë‹ˆë‹¤.

### âš ï¸ ë°˜ë³µ ê¸ˆì§€ ê·œì¹™
1. **í›… ë¬¸êµ¬ ë°˜ë³µ ê¸ˆì§€**: ì²« ì”¬ì˜ í›… ë¬¸êµ¬ë¥¼ ë§ˆì§€ë§‰ì— ì¬ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”
2. **ê°™ì€ í‘œí˜„ ê¸ˆì§€**: "ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤", "ê²°êµ­" ë“± 2ë²ˆ ì´ìƒ ì‚¬ìš© ê¸ˆì§€
3. **ê° ì”¬ ë…ë¦½ì **: ëª¨ë“  ì”¬ì´ ìƒˆë¡œìš´ ì‚¬ì‹¤/ê´€ì ì„ ì œê³µí•´ì•¼ í•¨

### ì¢‹ì€ ê²°ë§ ì˜ˆì‹œ
- "ì•ìœ¼ë¡œ [êµ¬ì²´ì  ìƒí™©]ì´ ì£¼ëª©ë©ë‹ˆë‹¤" (ë¯¸ë˜ ì˜ˆì¸¡)
- "ì´ ì‚¬ê±´ìœ¼ë¡œ [êµ¬ì²´ì  ë³€í™”]ê°€ ì˜ˆìƒë©ë‹ˆë‹¤" (íŒŒê¸‰ íš¨ê³¼)
- "[ì¸ë¬¼]ì˜ ë‹¤ìŒ í–‰ë³´ê°€ ê¶ê¸ˆí•´ì§‘ë‹ˆë‹¤" (í›„ì† ê´€ì‹¬)

### ë‚˜ìœ ê²°ë§ ì˜ˆì‹œ (ê¸ˆì§€!)
- âŒ "ê²°êµ­ ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤" (í›… ë°˜ë³µ)
- âŒ "ê·¸ë˜ì„œ [ì¸ë¬¼]ì€..." (ê²°ë¡  ì—†ì´ íì§€ë¶€ì§€)
- âŒ ì²« ì”¬ê³¼ ê°™ì€ ë¬¸ì¥ ì‚¬ìš©

## ğŸ“Œ ì‚¬ì‹¤ ê²€ì¦ ê·œì¹™ (í•„ìˆ˜!)

1. **ì¶œì²˜ ê¸°ë°˜**: ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ë§Œ ì‚¬ìš©, ì¶”ì¸¡/ì°½ì‘ ê¸ˆì§€
2. **í™•ì¸ëœ ì‚¬ì‹¤ë§Œ**: "~ë¼ê³  í•œë‹¤", "~ë¡œ ì•Œë ¤ì¡Œë‹¤" ë“± ë¶ˆí™•ì‹¤ í‘œí˜„ ì‚¬ìš©
3. **ë²•ì  ë¦¬ìŠ¤í¬ íšŒí”¼**:
   - ìœ ì£„ í™•ì • ì „: "í˜ì˜", "ì˜í˜¹" í‘œí˜„ í•„ìˆ˜
   - "ë²”ì¸", "ê°€í•´ì" ë‹¨ì • ê¸ˆì§€
4. **ê¸ˆì§€ í‘œí˜„**: "í™•ì‹¤íˆ ~ì´ë‹¤", "~ì„ì´ ë°í˜€ì¡Œë‹¤"(ë¯¸í™•ì¸), ë¹„ì†ì–´

## ğŸ’¬ ëŒ“ê¸€ ìœ ë„ ê¸°ìˆ  (ì•Œê³ ë¦¬ì¦˜ í•µì‹¬!)

ëŒ“ê¸€ì´ ë§ìœ¼ë©´ ì•Œê³ ë¦¬ì¦˜ì´ ì˜ìƒì„ ë” ë§ì´ ë…¸ì¶œí•©ë‹ˆë‹¤.
ì”¬5(ì—¬ë¡ )ë‚˜ ì”¬7(ë°˜ì „) í›„ì— ìì—°ìŠ¤ëŸ½ê²Œ ëŒ“ê¸€ ìœ ë„ ë¬¸êµ¬ë¥¼ ì‚½ì…í•˜ì„¸ìš”.

### ëŒ“ê¸€ ìœ ë„ ê¸°ë²•
1. **ì˜ê²¬ ìš”ì²­**: "ì—¬ëŸ¬ë¶„ ìƒê°ì€ ì–´ë– ì„¸ìš”?" (ìì—°ìŠ¤ëŸ½ê²Œ)
2. **íˆ¬í‘œí˜•**: "ì‘ì›í•˜ë©´ â¤ï¸, ì‹¤ë§ì´ë©´ ğŸ’”" (ì°¸ì—¬ ìœ ë„)
3. **ì˜ˆì¸¡í˜•**: "ì•ìœ¼ë¡œ ì–´ë–»ê²Œ ë ê¹Œìš”?" (ê¶ê¸ˆì¦ ì—°ì¥)
4. **ë…¼ìŸ ìœ ë°œ**: "íŒ¬ë“¤ ì‚¬ì´ì—ì„œë„ ì˜ê²¬ì´ ê°ˆë¦¬ê³  ìˆìŠµë‹ˆë‹¤" (ì–‘ì¸¡ ì˜ê²¬ ì¶©ëŒ)
5. **ê²½í—˜ ê³µìœ **: "ë¹„ìŠ·í•œ ê²½í—˜ ìˆìœ¼ì‹  ë¶„?" (ê³µê°ëŒ€ í˜•ì„±)

### ëŒ“ê¸€ ìœ ë„ ì˜ˆì‹œ
- "ì´ê±°... ì—¬ëŸ¬ë¶„ì€ ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?" (ì”¬5 ë)
- "ê²°ê³¼ê°€ ì–´ë–»ê²Œ ë ì§€... ëŒ“ê¸€ë¡œ ì˜ˆì¸¡í•´ë³´ì„¸ìš”" (ì”¬7 ë)

## ëŒ€ë³¸ ê·œì¹™
1. ì´ 200-260ì (30-40ì´ˆ TTS ê¸°ì¤€)
2. 5ê°œ ì”¬ìœ¼ë¡œ êµ¬ì„± (ì§§ê³  ì„íŒ©íŠ¸ìˆê²Œ!)
3. ëª¨ë“  ë¬¸ì¥ì€ ì§§ê³  ê°•ë ¬í•˜ê²Œ (í•œ ë¬¸ì¥ 15ì ì´ë‚´ ê¶Œì¥)
4. ì‚¬ì‹¤ ê¸°ë°˜, ì¶”ì¸¡/ë¹„ë°© ê¸ˆì§€
5. **ë§¤ ì”¬ë§ˆë‹¤ ìƒˆë¡œìš´ ì •ë³´** (ë°˜ë³µ ì ˆëŒ€ ê¸ˆì§€!)
6. **ì”¬4ì— ëŒ“ê¸€ ìœ ë„ ë¬¸êµ¬ 1ê°œ í•„ìˆ˜ ì‚½ì…**

## ì”¬ êµ¬ì„± ê°€ì´ë“œ (30-40ì´ˆ, 5ê°œ ì”¬)
- ì”¬1 (0-3ì´ˆ): âš¡ í‚¬ëŸ¬ í›… - ìŠ¤í¬ë¡¤ ë©ˆì¶”ê²Œ
- ì”¬2 (3-12ì´ˆ): ìƒí™© ì„¤ëª… - ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆë‚˜
- ì”¬3 (12-22ì´ˆ): í•µì‹¬ ë‚´ìš© - ê°€ì¥ ì¶©ê²©ì ì¸ ì‚¬ì‹¤
- ì”¬4 (22-32ì´ˆ): ë°˜ì‘/ì—¬ë¡  + ğŸ’¬ëŒ“ê¸€ìœ ë„
- ì”¬5 (32-40ì´ˆ): ğŸ¯ ê²°ë¡  - êµ¬ì²´ì  ë§ˆë¬´ë¦¬ (í›… ë°˜ë³µ ê¸ˆì§€!)

## ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê·œì¹™
- ì˜ì–´ë¡œ ì‘ì„±
- 9:16 ì„¸ë¡œ ë¹„ìœ¨ (YouTube Shorts)
- âš ï¸ ì‹¤ë£¨ì—£ì€ ì”¬1ì—ë§Œ! ë‚˜ë¨¸ì§€ëŠ” ëŒ€ë³¸ ë‚´ìš©ì— ë§ëŠ” ë°°ê²½ ì´ë¯¸ì§€
- ì”¬1: ì—°ì˜ˆì¸ ì‹¤ë£¨ì—£ (ê²€ì€ ê·¸ë¦¼ì, ì²« ì¸ìƒìš©)
- ì”¬2-4: ëŒ€ë³¸ ë‚´ìš©ì„ ì‹œê°í™”í•œ ë°°ê²½ (ì‚¬ëŒ ì—†ì´!)
- ì”¬5: ê²°ë¡  ë¶„ìœ„ê¸°ì— ë§ëŠ” ì´ë¯¸ì§€
- í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê³µê°„ í™•ë³´
- 4K í€„ë¦¬í‹°, ì˜í™”ì  ì¡°ëª…

## ì¶œë ¥ í˜•ì‹ (JSONë§Œ ë°˜í™˜)
{{
    "title": "ì‡¼ì¸  ì œëª© (30ì ì´ë‚´, ì´ëª¨ì§€ 1-2ê°œ, ê¶ê¸ˆì¦ ìœ ë°œ)",
    "hook_strength": "í›…ì˜ ê°•ë„ 1-10ì  ìì²´ í‰ê°€",
    "no_repetition_check": "ê° ì”¬ì´ ë°˜ë³µ ì—†ì´ ìƒˆë¡œìš´ ì •ë³´ë¥¼ ë‹´ê³  ìˆëŠ”ì§€ í™•ì¸ (ì˜ˆ/ì•„ë‹ˆì˜¤)",
    "comment_trigger": {{
        "scene": 4,
        "type": "opinion/vote/predict/debate/share ì¤‘ í•˜ë‚˜",
        "text": "ì‹¤ì œ ì‚½ì…ëœ ëŒ“ê¸€ ìœ ë„ ë¬¸êµ¬"
    }},
    "fact_sources": ["ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¸ìš©í•œ ì‚¬ì‹¤ë“¤ ìš”ì•½"],
    "bgm": {{
        "mood": "hopeful/sad/tense/dramatic/calm/inspiring/mysterious/epic/romantic/upbeat ì¤‘ í•˜ë‚˜",
        "reason": "ì´ ë¶„ìœ„ê¸°ë¥¼ ì„ íƒí•œ ì´ìœ  (í•œ ì¤„)"
    }},
    "highlight_keywords": ["ì¶©ê²©", "í­ë¡œ", "...ìë§‰ì—ì„œ ê°•ì¡°í•  í‚¤ì›Œë“œë“¤"],

    "youtube_seo": {{
        "title": "YouTube ì œëª© (70ì ì´ë‚´, í•µì‹¬ í‚¤ì›Œë“œ ì•ì—, ì´ëª¨ì§€ 1-2ê°œ)",
        "description": "YouTube ì„¤ëª…\\n- ì²« ì¤„: í•µì‹¬ ìš”ì•½\\n- ì£¼ìš” í¬ì¸íŠ¸ 3ê°œ\\n- í•´ì‹œíƒœê·¸\\n\\n#ì—°ì˜ˆì¸ì´ë¦„ #ì´ìŠˆ #Shorts",
        "tags": ["ì¸ë¬¼ëª…í•œê¸€", "ì¸ë¬¼ëª…ì˜ë¬¸", "ì´ìŠˆí‚¤ì›Œë“œ", "ì—°ì˜ˆë‰´ìŠ¤", "ì‡¼ì¸ ", "ìµœëŒ€30ê°œ"]
    }},

    "thumbnail": {{
        "hook_text": "ì¸ë„¤ì¼ì— í‘œì‹œí•  í•µì‹¬ ë¬¸êµ¬ (10ì ì´ë‚´, 2ì¤„ë¡œ ì¤„ë°”ê¿ˆ ê°€ëŠ¥)",
        "style": "ë…¼ë€/ì—´ì• /ì„±ê³¼/ìë‘/default ì¤‘ í•˜ë‚˜ (ì´ìŠˆ íƒ€ì…ì— ë§ê²Œ)",
        "image_prompt": "ì¸ë„¤ì¼ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì˜ì–´, ì‹¤ë£¨ì—£ í¬í•¨, ê·¹ì  ì¡°ëª…)"
    }},

    "scenes": [
        {{
            "scene_number": 1,
            "duration": "0-3ì´ˆ",
            "narration": "í‚¬ëŸ¬ í›… ë¬¸ì¥",
            "image_prompt": "ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì‹¤ë£¨ì—£ í¬í•¨)",
            "text_overlay": "í™”ë©´ í•µì‹¬ í…ìŠ¤íŠ¸ (5ì ì´ë‚´)",
            "emphasis": true
        }},
        ...ì´ 5ê°œ ì”¬
    ],
    "total_chars": 260,
    "estimated_seconds": 35,
    "hashtags": ["#ì—°ì˜ˆ", "#ì´ìŠˆ", "#ì‡¼ì¸ ", "..."]
}}
"""


def generate_shorts_script(
    celebrity: str,
    issue_type: str,
    news_title: str,
    news_summary: str,
    hook_text: str,
    silhouette_desc: str,
    model: str = None
) -> Dict[str, Any]:
    """
    GPT-5.1 Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‡¼ì¸  ëŒ€ë³¸ ìƒì„±

    Args:
        celebrity: ì—°ì˜ˆì¸ ì´ë¦„
        issue_type: ì´ìŠˆ ìœ í˜•
        news_title: ë‰´ìŠ¤ ì œëª©
        news_summary: ë‰´ìŠ¤ ìš”ì•½
        hook_text: í›… ë¬¸ì¥
        silhouette_desc: ì‹¤ë£¨ì—£ íŠ¹ì§• ì„¤ëª…
        model: ì‚¬ìš©í•  GPT ëª¨ë¸ (ê¸°ë³¸: gpt-5.1)

    Returns:
        {
            "ok": True,
            "title": "ì‡¼ì¸  ì œëª©",
            "scenes": [...],
            "full_script": "ì „ì²´ ëŒ€ë³¸",
            "total_chars": 450,
            "hashtags": [...],
            "cost": 0.03
        }
    """
    if model is None:
        model = DEFAULT_MODEL

    try:
        client = get_openai_client()

        user_prompt = SCRIPT_GENERATION_PROMPT.format(
            celebrity=celebrity,
            issue_type=issue_type,
            news_title=news_title,
            news_summary=news_summary,
            hook_text=hook_text,
            silhouette_desc=silhouette_desc,
        )

        system_prompt = "ë‹¹ì‹ ì€ ì—°ì˜ˆ ë‰´ìŠ¤ ì‡¼ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."

        print(f"[SHORTS] GPT-5.1 ëŒ€ë³¸ ìƒì„± ì¤‘: {celebrity} - {issue_type}")

        # GPT-5.1 Responses API í˜¸ì¶œ
        response = client.responses.create(
            model=model,
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": system_prompt}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": user_prompt}]
                }
            ],
            temperature=0.7
        )

        # ì‘ë‹µ ì¶”ì¶œ
        result_text = extract_gpt51_response(response)

        if not result_text:
            raise ValueError("GPT-5.1ì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤")

        # ì•ˆì „í•œ JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì œê±° + ìˆ˜ì • ì‹œë„)
        result = safe_json_parse(result_text)

        # ì „ì²´ ëŒ€ë³¸ ì¡°í•©
        full_script = "\n".join([
            scene["narration"] for scene in result.get("scenes", [])
        ])

        # ë¹„ìš© ê³„ì‚° (GPT-5.1 ê¸°ì¤€)
        # usage ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì¶”ì •
        if hasattr(response, 'usage') and response.usage:
            input_tokens = getattr(response.usage, 'input_tokens', 0) or getattr(response.usage, 'prompt_tokens', 0)
            output_tokens = getattr(response.usage, 'output_tokens', 0) or getattr(response.usage, 'completion_tokens', 0)
        else:
            # ëŒ€ëµì  ì¶”ì • (í•œê¸€ ê¸°ì¤€)
            input_tokens = len(system_prompt + user_prompt) // 2
            output_tokens = len(result_text) // 2

        cost = (input_tokens * GPT51_COSTS["input"] + output_tokens * GPT51_COSTS["output"]) / 1000

        print(f"[SHORTS] GPT-5.1 ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: {len(full_script)}ì, ${cost:.4f}")

        # YouTube SEO ë°ì´í„° ì¶”ì¶œ
        youtube_seo = result.get("youtube_seo", {})
        if not youtube_seo:
            # ê¸°ë³¸ê°’ ìƒì„±
            youtube_seo = {
                "title": result.get("title", f"{celebrity} ì´ìŠˆ"),
                "description": f"{result.get('title', celebrity)}\n\n#Shorts #{celebrity}",
                "tags": [celebrity, issue_type, "ì‡¼ì¸ ", "ì—°ì˜ˆë‰´ìŠ¤"] + result.get("hashtags", [])[:10],
            }

        # ì¸ë„¤ì¼ ë°ì´í„° ì¶”ì¶œ
        thumbnail = result.get("thumbnail", {})
        if not thumbnail:
            # ê¸°ë³¸ê°’ ìƒì„±
            thumbnail = {
                "hook_text": result.get("title", celebrity)[:20],
                "style": issue_type if issue_type in ["ë…¼ë€", "ì—´ì• ", "ì„±ê³¼", "ìë‘"] else "default",
                "image_prompt": f"YouTube Shorts thumbnail, dramatic black silhouette of {silhouette_desc}, spotlight, 9:16 vertical",
            }

        return {
            "ok": True,
            "title": result.get("title", f"{celebrity} ì´ìŠˆ"),
            "scenes": result.get("scenes", []),
            "full_script": full_script,
            "total_chars": len(full_script),
            "hashtags": result.get("hashtags", []),
            "youtube_seo": youtube_seo,
            "thumbnail": thumbnail,
            "bgm": result.get("bgm", {"mood": "dramatic", "reason": "ê¸°ë³¸ê°’"}),
            "highlight_keywords": result.get("highlight_keywords", []),
            "comment_trigger": result.get("comment_trigger", {}),
            "cost": round(cost, 4),
            "model": model,
        }

    except json.JSONDecodeError as e:
        print(f"[SHORTS] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"[SHORTS] ì›ë³¸ ì‘ë‹µ: {result_text[:500] if 'result_text' in dir() else 'N/A'}")
        return {"ok": False, "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}"}
    except Exception as e:
        print(f"[SHORTS] ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"ok": False, "error": str(e)}


def enhance_image_prompts(
    scenes: List[Dict[str, Any]],
    celebrity: str,
    silhouette_desc: str
) -> List[Dict[str, Any]]:
    """
    ì”¬ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê°•í™”

    - ì”¬1 (í›…): ì—°ì˜ˆì¸ ì‹¤ë£¨ì—£ í¬í•¨ (ì˜ìƒë‹¹ ìœ ì¼í•œ ì‹¤ë£¨ì—£!)
    - ë‚˜ë¨¸ì§€: ëŒ€ë³¸ ë‚´ìš©ì— ë§ëŠ” ë°°ê²½ ì´ë¯¸ì§€ (ì‹¤ë£¨ì—£ ì—†ìŒ)

    Args:
        scenes: GPTê°€ ìƒì„±í•œ ì”¬ ëª©ë¡
        celebrity: ì—°ì˜ˆì¸ ì´ë¦„
        silhouette_desc: ì‹¤ë£¨ì—£ íŠ¹ì§• ì„¤ëª…

    Returns:
        ê°•í™”ëœ ì”¬ ëª©ë¡
    """
    enhanced_scenes = []
    total_scenes = len(scenes)

    for scene in scenes:
        scene_num = scene.get("scene_number", 1)
        original_prompt = scene.get("image_prompt", "")
        narration = scene.get("narration", "")
        is_last_scene = (scene_num == total_scenes)

        # 9:16 ë¹„ìœ¨ ê°•ì œ
        aspect_instruction = (
            f"CRITICAL: Generate image in EXACT 9:16 VERTICAL PORTRAIT aspect ratio. "
            f"Target dimensions: {VIDEO_WIDTH}x{VIDEO_HEIGHT} pixels. "
            f"This is MANDATORY for YouTube Shorts format."
        )

        if scene_num == 1:
            # ì²« ì”¬ (í›…): ì˜ìƒì—ì„œ ìœ ì¼í•˜ê²Œ ì‹¤ë£¨ì—£ í¬í•¨
            enhanced_prompt = f"""
{aspect_instruction}

{original_prompt}

IMPORTANT - HOOK SCENE (ONLY silhouette in this video):
- Include a dramatic black silhouette of {silhouette_desc}
- Spotlight from above casting long shadow
- NO facial features visible - only dark shadow outline
- URGENT, BREAKING NEWS atmosphere
- Red/orange dramatic lighting
- Large empty space at top and bottom for Korean text overlay
- 4K quality, cinematic lighting, high contrast
"""
        elif is_last_scene:
            # ë§ˆì§€ë§‰ ì”¬: ê²°ë¡  ë¶„ìœ„ê¸° (ì‹¤ë£¨ì—£ ì—†ìŒ!)
            enhanced_prompt = f"""
{aspect_instruction}

{original_prompt}

IMPORTANT - CONCLUSION SCENE:
- NO silhouettes, NO people, NO human figures
- Create atmosphere matching the conclusion: "{narration[:50]}..."
- Symbolic imagery representing the story's ending
- Professional, polished look
- Large empty space for Korean text overlay
- 4K quality, cinematic composition
"""
        else:
            # ì¤‘ê°„ ì”¬: ëŒ€ë³¸ ë‚´ìš©ì— ë§ëŠ” ë°°ê²½ (ì‹¤ë£¨ì—£ ì—†ìŒ!)
            enhanced_prompt = f"""
{aspect_instruction}

{original_prompt}

IMPORTANT - CONTENT SCENE:
- NO silhouettes, NO people, NO human figures
- Visualize this narration: "{narration[:50]}..."
- Focus on objects, places, or abstract concepts from the story
- Dynamic, engaging visuals to prevent viewer drop-off
- Large empty space for Korean text overlay
- 4K quality, cinematic composition
- Korean news broadcast style atmosphere
"""

        scene["image_prompt_enhanced"] = enhanced_prompt.strip()
        enhanced_scenes.append(scene)

    return enhanced_scenes


def generate_complete_shorts_package(
    news_data: Dict[str, Any],
    model: str = None
) -> Dict[str, Any]:
    """
    ì‡¼ì¸  ì „ì²´ íŒ¨í‚¤ì§€ ìƒì„± (ëŒ€ë³¸ + ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸)

    Args:
        news_data: {
            "celebrity": "...",
            "issue_type": "...",
            "news_title": "...",
            "news_summary": "...",
            "hook_text": "...",
            "silhouette_desc": "..."
        }

    Returns:
        {
            "ok": True,
            "title": "ì‡¼ì¸  ì œëª©",
            "full_script": "ì „ì²´ ëŒ€ë³¸",
            "scenes": [
                {
                    "scene_number": 1,
                    "narration": "...",
                    "image_prompt_enhanced": "...",
                    "text_overlay": "..."
                },
                ...
            ],
            "hashtags": [...],
            "cost": 0.03
        }
    """
    # 1) ëŒ€ë³¸ ìƒì„±
    # person í•„ë“œ ìš°ì„ , ì—†ìœ¼ë©´ celebrity í˜¸í™˜
    person = news_data.get("person", news_data.get("celebrity", ""))

    script_result = generate_shorts_script(
        celebrity=person,  # í•¨ìˆ˜ íŒŒë¼ë¯¸í„°ëŠ” celebrityë¡œ ìœ ì§€ (ë‚´ë¶€ ì‚¬ìš©)
        issue_type=news_data.get("issue_type", ""),
        news_title=news_data.get("news_title", ""),
        news_summary=news_data.get("news_summary", ""),
        hook_text=news_data.get("hook_text", ""),
        silhouette_desc=news_data.get("silhouette_desc", ""),
        model=model,
    )

    if not script_result.get("ok"):
        return script_result

    # 2) ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê°•í™”
    enhanced_scenes = enhance_image_prompts(
        scenes=script_result.get("scenes", []),
        celebrity=person,
        silhouette_desc=news_data.get("silhouette_desc", ""),
    )

    return {
        "ok": True,
        "title": script_result.get("title"),
        "full_script": script_result.get("full_script"),
        "scenes": enhanced_scenes,
        "total_chars": script_result.get("total_chars"),
        "hashtags": script_result.get("hashtags", []),
        "youtube_seo": script_result.get("youtube_seo", {}),
        "thumbnail": script_result.get("thumbnail", {}),
        "bgm": script_result.get("bgm", {}),
        "highlight_keywords": script_result.get("highlight_keywords", []),
        "comment_trigger": script_result.get("comment_trigger", {}),
        "cost": script_result.get("cost", 0),
    }


def format_script_for_sheet(scenes: List[Dict[str, Any]]) -> str:
    """
    ì”¬ ëª©ë¡ì„ ì‹œíŠ¸ ì €ì¥ìš© ëŒ€ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

    Returns:
        "[ì”¬1] í›… ë¬¸ì¥\n[ì”¬2] ì„¤ëª… ë¬¸ì¥\n..."
    """
    lines = []
    for scene in scenes:
        scene_num = scene.get("scene_number", 0)
        narration = scene.get("narration", "")
        lines.append(f"[ì”¬{scene_num}] {narration}")
    return "\n".join(lines)
