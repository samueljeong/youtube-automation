"""
ì‡¼ì¸  íŒŒì´í”„ë¼ì¸ - ëŒ€ë³¸ ë° ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±

GPT-5.1 Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬:
1. 60ì´ˆ ì‡¼ì¸  ëŒ€ë³¸ ìƒì„± (9ê°œ ì”¬)
2. ì”¬ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± (ì‹¤ë£¨ì—£ í¬í•¨)
"""

import os
import json
from typing import Dict, Any, List, Optional

from openai import OpenAI

from .config import (
    DEFAULT_SCENE_COUNT,
    TARGET_SCRIPT_LENGTH,
    BACKGROUND_STYLES,
    SILHOUETTE_TEMPLATE,
    BACKGROUND_ONLY_TEMPLATE,
    VIDEO_WIDTH,
    VIDEO_HEIGHT,
)


# ê¸°ë³¸ ëª¨ë¸
DEFAULT_MODEL = "gpt-5.1"

# GPT-5.1 ë¹„ìš© (USD per 1K tokens)
GPT51_COSTS = {
    "input": 0.01,   # $0.01 per 1K input tokens
    "output": 0.03,  # $0.03 per 1K output tokens
}


def get_openai_client() -> OpenAI:
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    api_key = os.environ.get("OPENAI_API_KEY")
    if not api_key:
        raise ValueError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
    return OpenAI(api_key=api_key)


def extract_gpt51_response(response) -> str:
    """
    GPT-5.1 Responses API ì‘ë‹µì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ

    Args:
        response: client.responses.create() ì‘ë‹µ ê°ì²´

    Returns:
        ì¶”ì¶œëœ í…ìŠ¤íŠ¸
    """
    # ë°©ë²• 1: output_text ì§ì ‘ ì ‘ê·¼
    if getattr(response, "output_text", None):
        return response.output_text.strip()

    # ë°©ë²• 2: output ë°°ì—´ì—ì„œ ì¶”ì¶œ
    text_chunks = []
    for item in getattr(response, "output", []) or []:
        for content in getattr(item, "content", []) or []:
            if getattr(content, "type", "") == "text":
                text_chunks.append(getattr(content, "text", ""))

    return "\n".join(text_chunks).strip()


SCRIPT_GENERATION_PROMPT = """
ë‹¹ì‹ ì€ ì¡°íšŒìˆ˜ 1000ë§Œì„ ë§Œë“œëŠ” ì—°ì˜ˆ ë‰´ìŠ¤ ì‡¼ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.
ì•„ë˜ ë‰´ìŠ¤ ì •ë³´ë¥¼ 40-60ì´ˆ YouTube Shorts ëŒ€ë³¸ìœ¼ë¡œ ë³€í™˜í•˜ì„¸ìš”.

## ë‰´ìŠ¤ ì •ë³´
- ì—°ì˜ˆì¸: {celebrity}
- ì´ìŠˆ ìœ í˜•: {issue_type}
- ë‰´ìŠ¤ ì œëª©: {news_title}
- ë‰´ìŠ¤ ìš”ì•½: {news_summary}
- í›… ë¬¸ì¥ (ì°¸ê³ ): {hook_text}

## ì‹¤ë£¨ì—£ íŠ¹ì§• (ì´ë¯¸ì§€ìš©)
{silhouette_desc}

## âš ï¸ ê°€ì¥ ì¤‘ìš”: ì²« 3ì´ˆ í›…

ì²« 3ì´ˆê°€ ì „ë¶€ì…ë‹ˆë‹¤. ì‹œì²­ìê°€ ìŠ¤í¬ë¡¤ì„ ë©ˆì¶”ê³  "ë­ì§€?" í•˜ê³  ë³´ê²Œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

### í›… ì‘ì„± ê³µì‹
1. **ê¶ê¸ˆì¦ ìœ ë°œ**: "ì´ê²Œ ì‚¬ì‹¤ì´ë¼ë©´..." / "ì•„ë¬´ë„ ëª°ëë˜..."
2. **ì¶©ê²© ì˜ˆê³ **: "ê²°êµ­ ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤" / "ëª¨ë‘ê°€ ì¶©ê²©ë°›ì•˜ìŠµë‹ˆë‹¤"
3. **ê°ì • ìê·¹**: "íŒ¬ë“¤ì´ ìš¸ì—ˆìŠµë‹ˆë‹¤" / "ì—…ê³„ê°€ ë°œì¹µ ë’¤ì§‘í˜”ìŠµë‹ˆë‹¤"
4. **ìˆ«ì í™œìš©**: "24ì‹œê°„ ë§Œì—..." / "10ë…„ ë§Œì— ì²˜ìŒ..."
5. **ëŒ€ë¹„ í™œìš©**: "ì›ƒìœ¼ë©° ë§í–ˆì§€ë§Œ..." / "ëª¨ë‘ê°€ ì¶•í•˜í–ˆëŠ”ë°..."

### í›… ê¸ˆì§€ í‘œí˜„
- "ì•ˆë…•í•˜ì„¸ìš”", "ì˜¤ëŠ˜ì€", "ì—¬ëŸ¬ë¶„" (ì§€ë£¨í•¨)
- ì§ˆë¬¸ìœ¼ë¡œ ì‹œì‘ (ì•½í•¨)
- ì„¤ëª…ìœ¼ë¡œ ì‹œì‘ (ì´íƒˆ)

## ğŸ”„ ë¬´í•œë£¨í”„ êµ¬ì¡° (í•µì‹¬!)

ë§ˆì§€ë§‰ ì”¬ì´ ì²« ì”¬ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°ë˜ì–´ì•¼ í•©ë‹ˆë‹¤.
ì‹œì²­ìê°€ "ì–´? ì˜ìƒì´ ëë‚¬ë‚˜?" í•˜ê³  í—·ê°ˆë¦¬ê²Œ ë§Œë“¤ì–´ í•œ ë²ˆ ë” ë³´ê²Œ ë§Œë“œì„¸ìš”.

### ë¬´í•œë£¨í”„ ì˜ˆì‹œ
- ì²« ì”¬: "ë°•ë‚˜ë˜, ê²°êµ­ ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤"
- ë§ˆì§€ë§‰ ì”¬: "ê·¸ë¦¬ê³  ì´ ì‚¬ê±´ì€... (ì ì‹œ ë©ˆì¶¤) ì´ë ‡ê²Œ ëìŠµë‹ˆë‹¤" â†’ ìì—°ìŠ¤ëŸ½ê²Œ ì²« ì”¬ìœ¼ë¡œ

### ë¬´í•œë£¨í”„ ê¸°ë²•
1. ë§ˆì§€ë§‰ì— ê²°ë¡ ì„ ì™„ì „íˆ ë§í•˜ì§€ ì•ŠìŒ
2. ë§ˆì§€ë§‰ ë¶„ìœ„ê¸°ê°€ ì²« ì”¬ê³¼ ë¹„ìŠ·í•˜ê²Œ
3. "ê·¸ë˜ì„œ ê²°êµ­..." ìœ¼ë¡œ ëë‚´ê³  ì²« í›…ê³¼ ì—°ê²°
4. CTA(êµ¬ë… ìœ ë„) ì ˆëŒ€ ë„£ì§€ ì•ŠìŒ - ë£¨í”„ ê¹¨ì§

## ğŸ“Œ ì‚¬ì‹¤ ê²€ì¦ ê·œì¹™ (í•„ìˆ˜!)

1. **ì¶œì²˜ ê¸°ë°˜**: ë‰´ìŠ¤ ê¸°ì‚¬ ë‚´ìš©ë§Œ ì‚¬ìš©, ì¶”ì¸¡/ì°½ì‘ ê¸ˆì§€
2. **í™•ì¸ëœ ì‚¬ì‹¤ë§Œ**: "~ë¼ê³  í•œë‹¤", "~ë¡œ ì•Œë ¤ì¡Œë‹¤" ë“± ë¶ˆí™•ì‹¤ í‘œí˜„ ì‚¬ìš©
3. **ë²•ì  ë¦¬ìŠ¤í¬ íšŒí”¼**:
   - ìœ ì£„ í™•ì • ì „: "í˜ì˜", "ì˜í˜¹" í‘œí˜„ í•„ìˆ˜
   - "ë²”ì¸", "ê°€í•´ì" ë‹¨ì • ê¸ˆì§€
4. **ê¸ˆì§€ í‘œí˜„**: "í™•ì‹¤íˆ ~ì´ë‹¤", "~ì„ì´ ë°í˜€ì¡Œë‹¤"(ë¯¸í™•ì¸), ë¹„ì†ì–´

## ğŸ’¬ ëŒ“ê¸€ ìœ ë„ ê¸°ìˆ  (ì•Œê³ ë¦¬ì¦˜ í•µì‹¬!)

ëŒ“ê¸€ì´ ë§ìœ¼ë©´ ì•Œê³ ë¦¬ì¦˜ì´ ì˜ìƒì„ ë” ë§ì´ ë…¸ì¶œí•©ë‹ˆë‹¤.
ì”¬5(ì—¬ë¡ )ë‚˜ ì”¬7(ë°˜ì „) í›„ì— ìì—°ìŠ¤ëŸ½ê²Œ ëŒ“ê¸€ ìœ ë„ ë¬¸êµ¬ë¥¼ ì‚½ì…í•˜ì„¸ìš”.

### ëŒ“ê¸€ ìœ ë„ ê¸°ë²•
1. **ì˜ê²¬ ìš”ì²­**: "ì—¬ëŸ¬ë¶„ ìƒê°ì€ ì–´ë– ì„¸ìš”?" (ìì—°ìŠ¤ëŸ½ê²Œ)
2. **íˆ¬í‘œí˜•**: "ì‘ì›í•˜ë©´ â¤ï¸, ì‹¤ë§ì´ë©´ ğŸ’”" (ì°¸ì—¬ ìœ ë„)
3. **ì˜ˆì¸¡í˜•**: "ì•ìœ¼ë¡œ ì–´ë–»ê²Œ ë ê¹Œìš”?" (ê¶ê¸ˆì¦ ì—°ì¥)
4. **ë…¼ìŸ ìœ ë°œ**: "íŒ¬ë“¤ ì‚¬ì´ì—ì„œë„ ì˜ê²¬ì´ ê°ˆë¦¬ê³  ìˆìŠµë‹ˆë‹¤" (ì–‘ì¸¡ ì˜ê²¬ ì¶©ëŒ)
5. **ê²½í—˜ ê³µìœ **: "ë¹„ìŠ·í•œ ê²½í—˜ ìˆìœ¼ì‹  ë¶„?" (ê³µê°ëŒ€ í˜•ì„±)

### ëŒ“ê¸€ ìœ ë„ ì˜ˆì‹œ
- "ì´ê±°... ì—¬ëŸ¬ë¶„ì€ ì–´ë–»ê²Œ ìƒê°í•˜ì„¸ìš”?" (ì”¬5 ë)
- "ê²°ê³¼ê°€ ì–´ë–»ê²Œ ë ì§€... ëŒ“ê¸€ë¡œ ì˜ˆì¸¡í•´ë³´ì„¸ìš”" (ì”¬7 ë)

## ëŒ€ë³¸ ê·œì¹™
1. ì´ 350-400ì (40-60ì´ˆ TTS ê¸°ì¤€)
2. 8ê°œ ì”¬ìœ¼ë¡œ êµ¬ì„± (ë§ˆì§€ë§‰ì€ ë£¨í”„ ì—°ê²°)
3. ëª¨ë“  ë¬¸ì¥ì€ ì§§ê³  ê°•ë ¬í•˜ê²Œ (í•œ ë¬¸ì¥ 15ì ì´ë‚´ ê¶Œì¥)
4. ì‚¬ì‹¤ ê¸°ë°˜, ì¶”ì¸¡/ë¹„ë°© ê¸ˆì§€
5. ë§¤ ì”¬ë§ˆë‹¤ ìƒˆë¡œìš´ ì •ë³´ â†’ ì´íƒˆ ë°©ì§€
6. **ì”¬5 ë˜ëŠ” ì”¬7ì— ëŒ“ê¸€ ìœ ë„ ë¬¸êµ¬ 1ê°œ í•„ìˆ˜ ì‚½ì…**

## ì”¬ êµ¬ì„± ê°€ì´ë“œ (40-60ì´ˆ)
- ì”¬1 (0-3ì´ˆ): âš¡ í‚¬ëŸ¬ í›… - ìŠ¤í¬ë¡¤ ë©ˆì¶”ê²Œ
- ì”¬2 (3-10ì´ˆ): ìƒí™© ì„¤ëª… - ë¬´ìŠ¨ ì¼?
- ì”¬3 (10-18ì´ˆ): í•µì‹¬ í­ë¡œ - ê°€ì¥ ì¶©ê²©ì ì¸ ë‚´ìš©
- ì”¬4 (18-26ì´ˆ): ë°˜ì‘ - ë³¸ì¸/ì†Œì†ì‚¬
- ì”¬5 (26-34ì´ˆ): ì—¬ë¡  - ë„¤í‹°ì¦Œ ë°˜ì‘ + ğŸ’¬ëŒ“ê¸€ìœ ë„
- ì”¬6 (34-42ì´ˆ): íŒŒì¥ - ì–´ë–¤ ì˜í–¥?
- ì”¬7 (42-50ì´ˆ): ë°˜ì „/ì¶”ê°€ ì •ë³´ + ğŸ’¬ëŒ“ê¸€ìœ ë„ (ì„ íƒ)
- ì”¬8 (50-55ì´ˆ): ğŸ”„ ë£¨í”„ ì—°ê²° - ì²« ì”¬ê³¼ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°

## ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê·œì¹™
- ì˜ì–´ë¡œ ì‘ì„±
- 9:16 ì„¸ë¡œ ë¹„ìœ¨ (YouTube Shorts)
- ì—°ì˜ˆì¸ ì–¼êµ´ ì‚¬ìš© ê¸ˆì§€ - ì‹¤ë£¨ì—£ë§Œ ì‚¬ìš©
- ì”¬1, ì”¬8: ì—°ì˜ˆì¸ ì‹¤ë£¨ì—£ í¬í•¨ (ë£¨í”„ ì—°ê²°ìš©)
- ë‚˜ë¨¸ì§€: ë¶„ìœ„ê¸° ë°°ê²½
- í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê³µê°„ í™•ë³´

## ì¶œë ¥ í˜•ì‹ (JSONë§Œ ë°˜í™˜)
{{
    "title": "ì‡¼ì¸  ì œëª© (30ì ì´ë‚´, ì´ëª¨ì§€ 1-2ê°œ, ê¶ê¸ˆì¦ ìœ ë°œ)",
    "hook_strength": "í›…ì˜ ê°•ë„ 1-10ì  ìì²´ í‰ê°€",
    "loop_connection": "ì²« ì”¬ê³¼ ë§ˆì§€ë§‰ ì”¬ì´ ì–´ë–»ê²Œ ì—°ê²°ë˜ëŠ”ì§€ ì„¤ëª…",
    "comment_trigger": {{
        "scene": 5,
        "type": "opinion/vote/predict/debate/share ì¤‘ í•˜ë‚˜",
        "text": "ì‹¤ì œ ì‚½ì…ëœ ëŒ“ê¸€ ìœ ë„ ë¬¸êµ¬"
    }},
    "fact_sources": ["ë‰´ìŠ¤ ê¸°ì‚¬ì—ì„œ ì¸ìš©í•œ ì‚¬ì‹¤ë“¤ ìš”ì•½"],
    "scenes": [
        {{
            "scene_number": 1,
            "duration": "0-3ì´ˆ",
            "narration": "í‚¬ëŸ¬ í›… ë¬¸ì¥",
            "image_prompt": "ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì‹¤ë£¨ì—£ í¬í•¨)",
            "text_overlay": "í™”ë©´ í•µì‹¬ í…ìŠ¤íŠ¸ (5ì ì´ë‚´)"
        }},
        ...ì´ 8ê°œ ì”¬ (ë§ˆì§€ë§‰ì€ ë£¨í”„ ì—°ê²°)
    ],
    "total_chars": 380,
    "estimated_seconds": 50,
    "hashtags": ["#ì—°ì˜ˆ", "#ì´ìŠˆ", "#ì‡¼ì¸ ", "..."]
}}
"""


def generate_shorts_script(
    celebrity: str,
    issue_type: str,
    news_title: str,
    news_summary: str,
    hook_text: str,
    silhouette_desc: str,
    model: str = None
) -> Dict[str, Any]:
    """
    GPT-5.1 Responses APIë¥¼ ì‚¬ìš©í•˜ì—¬ ì‡¼ì¸  ëŒ€ë³¸ ìƒì„±

    Args:
        celebrity: ì—°ì˜ˆì¸ ì´ë¦„
        issue_type: ì´ìŠˆ ìœ í˜•
        news_title: ë‰´ìŠ¤ ì œëª©
        news_summary: ë‰´ìŠ¤ ìš”ì•½
        hook_text: í›… ë¬¸ì¥
        silhouette_desc: ì‹¤ë£¨ì—£ íŠ¹ì§• ì„¤ëª…
        model: ì‚¬ìš©í•  GPT ëª¨ë¸ (ê¸°ë³¸: gpt-5.1)

    Returns:
        {
            "ok": True,
            "title": "ì‡¼ì¸  ì œëª©",
            "scenes": [...],
            "full_script": "ì „ì²´ ëŒ€ë³¸",
            "total_chars": 450,
            "hashtags": [...],
            "cost": 0.03
        }
    """
    if model is None:
        model = DEFAULT_MODEL

    try:
        client = get_openai_client()

        user_prompt = SCRIPT_GENERATION_PROMPT.format(
            celebrity=celebrity,
            issue_type=issue_type,
            news_title=news_title,
            news_summary=news_summary,
            hook_text=hook_text,
            silhouette_desc=silhouette_desc,
        )

        system_prompt = "ë‹¹ì‹ ì€ ì—°ì˜ˆ ë‰´ìŠ¤ ì‡¼ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ ìˆœìˆ˜ JSONë§Œ ì¶œë ¥í•˜ì„¸ìš”."

        print(f"[SHORTS] GPT-5.1 ëŒ€ë³¸ ìƒì„± ì¤‘: {celebrity} - {issue_type}")

        # GPT-5.1 Responses API í˜¸ì¶œ
        response = client.responses.create(
            model=model,
            input=[
                {
                    "role": "system",
                    "content": [{"type": "input_text", "text": system_prompt}]
                },
                {
                    "role": "user",
                    "content": [{"type": "input_text", "text": user_prompt}]
                }
            ],
            temperature=0.7
        )

        # ì‘ë‹µ ì¶”ì¶œ
        result_text = extract_gpt51_response(response)

        if not result_text:
            raise ValueError("GPT-5.1ì—ì„œ ë¹ˆ ì‘ë‹µì„ ë°›ì•˜ìŠµë‹ˆë‹¤")

        # JSON íŒŒì‹± (```json ... ``` í˜•ì‹ ì²˜ë¦¬)
        if result_text.startswith("```"):
            # ì½”ë“œ ë¸”ë¡ ì œê±°
            lines = result_text.split("\n")
            if lines[0].startswith("```"):
                lines = lines[1:]
            if lines[-1].strip() == "```":
                lines = lines[:-1]
            result_text = "\n".join(lines)

        result = json.loads(result_text)

        # ì „ì²´ ëŒ€ë³¸ ì¡°í•©
        full_script = "\n".join([
            scene["narration"] for scene in result.get("scenes", [])
        ])

        # ë¹„ìš© ê³„ì‚° (GPT-5.1 ê¸°ì¤€)
        # usage ì •ë³´ê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ì¶”ì •
        if hasattr(response, 'usage') and response.usage:
            input_tokens = getattr(response.usage, 'input_tokens', 0) or getattr(response.usage, 'prompt_tokens', 0)
            output_tokens = getattr(response.usage, 'output_tokens', 0) or getattr(response.usage, 'completion_tokens', 0)
        else:
            # ëŒ€ëµì  ì¶”ì • (í•œê¸€ ê¸°ì¤€)
            input_tokens = len(system_prompt + user_prompt) // 2
            output_tokens = len(result_text) // 2

        cost = (input_tokens * GPT51_COSTS["input"] + output_tokens * GPT51_COSTS["output"]) / 1000

        print(f"[SHORTS] GPT-5.1 ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: {len(full_script)}ì, ${cost:.4f}")

        return {
            "ok": True,
            "title": result.get("title", f"{celebrity} ì´ìŠˆ"),
            "scenes": result.get("scenes", []),
            "full_script": full_script,
            "total_chars": len(full_script),
            "hashtags": result.get("hashtags", []),
            "cost": round(cost, 4),
            "model": model,
        }

    except json.JSONDecodeError as e:
        print(f"[SHORTS] JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        print(f"[SHORTS] ì›ë³¸ ì‘ë‹µ: {result_text[:500] if 'result_text' in dir() else 'N/A'}")
        return {"ok": False, "error": f"JSON íŒŒì‹± ì‹¤íŒ¨: {e}"}
    except Exception as e:
        print(f"[SHORTS] ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {e}")
        return {"ok": False, "error": str(e)}


def enhance_image_prompts(
    scenes: List[Dict[str, Any]],
    celebrity: str,
    silhouette_desc: str
) -> List[Dict[str, Any]]:
    """
    ì”¬ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê°•í™”

    - ì”¬1 (í›…): ì—°ì˜ˆì¸ ì‹¤ë£¨ì—£ í¬í•¨
    - ì”¬8 (ë£¨í”„ ì—°ê²°): ì—°ì˜ˆì¸ ì‹¤ë£¨ì—£ í¬í•¨ (ì²« ì”¬ê³¼ ë¹„ìŠ·í•˜ê²Œ)
    - ë‚˜ë¨¸ì§€: ë¶„ìœ„ê¸° ë°°ê²½

    Args:
        scenes: GPTê°€ ìƒì„±í•œ ì”¬ ëª©ë¡
        celebrity: ì—°ì˜ˆì¸ ì´ë¦„
        silhouette_desc: ì‹¤ë£¨ì—£ íŠ¹ì§• ì„¤ëª…

    Returns:
        ê°•í™”ëœ ì”¬ ëª©ë¡
    """
    enhanced_scenes = []
    total_scenes = len(scenes)

    for scene in scenes:
        scene_num = scene.get("scene_number", 1)
        original_prompt = scene.get("image_prompt", "")
        is_last_scene = (scene_num == total_scenes) or (scene_num == 8)

        # 9:16 ë¹„ìœ¨ ê°•ì œ
        aspect_instruction = (
            f"CRITICAL: Generate image in EXACT 9:16 VERTICAL PORTRAIT aspect ratio. "
            f"Target dimensions: {VIDEO_WIDTH}x{VIDEO_HEIGHT} pixels. "
            f"This is MANDATORY for YouTube Shorts format."
        )

        if scene_num == 1:
            # ì²« ì”¬ (í›…): ì‹¤ë£¨ì—£ í¬í•¨ + ê°•ë ¬í•œ ë¶„ìœ„ê¸°
            enhanced_prompt = f"""
{aspect_instruction}

{original_prompt}

IMPORTANT - HOOK SCENE:
- Include a black silhouette of {silhouette_desc}
- Dramatic spotlight from above casting long shadow
- NO facial features visible - only dark shadow outline
- URGENT, BREAKING NEWS atmosphere
- Red/orange dramatic lighting
- Large empty space at top and bottom for Korean text overlay
- 4K quality, cinematic lighting, high contrast
"""
        elif is_last_scene:
            # ë§ˆì§€ë§‰ ì”¬ (ë£¨í”„ ì—°ê²°): ì²« ì”¬ê³¼ ë¹„ìŠ·í•œ ë¶„ìœ„ê¸° + ì‹¤ë£¨ì—£
            enhanced_prompt = f"""
{aspect_instruction}

{original_prompt}

IMPORTANT - LOOP CONNECTION SCENE (similar to first scene):
- Include a black silhouette of {silhouette_desc}
- Similar composition to the opening scene for seamless loop
- Dramatic spotlight from above
- NO facial features visible - only dark shadow outline
- Slightly different angle but same mood as scene 1
- Large empty space for Korean text overlay
- 4K quality, cinematic lighting
"""
        else:
            # ì¤‘ê°„ ì”¬: ë°°ê²½ ìœ„ì£¼
            enhanced_prompt = f"""
{aspect_instruction}

{original_prompt}

IMPORTANT - BACKGROUND SCENE:
- NO people or human figures in this scene
- Focus on atmospheric background and mood
- Dynamic, engaging visuals to prevent viewer drop-off
- Large empty space for Korean text overlay
- 4K quality, cinematic composition
- Korean news broadcast style
"""

        scene["image_prompt_enhanced"] = enhanced_prompt.strip()
        enhanced_scenes.append(scene)

    return enhanced_scenes


def generate_complete_shorts_package(
    news_data: Dict[str, Any],
    model: str = None
) -> Dict[str, Any]:
    """
    ì‡¼ì¸  ì „ì²´ íŒ¨í‚¤ì§€ ìƒì„± (ëŒ€ë³¸ + ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸)

    Args:
        news_data: {
            "celebrity": "...",
            "issue_type": "...",
            "news_title": "...",
            "news_summary": "...",
            "hook_text": "...",
            "silhouette_desc": "..."
        }

    Returns:
        {
            "ok": True,
            "title": "ì‡¼ì¸  ì œëª©",
            "full_script": "ì „ì²´ ëŒ€ë³¸",
            "scenes": [
                {
                    "scene_number": 1,
                    "narration": "...",
                    "image_prompt_enhanced": "...",
                    "text_overlay": "..."
                },
                ...
            ],
            "hashtags": [...],
            "cost": 0.03
        }
    """
    # 1) ëŒ€ë³¸ ìƒì„±
    script_result = generate_shorts_script(
        celebrity=news_data.get("celebrity", ""),
        issue_type=news_data.get("issue_type", ""),
        news_title=news_data.get("news_title", ""),
        news_summary=news_data.get("news_summary", ""),
        hook_text=news_data.get("hook_text", ""),
        silhouette_desc=news_data.get("silhouette_desc", ""),
        model=model,
    )

    if not script_result.get("ok"):
        return script_result

    # 2) ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê°•í™”
    enhanced_scenes = enhance_image_prompts(
        scenes=script_result.get("scenes", []),
        celebrity=news_data.get("celebrity", ""),
        silhouette_desc=news_data.get("silhouette_desc", ""),
    )

    return {
        "ok": True,
        "title": script_result.get("title"),
        "full_script": script_result.get("full_script"),
        "scenes": enhanced_scenes,
        "total_chars": script_result.get("total_chars"),
        "hashtags": script_result.get("hashtags", []),
        "cost": script_result.get("cost", 0),
    }


def format_script_for_sheet(scenes: List[Dict[str, Any]]) -> str:
    """
    ì”¬ ëª©ë¡ì„ ì‹œíŠ¸ ì €ì¥ìš© ëŒ€ë³¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜

    Returns:
        "[ì”¬1] í›… ë¬¸ì¥\n[ì”¬2] ì„¤ëª… ë¬¸ì¥\n..."
    """
    lines = []
    for scene in scenes:
        scene_num = scene.get("scene_number", 0)
        narration = scene.get("narration", "")
        lines.append(f"[ì”¬{scene_num}] {narration}")
    return "\n".join(lines)
