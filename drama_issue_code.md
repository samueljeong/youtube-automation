# ë“œë¼ë§ˆ ì•± ë¬¸ì œ ì½”ë“œ - Opus 4.5 ë¶„ì„ìš©

## ğŸš¨ ë°œìƒ ì¤‘ì¸ ë¬¸ì œ

### 1. TTS ìŒì„± ìƒì„± ì˜¤ë¥˜
```
ì˜¤ë¥˜: Google TTS API ì˜¤ë¥˜ (400): {
  "error": {
    "code": 400,
    "message": "Either `input.text` or `input.ssml` is longer than the limit of 5000 bytes.
                This limit is different from quotas. To fix, reduce the byte length of the
                characters in this request, or consider using the Long Audio API:
                https://cloud.google.com/text-to-speech/docs/create-audio-text-long-audio-synthesis.",
    "status": "INVALID_ARGUMENT"
  }
}
```

### 2. í•œêµ­ì¸ ì¸ë¬¼ ì´ë¯¸ì§€ ìƒì„± ë¬¸ì œ
- í•œêµ­ í• ë¨¸ë‹ˆ/í• ì•„ë²„ì§€ ìƒì„± ì‹œ ì™¸êµ­ì¸ ì‚¬ì§„ì´ ë‚˜ì˜´
- ì”¬ 2, 3, 4ì—ì„œ ëª¨ë‘ ë™ì¼í•œ ë¬¸ì œ ë°œìƒ

---

## ğŸ“ ê´€ë ¨ ì½”ë“œ (drama_server.py)

### 1. TTS ìƒì„± í•¨ìˆ˜ (ë¼ì¸ 2913-3160)

```python
@app.route('/api/drama/generate-tts', methods=['POST'])
def api_generate_tts():
    """TTS ìŒì„± ìƒì„± - Google Cloud TTS (ê¸°ë³¸) ë˜ëŠ” ë„¤ì´ë²„ í´ë¡œë°”"""
    try:
        import requests
        import base64

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        text = data.get("text", "")
        speaker = data.get("speaker", "ko-KR-Wavenet-A")
        speed = data.get("speed", 1.0)
        pitch = data.get("pitch", 0)
        volume = data.get("volume", 0)
        tts_provider = data.get("ttsProvider", "google")

        if not text:
            return jsonify({"ok": False, "error": "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        char_count = len(text)

        # Google Cloud TTS
        if tts_provider == "google":
            google_api_key = os.getenv("GOOGLE_CLOUD_API_KEY", "")

            if not google_api_key:
                return jsonify({"ok": False, "error": "Google Cloud API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 200

            print(f"[TTS] Google TTS ìƒì„± ì‹œì‘ - ìŒì„±: {speaker}, í…ìŠ¤íŠ¸ ê¸¸ì´: {char_count}ì")

            # ê°ì • í‘œí˜„ í‚¤ì›Œë“œ
            emotional_keywords = [
                "ëˆˆë¬¼ì´", "ëˆˆì‹œìš¸", "ì†ì´ ë–¨", "ëª©ì´ ë©”", "ê°€ìŠ´ì´ ë¨¹ë¨¹",
                "ìŠ¬", "ì•„í”„", "ê³ í†µ", "ì ˆë§", "ë‘ë ¤", "ê°ì‚¬", "ì •ë§", "ì§„ì‹¬ìœ¼ë¡œ", "ê°„ì ˆíˆ"
            ]

            def apply_emotion_ssml(text_chunk, base_rate):
                """ê°ì • í‘œí˜„ì´ ìˆëŠ” ë¬¸ì¥ì— SSML ì†ë„ ì¡°ì ˆ ì ìš©"""
                import re
                import html

                def escape_for_ssml(text):
                    return html.escape(text, quote=False)

                sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', text_chunk)
                merged = []
                i = 0
                while i < len(sentences):
                    if i + 1 < len(sentences) and sentences[i+1] in '.!?ã€‚ï¼ï¼Ÿ':
                        merged.append(sentences[i] + sentences[i+1])
                        i += 2
                    else:
                        if sentences[i].strip():
                            merged.append(sentences[i])
                        i += 1

                result_parts = []
                has_emotion = False

                for sentence in merged:
                    sentence = sentence.strip()
                    if not sentence:
                        continue

                    is_emotional = any(kw in sentence for kw in emotional_keywords)

                    if is_emotional:
                        has_emotion = True
                        emotion_rate = max(0.25, base_rate * 0.9)
                        escaped_sentence = escape_for_ssml(sentence)
                        result_parts.append(f'<break time="300ms"/><prosody rate="{emotion_rate:.2f}">{escaped_sentence}</prosody><break time="200ms"/>')
                    else:
                        result_parts.append(escape_for_ssml(sentence))

                if has_emotion:
                    ssml_text = f'<speak>{" ".join(result_parts)}</speak>'
                    return ssml_text, True
                else:
                    return text_chunk, False

            # Google Cloud TTSëŠ” ìµœëŒ€ 5000ë°”ì´íŠ¸ ì œí•œ
            # í•œê¸€ì€ UTF-8ì—ì„œ 3ë°”ì´íŠ¸ì´ë¯€ë¡œ ì•ˆì „í•˜ê²Œ 3500ë°”ì´íŠ¸(ì•½ 1166ì) ì´í•˜ë¡œ ìœ ì§€
            # SSML íƒœê·¸ ì˜¤ë²„í—¤ë“œ(ìµœëŒ€ 1500ë°”ì´íŠ¸)ë¥¼ ê³ ë ¤í•˜ì—¬ ì—¬ìœ ìˆê²Œ ì„¤ì •
            max_bytes = 3500
            text_chunks = []

            def get_byte_length(s):
                return len(s.encode('utf-8'))

            def split_text_by_bytes(text, max_bytes):
                """í…ìŠ¤íŠ¸ë¥¼ ë°”ì´íŠ¸ ì œí•œì— ë§ê²Œ ë¶„í• """
                chunks = []
                import re
                sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', text)
                merged_sentences = []
                i = 0
                while i < len(sentences):
                    if i + 1 < len(sentences) and sentences[i+1] in '.!?ã€‚ï¼ï¼Ÿ':
                        merged_sentences.append(sentences[i] + sentences[i+1])
                        i += 2
                    else:
                        if sentences[i].strip():
                            merged_sentences.append(sentences[i])
                        i += 1

                current_chunk = ""
                for sentence in merged_sentences:
                    sentence = sentence.strip()
                    if not sentence:
                        continue

                    if get_byte_length(sentence) > max_bytes:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                            current_chunk = ""
                        sub_parts = re.split(r'([,ï¼Œã€\s])', sentence)
                        sub_chunk = ""
                        for part in sub_parts:
                            if get_byte_length(sub_chunk + part) < max_bytes:
                                sub_chunk += part
                            else:
                                if sub_chunk:
                                    chunks.append(sub_chunk.strip())
                                sub_chunk = part
                        if sub_chunk:
                            current_chunk = sub_chunk
                    elif get_byte_length(current_chunk + " " + sentence) < max_bytes:
                        current_chunk = (current_chunk + " " + sentence).strip()
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = sentence

                if current_chunk:
                    chunks.append(current_chunk.strip())

                return chunks if chunks else [text[:1500]]

            text_chunks = split_text_by_bytes(text, max_bytes)
            print(f"[TTS] í…ìŠ¤íŠ¸ë¥¼ {len(text_chunks)}ê°œ ì²­í¬ë¡œ ë¶„í•  (ë°”ì´íŠ¸ ì œí•œ: {max_bytes})")

            audio_data_list = []
            url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={google_api_key}"

            # ì†ë„ ë³€í™˜
            if isinstance(speed, (int, float)):
                if speed == 0:
                    google_speed = 1.0
                else:
                    google_speed = 1.0 + (speed * 0.1)
                    google_speed = max(0.25, min(4.0, google_speed))
            else:
                google_speed = 1.0

            google_pitch = pitch * 4 if isinstance(pitch, (int, float)) else 0

            emotion_chunk_count = 0
            for chunk in text_chunks:
                processed_chunk, is_ssml = apply_emotion_ssml(chunk, google_speed)

                if is_ssml:
                    emotion_chunk_count += 1
                    payload = {
                        "input": {"ssml": processed_chunk},
                        "voice": {
                            "languageCode": "ko-KR",
                            "name": speaker
                        },
                        "audioConfig": {
                            "audioEncoding": "MP3",
                            "speakingRate": google_speed,
                            "pitch": google_pitch
                        }
                    }
                else:
                    payload = {
                        "input": {"text": chunk},
                        "voice": {
                            "languageCode": "ko-KR",
                            "name": speaker
                        },
                        "audioConfig": {
                            "audioEncoding": "MP3",
                            "speakingRate": google_speed,
                            "pitch": google_pitch
                        }
                    }

                response = requests.post(url, json=payload, timeout=90)

                if response.status_code == 200:
                    result = response.json()
                    audio_content = base64.b64decode(result.get("audioContent", ""))
                    audio_data_list.append(audio_content)
                else:
                    error_text = response.text
                    print(f"[TTS][ERROR] Google API ì‘ë‹µ: {response.status_code} - {error_text}")
                    return jsonify({"ok": False, "error": f"Google TTS API ì˜¤ë¥˜ ({response.status_code}): {error_text}"}), 200

            combined_audio = b''.join(audio_data_list)
            audio_base64 = base64.b64encode(combined_audio).decode('utf-8')
            audio_url = f"data:audio/mp3;base64,{audio_base64}"

            cost_per_char = 0.0054 if "Wavenet" in speaker else 0.0216
            cost_krw = int(char_count * cost_per_char)

            return jsonify({
                "ok": True,
                "audioUrl": audio_url,
                "charCount": char_count,
                "cost": cost_krw,
                "provider": "google",
                "emotionChunks": emotion_chunk_count,
                "totalChunks": len(text_chunks)
            })
```

### 2. ìºë¦­í„° ë¶„ì„ í•¨ìˆ˜ (ë¼ì¸ 2368-2452)

```python
@app.route('/api/drama/analyze-characters', methods=['POST'])
def api_analyze_characters():
    """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥ì¸ë¬¼ê³¼ ì”¬ ì •ë³´ ì¶”ì¶œ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        script = data.get("script", "")

        if not script:
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[ANALYZE] ë“±ì¥ì¸ë¬¼ ë° ì”¬ ë¶„ì„ ì‹œì‘")

        system_content = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥ì¸ë¬¼ê³¼ ì”¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ë“±ì¥ì¸ë¬¼ (characters): ê° ì¸ë¬¼ì— ëŒ€í•´
   - name: ì¸ë¬¼ ì´ë¦„ (í•œê¸€)
   - description: ì¸ë¬¼ ì„¤ëª… (ë‚˜ì´, ì„±ê²©, ì—­í•  ë“± - í•œê¸€)
   - imagePrompt: DALL-Eìš© ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì™¸ëª¨, ì˜ìƒ, ë¶„ìœ„ê¸° ë¬˜ì‚¬)

2. ì”¬ (scenes): ê° ì”¬ì— ëŒ€í•´
   - title: ì”¬ ì œëª© ë˜ëŠ” ìš”ì•½ (í•œê¸€)
   - location: ì¥ì†Œ (í•œê¸€)
   - description: ì”¬ ì„¤ëª… (í•œê¸€)
   - characters: ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ ì´ë¦„ ë°°ì—´
   - backgroundPrompt: DALL-Eìš© ì˜ì–´ ë°°ê²½ í”„ë¡¬í”„íŠ¸ (ì¥ì†Œ, ë¶„ìœ„ê¸°, ì¡°ëª… ë¬˜ì‚¬)

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ:
{
  "characters": [
    {"name": "ìˆ˜ì§„", "description": "28ì„¸ ì—¬ì„±, ë°ê³  í™œë°œí•œ ì„±ê²©ì˜ ì¹´í˜ ì‚¬ì¥", "imagePrompt": "A Korean woman in her late 20s with East Asian features, Korean ethnicity, bright and cheerful expression, casual smart outfit..."},
    ...
  ],
  "scenes": [
    {"title": "ì²« ë§Œë‚¨", "location": "ì¹´í˜", "description": "ìˆ˜ì§„ì´ ì²˜ìŒ ë¯¼ìˆ˜ë¥¼ ë§Œë‚˜ëŠ” ì¥ë©´", "characters": ["ìˆ˜ì§„", "ë¯¼ìˆ˜"], "backgroundPrompt": "A cozy Korean cafe interior, warm afternoon light..."},
    ...
  ]
}

ì¤‘ìš”:
- imagePromptì™€ backgroundPromptëŠ” ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±
- í”„ë¡¬í”„íŠ¸ëŠ” DALL-E 3ì— ìµœì í™”ë˜ë„ë¡ ìƒì„¸í•˜ê²Œ ì‘ì„±
- ì¸ë¬¼ í”„ë¡¬í”„íŠ¸ëŠ” portrait ìŠ¤íƒ€ì¼ì— ì í•©í•˜ê²Œ ì‘ì„±
- í•œêµ­ ë“œë¼ë§ˆ ìŠ¤íƒ€ì¼ì˜ ì‹œê°ì  ìš”ì†Œ ë°˜ì˜
- âš ï¸ CRITICAL: ëª¨ë“  ì¸ë¬¼ì˜ imagePromptëŠ” ë°˜ë“œì‹œ "Korean" ë˜ëŠ” "Korean ethnicity", "East Asian features"ë¥¼ ëª…ì‹œì ìœ¼ë¡œ í¬í•¨í•´ì•¼ í•©ë‹ˆë‹¤
- í•œêµ­ì¸ í• ë¨¸ë‹ˆ/í• ì•„ë²„ì§€ëŠ” "elderly Korean woman/man with East Asian features" ë“±ìœ¼ë¡œ ëª…í™•íˆ í‘œí˜„"""

        user_content = f"""ë‹¤ìŒ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

{script[:15000]}

âš ï¸ ì¤‘ìš”: ëŒ€ë³¸ì— ìˆëŠ” ëª¨ë“  ì”¬ì„ ë¹ ì§ì—†ì´ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
ë“±ì¥ì¸ë¬¼ê³¼ ì”¬ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )

        result = completion.choices[0].message.content.strip()

        import json as json_module
        parsed = json_module.loads(result)

        characters = parsed.get("characters", [])
        scenes = parsed.get("scenes", [])

        print(f"[ANALYZE] ë¶„ì„ ì™„ë£Œ - ì¸ë¬¼: {len(characters)}ëª…, ì”¬: {len(scenes)}ê°œ")

        return jsonify({
            "ok": True,
            "characters": characters,
            "scenes": scenes
        })

    except Exception as e:
        print(f"[ANALYZE][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200
```

### 3. ì´ë¯¸ì§€ ìƒì„± í•¨ìˆ˜ (ë¼ì¸ 2556-2909) - í•µì‹¬ ë¶€ë¶„ë§Œ

```python
@app.route('/api/drama/generate-image', methods=['POST'])
def api_generate_image():
    """ì´ë¯¸ì§€ ìƒì„± - Gemini (ê¸°ë³¸) / FLUX.1 Pro / DALL-E 3"""
    try:
        import requests as req

        data = request.get_json()
        prompt = data.get("prompt", "")
        size = data.get("size", "1024x1024")
        image_provider = data.get("imageProvider", "gemini")

        if not prompt:
            return jsonify({"ok": False, "error": "í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        # Gemini 2.5 Flash Image
        if image_provider == "gemini":
            openrouter_api_key = os.getenv("OPENROUTER_API_KEY", "")

            if not openrouter_api_key:
                return jsonify({"ok": False, "error": "OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 200

            # í”„ë¡¬í”„íŠ¸ì— ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ê°€ ë° í•œêµ­ ì¸ì¢… ê°•ì¡°
            if "Korean" in prompt or "korean" in prompt:
                enhanced_prompt = f"Generate a high quality, photorealistic image: {prompt}. IMPORTANT: Ensure the person has authentic Korean/East Asian facial features, Korean ethnicity. Style: cinematic lighting, professional photography, 8k resolution, detailed"
            else:
                enhanced_prompt = f"Generate a high quality, photorealistic image: {prompt}. Style: cinematic lighting, professional photography, 8k resolution, detailed"

            headers = {
                "Authorization": f"Bearer {openrouter_api_key}",
                "Content-Type": "application/json"
            }

            payload = {
                "model": "google/gemini-2.5-flash-image-preview",
                "modalities": ["text", "image"],
                "messages": [
                    {
                        "role": "user",
                        "content": [{"type": "text", "text": enhanced_prompt}]
                    }
                ]
            }

            response = req.post(
                "https://openrouter.ai/api/v1/chat/completions",
                headers=headers,
                json=payload,
                timeout=90
            )

            # ... (ì´ë¯¸ì§€ URL ì¶”ì¶œ ë¡œì§)

        # FLUX.1 Pro
        elif image_provider == "flux":
            # í”„ë¡¬í”„íŠ¸ ê°•í™”
            if "Korean" in prompt or "korean" in prompt:
                enhanced_prompt = f"{prompt}, IMPORTANT: authentic Korean/East Asian facial features and ethnicity, high quality, photorealistic"
            else:
                enhanced_prompt = f"{prompt}, high quality, photorealistic"

        # DALL-E 3
        else:
            # í”„ë¡¬í”„íŠ¸ ê°•í™”
            if "Korean" in prompt or "korean" in prompt:
                enhanced_prompt = f"{prompt}, IMPORTANT: authentic Korean/East Asian facial features and ethnicity, high quality, photorealistic"
            else:
                enhanced_prompt = f"{prompt}, high quality, photorealistic"

            response = client.images.generate(
                model="dall-e-3",
                prompt=enhanced_prompt,
                size=size,
                quality="standard",
                n=1
            )
```

---

## ğŸ“Œ ë¶„ì„ ìš”ì²­ì‚¬í•­

Opus 4.5ì—ê²Œ:

1. **TTS ë¬¸ì œ**: SSML íƒœê·¸ê°€ ì¶”ê°€ë  ë•Œ 5000ë°”ì´íŠ¸ë¥¼ ì´ˆê³¼í•˜ëŠ” ê²½ìš°ê°€ ì—¬ì „íˆ ë°œìƒí•©ë‹ˆë‹¤. `max_bytes = 3500`ìœ¼ë¡œ ì„¤ì •í–ˆëŠ”ë°ë„ ë¬¸ì œê°€ ê³„ì†ë©ë‹ˆë‹¤. ì™„ë²½í•˜ê²Œ í•´ê²°í•´ì£¼ì„¸ìš”.

2. **ì´ë¯¸ì§€ ìƒì„± ë¬¸ì œ**: í•œêµ­ì¸ ìºë¦­í„° í”„ë¡¬í”„íŠ¸ì— "Korean ethnicity", "East Asian features"ë¥¼ ëª…ì‹œí–ˆëŠ”ë°ë„ ì—¬ì „íˆ ì™¸êµ­ì¸ ì´ë¯¸ì§€ê°€ ìƒì„±ë©ë‹ˆë‹¤. ë” ê°•ë ¥í•œ ë°©ë²•ì´ í•„ìš”í•©ë‹ˆë‹¤.

3. ë‘ ë¬¸ì œ ëª¨ë‘ ì™„ë²½í•˜ê²Œ ì‘ë™í•˜ë„ë¡ ì½”ë“œë¥¼ ìˆ˜ì •í•˜ê³ , ì „ì²´ ìˆ˜ì •ëœ í•¨ìˆ˜ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”.
