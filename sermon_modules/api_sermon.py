"""
api_sermon.py
ì„¤êµ ì²˜ë¦¬ ê´€ë ¨ API Blueprint

í¬í•¨ëœ ë¼ìš°íŠ¸:
- POST /api/sermon/process      - Step ì²˜ë¦¬ (Step1, Step2)
- POST /api/sermon/meditation   - ë¬µìƒë©”ì‹œì§€ ìƒì„±
- POST /api/sermon/gpt-pro      - GPT PRO (Step3)
- POST /api/sermon/qa           - Q&A ì§ˆì˜ì‘ë‹µ
- POST /api/sermon/recommend-scripture - ë³¸ë¬¸ ì¶”ì²œ
- POST /api/sermon/chat         - ì„¤êµ ì±—ë´‡

ì‚¬ìš©ë²•:
    from sermon_modules.api_sermon import api_sermon_bp, init_sermon_api
    init_sermon_api(client)  # OpenAI í´ë¼ì´ì–¸íŠ¸ ì£¼ì…
    app.register_blueprint(api_sermon_bp)
"""

import json
import time
import hashlib
import threading
from flask import Blueprint, request, jsonify, session

from .db import get_db_connection, USE_POSTGRES
from .utils import (
    calculate_cost, format_json_result, remove_markdown,
    is_json_guide, parse_json_guide
)
from .auth import (
    api_login_required, AUTH_ENABLED,
    get_user_credits, use_credit
)
from .prompt import (
    get_system_prompt_for_step, build_prompt_from_json, build_step3_prompt_from_json
)
from .strongs import analyze_verse_strongs, format_strongs_for_prompt
from .commentary import (
    init_commentary_service, get_verse_commentary, format_commentary_for_prompt
)
from .context import get_current_context, format_context_for_prompt, init_context_service

api_sermon_bp = Blueprint('api_sermon', __name__, url_prefix='/api/sermon')

# OpenAI í´ë¼ì´ì–¸íŠ¸ (init_sermon_apiì—ì„œ ì£¼ì…)
_client = None


def init_sermon_api(client):
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì£¼ì…"""
    global _client
    _client = client
    # Commentary ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (GPT ê¸°ë°˜ ì£¼ì„ ìƒì„±ìš©)
    init_commentary_service(client)
    # Context ì„œë¹„ìŠ¤ ì´ˆê¸°í™” (ì˜ˆí™” ê²€ì¦ìš©)
    init_context_service(client)


def get_client():
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ë°˜í™˜"""
    if _client is None:
        raise RuntimeError("OpenAI client not initialized. Call init_sermon_api() first.")
    return _client


# ===== í—¬í¼ í•¨ìˆ˜ë“¤ =====

def log_api_usage(step_name, model_name, input_tokens=0, output_tokens=0, style_name=None, category=None, user_id=None):
    """API ì‚¬ìš©ëŸ‰ì„ DBì— ê¸°ë¡"""
    try:
        total_tokens = input_tokens + output_tokens
        estimated_cost = calculate_cost(model_name, input_tokens, output_tokens)

        conn = get_db_connection()
        cursor = conn.cursor()
        if USE_POSTGRES:
            cursor.execute('''
                INSERT INTO api_usage_logs (step_name, model_name, style_name, category, input_tokens, output_tokens, total_tokens, estimated_cost_usd, user_id)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s)
            ''', (step_name, model_name, style_name, category, input_tokens, output_tokens, total_tokens, estimated_cost, user_id))
        else:
            cursor.execute('''
                INSERT INTO api_usage_logs (step_name, model_name, style_name, category, input_tokens, output_tokens, total_tokens, estimated_cost_usd, user_id)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (step_name, model_name, style_name, category, input_tokens, output_tokens, total_tokens, estimated_cost, user_id))
        conn.commit()
        conn.close()
        print(f"[USAGE-LOG] {step_name} - {model_name}: {total_tokens} tokens, ${estimated_cost:.6f}")
        return True
    except Exception as e:
        print(f"[USAGE-LOG] ê¸°ë¡ ì‹¤íŒ¨: {e}")
        return False


def save_step1_analysis(reference, sermon_text, analysis_text, category="", style_name="", step_name="step1"):
    """
    Step1 ë³¸ë¬¸ ë¶„ì„ ê²°ê³¼ë¥¼ ìë™ìœ¼ë¡œ DBì— ì €ì¥
    """
    try:
        client = get_client()

        # ë¶„ì„ í•´ì‹œ ìƒì„± (ì¤‘ë³µ ì²´í¬ìš©)
        hash_content = f"{reference}|{analysis_text}"
        analysis_hash = hashlib.md5(hash_content.encode('utf-8')).hexdigest()

        # DB ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            if USE_POSTGRES:
                cursor.execute("SELECT id FROM step1_analyses WHERE analysis_hash = %s", (analysis_hash,))
            else:
                cursor.execute("SELECT id FROM step1_analyses WHERE analysis_hash = ?", (analysis_hash,))
            existing = cursor.fetchone()
            conn.close()

            if existing:
                print(f"[STEP1-SAVE] ì¤‘ë³µ ë¶„ì„ ê°ì§€ (í•´ì‹œ: {analysis_hash[:8]}...) - ì €ì¥ ê±´ë„ˆëœ€")
                return {"ok": True, "message": "ì¤‘ë³µ ë¶„ì„ - ì €ì¥ ê±´ë„ˆëœ€", "isDuplicate": True}
        except Exception as e:
            print(f"[STEP1-SAVE] ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {str(e)}")

        print(f"[STEP1-SAVE] Step1 ë¶„ì„ ì €ì¥ ì‹œì‘ - ë³¸ë¬¸: {reference[:30]}...")

        # GPTë¡œ ë¶„ì„ í’ˆì§ˆ í‰ê°€
        evaluation_system = """ë‹¹ì‹ ì€ ì„±ê²½ ë³¸ë¬¸ ë¶„ì„ í‰ê°€ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì œê³µëœ ì„±ê²½ ë³¸ë¬¸ ë¶„ì„ì„ í‰ê°€í•˜ì—¬ ë‹¤ìŒ 3ê°€ì§€ ì ìˆ˜ë¥¼ 10ì  ë§Œì ìœ¼ë¡œ ë§¤ê¸°ì„¸ìš”:

1. **ì „ì²´ í’ˆì§ˆ (quality_score)**: ë¶„ì„ì˜ ì „ë°˜ì ì¸ ì™„ì„±ë„ì™€ ìœ ìš©ì„±
2. **ì‹ í•™ì  ê¹Šì´ (theological_depth_score)**: ì‹ í•™ì  í†µì°°ê³¼ í•´ì„ì˜ ê¹Šì´
3. **ì‹¤ì²œ ì ìš©ì„± (practical_application_score)**: ì‹¤ì œ ì„¤êµì— ì ìš© ê°€ëŠ¥í•œ ì •ë„

ê° ì ìˆ˜ëŠ” 1-10 ì‚¬ì´ì˜ ì •ìˆ˜ë¡œ ì œì‹œí•˜ì„¸ìš”.
JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”: {"quality": 8, "theological_depth": 9, "practical_application": 7}"""

        evaluation_user = f"""[ì„±ê²½ êµ¬ì ˆ]
{reference}

[ë¶„ì„ ë‚´ìš©]
{analysis_text[:2000]}

ìœ„ ë¶„ì„ì˜ í’ˆì§ˆì„ í‰ê°€í•´ì£¼ì„¸ìš”."""

        try:
            eval_completion = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": evaluation_system},
                    {"role": "user", "content": evaluation_user}
                ],
                temperature=0.3
            )

            eval_result = eval_completion.choices[0].message.content.strip()
            # JSON íŒŒì‹±
            if '```json' in eval_result:
                eval_result = eval_result.split('```json')[1].split('```')[0].strip()
            elif '```' in eval_result:
                eval_result = eval_result.split('```')[1].split('```')[0].strip()

            scores = json.loads(eval_result)
            quality_score = scores.get("quality", 5)
            theological_depth_score = scores.get("theological_depth", 5)
            practical_application_score = scores.get("practical_application", 5)

            print(f"[STEP1-SAVE] í‰ê°€ ì™„ë£Œ - í’ˆì§ˆ:{quality_score}, ì‹ í•™:{theological_depth_score}, ì ìš©:{practical_application_score}")
        except Exception as e:
            print(f"[STEP1-SAVE] í’ˆì§ˆ í‰ê°€ ì‹¤íŒ¨ (ê¸°ë³¸ê°’ ì‚¬ìš©): {str(e)}")
            quality_score = 5
            theological_depth_score = 5
            practical_application_score = 5

        # DBì— ì €ì¥
        try:
            conn = get_db_connection()
            cursor = conn.cursor()

            estimated_tokens = len(analysis_text) // 3

            if USE_POSTGRES:
                cursor.execute('''
                    INSERT INTO step1_analyses
                    (reference, sermon_text, analysis_text, analysis_hash, category, style_name, step_name,
                     quality_score, theological_depth_score, practical_application_score, ai_model, analysis_tokens)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ''', (reference, sermon_text, analysis_text, analysis_hash, category, style_name, step_name,
                      quality_score, theological_depth_score, practical_application_score, 'gpt-5', estimated_tokens))
            else:
                cursor.execute('''
                    INSERT INTO step1_analyses
                    (reference, sermon_text, analysis_text, analysis_hash, category, style_name, step_name,
                     quality_score, theological_depth_score, practical_application_score, ai_model, analysis_tokens)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (reference, sermon_text, analysis_text, analysis_hash, category, style_name, step_name,
                      quality_score, theological_depth_score, practical_application_score, 'gpt-5', estimated_tokens))

            conn.commit()
            conn.close()
            print(f"[STEP1-SAVE] DB ì €ì¥ ì™„ë£Œ (í•´ì‹œ: {analysis_hash[:8]}...)")
        except Exception as e:
            print(f"[STEP1-SAVE] DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")

        return {"ok": True, "message": "Step1 ë¶„ì„ ì €ì¥ ì™„ë£Œ", "isDuplicate": False}

    except Exception as e:
        print(f"[STEP1-SAVE][ERROR] {str(e)}")
        return {"ok": False, "message": f"ì €ì¥ ì‹¤íŒ¨: {str(e)}"}


def analyze_sermon_for_benchmark(sermon_text, reference="", sermon_title="", category="", style_name=""):
    """
    ìƒì„±ëœ ì„¤êµë¬¸ì„ ìë™ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ DBì— ì €ì¥
    """
    try:
        client = get_client()

        # ì„¤êµë¬¸ í•´ì‹œ ìƒì„± (ì¤‘ë³µ ì²´í¬ìš©)
        sermon_hash = hashlib.md5(sermon_text.encode('utf-8')).hexdigest()

        # DB ê¸°ë°˜ ì¤‘ë³µ ì²´í¬
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            if USE_POSTGRES:
                cursor.execute("SELECT id FROM sermon_benchmark_analyses WHERE sermon_hash = %s", (sermon_hash,))
            else:
                cursor.execute("SELECT id FROM sermon_benchmark_analyses WHERE sermon_hash = ?", (sermon_hash,))
            existing = cursor.fetchone()
            conn.close()

            if existing:
                print(f"[SERMON-BENCHMARK] ì¤‘ë³µ ì„¤êµë¬¸ ê°ì§€ (í•´ì‹œ: {sermon_hash[:8]}...) - ë¶„ì„ ê±´ë„ˆëœ€")
                return {"ok": True, "message": "ì¤‘ë³µ ì„¤êµë¬¸ - ë¶„ì„ ê±´ë„ˆëœ€", "isDuplicate": True}
        except Exception as e:
            print(f"[SERMON-BENCHMARK] ì¤‘ë³µ ì²´í¬ ì‹¤íŒ¨: {str(e)}")

        print(f"[SERMON-BENCHMARK] ì„¤êµë¬¸ ë¶„ì„ ì‹œì‘ - ìŠ¤íƒ€ì¼: {style_name}, ì¹´í…Œê³ ë¦¬: {category}")

        # GPTë¡œ ì„¤êµë¬¸ ë¶„ì„
        system_content = """ë‹¹ì‹ ì€ ì„¤êµë¬¸ ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì œê³µëœ ì„¤êµë¬¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ìš”ì†Œë“¤ì„ ì¶”ì¶œí•˜ê³  ì •ë¦¬í•˜ì„¸ìš”:

1. **ì„¤êµ êµ¬ì¡° ë¶„ì„**
   - ì„œë¡ , ë³¸ë¡ , ê²°ë¡ ì˜ êµ¬ì„± ë°©ì‹
   - ê° íŒŒíŠ¸ì˜ ë¹„ì¤‘ê³¼ ì „í™˜ íë¦„
   - ëŒ€ì§€ êµ¬ì¡° (ìˆëŠ” ê²½ìš°)

2. **ì‹ í•™ì  ê¹Šì´**
   - ì„±ê²½ í•´ì„ì˜ ì •í™•ì„±ê³¼ ê¹Šì´
   - ì‹ í•™ì  í†µì°°ì˜ ìˆ˜ì¤€
   - ë³µìŒ ì¤‘ì‹¬ì„±

3. **ì ìš© ìš”ì†Œ**
   - ì‹¤ì²œ ê°€ëŠ¥í•œ ì ìš©ì˜ êµ¬ì²´ì„±
   - ì²­ì¤‘ ë§¥ë½ì— ëŒ€í•œ ì´í•´
   - ì‹¤ìƒí™œ ì—°ê²°ì„±

4. **ì˜ˆí™” ë° ìŠ¤í† ë¦¬í…”ë§**
   - ì˜ˆí™” ì‚¬ìš© ë°©ì‹ê³¼ íš¨ê³¼
   - ìŠ¤í† ë¦¬í…”ë§ ê¸°ë²•
   - ê°ì •ì  ê³µê° ìœ ë„ ë°©ë²•

5. **ì–¸ì–´ ìŠ¤íƒ€ì¼**
   - ë¬¸ì²´ì™€ ì–´ì¡°
   - ë¬¸ì¥ êµ¬ì¡°ì™€ ë¦¬ë“¬
   - ëª…í™•ì„±ê³¼ ì„¤ë“ë ¥

6. **ì„±ê³µ ìš”ì¸ ë¶„ì„**
   - ì „ë°˜ì ì¸ ì„¤êµì˜ ê°•ì 
   - ì²­ì¤‘ ëª°ì… ìš”ì†Œ
   - ì°¨ë³„í™” í¬ì¸íŠ¸

ë¶„ì„ ê²°ê³¼ëŠ” êµ¬ì¡°í™”ë˜ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""

        user_content = f"""[ì„¤êµë¬¸ ì •ë³´]
- ë³¸ë¬¸ ì„±ê²½êµ¬ì ˆ: {reference}
- ì„¤êµ ì œëª©: {sermon_title}
- ì¹´í…Œê³ ë¦¬: {category}
- ìŠ¤íƒ€ì¼: {style_name}

[ì„¤êµë¬¸ ë‚´ìš©]
{sermon_text}

ìœ„ ì„¤êµë¬¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ íŒ¨í„´ê³¼ ì„±ê³µ ìš”ì¸ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-5",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ]
        )

        analysis = completion.choices[0].message.content.strip()
        total_tokens = completion.usage.total_tokens if hasattr(completion, 'usage') else 0

        # ë¶„ì„ ê²°ê³¼ë¥¼ ì„¹ì…˜ë³„ë¡œ íŒŒì‹±
        sermon_structure = ""
        theological_depth = ""
        application_elements = ""
        illustration_style = ""
        language_style = ""
        success_factors = ""

        sections = analysis.split('\n\n')
        for section in sections:
            if 'ì„¤êµ êµ¬ì¡°' in section or 'êµ¬ì¡° ë¶„ì„' in section:
                sermon_structure = section
            elif 'ì‹ í•™ì  ê¹Šì´' in section or 'ì‹ í•™' in section:
                theological_depth = section
            elif 'ì ìš©' in section:
                application_elements = section
            elif 'ì˜ˆí™”' in section or 'ìŠ¤í† ë¦¬í…”ë§' in section:
                illustration_style = section
            elif 'ì–¸ì–´' in section or 'ìŠ¤íƒ€ì¼' in section:
                language_style = section
            elif 'ì„±ê³µ ìš”ì¸' in section:
                success_factors = section

        # DBì— ì €ì¥
        try:
            conn = get_db_connection()
            cursor = conn.cursor()

            if USE_POSTGRES:
                cursor.execute('''
                    INSERT INTO sermon_benchmark_analyses
                    (sermon_text, sermon_hash, reference, sermon_title, category, style_name,
                     analysis_result, sermon_structure, theological_depth, application_elements,
                     illustration_style, language_style, success_factors, ai_model, analysis_tokens)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                ''', (sermon_text, sermon_hash, reference, sermon_title, category, style_name,
                      analysis, sermon_structure, theological_depth, application_elements,
                      illustration_style, language_style, success_factors, 'gpt-5', total_tokens))
            else:
                cursor.execute('''
                    INSERT INTO sermon_benchmark_analyses
                    (sermon_text, sermon_hash, reference, sermon_title, category, style_name,
                     analysis_result, sermon_structure, theological_depth, application_elements,
                     illustration_style, language_style, success_factors, ai_model, analysis_tokens)
                    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
                ''', (sermon_text, sermon_hash, reference, sermon_title, category, style_name,
                      analysis, sermon_structure, theological_depth, application_elements,
                      illustration_style, language_style, success_factors, 'gpt-5', total_tokens))

            conn.commit()
            conn.close()
            print(f"[SERMON-BENCHMARK] DB ì €ì¥ ì™„ë£Œ (í•´ì‹œ: {sermon_hash[:8]}..., í† í°: {total_tokens})")
        except Exception as e:
            print(f"[SERMON-BENCHMARK] DB ì €ì¥ ì‹¤íŒ¨: {str(e)}")

        print(f"[SERMON-BENCHMARK] ë¶„ì„ ì™„ë£Œ - ëª¨ë¸: gpt-5")

        return {"ok": True, "message": "ë¶„ì„ ì™„ë£Œ ë° DB ì €ì¥ë¨", "isDuplicate": False}

    except Exception as e:
        print(f"[SERMON-BENCHMARK][ERROR] {str(e)}")
        return {"ok": False, "message": f"ë¶„ì„ ì‹¤íŒ¨: {str(e)}"}


# ===== API ë¼ìš°íŠ¸ë“¤ =====

@api_sermon_bp.route('/process', methods=['POST'])
@api_login_required
def process_step():
    """ë‹¨ì¼ ì²˜ë¦¬ ë‹¨ê³„ ì‹¤í–‰ (gpt-4o-mini ì‚¬ìš©)"""
    try:
        client = get_client()
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        category = data.get("category", "")
        step_id = data.get("stepId", "")
        step_name = data.get("stepName", "")
        step_type = data.get("stepType", "step1")
        reference = data.get("reference", "")
        title = data.get("title", "")
        text = data.get("text", "")
        guide = data.get("guide", "")
        master_guide = data.get("masterGuide", "")
        previous_results = data.get("previousResults", {})

        # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬ë°›ì€ ëª¨ë¸ ì‚¬ìš© (ì—†ìœ¼ë©´ ê¸°ë³¸ê°’)
        model_name = data.get("model")
        if not model_name:
            if step_type == "step1":
                model_name = "gpt-5"
            else:
                model_name = "gpt-4o-mini"

        # temperature ì„¤ì • (gpt-4o-minië§Œ ì‚¬ìš©)
        use_temperature = (model_name == "gpt-4o-mini")

        print(f"[PROCESS] {category} - {step_name} (Step: {step_type}, ëª¨ë¸: {model_name})")

        # JSON ì§€ì¹¨ ì—¬ë¶€ í™•ì¸
        is_json = is_json_guide(guide)
        json_guide = None

        if is_json:
            json_guide = parse_json_guide(guide)
            if json_guide:
                print(f"[PROCESS] JSON ì§€ì¹¨ ê°ì§€ë¨ - style: {json_guide.get('style', 'unknown')}")
                system_content = build_prompt_from_json(json_guide, step_type)
            else:
                print(f"[PROCESS] JSON íŒŒì‹± ì‹¤íŒ¨ - ê¸°ì¡´ í…ìŠ¤íŠ¸ ë°©ì‹ ì‚¬ìš©")
                is_json = False

        if not is_json:
            # Step1ì¸ ê²½ìš°: ë³¸ë¬¸ ì—°êµ¬ ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            if step_type == "step1":
                from .prompt import build_step1_research_prompt
                system_content = build_step1_research_prompt()
                print(f"[PROCESS] Step1 ì—°êµ¬ ëª¨ë“œ í”„ë¡¬í”„íŠ¸ ì ìš©")
            else:
                system_content = get_system_prompt_for_step(step_name)

                if master_guide:
                    system_content += f"\n\nã€ ì¹´í…Œê³ ë¦¬ ì´ê´„ ì§€ì¹¨ ã€‘\n{master_guide}\n\n"
                    system_content += f"ã€ í˜„ì¬ ë‹¨ê³„ ì—­í•  ã€‘\n{step_name}\n\n"
                    system_content += "ìœ„ ì´ê´„ ì§€ì¹¨ì„ ì°¸ê³ í•˜ì—¬, í˜„ì¬ ë‹¨ê³„ì˜ ì—­í• ê³¼ ë¹„ì¤‘ì— ë§ê²Œ 'ìë£Œë§Œ' ì‘ì„±í•˜ì„¸ìš”."

                if guide:
                    system_content += f"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    system_content += f"ã€ ìµœìš°ì„  ì§€ì¹¨: {step_name} ë‹¨ê³„ ì„¸ë¶€ ì§€ì¹¨ ã€‘\n"
                    system_content += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
                    system_content += guide
                    system_content += f"\n\nìœ„ ì§€ì¹¨ì„ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„ í•˜ì—¬ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤."
                    system_content += f"\nì´ ì§€ì¹¨ì´ ê¸°ë³¸ ì—­í• ê³¼ ì¶©ëŒí•˜ë©´, ì´ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”."

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_content = f"[ì„±ê²½êµ¬ì ˆ]\n{reference}\n\n"

        if title and 'ì œëª©' not in step_name:
            user_content += f"[ì„¤êµ ì œëª©]\n{title}\n\n"
            user_content += "ìœ„ ì œëª©ì„ ì—¼ë‘ì— ë‘ê³  ëª¨ë“  ë‚´ìš©ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"

        if text:
            user_content += f"[ì„±ê²½ ë³¸ë¬¸]\n{text}\n\n"

        # Step1ì¸ ê²½ìš°: ì›ì–´ ë¶„ì„ ë° ì£¼ì„ ë°ì´í„° ìë™ ì¶”ê°€
        if step_type == "step1" and reference:
            try:
                # 1. Strong's ì›ì–´ ë¶„ì„
                strongs_analysis = analyze_verse_strongs(reference, top_n=5)
                strongs_text = format_strongs_for_prompt(strongs_analysis)
                if strongs_text:
                    # Strong's ìš°ì„ ìˆœìœ„ ê°•ì œ ë¬¸êµ¬ ì¶”ê°€
                    user_content += "\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    user_content += "ã€ âš ï¸ Strong's ì›ì–´ ìë£Œ (ë³´ì¡° ì°¸ê³ ìš©) ã€‘\n"
                    user_content += "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
                    user_content += "â€» ì£¼ì˜: Strong'sëŠ” ì°¸ê³ ë¡œë§Œ ì‚¬ìš©í•˜ë©°, ë³¸ë¬¸ êµ¬ì¡°/ë¬¸ë§¥/ì—­ì‚¬ ë°°ê²½ ì„¤ëª…ì„ ë¨¼ì € ì™„ë£Œí•˜ë¼.\n"
                    user_content += "â€» ì›ì–´ ë¶„ì„ì€ ìµœëŒ€ 5ê°œ ë‹¨ì–´ë§Œ ì„ íƒí•˜ê³ , ì„¤êµ ì ìš©ì€ ì“°ì§€ ë§ë¼(ê´€ì°°ë§Œ).\n\n"
                    user_content += f"{strongs_text}\n"
                    print(f"[PROCESS] Step1 ì›ì–´ ë¶„ì„ ì¶”ê°€ (ìš°ì„ ìˆœìœ„ ê°•ì œ): {len(strongs_analysis.get('key_words', []))}ê°œ ë‹¨ì–´")

                # 2. ì£¼ì„ ì°¸ê³  ìë£Œ (GPT ê¸°ë°˜ ìƒì„±)
                # ë¹„ìš© ì ˆê°ì„ ìœ„í•´ ê¸°ë³¸ì ìœ¼ë¡œ ë¹„í™œì„±í™”, í•„ìš”ì‹œ í™œì„±í™”
                enable_commentary = data.get("enableCommentary", False)
                if enable_commentary:
                    commentary_result = get_verse_commentary(
                        reference,
                        verse_text=text,
                        styles=["matthew_henry", "john_gill"]
                    )
                    commentary_text = format_commentary_for_prompt(commentary_result)
                    if commentary_text:
                        user_content += f"\n{commentary_text}\n"
                        print(f"[PROCESS] Step1 ì£¼ì„ ì°¸ê³  ì¶”ê°€: {len(commentary_result.get('commentaries', []))}ê°œ ìŠ¤íƒ€ì¼")
            except Exception as e:
                print(f"[PROCESS] ì›ì–´/ì£¼ì„ ë¶„ì„ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        # Step2ì¸ ê²½ìš°: ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ ìë™ ì¶”ê°€
        if step_type == "step2" or (step_id and "step2" in step_id.lower()):
            try:
                # ì²­ì¤‘ ìœ í˜• ì¶”ì¶œ (dataì—ì„œ ë˜ëŠ” ê¸°ë³¸ê°’)
                audience_type = data.get("audienceType", "ì „ì²´")
                enable_context = data.get("enableContext", True)  # ê¸°ë³¸ í™œì„±í™”

                if enable_context:
                    context_result = get_current_context(audience_type=audience_type)
                    context_text = format_context_for_prompt(context_result, sermon_topic=title or "")
                    if context_text:
                        user_content += f"\n{context_text}\n"
                        news_count = sum(len(v) for v in context_result.get("news", {}).values())
                        print(f"[PROCESS] Step2 ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€: {audience_type} ì²­ì¤‘, {news_count}ê°œ ë‰´ìŠ¤")
            except Exception as e:
                print(f"[PROCESS] ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ ë¶„ì„ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        if previous_results:
            user_content += "[ì´ì „ ë‹¨ê³„ ê²°ê³¼ (ì°¸ê³ ìš©)]\n"
            for prev_id, prev_data in previous_results.items():
                user_content += f"\n### {prev_data['name']}\n{prev_data['result']}\n"
            user_content += "\n"

        if 'ì œëª©' in step_name:
            user_content += f"ìœ„ ì„±ê²½ ë³¸ë¬¸({reference})ì— ì í•©í•œ ì„¤êµ ì œëª©ì„ ì •í™•íˆ 3ê°œë§Œ ì œì•ˆí•´ì£¼ì„¸ìš”.\n"
            user_content += "ê° ì œëª©ì€ í•œ ì¤„ë¡œ, ë²ˆí˜¸ë‚˜ ê¸°í˜¸ ì—†ì´ ì‘ì„±í•˜ì„¸ìš”."
        else:
            user_content += f"ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ '{step_name}' ë‹¨ê³„ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"

        if title and 'ì œëª©' not in step_name:
            user_content += f"\nì œëª© '{title}'ì„ ê³ ë ¤í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”."

        # GPT í˜¸ì¶œ
        if use_temperature:
            completion = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.7,
            )
        else:
            completion = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ]
            )

        result = completion.choices[0].message.content.strip()

        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        usage_data = None
        if hasattr(completion, 'usage') and completion.usage:
            usage_data = {
                "input_tokens": completion.usage.prompt_tokens,
                "output_tokens": completion.usage.completion_tokens,
                "total_tokens": completion.usage.total_tokens
            }
            log_api_usage(
                step_name=step_id or step_type or 'step',
                model_name=model_name,
                input_tokens=usage_data['input_tokens'],
                output_tokens=usage_data['output_tokens'],
                style_name=data.get('styleName'),
                category=category
            )

        # ì œëª© ì¶”ì²œ ë‹¨ê³„ëŠ” JSON íŒŒì‹±í•˜ì§€ ì•Šê³  ê·¸ëŒ€ë¡œ ë°˜í™˜
        if 'ì œëª©' in step_name:
            result = remove_markdown(result)
            return jsonify({"ok": True, "result": result, "usage": usage_data})

        # Step1/Step2 ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ (Step4ì—ì„œ ì‚¬ìš©)
        extra_info = {}

        # Step1ì¸ ê²½ìš°: Strong's ì›ì–´ ë¶„ì„ ì •ë³´ ì¶”ê°€
        if step_type == "step1" and reference:
            try:
                strongs_analysis = analyze_verse_strongs(reference, top_n=5)
                if strongs_analysis and not strongs_analysis.get('error'):
                    extra_info['strongs_analysis'] = {
                        'reference': strongs_analysis.get('reference', ''),
                        'text': strongs_analysis.get('text', ''),
                        'key_words': strongs_analysis.get('key_words', [])
                    }
                    print(f"[PROCESS] Step1 extra_info: Strong's {len(strongs_analysis.get('key_words', []))}ê°œ ë‹¨ì–´")
            except Exception as e:
                print(f"[PROCESS] Strong's ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        # Step2ì¸ ê²½ìš°: ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ ì •ë³´ ì¶”ê°€
        if step_type == "step2" or (step_id and "step2" in step_id.lower()):
            try:
                audience_type = data.get("audienceType", "ì „ì²´")
                context_result = get_current_context(audience_type=audience_type)
                if context_result:
                    extra_info['context_data'] = {
                        'audience': context_result.get('audience', 'ì „ì²´'),
                        'news': context_result.get('news', {}),
                        'indicators': context_result.get('indicators', {}),
                        'concerns': context_result.get('concerns', [])
                    }
                    news_count = sum(len(v) for v in context_result.get("news", {}).values())
                    print(f"[PROCESS] Step2 extra_info: ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ {news_count}ê°œ ë‰´ìŠ¤")
            except Exception as e:
                print(f"[PROCESS] ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ ì¶”ê°€ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

        # JSON íŒŒì‹± ì‹œë„ (ì„ íƒì )
        try:
            cleaned_result = result
            if cleaned_result.startswith('```'):
                lines = cleaned_result.split('\n')
                if lines[0].startswith('```'):
                    lines = lines[1:]
                if lines and lines[-1].startswith('```'):
                    lines = lines[:-1]
                cleaned_result = '\n'.join(lines).strip()

            json_data = json.loads(cleaned_result)
            formatted_result = format_json_result(json_data)

            print(f"[PROCESS][SUCCESS] JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µë°›ì•„ í¬ë§·íŒ… ì™„ë£Œ")

            # Step1ì¸ ê²½ìš° ë°±ê·¸ë¼ìš´ë“œë¡œ DB ì €ì¥
            if step_type == "step1" or step_id == "step1":
                try:
                    save_thread = threading.Thread(
                        target=save_step1_analysis,
                        args=(reference, text, formatted_result, category, data.get("styleName", ""), step_id)
                    )
                    save_thread.daemon = True
                    save_thread.start()
                    print(f"[PROCESS] Step1 ë¶„ì„ ì €ì¥ ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘")
                except Exception as e:
                    print(f"[PROCESS] Step1 ì €ì¥ ì‹œì‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {str(e)}")

            response = {"ok": True, "result": formatted_result, "usage": usage_data}
            if extra_info:
                response["extraInfo"] = extra_info
            return jsonify(response)

        except json.JSONDecodeError:
            print(f"[PROCESS][INFO] í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µë°›ìŒ (JSON ì•„ë‹˜)")
            result = remove_markdown(result)

            if step_type == "step1" or step_id == "step1":
                try:
                    save_thread = threading.Thread(
                        target=save_step1_analysis,
                        args=(reference, text, result, category, data.get("styleName", ""), step_id)
                    )
                    save_thread.daemon = True
                    save_thread.start()
                    print(f"[PROCESS] Step1 ë¶„ì„ ì €ì¥ ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘")
                except Exception as e:
                    print(f"[PROCESS] Step1 ì €ì¥ ì‹œì‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {str(e)}")

            response = {"ok": True, "result": result, "usage": usage_data}
            if extra_info:
                response["extraInfo"] = extra_info
            return jsonify(response)

    except Exception as e:
        print(f"[PROCESS][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


@api_sermon_bp.route('/meditation', methods=['POST'])
@api_login_required
def create_meditation():
    """ë¬µìƒë©”ì‹œì§€ ìƒì„± (GPT-4o-mini ì‚¬ìš©)"""
    try:
        client = get_client()
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        reference = data.get("reference", "")
        verse = data.get("verse", "")
        template = data.get("template", "")
        date_str = data.get("dateStr", "")
        sender = data.get("sender", "")

        if not reference:
            return jsonify({"ok": False, "error": "ì„±ê²½êµ¬ì ˆì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400
        if not verse:
            return jsonify({"ok": False, "error": "ë³¸ë¬¸ë§ì”€ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        print(f"[Meditation] ë¬µìƒë©”ì‹œì§€ ìƒì„± ì‹œì‘ - êµ¬ì ˆ: {reference}, í…œí”Œë¦¿ ì‚¬ìš©: {'ì˜ˆ' if template else 'ì•„ë‹ˆì˜¤'}")

        if template:
            # í…œí”Œë¦¿ì— placeholderê°€ ìˆëŠ”ì§€ í™•ì¸
            has_placeholder = "{{" in template and "}}" in template

            if has_placeholder:
                # placeholder ë°©ì‹: GPTëŠ” ë¬µìƒ, ì œëª©, ì¸ìš©êµ¬ë§Œ ìƒì„±
                system_content = """ë‹¹ì‹ ì€ ë¬µìƒë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•œ ìƒ˜í”Œ í…œí”Œë¦¿ì˜ ìŠ¤íƒ€ì¼(ì–´ì¡°, ë¬¸ë‹¨ êµ¬ì¡°, ê¸¸ì´)ì„ ì°¸ê³ í•˜ì—¬ ë¬µìƒ ë‚´ìš©ì„ ì‘ì„±í•©ë‹ˆë‹¤.

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "ì œëª©": "ë§ì”€ì˜ í•µì‹¬ì„ ë‹´ì€ ì§§ì€ ì œëª© (10ì ì´ë‚´)",
  "ì¸ìš©êµ¬": "ë³¸ë¬¸ì—ì„œ í•µì‹¬ ë©”ì‹œì§€ë¥¼ ìš”ì•½í•œ ì§§ì€ ë¬¸ì¥",
  "ë¬µìƒ": "ìƒ˜í”Œê³¼ ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ì˜ ë¬µìƒ ë‚´ìš©"
}

ì£¼ì˜ì‚¬í•­:
- ìƒ˜í”Œì˜ ë¬µìƒ ë¶€ë¶„ ìŠ¤íƒ€ì¼(ë¬¸ë‹¨ ìˆ˜, ë¬¸ì¥ ê¸¸ì´, ì–´ì¡°)ì„ ë”°ë¼í•˜ì„¸ìš”
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì‚¬ìš© ê¸ˆì§€
- JSON ì™¸ì˜ ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì¶œë ¥ ê¸ˆì§€"""

                user_content = f"""[ì°¸ê³ í•  ìƒ˜í”Œ]
{template}

[ìƒˆ ë§ì”€ ì •ë³´]
ì„±ê²½êµ¬ì ˆ: {reference}
ë³¸ë¬¸ë§ì”€: {verse}

ìœ„ ìƒ˜í”Œì˜ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•˜ì—¬ JSONìœ¼ë¡œ ì‘ë‹µí•˜ì„¸ìš”."""
            else:
                # ê¸°ì¡´ ë°©ì‹: GPTê°€ ì „ì²´ ë©”ì‹œì§€ ìƒì„±
                system_content = """ë‹¹ì‹ ì€ ë¬µìƒë©”ì‹œì§€ ì–‘ì‹ì„ ì •í™•íˆ ë³µì œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ë§¤ìš° ì¤‘ìš”: ì‚¬ìš©ìê°€ ì œê³µí•œ ìƒ˜í”Œ í…œí”Œë¦¿ì˜ "ì „ì²´ í˜•ì‹"ì„ ì™„ë²½íˆ ëª¨ë°©í•´ì•¼ í•©ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ë‚ ì§œ, ì„±ê²½êµ¬ì ˆ, ë³¸ë¬¸ë§ì”€ ê°’ì„ ìƒ˜í”Œ í…œí”Œë¦¿ì˜ í˜•ì‹ì— ë§ì¶° ëŒ€ì²´í•˜ì„¸ìš”.

í•„ìˆ˜ ì¤€ìˆ˜ ì‚¬í•­:
1. ìƒ˜í”Œì˜ ì „ì²´ êµ¬ì¡°(ì œëª©, ë‚ ì§œ í˜•ì‹, ì„±ê²½êµ¬ì ˆ í‘œê¸° ë°©ì‹, ë³¸ë¬¸, ë¬µìƒ ë‚´ìš©, í•´ì‹œíƒœê·¸ ë“±)ë¥¼ ë™ì¼í•˜ê²Œ ìœ ì§€
2. ìƒ˜í”Œì˜ ë¬¸ë‹¨ ìˆ˜, ë¬¸ì¥ ê¸¸ì´, ì–´ì¡°ë¥¼ ë™ì¼í•˜ê²Œ ìœ ì§€
3. ìƒ˜í”Œì— ì´ëª¨ì§€, í•´ì‹œíƒœê·¸, íŠ¹ìˆ˜ ê¸°í˜¸ê°€ ìˆìœ¼ë©´ ë™ì¼í•œ ìœ„ì¹˜ì— ë™ì¼í•˜ê²Œ ì‚¬ìš©
4. ìƒ˜í”Œì˜ ì „ì²´ ê¸€ì ìˆ˜ì™€ ë¹„ìŠ·í•˜ê²Œ ì‘ì„± (Â±20% ì´ë‚´)

ì ˆëŒ€ í•˜ì§€ ë§ ê²ƒ:
- ìƒ˜í”Œê³¼ ë‹¤ë¥¸ êµ¬ì¡°ë¡œ ì‘ì„±
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, - ë“±) ì‚¬ìš© (í•´ì‹œíƒœê·¸ ì œì™¸)

ì „ì²´ ë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”."""

                sender_info = f"\në³´ë‚´ëŠ” ì‚¬ëŒ: {sender}" if sender else ""

                user_content = f"""[ë³µì œí•  ìƒ˜í”Œ ì–‘ì‹]
{template}

---

[ìƒˆë¡œ ì‘ì„±í•  ë‚´ìš©ì˜ ê°’]
ë‚ ì§œ: {date_str}
ì„±ê²½êµ¬ì ˆ: {reference}
ë³¸ë¬¸ë§ì”€: {verse}{sender_info}

ìœ„ ìƒ˜í”Œì˜ "ì „ì²´ í˜•ì‹"ì„ ì™„ë²½íˆ ë”°ë¼ì„œ ìƒˆ ë¬µìƒë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ì„¸ìš”."""
        else:
            system_content = """ë‹¹ì‹ ì€ ë”°ëœ»í•˜ê³  ì€í˜œë¡œìš´ ë¬µìƒë©”ì‹œì§€ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ ì„±ê²½êµ¬ì ˆê³¼ ë³¸ë¬¸ë§ì”€ì„ ë°”íƒ•ìœ¼ë¡œ ê¹Šì´ ìˆëŠ” ë¬µìƒë©”ì‹œì§€ë¥¼ ì‘ì„±í•©ë‹ˆë‹¤.

ì‘ì„± ì§€ì¹¨:
1. ì²« ë²ˆì§¸ ë¬¸ë‹¨: ì„±ê²½ ë³¸ë¬¸ì˜ ì—­ì‚¬ì /ì‹ í•™ì  ë°°ê²½ ì„¤ëª… (3-4ë¬¸ì¥)
2. ë‘ ë²ˆì§¸ ë¬¸ë‹¨: ìš°ë¦¬ ì¼ìƒì—ì„œì˜ ì ìš©ê³¼ ì„±ì°° (3-4ë¬¸ì¥)
3. ì„¸ ë²ˆì§¸ ë¬¸ë‹¨: ë”°ëœ»í•œ ê¶Œë©´ê³¼ ì¶•ë³µì˜ ë§ì”€ (2-3ë¬¸ì¥)
4. ë§ˆì§€ë§‰: ì§§ì€ ê¸°ë„ë¬¸ (ì„ íƒ)
5. ë”°ëœ»í•˜ê³  ìœ„ë¡œê°€ ë˜ëŠ” ì–´ì¡° ì‚¬ìš©
6. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì‚¬ìš©í•˜ì§€ ì•Šê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±
7. ë‚ ì§œ, ì„±ê²½êµ¬ì ˆ, ë³¸ë¬¸ë§ì”€ì€ ì œì™¸í•˜ê³  ë¬µìƒ ë‚´ìš©ë§Œ ì‘ì„±"""

            user_content = f"""ì„±ê²½êµ¬ì ˆ: {reference}
ë³¸ë¬¸ë§ì”€: {verse}

ìœ„ ë§ì”€ì„ ë°”íƒ•ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ ë¬µìƒë©”ì‹œì§€ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.
ë‚ ì§œ, ì„±ê²½êµ¬ì ˆ, ë³¸ë¬¸ë§ì”€ ë¶€ë¶„ì€ ì œì™¸í•˜ê³  ë¬µìƒ ë³¸ë¬¸ë§Œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            max_tokens=1500
        )

        result = completion.choices[0].message.content.strip()
        print(f"[Meditation] ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(result)}ì")

        # placeholder ëª¨ë“œì¼ ë•Œ JSON íŒŒì‹±
        response_data = {
            "ok": True,
            "usage": {
                "input_tokens": completion.usage.prompt_tokens if hasattr(completion, 'usage') else 0,
                "output_tokens": completion.usage.completion_tokens if hasattr(completion, 'usage') else 0
            }
        }

        if template and "{{" in template and "}}" in template:
            # placeholder ëª¨ë“œ: JSON íŒŒì‹± ì‹œë„
            try:
                import json
                # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•ì‹ ì²˜ë¦¬)
                json_str = result
                if "```json" in result:
                    json_str = result.split("```json")[1].split("```")[0].strip()
                elif "```" in result:
                    json_str = result.split("```")[1].split("```")[0].strip()

                parsed = json.loads(json_str)
                response_data["mode"] = "placeholder"
                response_data["ì œëª©"] = parsed.get("ì œëª©", "")
                response_data["ì¸ìš©êµ¬"] = parsed.get("ì¸ìš©êµ¬", "")
                response_data["ë¬µìƒ"] = parsed.get("ë¬µìƒ", "")
                response_data["result"] = parsed.get("ë¬µìƒ", result)  # fallback
                print(f"[Meditation] placeholder ëª¨ë“œ - JSON íŒŒì‹± ì„±ê³µ")
            except Exception as parse_err:
                print(f"[Meditation] JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {parse_err}")
                response_data["mode"] = "legacy"
                response_data["result"] = result
        else:
            response_data["mode"] = "legacy" if template else "default"
            response_data["result"] = result

        return jsonify(response_data)

    except Exception as e:
        print(f"[Meditation] ì˜¤ë¥˜: {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 500


@api_sermon_bp.route('/gpt-pro', methods=['POST'])
@api_login_required
def gpt_pro():
    """GPT PRO ì™„ì„±ë³¸ ì‘ì„±"""
    try:
        client = get_client()

        # ì¸ì¦ì´ ë¹„í™œì„±í™”ëœ ê²½ìš° í¬ë ˆë”§ ì²´í¬ ê±´ë„ˆë›°ê¸°
        if AUTH_ENABLED:
            user_id = session.get('user_id')
            current_credits = get_user_credits(user_id)

            is_admin = session.get('is_admin', 0)
            if not is_admin and current_credits <= 0:
                return jsonify({
                    "ok": False,
                    "error": "Step3 ì‚¬ìš© í¬ë ˆë”§ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.",
                    "credits": 0,
                    "needCredits": True
                }), 200
        else:
            user_id = None
            current_credits = -1
            is_admin = 0

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        reference = data.get("reference", "")
        title = data.get("title", "")
        series_name = data.get("seriesName", "")
        style_name = data.get("styleName", "")
        category = data.get("category", "")
        draft_content = data.get("draftContent", "")
        style_description = data.get("styleDescription", "")
        completed_step_names = data.get("completedStepNames", [])

        gpt_pro_model = data.get("model", "gpt-5")
        max_tokens = data.get("maxTokens", 16000)
        custom_prompt = data.get("customPrompt", "")

        # JSON ëª¨ë“œ ë°ì´í„°
        step1_result = data.get("step1Result")
        step2_result = data.get("step2Result")
        step3_guide = data.get("step3Guide")
        target_audience = data.get("target", "")
        worship_type = data.get("worshipType", "")
        duration = data.get("duration", "20ë¶„")
        special_notes = data.get("specialNotes", "")

        # ë¬¸ë‹¨/ì¤„ë°”ê¿ˆ ìŠ¤íƒ€ì¼ ë° ì„±ê²½êµ¬ì ˆ ì¸ìš© ê·œì¹™ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì „ë‹¬)
        writing_style = data.get("writingStyle")
        scripture_citation = data.get("scriptureCitation")

        # Step1/Step2 ì¶”ê°€ ì •ë³´ (Strong's ì›ì–´ ë¶„ì„, ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸)
        step1_extra_info = data.get("step1ExtraInfo")
        step2_extra_info = data.get("step2ExtraInfo")

        # JSON ëª¨ë“œ ì—¬ë¶€ í™•ì¸
        is_json_mode = (isinstance(step1_result, dict) and len(step1_result) > 0) or \
                       (isinstance(step2_result, dict) and len(step2_result) > 0)

        print(f"[GPT-PRO/Step3] JSON ëª¨ë“œ: {is_json_mode}, step1_result íƒ€ì…: {type(step1_result)}, step2_result íƒ€ì…: {type(step2_result)}")
        print(f"[GPT-PRO/Step3] ì²˜ë¦¬ ì‹œì‘ - ìŠ¤íƒ€ì¼: {style_name}, ëª¨ë¸: {gpt_pro_model}, í† í°: {max_tokens}")
        print(f"[GPT-PRO/Step3] writing_style: {'ìˆìŒ' if writing_style else 'ì—†ìŒ'}, scripture_citation: {'ìˆìŒ' if scripture_citation else 'ì—†ìŒ'}")
        print(f"[GPT-PRO/Step3] step1_extra_info: {'ìˆìŒ' if step1_extra_info else 'ì—†ìŒ'}, step2_extra_info: {'ìˆìŒ' if step2_extra_info else 'ì—†ìŒ'}")

        has_title = bool(title and title.strip())

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_content = "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì„¤êµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ëŒ€ì‹  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤."

        # ìµœìš°ì„  ì§€ì¹¨
        system_content += "\n\n" + "=" * 50
        system_content += "\nã€ â˜… ìµœìš°ì„  ì§€ì¹¨ - ë°˜ë“œì‹œ ì¤€ìˆ˜ â˜… ã€‘"
        system_content += "\n" + "=" * 50
        if duration:
            system_content += f"\n\nğŸš¨ ë¶„ëŸ‰ ì œí•œ: ì´ ì„¤êµëŠ” ë°˜ë“œì‹œ {duration} ë¶„ëŸ‰ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
            system_content += f"\n   - {duration} ë¶„ëŸ‰ì„ ì ˆëŒ€ ì´ˆê³¼í•˜ì§€ ë§ˆì„¸ìš”."
            system_content += "\n   - Step1, Step2ì˜ êµ¬ì¡°ê°€ ê¸¸ë”ë¼ë„ {duration} ì•ˆì— ë§ì¶° ì••ì¶•í•˜ì„¸ìš”."
            system_content += "\n   - ì´ ë¶„ëŸ‰ ì œí•œì€ ë‹¤ë¥¸ ëª¨ë“  ì§€ì¹¨ë³´ë‹¤ ìš°ì„ í•©ë‹ˆë‹¤."
        if worship_type:
            system_content += f"\n\nğŸš¨ ì˜ˆë°°/ì§‘íšŒ ìœ í˜•: '{worship_type}'"
            system_content += f"\n   - ì´ ì„¤êµëŠ” '{worship_type}'ì— ë§ëŠ” í†¤ê³¼ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”."
        if special_notes:
            system_content += f"\n\nğŸš¨ íŠ¹ë³„ ì°¸ê³  ì‚¬í•­:"
            system_content += f"\n   {special_notes}"
            system_content += f"\n   - ìœ„ ë‚´ìš©ì„ ì„¤êµë¬¸ ì‘ì„± ì‹œ ë°˜ë“œì‹œ ê³ ë ¤í•˜ì„¸ìš”."
        system_content += "\n" + "=" * 50

        # ë¬¸ë‹¨/ì¤„ë°”ê¿ˆ ìŠ¤íƒ€ì¼ ê·œì¹™ ì¶”ê°€
        if writing_style and isinstance(writing_style, dict):
            system_content += "\n\n" + "=" * 50
            system_content += f"\nã€ â˜…â˜…â˜… {writing_style.get('label', 'ë¬¸ë‹¨/ì¤„ë°”ê¿ˆ ìŠ¤íƒ€ì¼')} â˜…â˜…â˜… ã€‘"
            system_content += "\n" + "=" * 50

            if writing_style.get('core_principle'):
                system_content += f"\n\ní•µì‹¬ ì›ì¹™: {writing_style['core_principle']}"

            if writing_style.get('must_do'):
                system_content += "\n\nâœ… ë°˜ë“œì‹œ í•´ì•¼ í•  ê²ƒ:"
                for item in writing_style['must_do']:
                    system_content += f"\n  - {item}"

            if writing_style.get('must_not'):
                system_content += "\n\nâŒ ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ:"
                for item in writing_style['must_not']:
                    system_content += f"\n  - {item}"

            if writing_style.get('good_example'):
                system_content += f"\n\nâœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:\n{writing_style['good_example']}"

            if writing_style.get('bad_example'):
                system_content += f"\n\nâŒ ì˜ëª»ëœ ì˜ˆì‹œ (ì´ë ‡ê²Œ ì“°ì§€ ë§ˆì„¸ìš”):\n{writing_style['bad_example']}"

            if writing_style.get('critical_warning'):
                system_content += f"\n\nâš ï¸ ê²½ê³ : {writing_style['critical_warning']}"

        # ì„±ê²½êµ¬ì ˆ ì¸ìš© ê·œì¹™ ì¶”ê°€
        if scripture_citation and isinstance(scripture_citation, dict):
            system_content += "\n\n" + "=" * 50
            system_content += f"\nã€ â˜…â˜…â˜… {scripture_citation.get('label', 'ì„±ê²½êµ¬ì ˆ ì¸ìš© ë°©ì‹')} â˜…â˜…â˜… ã€‘"
            system_content += "\n" + "=" * 50

            if scripture_citation.get('core_principle'):
                system_content += f"\n\ní•µì‹¬ ì›ì¹™: {scripture_citation['core_principle']}"

            if scripture_citation.get('must_do'):
                system_content += "\n\nâœ… ë°˜ë“œì‹œ í•´ì•¼ í•  ê²ƒ:"
                for item in scripture_citation['must_do']:
                    system_content += f"\n  - {item}"

            if scripture_citation.get('must_not'):
                system_content += "\n\nâŒ ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  ê²ƒ:"
                for item in scripture_citation['must_not']:
                    system_content += f"\n  - {item}"

            if scripture_citation.get('good_examples'):
                system_content += "\n\nâœ… ì˜¬ë°”ë¥¸ ì˜ˆì‹œ:"
                for example in scripture_citation['good_examples']:
                    system_content += f"\n  {example}"

            if scripture_citation.get('bad_examples'):
                system_content += "\n\nâŒ ì˜ëª»ëœ ì˜ˆì‹œ (ì´ë ‡ê²Œ ì“°ì§€ ë§ˆì„¸ìš”):"
                for example in scripture_citation['bad_examples']:
                    system_content += f"\n  {example}"

            if scripture_citation.get('usage_guide'):
                system_content += f"\n\nğŸ“Œ {scripture_citation['usage_guide']}"

        if not has_title:
            system_content += (
                "\n\nâš ï¸ ì œëª© ìƒì„±: ì„¤êµë¬¸ ë§¨ ì•ì— 'ì„¤êµ ì œëª©: (ì œëª© ë‚´ìš©)' í˜•ì‹ìœ¼ë¡œ ì ì ˆí•œ ì œëª©ì„ ë¨¼ì € ìƒì„±í•˜ì„¸ìš”."
                "\nê·¸ ë‹¤ìŒ ë¹ˆ ì¤„ì„ ë„£ê³  ë°”ë¡œ ì„¤êµ ë‚´ìš©ì„ ì‹œì‘í•˜ì„¸ìš”. ë³¸ë¬¸ ì„±ê²½êµ¬ì ˆì€ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”."
            )
        else:
            system_content += "\n\nâš ï¸ ì¤‘ìš”: ì„¤êµ ì œëª©ê³¼ ë³¸ë¬¸ ì„±ê²½êµ¬ì ˆì€ ë‹¤ì‹œ ì¶œë ¥í•˜ì§€ ë§ˆì„¸ìš”. ë°”ë¡œ ì„¤êµ ë‚´ìš©ë¶€í„° ì‹œì‘í•˜ì„¸ìš”."

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        meta_lines = []
        if category:
            meta_lines.append(f"- ì¹´í…Œê³ ë¦¬: {category}")
        if style_name:
            meta_lines.append(f"- ì„¤êµ ìŠ¤íƒ€ì¼: {style_name}")
        if style_description:
            meta_lines.append(f"- ìŠ¤íƒ€ì¼ ì„¤ëª…: {style_description}")
        if reference:
            meta_lines.append(f"- ë³¸ë¬¸ ì„±ê²½êµ¬ì ˆ: {reference}")
        if title:
            meta_lines.append(f"- ì„¤êµ ì œëª©: {title}")
        if series_name:
            meta_lines.append(f"- ì‹œë¦¬ì¦ˆëª…: {series_name}")

        meta_section = "\n".join(meta_lines)

        if is_json_mode:
            try:
                print(f"[GPT-PRO/Step3] JSON ëª¨ë“œ í™œì„±í™”")
                meta_data = {
                    "scripture": reference,
                    "title": title,
                    "target": target_audience,
                    "worship_type": worship_type,
                    "duration": duration,
                    "sermon_style": style_name,
                    "category": category,
                    "special_notes": special_notes
                }

                writing_spec = {}
                if step2_result and isinstance(step2_result, dict):
                    writing_spec = step2_result.get("writing_spec", {})
                    if "length" in writing_spec:
                        del writing_spec["length"]

                if writing_spec:
                    system_content += "\n\nã€ ì‘ì„± ê·œê²© ã€‘\n"
                    for key, value in writing_spec.items():
                        if isinstance(value, list):
                            system_content += f"- {key}: {', '.join(value)}\n"
                        else:
                            system_content += f"- {key}: {value}\n"

                user_content = build_step3_prompt_from_json(
                    json_guide=step3_guide,
                    meta_data=meta_data,
                    step1_result=step1_result,
                    step2_result=step2_result
                )

                if custom_prompt and custom_prompt.strip():
                    user_content += f"\n\nã€ì¶”ê°€ ì§€ì¹¨ã€‘\n{custom_prompt.strip()}"

            except Exception as json_err:
                print(f"[GPT-PRO/Step3] JSON ëª¨ë“œ ì˜¤ë¥˜, í…ìŠ¤íŠ¸ ëª¨ë“œë¡œ ì „í™˜: {str(json_err)}")
                is_json_mode = False

        if not is_json_mode:
            user_content = (
                "ì•„ë˜ëŠ” gpt-4o-miniê°€ ì •ë¦¬í•œ ì—°êµ¬Â·ê°œìš” ìë£Œì…ë‹ˆë‹¤."
                " ì°¸ê³ ë§Œ í•˜ê³ , ë¬¸ì¥ì€ ì²˜ìŒë¶€í„° ìƒˆë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
            )
            if meta_section:
                user_content += f"\n\n[ê¸°ë³¸ ì •ë³´]\n{meta_section}"
            user_content += "\n\n[ì„¤êµ ì´ˆì•ˆ ìë£Œ]\n"
            user_content += draft_content

            if custom_prompt and custom_prompt.strip():
                user_content += f"\n\nã€ì§€ì¹¨ã€‘\n{custom_prompt.strip()}"
            else:
                user_content += "\n\nã€ì§€ì¹¨ã€‘\n"
                user_content += (
                    "ë‹¹ì‹ ì€ í•œêµ­ì–´ ì„¤êµ ì „ë¬¸ê°€ì…ë‹ˆë‹¤.\n"
                    "step1,2 ìë£ŒëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©í•˜ê³  ë¬¸ì¥ì€ ì²˜ìŒë¶€í„° ìƒˆë¡œ êµ¬ì„±í•˜ë©°,\n"
                    "ë¬µì§í•˜ê³  ëª…ë£Œí•œ ì–´ì¡°ë¡œ ì‹ í•™ì  í†µì°°ê³¼ ì‹¤ì œì  ì ìš©ì„ ê· í˜• ìˆê²Œ ì œì‹œí•˜ì„¸ìš”.\n\n"
                    "1. Step2ì˜ ì„¤êµ êµ¬ì¡°(ì„œë¡ , ë³¸ë¡ , ê²°ë¡ )ë¥¼ ë°˜ë“œì‹œ ë”°ë¼ ì‘ì„±í•˜ì„¸ìš”.\n"
                    "2. Step2ì˜ ëŒ€ì§€(í¬ì¸íŠ¸) êµ¬ì„±ì„ ìœ ì§€í•˜ê³  ê° ì„¹ì…˜ì˜ í•µì‹¬ ë©”ì‹œì§€ë¥¼ í™•ì¥í•˜ì„¸ìš”.\n"
                    "3. ì—­ì‚¬ì  ë°°ê²½, ì‹ í•™ì  í†µì°°, ì‹¤ì œ ì ìš©ì„ ê· í˜• ìˆê²Œ ì œì‹œí•˜ì„¸ìš”.\n"
                    "4. ê´€ë ¨ ì„±ê²½êµ¬ì ˆì„ ì ì ˆíˆ ì¸ìš©í•˜ì„¸ìš”.\n"
                    "5. ê°€ë…ì„±ì„ ìœ„í•´ ê° ì„¹ì…˜ ì‚¬ì´ì— ë¹ˆ ì¤„ì„ ë„£ìœ¼ì„¸ìš”.\n"
                    "6. ë§ˆí¬ë‹¤ìš´, ë¶ˆë¦¿ ê¸°í˜¸ ëŒ€ì‹  ìˆœìˆ˜ í…ìŠ¤íŠ¸ ë‹¨ë½ì„ ì‚¬ìš©í•˜ì„¸ìš”.\n"
                    "7. ì¶©ë¶„íˆ ê¸¸ê³  ìƒì„¸í•˜ë©° í’ì„±í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
                )

        # Step1/Step2 ì¶”ê°€ ì •ë³´ë¥¼ í”„ë¡¬í”„íŠ¸ì— í¬í•¨
        if step1_extra_info or step2_extra_info:
            user_content += "\n\n" + "=" * 50
            user_content += "\nã€ â˜…â˜…â˜… ì¶”ê°€ ë¶„ì„ ìë£Œ (ì„¤êµì— í™œìš©í•˜ì„¸ìš”) â˜…â˜…â˜… ã€‘"
            user_content += "\n" + "=" * 50

            # Strong's ì›ì–´ ë¶„ì„
            if step1_extra_info and step1_extra_info.get('strongs_analysis'):
                strongs = step1_extra_info['strongs_analysis']
                key_words = strongs.get('key_words', [])
                if key_words:
                    user_content += "\n\nâ–¶ Strong's ì›ì–´ ë¶„ì„ (í•µì‹¬ ë‹¨ì–´)"
                    if strongs.get('text'):
                        user_content += f"\n   ì˜ë¬¸ (KJV): {strongs['text']}"
                    for i, word in enumerate(key_words[:5], 1):
                        lemma = word.get('lemma', '')
                        translit = word.get('translit', '')
                        strongs_num = word.get('strongs', '')
                        definition = word.get('definition', '')[:150]
                        user_content += f"\n   {i}. {lemma} ({translit}, {strongs_num})"
                        if word.get('english'):
                            user_content += f" - {word['english']}"
                        if definition:
                            user_content += f"\n      â†’ {definition}"

            # ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸
            if step2_extra_info and step2_extra_info.get('context_data'):
                context = step2_extra_info['context_data']
                user_content += "\n\nâ–¶ í˜„ì¬ ì‹œëŒ€ ì»¨í…ìŠ¤íŠ¸ (ë„ì…ë¶€/ì˜ˆí™”/ì ìš©ì— í™œìš©)"
                user_content += f"\n   ì²­ì¤‘ ìœ í˜•: {context.get('audience', 'ì „ì²´')}"

                # ì£¼ìš” ë‰´ìŠ¤
                news = context.get('news', {})
                if news:
                    cat_names = {'economy': 'ê²½ì œ', 'politics': 'ì •ì¹˜', 'society': 'ì‚¬íšŒ', 'world': 'êµ­ì œ', 'culture': 'ë¬¸í™”'}
                    user_content += "\n   ì£¼ìš” ì‹œì‚¬ ì´ìŠˆ:"
                    for cat, items in news.items():
                        if items:
                            for item in items[:1]:  # ì¹´í…Œê³ ë¦¬ë‹¹ 1ê°œë§Œ
                                title_text = item.get('title', '')[:50]
                                user_content += f"\n   - [{cat_names.get(cat, cat)}] {title_text}"

                # ì²­ì¤‘ ê´€ì‹¬ì‚¬
                concerns = context.get('concerns', [])
                if concerns:
                    user_content += f"\n   ì²­ì¤‘ì˜ ì£¼ìš” ê´€ì‹¬ì‚¬: {', '.join(concerns[:3])}"

            user_content += "\n" + "=" * 50

        if duration:
            user_content += f"\n\nâš ï¸ ë§¤ìš° ì¤‘ìš” - ë¶„ëŸ‰ ì œí•œ: {duration} ë¶„ëŸ‰ ì•ˆì—ì„œ ì¶©ë¶„íˆ ìƒì„¸í•˜ê³  í’ì„±í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”!"
            user_content += f"\n{duration} ë¶„ëŸ‰ì„ ë°˜ë“œì‹œ ì§€í‚¤ë˜, ê·¸ ì•ˆì—ì„œ ìµœëŒ€í•œ ê¹Šì´ ìˆê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        else:
            user_content += f"\n\nâš ï¸ ì¤‘ìš”: ì¶©ë¶„íˆ ê¸¸ê³  ìƒì„¸í•˜ë©° í’ì„±í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."

        usage_data = None

        messages = [
            {"role": "system", "content": system_content},
            {"role": "user", "content": user_content}
        ]

        api_kwargs = {"model": gpt_pro_model, "messages": messages}
        if gpt_pro_model in ["gpt-5", "gpt-5.1"]:
            api_kwargs["max_completion_tokens"] = max_tokens
        elif gpt_pro_model.startswith("gpt-5"):
            api_kwargs["temperature"] = 0.8
            api_kwargs["max_completion_tokens"] = max_tokens
        else:
            api_kwargs["temperature"] = 0.8
            api_kwargs["max_tokens"] = max_tokens

        # API í˜¸ì¶œ (ìµœëŒ€ 3íšŒ ì¬ì‹œë„)
        max_retries = 3
        completion = None
        last_error = None

        for attempt in range(max_retries):
            try:
                completion = client.chat.completions.create(**api_kwargs)
                break
            except Exception as e:
                last_error = e
                if attempt < max_retries - 1:
                    wait_time = 2 ** attempt
                    print(f"[GPT-PRO/Step3] API í˜¸ì¶œ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}), {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {str(e)}")
                    time.sleep(wait_time)
                else:
                    print(f"[GPT-PRO/Step3] API í˜¸ì¶œ ìµœì¢… ì‹¤íŒ¨ ({max_retries}íšŒ ì‹œë„): {str(e)}")
                    raise e

        if not completion:
            raise RuntimeError(f"{gpt_pro_model} API í˜¸ì¶œ ì‹¤íŒ¨: {str(last_error)}")

        result = completion.choices[0].message.content.strip()

        if hasattr(completion, 'usage') and completion.usage:
            usage_data = {
                "input_tokens": getattr(completion.usage, 'prompt_tokens', 0),
                "output_tokens": getattr(completion.usage, 'completion_tokens', 0),
                "total_tokens": getattr(completion.usage, 'total_tokens', 0)
            }

        if not result:
            raise RuntimeError(f"{gpt_pro_model} APIë¡œë¶€í„° ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        if usage_data:
            log_api_usage(
                step_name='step3',
                model_name=gpt_pro_model,
                input_tokens=usage_data.get('input_tokens', 0),
                output_tokens=usage_data.get('output_tokens', 0),
                style_name=style_name,
                category=category
            )

        result = remove_markdown(result)

        final_result = ""

        if has_title:
            final_result += f"ì„¤êµ ì œëª©: {title}\n\n"
            if reference:
                final_result += f"ë³¸ë¬¸: {reference}\n\n"
            final_result += result
        else:
            if reference:
                final_result += f"ë³¸ë¬¸: {reference}\n\n"
            final_result += result

        print(f"[GPT-PRO] ì™„ë£Œ")

        # ì„¤êµë¬¸ ìë™ ë¶„ì„ ë° DB ì €ì¥
        try:
            extracted_title = title if has_title else ""
            if not has_title and "ì„¤êµ ì œëª©:" in final_result:
                lines = final_result.split('\n')
                for line in lines:
                    if line.startswith("ì„¤êµ ì œëª©:"):
                        extracted_title = line.replace("ì„¤êµ ì œëª©:", "").strip()
                        break

            analysis_thread = threading.Thread(
                target=analyze_sermon_for_benchmark,
                args=(final_result, reference, extracted_title, category, style_name)
            )
            analysis_thread.daemon = True
            analysis_thread.start()
            print(f"[GPT-PRO] ë²¤ì¹˜ë§ˆí¬ ë¶„ì„ ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘")
        except Exception as e:
            print(f"[GPT-PRO] ë²¤ì¹˜ë§ˆí¬ ë¶„ì„ ì‹œì‘ ì‹¤íŒ¨ (ë¬´ì‹œ): {str(e)}")

        # í¬ë ˆë”§ ì°¨ê°
        remaining_credits = current_credits
        if AUTH_ENABLED and not is_admin and user_id:
            use_credit(user_id)
            remaining_credits = get_user_credits(user_id)
            print(f"[GPT-PRO/Step3] í¬ë ˆë”§ ì°¨ê° - ì‚¬ìš©ì: {user_id}, ë‚¨ì€ í¬ë ˆë”§: {remaining_credits}")

        print(f"[GPT-PRO/Step3] ì™„ë£Œ - í† í°: {usage_data}")
        return jsonify({
            "ok": True,
            "result": final_result,
            "usage": usage_data,
            "credits": remaining_credits if not is_admin else -1
        })

    except Exception as e:
        print(f"[GPT-PRO/Step3][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


@api_sermon_bp.route('/qa', methods=['POST'])
@api_login_required
def sermon_qa():
    """ì„¤êµ ì¤€ë¹„ Q&A - ì²˜ë¦¬ ë‹¨ê³„ ê²°ê³¼ì™€ ë³¸ë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ì§ˆë¬¸ì— ë‹µë³€"""
    try:
        client = get_client()
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        question = data.get("question", "")
        reference = data.get("reference", "")
        step_results = data.get("stepResults", {})

        if not question:
            return jsonify({"ok": False, "error": "ì§ˆë¬¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"}), 400

        print(f"[Q&A] ì§ˆë¬¸: {question}")

        system_content = """ë‹¹ì‹ ì€ ì„¤êµ ì¤€ë¹„ë¥¼ ë•ëŠ” ì„±ê²½ ì—°êµ¬ ë„ìš°ë¯¸ì…ë‹ˆë‹¤.

ë‹¹ì‹ ì˜ ì—­í• :
- ì‚¬ìš©ìê°€ í˜„ì¬ ì¤€ë¹„ ì¤‘ì¸ ì„±ê²½ ë³¸ë¬¸ê³¼ ê´€ë ¨ëœ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤
- ì œê³µëœ ì²˜ë¦¬ ë‹¨ê³„ ê²°ê³¼(ë°°ê²½ ì§€ì‹, ë³¸ë¬¸ ë¶„ì„, ê°œìš” ë“±)ë¥¼ ì°¸ê³ í•˜ì—¬ ë‹µë³€í•©ë‹ˆë‹¤
- ì§ˆë¬¸ì´ ëª¨í˜¸í•œ ê²½ìš°, í˜„ì¬ ë§¥ë½(ì„±ê²½ ë³¸ë¬¸, ì²˜ë¦¬ ë‹¨ê³„)ì„ ê¸°ì¤€ìœ¼ë¡œ ì´í•´í•˜ê³  ë‹µë³€í•©ë‹ˆë‹¤
- ê°„ë‹¨í•˜ê³  ëª…í™•í•˜ê²Œ ë‹µë³€í•˜ë˜, í•„ìš”ì‹œ ì„±ê²½ì  ë°°ê²½ì´ë‚˜ ì‹ í•™ì  ì„¤ëª…ì„ ì¶”ê°€í•©ë‹ˆë‹¤

ë‹µë³€ ì›ì¹™:
- ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰¬ìš´ í†¤ìœ¼ë¡œ ì‘ì„±
- ë¶ˆí™•ì‹¤í•œ ê²½ìš° "ì •í™•í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤"ë¼ê³  ëª…ì‹œ
- í•„ìš”ì‹œ ê´€ë ¨ ì„±ê²½ êµ¬ì ˆì´ë‚˜ ì—­ì‚¬ì  ë°°ê²½ ì–¸ê¸‰"""

        user_content = ""

        if reference:
            user_content += f"ã€ í˜„ì¬ ì¤€ë¹„ ì¤‘ì¸ ì„±ê²½ ë³¸ë¬¸ ã€‘\n{reference}\n\n"

        if step_results:
            user_content += "ã€ ì²˜ë¦¬ ë‹¨ê³„ ê²°ê³¼ ã€‘\n"
            for step_id, step_data in step_results.items():
                step_name = step_data.get("name", "")
                step_result = step_data.get("result", "")
                if step_result:
                    user_content += f"\n### {step_name}\n{step_result}\n"
            user_content += "\n"

        user_content += f"ã€ ì‚¬ìš©ì ì§ˆë¬¸ ã€‘\n{question}\n\n"
        user_content += "ìœ„ ë§¥ë½ì„ ì°¸ê³ í•˜ì—¬ ì§ˆë¬¸ì— ë‹µë³€í•´ì£¼ì„¸ìš”."

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7
        )

        answer = completion.choices[0].message.content

        print(f"[Q&A] ë‹µë³€ ì™„ë£Œ")

        return jsonify({"ok": True, "answer": answer})

    except Exception as e:
        print(f"[Q&A][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


@api_sermon_bp.route('/recommend-scripture', methods=['POST'])
@api_login_required
def recommend_scripture():
    """ìƒí™©ì— ë§ëŠ” ì„±ê²½ ë³¸ë¬¸ ì¶”ì²œ (ë‹¨ë½ ë‹¨ìœ„, ë³¸ë¬¸ í¬í•¨)"""
    try:
        client = get_client()
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        query = data.get("query", "")
        if not query:
            return jsonify({"ok": False, "error": "ìƒí™©ì„ ì…ë ¥í•´ì£¼ì„¸ìš”"}), 400

        print(f"[ë³¸ë¬¸ì¶”ì²œ] ê²€ìƒ‰ì–´: {query}")

        system_content = """ë‹¹ì‹ ì€ ì„¤êµ ë³¸ë¬¸ ì„ ì • ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì‚¬ìš©ìê°€ ì œì‹œí•˜ëŠ” ìƒí™©, í–‰ì‚¬, ì£¼ì œì— ê°€ì¥ ì í•©í•œ ì„±ê²½ ë³¸ë¬¸ì„ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ã€ í•µì‹¬ ì›ì¹™ ã€‘
1. ë‹¨ë½(Pericope) ë‹¨ìœ„ë¡œ ì¶”ì²œ: 1-2ì ˆì´ ì•„ë‹Œ, í•˜ë‚˜ì˜ ì™„ê²°ëœ ì´ì•¼ê¸°ë‚˜ ë…¼ì¦ ë‹¨ìœ„ë¡œ ì¶”ì²œí•˜ì„¸ìš”.
   - ì¢‹ì€ ì˜ˆ: ì°½ì„¸ê¸° 18:17-33 (ì•„ë¸Œë¼í•¨ì˜ ì¤‘ë³´ê¸°ë„), ìš”í•œë³µìŒ 15:1-17 (í¬ë„ë‚˜ë¬´ ë¹„ìœ )
   - ë‚˜ìœ ì˜ˆ: ì°½ì„¸ê¸° 18:17 (ë„ˆë¬´ ì§§ìŒ), ì‹œí¸ 23:1 (ë‹¨ì ˆë¨)
2. ìƒˆë²½ì„¤êµ, ì£¼ì¼ì„¤êµ ë“±ì— ì í•©í•œ 5-20ì ˆ ë¶„ëŸ‰ì˜ ë³¸ë¬¸ì„ ì¶”ì²œí•˜ì„¸ìš”.
3. ì‹¤ì œ ì„±ê²½ ë³¸ë¬¸ ë‚´ìš©ì„ í¬í•¨í•˜ì„¸ìš” (ê°œì—­ê°œì • ê¸°ì¤€).

ã€ ì‘ë‹µ í˜•ì‹ ã€‘
ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
[
  {
    "scripture": "ì°½ì„¸ê¸° 18:17-33",
    "title": "ì•„ë¸Œë¼í•¨ì˜ ì¤‘ë³´ê¸°ë„",
    "text": "ì—¬í˜¸ì™€ê»˜ì„œ ì´ë¥´ì‹œë˜ ë‚´ê°€ í•˜ë ¤ëŠ” ê²ƒì„ ì•„ë¸Œë¼í•¨ì—ê²Œ ìˆ¨ê¸°ê² ëŠëƒ... (í•µì‹¬ êµ¬ì ˆ 3-5ê°œ ë°œì·Œ)",
    "reason": "ì´ ë³¸ë¬¸ì´ í•´ë‹¹ ìƒí™©ì— ì í•©í•œ ì´ìœ ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…. ë³¸ë¬¸ì˜ í•µì‹¬ ë©”ì‹œì§€ì™€ ìƒí™©ì˜ ì—°ê²°ì ì„ ë¶„ì„ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”."
  },
  ...
]

ã€ ì£¼ì˜ì‚¬í•­ ã€‘
- ì •í™•íˆ 5ê°œì˜ ì¶”ì²œì„ ì œê³µí•˜ì„¸ìš”
- scripture: í•œê¸€ ì„±ê²½ í‘œê¸°ë²• + ë‹¨ë½ ë²”ìœ„ (ì˜ˆ: ì°½ì„¸ê¸° 18:17-33)
- title: ë³¸ë¬¸ì˜ í•µì‹¬ ì£¼ì œë¥¼ 5-10ìë¡œ
- text: í•´ë‹¹ ë³¸ë¬¸ì˜ í•µì‹¬ êµ¬ì ˆ 3-5ê°œë¥¼ ë°œì·Œ (... ìœ¼ë¡œ ì—°ê²°)
- reason: 50-100ìë¡œ ìƒí™©ê³¼ ë³¸ë¬¸ì˜ ì—°ê²°ì ì„ ë¶„ì„ì ìœ¼ë¡œ ì„¤ëª…
- JSON í˜•ì‹ë§Œ ì‘ë‹µí•˜ì„¸ìš”"""

        user_content = f"""ë‹¤ìŒ ìƒí™©/í–‰ì‚¬/ì£¼ì œì— ì í•©í•œ ì„¤êµ ë³¸ë¬¸ 5ê°œë¥¼ ì¶”ì²œí•´ì£¼ì„¸ìš”.

ìƒí™©: {query}

ê° ì¶”ì²œì— ëŒ€í•´:
1. ë‹¨ë½ ë‹¨ìœ„ì˜ ë³¸ë¬¸ ë²”ìœ„ (5-20ì ˆ)
2. ë³¸ë¬¸ ì œëª©
3. í•µì‹¬ ì„±ê²½ êµ¬ì ˆ ë°œì·Œ
4. ì´ ë³¸ë¬¸ì„ ì¶”ì²œí•˜ëŠ” êµ¬ì²´ì ì¸ ì´ìœ  (ìƒí™©ê³¼ì˜ ì—°ê²°ì )

ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7
        )

        response_text = completion.choices[0].message.content.strip()

        try:
            if response_text.startswith("```"):
                response_text = response_text.split("```")[1]
                if response_text.startswith("json"):
                    response_text = response_text[4:]
            recommendations = json.loads(response_text)
        except json.JSONDecodeError:
            print(f"[ë³¸ë¬¸ì¶”ì²œ] JSON íŒŒì‹± ì‹¤íŒ¨: {response_text[:200]}")
            return jsonify({"ok": False, "error": "ì¶”ì²œ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 200

        print(f"[ë³¸ë¬¸ì¶”ì²œ] ì™„ë£Œ: {len(recommendations)}ê°œ ì¶”ì²œ")

        return jsonify({"ok": True, "recommendations": recommendations})

    except Exception as e:
        print(f"[ë³¸ë¬¸ì¶”ì²œ][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


@api_sermon_bp.route('/chat', methods=['POST'])
def sermon_chat():
    """ì„¤êµ í˜ì´ì§€ AI ì±—ë´‡ - í˜„ì¬ ì‘ì—… ìƒí™© ë° ì˜¤ë¥˜ì— ëŒ€í•´ ì§ˆë¬¸/ë‹µë³€"""
    try:
        client = get_client()
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        question = data.get("question", "")
        context = data.get("context", {})
        selected_model = data.get("model", "gpt-4o-mini")

        allowed_models = ["gpt-4o-mini", "gpt-4o", "gpt-5"]
        if selected_model not in allowed_models:
            selected_model = "gpt-4o-mini"

        if not question:
            return jsonify({"ok": False, "error": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        print(f"[SERMON-CHAT] ëª¨ë¸: {selected_model}, ì§ˆë¬¸: {question[:100]}...")

        context_text = ""

        if context.get("step1Result"):
            context_text += f"ã€Step1 ê²°ê³¼ (ë³¸ë¬¸ ì—°êµ¬)ã€‘\n{context.get('step1Result', '')[:2000]}\n\n"

        if context.get("step2Result"):
            context_text += f"ã€Step2 ê²°ê³¼ (ì„¤êµ êµ¬ì¡°)ã€‘\n{context.get('step2Result', '')[:2000]}\n\n"

        if context.get("step3Result"):
            context_text += f"ã€Step3 ê²°ê³¼ (ì„¤êµë¬¸)ã€‘\n{context.get('step3Result', '')[:3000]}\n\n"

        if context.get("bibleVerse"):
            context_text += f"ã€ì„±ê²½ ë³¸ë¬¸ã€‘\n{context.get('bibleVerse', '')}\n\n"

        if context.get("sermonStyle"):
            context_text += f"ã€ì„¤êµ ìŠ¤íƒ€ì¼ã€‘\n{context.get('sermonStyle', '')}\n\n"

        if context.get("lastError"):
            context_text += f"ã€ìµœê·¼ ì˜¤ë¥˜ã€‘\n{context.get('lastError', '')}\n\n"

        if context.get("apiResponse"):
            context_text += f"ã€API ì‘ë‹µ ì •ë³´ã€‘\n{context.get('apiResponse', '')}\n\n"

        system_prompt = """ë‹¹ì‹ ì€ ì„¤êµë¬¸ ì‘ì„± ë„êµ¬ì˜ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ì„¤êµë¬¸ ì‘ì„± ê³¼ì •ì—ì„œ ê²ªëŠ” ë¬¸ì œë‚˜ ì§ˆë¬¸ì— ë‹µë³€í•©ë‹ˆë‹¤.

ì—­í• :
1. í˜„ì¬ ì„¤êµë¬¸ ì‘ì„± ìƒí™© ë¶„ì„ ë° ì„¤ëª…
2. Step1(ë³¸ë¬¸ ì—°êµ¬), Step2(ì„¤êµ êµ¬ì¡°), Step3(ì„¤êµë¬¸ ì‘ì„±) ë‹¨ê³„ë³„ ë„ì›€
3. ì˜¤ë¥˜ ë°œìƒ ì‹œ ì›ì¸ ë¶„ì„ ë° í•´ê²° ë°©ë²• ì•ˆë‚´
4. API ì˜¤ë¥˜, í¬ë ˆë”§ ë¬¸ì œ, ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜ ë“± ê¸°ìˆ ì  ë¬¸ì œ í•´ê²° ë„ì›€
5. ì„¤êµ ë‚´ìš©ì— ëŒ€í•œ í”¼ë“œë°± ë° ê°œì„  ì œì•ˆ

ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ìœ í˜•:
- Step3 í¬ë ˆë”§ ë¶€ì¡±: ê´€ë¦¬ìì—ê²Œ í¬ë ˆë”§ ì¶©ì „ ìš”ì²­ í•„ìš”
- API íƒ€ì„ì•„ì›ƒ: ì…ë ¥ ë‚´ìš©ì´ ë„ˆë¬´ ê¸¸ê±°ë‚˜ ì„œë²„ ë¶€í•˜
- ë„¤íŠ¸ì›Œí¬ ì˜¤ë¥˜: ì¸í„°ë„· ì—°ê²° í™•ì¸ í•„ìš”
- ëª¨ë¸ ì˜¤ë¥˜: ë‹¤ë¥¸ AI ëª¨ë¸ë¡œ ì‹œë„ ê¶Œì¥

ë‹µë³€ ì‹œ ìœ ì˜ì‚¬í•­:
- ê¸°ìˆ ì  ë¬¸ì œëŠ” êµ¬ì²´ì ì¸ í•´ê²° ë°©ë²•ì„ ì•ˆë‚´í•˜ì„¸ìš”
- ì„¤êµ ë‚´ìš© ê´€ë ¨ ì§ˆë¬¸ì€ ì‹ í•™ì ìœ¼ë¡œ ì ì ˆí•œ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê³  ì´í•´í•˜ê¸° ì‰½ê²Œ ë‹µë³€í•˜ì„¸ìš”"""

        user_content = ""
        if context_text:
            user_content += f"{context_text}\n"
        user_content += f"ã€ì§ˆë¬¸ã€‘\n{question}"

        completion = client.chat.completions.create(
            model=selected_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            max_tokens=4000 if selected_model in ["gpt-4o", "gpt-5"] else 2000
        )

        answer = completion.choices[0].message.content.strip()

        usage = {
            "input_tokens": completion.usage.prompt_tokens,
            "output_tokens": completion.usage.completion_tokens,
            "model": selected_model
        }

        print(f"[SERMON-CHAT][SUCCESS] {selected_model}ë¡œ ë‹µë³€ ìƒì„± ì™„ë£Œ")
        return jsonify({"ok": True, "answer": answer, "usage": usage})

    except Exception as e:
        print(f"[SERMON-CHAT][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 500
