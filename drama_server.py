import os
import re
import json
import sqlite3
import subprocess
import threading
import queue
import uuid
import tempfile
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from datetime import datetime as dt
from flask import Flask, render_template, request, jsonify, send_file, Response, redirect, send_from_directory
from openai import OpenAI

# Assistant Blueprint ë“±ë¡
from assistant_server import assistant_bp
# TubeLens Blueprint ë“±ë¡
from tubelens_server import tubelens_bp

# ì–¸ì–´ë³„ ì„¤ì • (í°íŠ¸, ìë§‰, TTS ë“±)
from lang import ko as lang_ko
from lang import ja as lang_ja
from lang import en as lang_en

# GPT-5.1 í”„ë¡¬í”„íŠ¸ ëª¨ë“ˆ (í† í° ìµœì í™”)
from prompts import build_system_prompt, detect_category_simple, detect_language_simple
from prompts.category.styles import CATEGORY_IMAGE_STYLES, get_category_style

# YouTube í† í°/í• ë‹¹ëŸ‰ ê´€ë¦¬ ëª¨ë“ˆ
import youtube_auth
from youtube_auth import (
    get_youtube_credentials, set_youtube_quota_exceeded,
    check_youtube_quota_before_pipeline, reset_youtube_quota_exceeded,
    YOUTUBE_TOKEN_FILE, YOUTUBE_QUOTA_FLAG_FILE,
    save_youtube_token_to_db, load_youtube_token_from_db,
    load_all_youtube_channels_from_db, delete_youtube_channel_from_db,
    _load_quota_flag, _save_quota_flag
)

# ì´ë¯¸ì§€ ìƒì„± ëª¨ë“ˆ
from image import generate_image as image_generate, generate_image_base64, generate_thumbnail_image, get_image_count_by_script, GEMINI_FLASH, GEMINI_PRO

# TTS ì²­í‚¹ ëª¨ë“ˆ (ë¬¸ì¥ë³„ TTS ê°œì„ )
from tts.tts_chunking import split_korean_sentences as tts_split_sentences

# Sermon API Blueprint
from sermon_modules.api_sermon import api_sermon_bp

app = Flask(__name__)

# Assistant Blueprint ë“±ë¡
app.register_blueprint(assistant_bp)
# TubeLens Blueprint ë“±ë¡
app.register_blueprint(tubelens_bp)
# Sermon API Blueprint ë“±ë¡
app.register_blueprint(api_sermon_bp)

# ===== ì „ì—­ ì—ëŸ¬ í•¸ë“¤ëŸ¬ (í•­ìƒ JSON ë°˜í™˜) =====
@app.errorhandler(500)
def handle_500_error(e):
    """500 ì—ëŸ¬ ë°œìƒ ì‹œ HTML ëŒ€ì‹  JSON ë°˜í™˜"""
    print(f"[FLASK-500] ë‚´ë¶€ ì„œë²„ ì˜¤ë¥˜: {str(e)}")
    return jsonify({
        "ok": False,
        "error": f"ì„œë²„ ë‚´ë¶€ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"
    }), 500

@app.errorhandler(Exception)
def handle_exception(e):
    """ëª¨ë“  ì˜ˆì™¸ë¥¼ JSONìœ¼ë¡œ ë°˜í™˜"""
    print(f"[FLASK-ERROR] ì˜ˆì™¸ ë°œìƒ: {type(e).__name__}: {str(e)}")
    import traceback
    traceback.print_exc()
    return jsonify({
        "ok": False,
        "error": f"ì„œë²„ ì˜¤ë¥˜: {type(e).__name__}: {str(e)}"
    }), 500


# ===== favicon.ico ì²˜ë¦¬ (ë¸Œë¼ìš°ì € ìë™ ìš”ì²­) =====
@app.route('/favicon.ico')
def favicon():
    """íŒŒë¹„ì½˜ ìš”ì²­ ì²˜ë¦¬ - 204 No Content ë°˜í™˜"""
    return '', 204


# ===== uploads í´ë” ì •ì  íŒŒì¼ ì„œë¹™ =====
@app.route('/uploads/<path:filename>')
def serve_uploads(filename):
    """uploads í´ë”ì˜ íŒŒì¼ì„ ì œê³µ"""
    upload_dir = os.path.join(os.getcwd(), 'uploads')
    os.makedirs(upload_dir, exist_ok=True)
    return send_from_directory(upload_dir, filename)


# ===== outputs í´ë” ì •ì  íŒŒì¼ ì„œë¹™ =====
@app.route('/output/<path:filename>')
def serve_output(filename):
    """outputs í´ë”ì˜ íŒŒì¼ì„ ì œê³µ (ì¸ë„¤ì¼, ì´ë¯¸ì§€ ë“±)"""
    output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
    os.makedirs(output_dir, exist_ok=True)
    return send_from_directory(output_dir, filename)


# ===== FFmpeg ë™ì‹œ ì‹¤í–‰ ì œí•œ (ë©”ëª¨ë¦¬ ë³´í˜¸) =====
# Render 2GB ë©”ëª¨ë¦¬ì—ì„œ ë™ì‹œì— 2ê°œ ì´ìƒì˜ FFmpeg í”„ë¡œì„¸ìŠ¤ ì‹¤í–‰ ì‹œ OOM ìœ„í—˜
# ì„¸ë§ˆí¬ì–´ë¡œ ìµœëŒ€ 1ê°œì˜ FFmpeg ì‘ì—…ë§Œ ë™ì‹œ ì‹¤í–‰ í—ˆìš©
ffmpeg_semaphore = threading.Semaphore(1)

# ===== ë¹„ë™ê¸° ì˜ìƒ ìƒì„± ì‘ì—… í ì‹œìŠ¤í…œ =====
video_job_queue = queue.Queue()
video_jobs = {}  # {job_id: {status, progress, result, error, created_at}}
video_jobs_lock = threading.Lock()
VIDEO_JOBS_FILE = 'data/video_jobs.json'

# ===== íŒŒì´í”„ë¼ì¸ ë™ì‹œ ì‹¤í–‰ ë°©ì§€ Lock =====
# cron jobì´ ë™ì‹œì— ì—¬ëŸ¬ workerì—ì„œ ì‹¤í–‰ë˜ëŠ” ê²ƒì„ ë°©ì§€
pipeline_lock = threading.Lock()

# ===== ì„œë²„ ì‹œì‘ ì‹œê°„ (orphan ì‘ì—… ê°ì§€ìš©) =====
# ì„œë²„ ì¬ì‹œì‘ ì „ì— ì‹œì‘ëœ "ì²˜ë¦¬ì¤‘" ì‘ì—…ì„ ìë™ ê°ì§€í•˜ì—¬ ì‹¤íŒ¨ ì²˜ë¦¬
SERVER_START_TIME = dt.now()
print(f"[SERVER] ì‹œì‘ ì‹œê°„: {SERVER_START_TIME.strftime('%Y-%m-%d %H:%M:%S')}")

# ===== í•œê¸€ ìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì ë³€í™˜ (ìë§‰ìš©) =====
def korean_number_to_arabic(text):
    """
    í•œê¸€ ìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜ (ìë§‰ í‘œì‹œìš©)
    TTSìš© ëŒ€ë³¸ì€ í•œê¸€ ìˆ«ìë¡œ ì‘ì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ìë§‰ í‘œì‹œ ì‹œ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
    """
    result = text

    # 1. ê³ ìœ ì–´ ìˆ«ì (ë‚˜ì´, ê°œìˆ˜ ë“±ì— ì‚¬ìš©)
    # ì¼í”ì—¬ì„¯ ì‚´ â†’ 76ì‚´, ì—¬ë“ ì¼ê³± ì‚´ â†’ 87ì‚´
    native_tens = {
        'ì—´': 10, 'ìŠ¤ë¬¼': 20, 'ì„œë¥¸': 30, 'ë§ˆí”': 40, 'ì‰°': 50,
        'ì˜ˆìˆœ': 60, 'ì¼í”': 70, 'ì—¬ë“ ': 80, 'ì•„í”': 90
    }
    native_ones = {
        'í•˜ë‚˜': 1, 'ë‘˜': 2, 'ì…‹': 3, 'ë„·': 4, 'ë‹¤ì„¯': 5,
        'ì—¬ì„¯': 6, 'ì¼ê³±': 7, 'ì—¬ëŸ': 8, 'ì•„í™‰': 9,
        'í•œ': 1, 'ë‘': 2, 'ì„¸': 3, 'ë„¤': 4
    }

    # ê³ ìœ ì–´ ì‹­ë‹¨ìœ„+ì¼ë‹¨ìœ„ íŒ¨í„´ (ì˜ˆ: ì¼í”ì—¬ì„¯)
    for ten_kr, ten_val in native_tens.items():
        for one_kr, one_val in native_ones.items():
            pattern = ten_kr + one_kr
            if pattern in result:
                result = result.replace(pattern, str(ten_val + one_val))

    # ê³ ìœ ì–´ ì‹­ë‹¨ìœ„ë§Œ (ì˜ˆ: ìŠ¤ë¬¼, ì„œë¥¸)
    for ten_kr, ten_val in native_tens.items():
        # "ìŠ¤ë¬¼ " ë˜ëŠ” "ìŠ¤ë¬¼ì‚´" ë“±ì˜ íŒ¨í„´
        result = re.sub(rf'{ten_kr}(?=\s|ì‚´|ì„¸|ëª…|ê°œ|ë²ˆ|ë…„|ì›”|ì¼|ì‹œ|ë¶„|$)', str(ten_val), result)

    # ê³ ìœ ì–´ ì¼ë‹¨ìœ„ë§Œ (í•œ, ë‘, ì„¸, ë„¤ + ë‹¨ìœ„)
    result = re.sub(r'í•œ(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '1', result)
    result = re.sub(r'ë‘(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '2', result)
    result = re.sub(r'ì„¸(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '3', result)
    result = re.sub(r'ë„¤(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '4', result)
    result = re.sub(r'ë‹¤ì„¯(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '5', result)
    result = re.sub(r'ì—¬ì„¯(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '6', result)
    result = re.sub(r'ì¼ê³±(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '7', result)
    result = re.sub(r'ì—¬ëŸ(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '8', result)
    result = re.sub(r'ì•„í™‰(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '9', result)
    result = re.sub(r'ì—´(?=\s*(?:ëª…|ê°œ|ë²ˆ|ì‚´|ë¶„|ì‹œê°„|ë‹¬|í•´))', '10', result)

    # 2. í•œìì–´ ìˆ«ì (ì „í™”ë²ˆí˜¸, ì—°ë„, ê¸ˆì•¡ ë“±)
    sino_digits = {
        'ì˜': '0', 'ì¼': '1', 'ì´': '2', 'ì‚¼': '3', 'ì‚¬': '4',
        'ì˜¤': '5', 'ìœ¡': '6', 'ì¹ ': '7', 'íŒ”': '8', 'êµ¬': '9'
    }

    # ì „í™”ë²ˆí˜¸ íŒ¨í„´ (ì¼ì¼ì´, ì¼ì¼êµ¬, ì¼ì´ì‚¼ì‚¬ ë“±)
    # ì—°ì†ëœ í•œìì–´ ìˆ«ìë¥¼ ì•„ë¼ë¹„ì•„ ìˆ«ìë¡œ ë³€í™˜
    def convert_sino_sequence(match):
        seq = match.group(0)
        result_num = ''
        for char in seq:
            if char in sino_digits:
                result_num += sino_digits[char]
        return result_num

    # 2-4ìë¦¬ ì—°ì† í•œìì–´ ìˆ«ì (ì „í™”ë²ˆí˜¸ ë“±)
    sino_pattern = '[ì˜ì¼ì´ì‚¼ì‚¬ì˜¤ìœ¡ì¹ íŒ”êµ¬]{2,4}'
    result = re.sub(sino_pattern, convert_sino_sequence, result)

    # 3. í•œìì–´ ë³µí•© ìˆ«ì (ì´ì‹­, ì‚¼ì‹­, ë°±, ì²œ, ë§Œ ë“±)
    # ì´ì‹­ ë…„ â†’ 20ë…„, ì‚¬ì‹­ì¹  ë…„ â†’ 47ë…„
    sino_tens = {'ì´ì‹­': 20, 'ì‚¼ì‹­': 30, 'ì‚¬ì‹­': 40, 'ì˜¤ì‹­': 50, 'ìœ¡ì‹­': 60, 'ì¹ ì‹­': 70, 'íŒ”ì‹­': 80, 'êµ¬ì‹­': 90}
    sino_ones_after = {'ì¼': 1, 'ì´': 2, 'ì‚¼': 3, 'ì‚¬': 4, 'ì˜¤': 5, 'ìœ¡': 6, 'ì¹ ': 7, 'íŒ”': 8, 'êµ¬': 9}

    # ì‹­ë‹¨ìœ„+ì¼ë‹¨ìœ„ (ì‚¬ì‹­ì¹  â†’ 47)
    for ten_kr, ten_val in sino_tens.items():
        for one_kr, one_val in sino_ones_after.items():
            pattern = ten_kr + one_kr
            if pattern in result:
                result = result.replace(pattern, str(ten_val + one_val))

    # ì‹­ë‹¨ìœ„ë§Œ (ì´ì‹­ â†’ 20)
    for ten_kr, ten_val in sino_tens.items():
        result = result.replace(ten_kr, str(ten_val))

    # ì‹­+ì¼ë‹¨ìœ„ (ì‹­ì˜¤ â†’ 15)
    for one_kr, one_val in sino_ones_after.items():
        pattern = f'ì‹­{one_kr}'
        if pattern in result:
            result = result.replace(pattern, str(10 + one_val))

    # ì‹­ â†’ 10
    result = re.sub(r'(?<![ì´ì‚¼ì‚¬ì˜¤ìœ¡ì¹ íŒ”êµ¬])ì‹­(?![ì¼ì´ì‚¼ì‚¬ì˜¤ìœ¡ì¹ íŒ”êµ¬])', '10', result)

    # 4. í° ë‹¨ìœ„ (ë°±, ì²œ, ë§Œ)
    # ë°±ë§Œ ì› â†’ 100ë§Œì›, ì˜¤ì‹­ë§Œ ì› â†’ 50ë§Œì›
    result = re.sub(r'(\d+)ë°±(\d+)', lambda m: str(int(m.group(1)) * 100 + int(m.group(2))), result)
    result = re.sub(r'(\d+)ë°±(?!\d)', lambda m: str(int(m.group(1)) * 100), result)
    result = re.sub(r'(?<!\d)ë°±(?!\d)', '100', result)

    # 5. ê³µë°± ì •ë¦¬ (ì˜ˆ: "50 ë§Œ ì›" â†’ "50ë§Œì›")
    result = re.sub(r'(\d+)\s*(ë§Œ|ì²œ|ë°±)\s*(ì›|ëª…|ê°œ)', r'\1\2\3', result)
    result = re.sub(r'(\d+)\s+(ë…„|ì›”|ì¼|ì‚´|ì„¸|ëª…|ê°œ|ë²ˆ|ì‹œ|ë¶„|ì´ˆ)', r'\1\2', result)

    return result

# Job íŒŒì¼ ì €ì¥/ë¡œë“œ í•¨ìˆ˜ (Render ì¬ì‹œì‘ ëŒ€ë¹„)
def save_video_jobs():
    """video_jobsë¥¼ íŒŒì¼ì— ì €ì¥"""
    try:
        os.makedirs('data', exist_ok=True)
        with open(VIDEO_JOBS_FILE, 'w', encoding='utf-8') as f:
            json.dump(video_jobs, f, ensure_ascii=False, indent=2)
    except Exception as e:
        print(f"[VIDEO-JOBS] ì €ì¥ ì‹¤íŒ¨: {e}")

def load_video_jobs():
    """íŒŒì¼ì—ì„œ video_jobs ë¡œë“œ"""
    global video_jobs
    try:
        if os.path.exists(VIDEO_JOBS_FILE):
            with open(VIDEO_JOBS_FILE, 'r', encoding='utf-8') as f:
                video_jobs = json.load(f)
            print(f"[VIDEO-JOBS] {len(video_jobs)}ê°œ ì‘ì—… ë¡œë“œë¨")
        else:
            video_jobs = {}
            print("[VIDEO-JOBS] ìƒˆë¡œìš´ ì‘ì—… ì €ì¥ì†Œ ìƒì„±")
    except Exception as e:
        print(f"[VIDEO-JOBS] ë¡œë“œ ì‹¤íŒ¨: {e}")
        video_jobs = {}

def video_worker():
    """ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤: ì˜ìƒ ìƒì„± ì‘ì—… ì²˜ë¦¬

    íì—ì„œ ì‘ì—…ì„ ê°€ì ¸ì™€ ë¹„ë™ê¸°ì ìœ¼ë¡œ ì˜ìƒ ìƒì„±.
    Render ë“± íƒ€ì„ì•„ì›ƒ í™˜ê²½ì—ì„œë„ ì•ˆì •ì ìœ¼ë¡œ ë™ì‘.
    """
    print(f"[VIDEO-WORKER] ì›Œì»¤ ë£¨í”„ ì‹œì‘")
    while True:
        try:
            job = video_job_queue.get()
            if job is None:  # ì¢…ë£Œ ì‹ í˜¸
                print(f"[VIDEO-WORKER] ì¢…ë£Œ ì‹ í˜¸ ìˆ˜ì‹ ")
                break

            job_id = job['job_id']
            print(f"[VIDEO-WORKER] ì‘ì—… ì‹œì‘: {job_id}")

            # ë””ë²„ê¹…: ì‘ì—… ë°ì´í„° ìƒì„¸ ì¶œë ¥
            print(f"[VIDEO-WORKER] ì‘ì—… ë°ì´í„°:")
            print(f"  - images: {len(job.get('images', []))}ê°œ")
            print(f"  - cuts: {len(job.get('cuts', []))}ê°œ")
            print(f"  - audio_url: {'ìˆìŒ' if job.get('audio_url') else 'ì—†ìŒ'}")
            print(f"  - resolution: {job.get('resolution', 'N/A')}")
            print(f"  - fps: {job.get('fps', 'N/A')}")

            # ìƒíƒœ ì—…ë°ì´íŠ¸: processing
            with video_jobs_lock:
                if job_id in video_jobs:
                    video_jobs[job_id]['status'] = 'processing'
                    video_jobs[job_id]['progress'] = 0
                    video_jobs[job_id]['message'] = 'ì˜ìƒ ìƒì„± ì‹œì‘...'
                    save_video_jobs()

            try:
                # ì‹¤ì œ ì˜ìƒ ìƒì„± ë¡œì§ ì‹¤í–‰ (cuts ì§€ì›)
                result = _generate_video_sync(
                    images=job.get('images', []),
                    audio_url=job.get('audio_url', ''),
                    cuts=job.get('cuts', []),  # cuts ë°°ì—´ ì „ë‹¬
                    subtitle_data=job.get('subtitle_data'),
                    burn_subtitle=job.get('burn_subtitle', False),
                    resolution=job.get('resolution', '1920x1080'),
                    fps=job.get('fps', 30),
                    transition=job.get('transition', 'fade'),
                    job_id=job_id
                )

                # ì„±ê³µ
                with video_jobs_lock:
                    if job_id in video_jobs:
                        video_jobs[job_id]['status'] = 'completed'
                        video_jobs[job_id]['progress'] = 100
                        video_jobs[job_id]['message'] = 'ì˜ìƒ ìƒì„± ì™„ë£Œ'
                        video_jobs[job_id]['result'] = result
                        video_jobs[job_id]['completed_at'] = dt.now().isoformat()
                        save_video_jobs()

                print(f"[VIDEO-WORKER] ì‘ì—… ì™„ë£Œ: {job_id}")

            except Exception as e:
                # ì‹¤íŒ¨
                import traceback
                error_msg = str(e)
                print(f"[VIDEO-WORKER] ì‘ì—… ì‹¤íŒ¨: {job_id} - {error_msg}")
                traceback.print_exc()

                with video_jobs_lock:
                    if job_id in video_jobs:
                        video_jobs[job_id]['status'] = 'failed'
                        video_jobs[job_id]['error'] = error_msg
                        video_jobs[job_id]['message'] = f'ì‹¤íŒ¨: {error_msg}'
                        save_video_jobs()

            video_job_queue.task_done()

        except Exception as e:
            import traceback
            print(f"[VIDEO-WORKER] ì›Œì»¤ ë£¨í”„ ì˜¤ë¥˜: {str(e)}")
            traceback.print_exc()

# ì„œë²„ ì‹œì‘ ì‹œ ì €ì¥ëœ jobs ë¡œë“œ
load_video_jobs()

# ì„œë²„ ì¬ì‹œì‘ ì‹œ pending/processing ì‘ì—… ì •ë¦¬
# (íê°€ ë¹„ì–´ìˆìœ¼ë¯€ë¡œ ì´ ì‘ì—…ë“¤ì€ ì²˜ë¦¬ë˜ì§€ ì•ŠìŒ â†’ ì‹¤íŒ¨ ì²˜ë¦¬)
def cleanup_stale_jobs():
    """ì„œë²„ ì¬ì‹œì‘ ì‹œ ì²˜ë¦¬ë˜ì§€ ì•Šì€ ì‘ì—…ë“¤ì„ ì‹¤íŒ¨ ì²˜ë¦¬"""
    with video_jobs_lock:
        stale_count = 0
        for job_id, job in video_jobs.items():
            if job['status'] in ['pending', 'processing']:
                job['status'] = 'failed'
                job['error'] = 'ì„œë²„ ì¬ì‹œì‘ìœ¼ë¡œ ì¸í•´ ì‘ì—…ì´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.'
                stale_count += 1
        if stale_count > 0:
            save_video_jobs()
            print(f"[VIDEO-JOBS] ì„œë²„ ì¬ì‹œì‘: {stale_count}ê°œ ë¯¸ì™„ë£Œ ì‘ì—… ì‹¤íŒ¨ ì²˜ë¦¬ë¨")

cleanup_stale_jobs()

# ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘
video_worker_thread = threading.Thread(target=video_worker, daemon=True)
video_worker_thread.start()
print(f"[VIDEO-WORKER] ì›Œì»¤ ìŠ¤ë ˆë“œ ì‹œì‘ë¨ (alive: {video_worker_thread.is_alive()})")

# ===== JSON ì§€ì¹¨ íŒŒì¼ ë¡œë“œ =====
GUIDES_DIR = os.path.join(os.path.dirname(__file__), 'guides')
_drama_guidelines_cache = None

def load_drama_guidelines(force_reload=False):
    """JSON ì§€ì¹¨ íŒŒì¼ ë¡œë“œ (ìºì‹± ì§€ì›)"""
    global _drama_guidelines_cache

    if _drama_guidelines_cache is not None and not force_reload:
        return _drama_guidelines_cache

    json_path = os.path.join(GUIDES_DIR, 'drama.json')
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            _drama_guidelines_cache = json.load(f)
            print(f"[GUIDELINES] drama.json ë¡œë“œ ì™„ë£Œ (version: {_drama_guidelines_cache.get('version', 'unknown')})")
            return _drama_guidelines_cache
    except FileNotFoundError:
        print(f"[GUIDELINES] ê²½ê³ : {json_path} íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
        return None
    except json.JSONDecodeError as e:
        print(f"[GUIDELINES] ê²½ê³ : JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return None

def get_guideline(path, default=None):
    """
    ì  í‘œê¸°ë²•ìœ¼ë¡œ JSON ì§€ì¹¨ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°
    ì˜ˆ: get_guideline('contentTypes.testimony.systemPrompt')
    """
    guidelines = load_drama_guidelines()
    if guidelines is None:
        return default

    keys = path.split('.')
    value = guidelines
    try:
        for key in keys:
            value = value[key]
        return value
    except (KeyError, TypeError):
        return default

def build_testimony_prompt_from_guide(custom_guide=None, duration_minutes=20, test_mode=False):
    """
    guides/drama.jsonì˜ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê°„ì¦ ëŒ€ë³¸ ìƒì„±ìš© í”„ë¡¬í”„íŠ¸ êµ¬ì¶•
    custom_guide: í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë³´ë‚¸ ì»¤ìŠ¤í…€ JSON ê°€ì´ë“œ (ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©)
    duration_minutes: ì˜ìƒ ê¸¸ì´ (10, 20, 30ë¶„)
    test_mode: í…ŒìŠ¤íŠ¸ ëª¨ë“œ (Trueì¼ ê²½ìš° ìµœì†Œ ë¶„ëŸ‰ìœ¼ë¡œ ìƒì„±)
    """
    # ì»¤ìŠ¤í…€ ê°€ì´ë“œê°€ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©, ì—†ìœ¼ë©´ ì„œë²„ íŒŒì¼ì—ì„œ ë¡œë“œ
    guide = custom_guide if custom_guide else load_drama_guidelines()
    if not guide:
        return None, None

    # Step1 ê°€ì´ë“œë¼ì¸ ê°€ì ¸ì˜¤ê¸°
    step1_guidelines = guide.get('step1_script_guidelines', {})
    duration_key = f"{duration_minutes}min"
    duration_settings = step1_guidelines.get('duration_settings', {}).get(duration_key, {
        'target_length': 6000,
        'max_characters': 4,  # ìµœëŒ€ 4ëª…ìœ¼ë¡œ ì œí•œ
        'max_scenes': 6,
        'highlight_scenes': 3
    })

    # ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë¹„ìš© ìµœì†Œí™”ë¥¼ ìœ„í•´ ìµœì†Œ ë¶„ëŸ‰ìœ¼ë¡œ ì„¤ì •
    if test_mode:
        print("[DRAMA] ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ í™œì„±í™” - ìµœì†Œ ë¶„ëŸ‰ìœ¼ë¡œ ìƒì„±")
        duration_settings = {
            'target_length': 500,      # 500ì (ê¸°ì¡´ 3000~9000ì)
            'max_characters': 2,       # 2ëª… (ê¸°ì¡´ 2~4ëª…)
            'max_scenes': 2,           # 2ê°œ ì”¬ (ê¸°ì¡´ 4~8ê°œ)
            'highlight_scenes': 1      # 1ê°œ í•˜ì´ë¼ì´íŠ¸ (ê¸°ì¡´ 2~3ê°œ)
        }
        duration_minutes = 3  # 3ë¶„ ì˜ìƒìœ¼ë¡œ ì„¤ì •

    character_rules = step1_guidelines.get('character_rules', {})
    highlight_rules = step1_guidelines.get('highlight_rules', {})
    output_format = step1_guidelines.get('output_format', {})

    # ê¸°ì¡´ ìŠ¤íƒ€ì¼ ê°€ì´ë“œë„ ì°¸ì¡°
    script_style = guide.get('script_style', {})
    structure = guide.get('structure', {})
    dialogue_ratio = guide.get('dialogue_ratio', {})
    detail_req = guide.get('detail_requirements', {})
    emotional = guide.get('emotional_expressions', {})
    mandatory = guide.get('mandatory_elements', {})
    honorific_rules = guide.get('honorific_rules', {})
    number_rules = guide.get('number_expression_rules', {})

    system_prompt = f"""ë‹¹ì‹ ì€ ê¸°ë…êµ ê°„ì¦/ë“œë¼ë§ˆ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.
ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ëŒ€ë³¸ì„ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ âš ï¸ ëŒ€ë³¸ ì‘ì„± ì „ í•„ìˆ˜ í™•ì¸ ì‚¬í•­ ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ì˜ìƒ ê¸¸ì´: {duration_minutes}ë¶„
- ëª©í‘œ ê¸€ììˆ˜: {duration_settings.get('target_length', 6000)}ì
- ìµœëŒ€ ì¸ë¬¼ ìˆ˜: {duration_settings.get('max_characters', 4)}ëª… âš ï¸ ì ˆëŒ€ 4ëª… ì´ˆê³¼ ê¸ˆì§€! (ì£¼ì¸ê³µ 1ëª… + ì¡°ì—° ìµœëŒ€ 3ëª…)
- ìµœëŒ€ ì”¬ ê°œìˆ˜: {duration_settings.get('max_scenes', 6)}ê°œ
- ì”¬ë‹¹ ì´ë¯¸ì§€: 1-2ê°œ

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ğŸ¬ í•˜ì´ë¼ì´íŠ¸ (ì˜ìƒ ì‹œì‘ 1ë¶„) - ë§¤ìš° ì¤‘ìš”! ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ëª©ì : ì‹œì²­ì ì´íƒˆ ë°©ì§€
- ìµœëŒ€ {highlight_rules.get('max_scenes', 3)}ê°œ ì¥ë©´ìœ¼ë¡œ êµ¬ì„±
- ìœ í˜• ì„ íƒ:
  * climax_preview: ê·¹ì ì¸ í´ë¼ì´ë§¥ìŠ¤ ë¯¸ë¦¬ë³´ê¸°
  * curiosity_hook: ê²°ë§ ì•”ì‹œí•˜ë©° ê¶ê¸ˆì¦ ìœ ë°œ
- ëŒ€ë³¸ ë‚´ìš©ì— ë”°ë¼ ë” íš¨ê³¼ì ì¸ ë°©ì‹ì„ ì„ íƒí•˜ì„¸ìš”
- ìŠ¤í¬ì¼ëŸ¬ëŠ” í”¼í•˜ë˜, ì‹œì²­ìê°€ ëê¹Œì§€ ë³´ê³  ì‹¶ê²Œ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ğŸ‘¤ ì¸ë¬¼ ì„¤ì • ê·œì¹™ - ë§¤ìš° ì¤‘ìš”! ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- ìµœì†Œ {character_rules.get('min_count', 1)}ëª… ~ ìµœëŒ€ {character_rules.get('max_count', 4)}ëª…
- ì´ìœ : TTS ìŒì„± ë‹¤ì–‘ì„± í•œê³„ë¡œ ì¸ë¬¼ì´ ë§ìœ¼ë©´ ëª©ì†Œë¦¬ ì¤‘ë³µ ë°œìƒ
- ê° ì¸ë¬¼ì€ ëª…í™•í•œ ì—­í• ê³¼ ëª©ì ì´ ìˆì–´ì•¼ í•¨
- ì–µì§€ë¡œ ì¸ë¬¼ì„ ëŠ˜ë¦¬ì§€ ë§ ê²ƒ!

â­ ã€ ì£¼ì¸ê³µ ë‚˜ì´ í•„ìˆ˜ ì¡°ê±´ - ì ˆëŒ€ ê·œì¹™! ã€‘
ğŸš«ğŸš«ğŸš« ì Šì€ ì¸ë¬¼ ì ˆëŒ€ ê¸ˆì§€! ğŸš«ğŸš«ğŸš«
- ì£¼ì¸ê³µì€ ë°˜ë“œì‹œ 60ëŒ€ ì´ìƒì´ì–´ì•¼ í•©ë‹ˆë‹¤! (60ì„¸~85ì„¸ ì‚¬ì´)
- 20ëŒ€, 30ëŒ€, 40ëŒ€ ì¸ë¬¼ì„ ì£¼ì¸ê³µìœ¼ë¡œ ì„¤ì •í•˜ë©´ ì•ˆ ë©ë‹ˆë‹¤!
- ì‹œì²­ì ëŒ€ë¶€ë¶„ì´ ì‹œë‹ˆì–´ì´ë¯€ë¡œ ê³µê°í•  ìˆ˜ ìˆëŠ” ì—°ë ¹ëŒ€ ì„¤ì • í•„ìˆ˜
- 62ì„¸, 67ì„¸, 71ì„¸, 75ì„¸, 78ì„¸, 82ì„¸ ë“± êµ¬ì²´ì ì¸ ë‚˜ì´ ëª…ì‹œ
- ì¡°ì—°ë„ ê°€ê¸‰ì  50ëŒ€ ì´ìƒìœ¼ë¡œ ì„¤ì • (ê°€ì¡± ì™¸)

â­ ã€ ë§¤ë²ˆ ë‹¤ë¥¸ ì¸ë¬¼ ìƒì„± - ìµœìš°ì„  ê·œì¹™! ã€‘
ğŸš« ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€ ì´ë¦„ (ë„ˆë¬´ í”í•˜ê±°ë‚˜ ì´ì „ì— ì‚¬ìš©ë¨):
  - ì§€ì„ , ë¯¼ìˆ˜, ì˜í¬, ì² ìˆ˜, ìˆ˜ì§„, ë¯¼ì§€, í˜„ìˆ˜, ì§€ì˜, ì¤€í˜¸, ë¯¸ì˜
  - ì˜ìˆ˜, ì •í¬, ë¯¸ìˆ™, ìˆœì, ì˜¥ìˆœ, ë§ì, ê¸¸ë™

âœ… ë°˜ë“œì‹œ ì‚¬ìš©í•  ì´ë¦„ ìŠ¤íƒ€ì¼ (ë§¤ë²ˆ ë‹¤ì–‘í•˜ê²Œ ì„ íƒ!):
  - êµíšŒ ì§ë¶„ + ì„±ì”¨ í˜•íƒœ (ì˜ˆ: ê¹€ì§‘ì‚¬(ê°€ëª…), ë°•ê¶Œì‚¬(ê°€ëª…), ì´ì¥ë¡œ(ê°€ëª…), ì •ì§‘ì‚¬(ê°€ëª…), ìµœê¶Œì‚¬(ê°€ëª…), ì†¡ì¥ë¡œ(ê°€ëª…))
  - ë…íŠ¹í•œ í•œêµ­ì‹ ì´ë¦„ + (ê°€ëª…) (ì˜ˆ: ë³µìˆœ(ê°€ëª…), ê°‘ëŒ(ê°€ëª…), ìˆœì„(ê°€ëª…), ìš©íŒ”(ê°€ëª…), ë¶„ì´(ê°€ëª…))
  - ì§€ì—­ë³„ íŠ¹ìƒ‰ ì´ë¦„ + (ê°€ëª…) (ì˜ˆ: ìˆœë•(ê°€ëª…), ì˜¥ë…€(ê°€ëª…), ì¶˜ì(ê°€ëª…), íŒìˆ˜(ê°€ëª…))
  - ì„¸ëŒ€ê°ì´ ëŠê»´ì§€ëŠ” ì´ë¦„ (60-80ëŒ€ì— ì–´ìš¸ë¦¬ëŠ”)
  âš ï¸ ì¤‘ìš”: ëª¨ë“  ì´ë¦„ ë’¤ì— ë°˜ë“œì‹œ "(ê°€ëª…)"ì„ ë¶™ì¼ ê²ƒ!

- ì´ ì±„ë„ì—ëŠ” ê³„ì†í•´ì„œ ìƒˆë¡œìš´ ì˜ìƒì´ ì—…ë¡œë“œë©ë‹ˆë‹¤
- ë”°ë¼ì„œ ë§¤ë²ˆ ì™„ì „íˆ ìƒˆë¡­ê³  ë…íŠ¹í•œ ì¸ë¬¼ì„ ì°½ì¡°í•´ì•¼ í•©ë‹ˆë‹¤!
- ë°˜ë“œì‹œ ë‹¤ë¥´ê²Œ ì„¤ì •í•  í•­ëª©:
  * ì´ë¦„: ë§¤ë²ˆ ìƒˆë¡­ê³  ë…íŠ¹í•œ í•œêµ­ì‹ ì´ë¦„ (ìœ„ ê¸ˆì§€ ëª©ë¡ ì œì™¸!)
  * ì§ì—…/ì—­í• : ë‹¤ì–‘í•œ ì§ì—…êµ° (ëª©ì‚¬, ë†ë¶€, ì–´ë¶€, ìƒì¸, êµì‚¬, ê°„í˜¸ì‚¬, ìš”ë¦¬ì‚¬, ìš´ì „ì‚¬, ê²½ë¹„ì›, ì²­ì†Œë¶€, ë´‰ì‚¬ì, í•œì˜ì‚¬, ëª©ìˆ˜, ëŒ€ì¥ì¥ì´, ë–¡ì§‘ ì£¼ì¸, ì² ë¬¼ì  ì£¼ì¸, ë¯¸ìš©ì‚¬, ì´ë°œì‚¬, ì•½ì‚¬, ìš´ì†¡ì—… ë“±)
  * ê±°ì£¼ì§€: ë§¤ë²ˆ ë‹¤ë¥¸ ì§€ì—­ (ê°•ì›ë„ ì •ì„ , ì „ë‚¨ ê³¡ì„±, ê²½ë¶ ì˜ë•, ì¶©ë¶ ë‹¨ì–‘, ì œì£¼ ì„œê·€í¬, ì „ë¶ ë‚¨ì›, ê²½ë‚¨ í•˜ë™ ë“± êµ¬ì²´ì  ì§€ëª…)
  * ê°€ì¡± êµ¬ì„±: ë°°ìš°ì ìœ ë¬´, ìë…€ ìˆ˜(1~5ëª…), ì†ìë…€ ë“± ë‹¤ì–‘í•˜ê²Œ
  * ì„±ê²©ê³¼ ë§íˆ¬: ë…íŠ¹í•œ ê°œì„± ë¶€ì—¬ (ë¬´ëšëš, ê³¼ë¬µ, ìˆ˜ë‹¤ìŠ¤ëŸ¬ì›€, í˜¸íƒ•í•¨ ë“±)
  * ì™¸ëª¨: ì²´í˜•, ì–¼êµ´ íŠ¹ì§•, ë¨¸ë¦¬ ìŠ¤íƒ€ì¼ ë“± êµ¬ì²´ì ìœ¼ë¡œ
  * ë°°ê²½ ìŠ¤í† ë¦¬: ì „í˜€ ë‹¤ë¥¸ ì¸ìƒ ê²½í—˜
- ì ˆëŒ€ ê¸ˆì§€: ì „í˜•ì ì´ê±°ë‚˜ ì´ì „ì— ì‚¬ìš©ëœ ë“¯í•œ ì„¤ì •, ì Šì€ ì¸ë¬¼

ã€ ì¸ë¬¼ ì™¸ëª¨ ìƒì„¸ ì‘ì„± (Step2 ì´ë¯¸ì§€ ìƒì„±ìš©) ã€‘
ê° ì¸ë¬¼ì— ëŒ€í•´ ë‹¤ìŒì„ ìƒì„¸íˆ ê¸°ìˆ :
- appearance.height: í‚¤ì™€ ìì„¸ (ì˜ˆ: "170cm ì •ë„, ì•½ê°„ êµ½ì€ ìì„¸")
- appearance.body_type: ì²´í˜• (ì˜ˆ: "ë§ˆë¥¸ ì²´í˜•", "ê±´ì¥í•œ ì²´ê²©")
- appearance.face: ì–¼êµ´ íŠ¹ì§• ìƒì„¸íˆ (ì˜ˆ: "ê¹Šì€ ì£¼ë¦„, ì˜¨í™”í•œ ëˆˆë§¤, ì²˜ì§„ ëˆˆê¼¬ë¦¬")
- appearance.hair: ë¨¸ë¦¬ ìŠ¤íƒ€ì¼ê³¼ ìƒ‰ìƒ (ì˜ˆ: "ë°±ë°œ, ì§§ê²Œ ì •ëˆëœ ë¨¸ë¦¬")
- appearance.skin: í”¼ë¶€ ìƒíƒœ/í†¤ (ì˜ˆ: "í–‡ë³•ì— ê·¸ì„ë¦° ê²€ì€ í”¼ë¶€")
- appearance.distinctive_features: íŠ¹ì§•ì ì¸ ì™¸ëª¨ ìš”ì†Œ
- clothing_style: ì£¼ë¡œ ì…ëŠ” ì˜·ì°¨ë¦¼
- voice_characteristics: ëª©ì†Œë¦¬ íŠ¹ì§• (TTS ì°¸ê³ ìš©)

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ğŸ­ ì”¬ ë©”íƒ€ë°ì´í„° (ë‚˜ë ˆì´ì…˜ì´ ì½ì§€ ì•ŠìŒ!) ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ê° ì”¬ì˜ scene_metaëŠ” Step2 ì´ë¯¸ì§€ ìƒì„±ìš©ì´ë©°, TTSê°€ ì½ì§€ ì•ŠìŠµë‹ˆë‹¤.
ë°˜ë“œì‹œ ë‹¤ìŒ ì •ë³´ë¥¼ í¬í•¨í•˜ì„¸ìš”:

- location: ì¥ì†Œëª…, ì„¸ë¶€ ì„¤ì •, ì‹¤ë‚´/ì‹¤ì™¸
- time: ì‹œê°„ëŒ€, ê³„ì ˆ, ë‚ ì”¨
- atmosphere: ë¶„ìœ„ê¸°, ì¡°ëª… ìƒíƒœ, ë°°ê²½ ì†Œë¦¬
- visual_direction: ì¹´ë©”ë¼ ì œì•ˆ, í•µì‹¬ ì‹œê° ìš”ì†Œ, ìƒ‰ê°/í†¤
- character_states: ê° ì¸ë¬¼ì˜ í˜„ì¬ ê°ì •, í‘œì •, ìì„¸, í–‰ë™

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ğŸ“– ëŒ€ë³¸ ìŠ¤íƒ€ì¼ ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
- í™”ì ìœ í˜•: {script_style.get('perspective', 'ì£¼ì¸ê³µì´ ì§ì ‘ ê³ ë°±í•˜ëŠ” í˜•ì‹')}
- ì‹œì‘ í˜•ì‹: "{script_style.get('opening', 'ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ”...')}"
- ë§ˆë¬´ë¦¬: ì‹œì²­ìì—ê²Œ ê³µê° ì§ˆë¬¸ + ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„

ã€ ëŒ€í™” ë¹„ìœ¨ ã€‘
- ì„œìˆ /ë‚˜ë ˆì´ì…˜: {dialogue_ratio.get('narration', 55)}%
- ë‚´ë©´ ë…ë°±: {dialogue_ratio.get('inner_monologue', 15)}%
- ì§ì ‘ ëŒ€í™”: {dialogue_ratio.get('direct_dialogue', 30)}%

ã€ í˜¸ì¹­ ê·œì¹™ - ë§¤ìš° ì¤‘ìš”! ã€‘
ğŸš¨ í•µì‹¬ ì›ì¹™: {honorific_rules.get('core_principle', '60ëŒ€ ì´ìƒ ì¸ë¬¼ë“¤ì€ ì„œë¡œ ì´ë¦„ì„ ì§ì ‘ ë¶€ë¥´ì§€ ì•ŠìŒ')}

âœ… ë¶€ë¶€ ê°„ í˜¸ì¹­ (ë°˜ë“œì‹œ ì‚¬ìš©):
- ë‚¨í¸â†’ì•„ë‚´: {', '.join(honorific_rules.get('spouse_terms', {}).get('husband_calls_wife', ['ì—¬ë³´', 'ë‹¹ì‹ ', 'ì•„ì´ ì—„ë§ˆ']))}
- ì•„ë‚´â†’ë‚¨í¸: {', '.join(honorific_rules.get('spouse_terms', {}).get('wife_calls_husband', ['ì—¬ë³´', 'ë‹¹ì‹ ', 'ì•„ì´ ì•„ë¹ ']))}

ğŸš« ì ˆëŒ€ ê¸ˆì§€:
{chr(10).join('- ' + x for x in honorific_rules.get('forbidden_patterns', ['ë¶€ë¶€ê°€ ì„œë¡œ ì´ë¦„ ë¶€ë¥´ê¸° (ìˆœìì•¼, ì˜ìˆ˜ì•¼)', '60ëŒ€ ì´ìƒë¼ë¦¬ ì´ë¦„ìœ¼ë¡œ í˜¸ì¹­', 'ëŒ€í™” ì¤‘ ìƒëŒ€ë°© ì´ë¦„ ì§ì ‘ ì–¸ê¸‰']))}

ì˜ˆì‹œ:
âŒ ì˜ëª»ëœ í‘œí˜„: "ìˆœìì•¼, ë°¥ ë¨¹ì—ˆì–´?" / "ì˜ìˆ˜ ì”¨, ì–´ë”” ê°€ì„¸ìš”?"
âœ… ì˜¬ë°”ë¥¸ í‘œí˜„: "ì—¬ë³´, ì§„ì§€ ë“œì…¨ì–´ìš”?" / "ë‹¹ì‹ , ì–´ë”” ê°€ì‹œëŠ” ê±°ì˜ˆìš”?"

ã€ ìˆ«ì í‘œí˜„ ê·œì¹™ - TTS í•„ìˆ˜! ã€‘
ğŸš¨ ì¤‘ìš”: {number_rules.get('tts_narration', {}).get('rule', 'ëª¨ë“  ìˆ«ìëŠ” í•œê¸€ë¡œ í‘œê¸°')}
ì´ìœ : {number_rules.get('tts_narration', {}).get('reason', 'TTSê°€ ìˆ«ìë¥¼ ì˜ëª» ì½ëŠ” ë¬¸ì œ ë°©ì§€')}

ì˜ˆì‹œ:
âŒ ì˜ëª»: 76ì„¸, 20ë…„, 112, 3ëª…
âœ… ì˜¬ë°”ë¦„: ì¼í”ì—¬ì„¯ ì‚´, ì´ì‹­ ë…„, ì¼ì¼ì´, ì„¸ ëª…

ã€ ê°ì • í‘œí˜„ ã€‘
ì‹ ì²´ ë°˜ì‘: {', '.join(emotional.get('physical_reactions', [])[:5])}
ê°ì • ìƒíƒœ: {', '.join(emotional.get('emotional_states', [])[:4])}

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ âŒ ì ˆëŒ€ ê¸ˆì§€ - ìœ„ë°˜ ì‹œ ì¬ìƒì„±! ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸš« ì¸ë¬¼ ê´€ë ¨ ê¸ˆì§€:
- 60ì„¸ ë¯¸ë§Œ ì£¼ì¸ê³µ (20ëŒ€, 30ëŒ€, 40ëŒ€ ì ˆëŒ€ ê¸ˆì§€!)
- í”í•œ ì´ë¦„: ì§€ì„ , ë¯¼ìˆ˜, ì˜í¬, ì² ìˆ˜, ìˆ˜ì§„, ë¯¼ì§€, í˜„ìˆ˜ ë“±
- 4ëª… ì´ˆê³¼ ì¸ë¬¼ ë“±ì¥

ğŸš« ì„œìˆ  ê´€ë ¨ ê¸ˆì§€:
- 3ì¸ì¹­ ì„œìˆ  (ê·¸ëŠ”, ê·¸ë…€ëŠ”) â†’ ë°˜ë“œì‹œ 1ì¸ì¹­ (ì €ëŠ”, ì œê°€)
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ (#, *, -, **)
- ì„¤êµì¡°ì˜ ì¼ë°˜ì  êµí›ˆë§Œ ë‚˜ì—´

ğŸš« êµ¬ì¡° ê´€ë ¨ ê¸ˆì§€:
- ì”¬ ê°œìˆ˜ ì´ˆê³¼ ({duration_settings.get('max_scenes', 6)}ê°œ ì´í•˜!)
- í•˜ì´ë¼ì´íŠ¸ ì—†ì´ ì‹œì‘

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ğŸ“‹ ì¶œë ¥ JSON í˜•ì‹ (ë°˜ë“œì‹œ ì¤€ìˆ˜!) ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
```json
{{
  "metadata": {{
    "title": "ëŒ€ë³¸ ì œëª©",
    "duration_minutes": {duration_minutes},
    "target_length": {duration_settings.get('target_length', 6000)},
    "genre": "testimony",
    "total_scenes": ì”¬ê°œìˆ˜,
    "total_characters": ì¸ë¬¼ìˆ˜
  }},
  "characters": [
    {{
      "id": "char_01",
      "name": "ë…íŠ¹í•œ ì´ë¦„ (ê¸ˆì§€: ì§€ì„ ,ë¯¼ìˆ˜,ì˜í¬,ì² ìˆ˜ ë“±)",
      "age": "ë°˜ë“œì‹œ 60ì„¸ ì´ìƒ! (ì˜ˆ: 67ì„¸, 72ì„¸, 78ì„¸, 82ì„¸)",
      "gender": "ë‚¨ì„±/ì—¬ì„±",
      "role": "ì£¼ì¸ê³µ/ì¡°ì—°/ë‹¨ì—­",
      "occupation": "ì§ì—…",
      "relationship_to_protagonist": "ê´€ê³„",
      "appearance": {{
        "height": "í‚¤ì™€ ìì„¸",
        "body_type": "ì²´í˜•",
        "face": "ì–¼êµ´ íŠ¹ì§•",
        "hair": "ë¨¸ë¦¬ ìŠ¤íƒ€ì¼",
        "skin": "í”¼ë¶€ ìƒíƒœ",
        "distinctive_features": "íŠ¹ì§•"
      }},
      "clothing_style": "ì˜·ì°¨ë¦¼",
      "personality": "ì„±ê²©",
      "speaking_style": "ë§íˆ¬",
      "voice_characteristics": "ëª©ì†Œë¦¬ íŠ¹ì§•"
    }}
  ],
  "highlight": {{
    "purpose": "ì‹œì²­ì ì´íƒˆ ë°©ì§€",
    "duration_seconds": 60,
    "type": "climax_preview ë˜ëŠ” curiosity_hook",
    "scenes": [
      {{
        "order": 1,
        "preview_text": "í•˜ì´ë¼ì´íŠ¸ í…ìŠ¤íŠ¸",
        "scene_hint": "ì¥ë©´ íŒíŠ¸",
        "emotion": "ê°ì •"
      }}
    ]
  }},
  "script": {{
    "scenes": [
      {{
        "scene_meta": {{
          "scene_id": 1,
          "scene_title": "ì”¬ ì œëª©",
          "structure_phase": "7ë‹¨ê³„ ì¤‘ í•´ë‹¹ ë‹¨ê³„",
          "location": {{
            "place": "ì¥ì†Œëª…",
            "setting": "ì„¸ë¶€ ì„¤ì •",
            "indoor_outdoor": "ì‹¤ë‚´/ì‹¤ì™¸"
          }},
          "time": {{
            "period": "ì‹œê°„ëŒ€",
            "season": "ê³„ì ˆ",
            "weather": "ë‚ ì”¨"
          }},
          "atmosphere": {{
            "mood": "ë¶„ìœ„ê¸°",
            "lighting": "ì¡°ëª… ìƒíƒœ",
            "sound_ambience": "ë°°ê²½ ì†Œë¦¬"
          }},
          "visual_direction": {{
            "camera_suggestion": "ì¹´ë©”ë¼ ì•µê¸€",
            "key_visual": "í•µì‹¬ ì‹œê° ìš”ì†Œ",
            "color_tone": "ìƒ‰ê°"
          }},
          "characters_in_scene": ["char_01"],
          "character_states": {{
            "char_01": {{
              "emotion": "ê°ì •",
              "expression": "í‘œì •",
              "posture": "ìì„¸",
              "action": "í–‰ë™"
            }}
          }}
        }},
        "narration": "ì‹¤ì œ ë‚˜ë ˆì´ì…˜ í…ìŠ¤íŠ¸ (TTSê°€ ì½ì„ ë‚´ìš©)",
        "tts_text": "TTSê°€ ì½ì„ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ (ì¥ë©´ ì œëª©, ì¸ë¬¼ ì†Œê°œ, ì§€ë¬¸ ì œì™¸)"
      }}
    ]
  }}
}}
```
"""

    # 2. ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ suffix
    user_suffix = f"""

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
âš ï¸ ìµœì¢… ì ê²€ ì‚¬í•­ (ë°˜ë“œì‹œ í™•ì¸!)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
1. âœ… ì˜ìƒ ê¸¸ì´ {duration_minutes}ë¶„ì— ë§ëŠ” ë¶„ëŸ‰ì¸ê°€? (ëª©í‘œ: {duration_settings.get('target_length', 6000)}ì)
2. âœ… ì¸ë¬¼ì´ {duration_settings.get('max_characters', 3)}ëª… ì´í•˜ì¸ê°€?
3. âœ… ì”¬ì´ {duration_settings.get('max_scenes', 6)}ê°œ ì´í•˜ì¸ê°€?
4. âœ… í•˜ì´ë¼ì´íŠ¸ê°€ ì˜ìƒ ì‹œì‘ë¶€ì— ìˆëŠ”ê°€?
5. âœ… JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í–ˆëŠ”ê°€?
6. âœ… scene_metaì— ëª¨ë“  ì‹œê° ì •ë³´ê°€ ìˆëŠ”ê°€?
7. âœ… ê° ì¸ë¬¼ì˜ ì™¸ëª¨ê°€ ìƒì„¸íˆ ê¸°ìˆ ë˜ì—ˆëŠ”ê°€?
8. âœ… 1ì¸ì¹­ ì‹œì ìœ¼ë¡œ ì‘ì„±í–ˆëŠ”ê°€?

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ğŸ™ï¸ TTS í…ìŠ¤íŠ¸ ì‘ì„± ê·œì¹™ (ë§¤ìš° ì¤‘ìš”!)
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ê° ì”¬ì˜ tts_text í•„ë“œì—ëŠ” TTSê°€ ì½ì„ ìˆœìˆ˜ ëŒ€ì‚¬/ë‚˜ë ˆì´ì…˜ë§Œ ì‘ì„±í•˜ì„¸ìš”.

âŒ tts_textì— í¬í•¨í•˜ë©´ ì•ˆ ë˜ëŠ” ê²ƒ:
- ì¥ë©´ ë²ˆí˜¸ë‚˜ ì œëª© ("ì¥ë©´ 1:", "Scene 1:", "[ë³‘ì›]" ë“±)
- ì¸ë¬¼ ì†Œê°œ ("ê¹€ì˜í¬(45ì„¸, êµì‚¬)" ë“±)
- ì§€ë¬¸ì´ë‚˜ ì—°ì¶œ ("(ìŠ¬í”ˆ í‘œì •ìœ¼ë¡œ)", "[ëˆˆë¬¼ì„ í˜ë¦¬ë©°]" ë“±)
- í™”ì í‘œì‹œ ("ì˜í¬:", "ë‚˜ë ˆì´ì…˜:" ë“±)

âœ… tts_textì— í¬í•¨í•  ê²ƒ:
- ì£¼ì¸ê³µì´ ì§ì ‘ ë§í•˜ëŠ” ëŒ€ì‚¬ì™€ ë…ë°±ë§Œ
- "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ”..." í˜•ì‹ì˜ ìˆœìˆ˜ í…ìŠ¤íŠ¸

ë°˜ë“œì‹œ ìœ íš¨í•œ JSON í˜•ì‹ìœ¼ë¡œ ì¶œë ¥í•˜ì„¸ìš”!
"""

    return system_prompt, user_suffix


def build_testimony_prompt_from_guide_legacy(custom_guide=None):
    """
    [ë ˆê±°ì‹œ] ê¸°ì¡´ í…ìŠ¤íŠ¸ í˜•ì‹ ëŒ€ë³¸ìš© í”„ë¡¬í”„íŠ¸ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)
    """
    guide = custom_guide if custom_guide else load_drama_guidelines()
    if not guide:
        return None, None

    script_style = guide.get('script_style', {})
    structure = guide.get('structure', {})
    dialogue_ratio = guide.get('dialogue_ratio', {})
    detail_req = guide.get('detail_requirements', {})
    emotional = guide.get('emotional_expressions', {})
    mandatory = guide.get('mandatory_elements', {})

    system_prompt = f"""ë‹¹ì‹ ì€ ê¸°ë…êµ ê°„ì¦ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ í•µì‹¬ ì›ì¹™ ã€‘
- í™”ì ìœ í˜•: {script_style.get('perspective', 'ì£¼ì¸ê³µì´ ì§ì ‘ ê³ ë°±í•˜ëŠ” í˜•ì‹')}
- ì‹œì‘ í˜•ì‹: "{script_style.get('opening', 'ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ”...')}"
- ë§ˆë¬´ë¦¬ í˜•ì‹: ì‹œì²­ìì—ê²Œ ê³µê° ì§ˆë¬¸ + ì¢‹ì•„ìš”/êµ¬ë… ìœ ë„

ã€ í•„ìˆ˜ ë¶„ëŸ‰ ã€‘
ì´ {structure.get('total_length', 15000)}ì ì´ìƒ (ë§¤ìš° ì¤‘ìš”!)

ã€ 7ë‹¨ê³„ êµ¬ì¡° (ë°˜ë“œì‹œ ì¤€ìˆ˜) ã€‘
"""

    sections = structure.get('sections', [])
    for sec in sections:
        ratio_percent = int(sec.get('length_ratio', 0) * 100)
        system_prompt += f"""
{sec.get('id')}. {sec.get('korean_name', sec.get('name'))} ({ratio_percent}%)
   - ëª©ì : {sec.get('purpose', '')}
   - í•„ìˆ˜ í¬í•¨: {', '.join(sec.get('must_include', []))}
   - ì˜ˆì‹œ: "{sec.get('example', '')[:100]}..."
"""

    system_prompt += f"""
ã€ ëŒ€í™” ë¹„ìœ¨ ã€‘
- ì„œìˆ /ë‚˜ë ˆì´ì…˜: {dialogue_ratio.get('narration', 55)}%
- ë‚´ë©´ ë…ë°±: {dialogue_ratio.get('inner_monologue', 15)}%
- ì§ì ‘ ëŒ€í™”: {dialogue_ratio.get('direct_dialogue', 30)}%

ã€ í•„ìˆ˜ ë””í…Œì¼ ã€‘
- ì´ë¦„: ìµœì†Œ {detail_req.get('naming', {}).get('min_count', 5)}ê°œ
- ë‚˜ì´: ìµœì†Œ {detail_req.get('ages', {}).get('min_count', 3)}ê°œ
- ì¥ì†Œ: ìµœì†Œ {detail_req.get('locations', {}).get('min_count', 3)}ê°œ
- ìˆ«ì/ê¸°ê°„: ìµœì†Œ {detail_req.get('amounts', {}).get('min_count', 10)}ê°œ

ã€ ê°ì • í‘œí˜„ ã€‘
ì‹ ì²´ ë°˜ì‘: {', '.join(emotional.get('physical_reactions', [])[:5])}

ã€ ì ˆëŒ€ ê¸ˆì§€ ã€‘
- 3ì¸ì¹­ ì„œìˆ  â†’ ë°˜ë“œì‹œ 1ì¸ì¹­
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸
- ì§§ì€ ë¶„ëŸ‰
"""

    user_suffix = f"""

âš ï¸ ìµœì¢… ì ê²€:
1. ì²« ë¬¸ì¥ì´ "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ”..."ìœ¼ë¡œ ì‹œì‘í•˜ëŠ”ê°€?
2. ì „ì²´ê°€ 1ì¸ì¹­ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆëŠ”ê°€?
3. ì´ ê¸€ììˆ˜ê°€ {structure.get('total_length', 15000)}ì ì´ìƒì¸ê°€?
"""

    return system_prompt, user_suffix


def get_client():
    key = (os.getenv("OPENAI_API_KEY") or "").strip()
    if not key:
        print("[WARNING] OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. API í˜¸ì¶œ ì‹œ ì˜¤ë¥˜ê°€ ë°œìƒí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
        return None
    # GPT-5.1 ê¸´ ì²˜ë¦¬ ì‹œê°„ì„ ìœ„í•œ íƒ€ì„ì•„ì›ƒ ì„¤ì • (10ë¶„) - sermon_server.pyì™€ ë™ì¼
    return OpenAI(api_key=key, timeout=600.0)

client = get_client()

# OpenRouter í´ë¼ì´ì–¸íŠ¸ (Step3 Claudeìš©)
def get_openrouter_client():
    key = (os.getenv("OPENROUTER_API_KEY") or "").strip()
    if not key:
        print("[OPENROUTER] API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
        return None
    try:
        return OpenAI(
            base_url="https://openrouter.ai/api/v1",
            api_key=key
        )
    except Exception as e:
        print(f"[OPENROUTER] í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
        return None

openrouter_client = get_openrouter_client()

# Database setup
DATABASE_URL = os.getenv('DATABASE_URL')
USE_POSTGRES = DATABASE_URL is not None

if USE_POSTGRES:
    # PostgreSQL ì‚¬ìš©
    import psycopg2
    from psycopg2.extras import RealDictCursor

    # Renderì˜ postgres:// URLì„ postgresql://ë¡œ ë³€ê²½
    if DATABASE_URL.startswith('postgres://'):
        DATABASE_URL = DATABASE_URL.replace('postgres://', 'postgresql://', 1)

    def get_db_connection():
        """Create a PostgreSQL database connection"""
        conn = psycopg2.connect(DATABASE_URL, cursor_factory=RealDictCursor)
        return conn
else:
    # SQLite ì‚¬ìš© (ë¡œì»¬ ê°œë°œìš©)
    DB_PATH = os.path.join(os.path.dirname(__file__), 'drama_data.db')

    def get_db_connection():
        """Create a SQLite database connection"""
        conn = sqlite3.connect(DB_PATH)
        conn.row_factory = sqlite3.Row
        return conn

# DB ì´ˆê¸°í™”
def init_db():
    """Initialize database tables"""
    conn = get_db_connection()
    cursor = conn.cursor()

    if USE_POSTGRES:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS benchmark_analyses (
                id SERIAL PRIMARY KEY,
                script_text TEXT NOT NULL,
                script_hash VARCHAR(100) UNIQUE,
                upload_date VARCHAR(50),
                view_count INTEGER,
                category VARCHAR(100),
                analysis_result TEXT NOT NULL,
                story_structure TEXT,
                character_elements TEXT,
                dialogue_style TEXT,
                success_factors TEXT,
                ai_model VARCHAR(50) DEFAULT 'gpt-5',
                analysis_tokens INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_benchmark_view_count
            ON benchmark_analyses(view_count DESC)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_benchmark_created_at
            ON benchmark_analyses(created_at DESC)
        ''')
    else:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS benchmark_analyses (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                script_text TEXT NOT NULL,
                script_hash TEXT UNIQUE,
                upload_date TEXT,
                view_count INTEGER,
                category TEXT,
                analysis_result TEXT NOT NULL,
                story_structure TEXT,
                character_elements TEXT,
                dialogue_style TEXT,
                success_factors TEXT,
                ai_model TEXT DEFAULT 'gpt-5',
                analysis_tokens INTEGER,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_benchmark_view_count
            ON benchmark_analyses(view_count DESC)
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_benchmark_created_at
            ON benchmark_analyses(created_at DESC)
        ''')

    # YouTube í† í° í…Œì´ë¸” ìƒì„±
    if USE_POSTGRES:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS youtube_tokens (
                id SERIAL PRIMARY KEY,
                user_id VARCHAR(100) UNIQUE DEFAULT 'default',
                token TEXT,
                refresh_token TEXT,
                token_uri TEXT,
                client_id TEXT,
                client_secret TEXT,
                scopes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
    else:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS youtube_tokens (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT UNIQUE DEFAULT 'default',
                token TEXT,
                refresh_token TEXT,
                token_uri TEXT,
                client_id TEXT,
                client_secret TEXT,
                scopes TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')

    # ìƒí’ˆê´€ë¦¬ í…Œì´ë¸” ìƒì„±
    if USE_POSTGRES:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id VARCHAR(100) PRIMARY KEY,
                name TEXT NOT NULL,
                category TEXT,
                cny_price REAL,
                sell_price INTEGER,
                quantity INTEGER DEFAULT 1,
                stock INTEGER DEFAULT 0,
                platform TEXT,
                sale_type TEXT,
                hs_code TEXT,
                duty_rate REAL,
                link TEXT,
                image_url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sales_logs (
                id SERIAL PRIMARY KEY,
                product_id VARCHAR(100) REFERENCES products(id) ON DELETE CASCADE,
                product_name TEXT,
                change_amount INTEGER,
                log_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
    else:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS products (
                id TEXT PRIMARY KEY,
                name TEXT NOT NULL,
                category TEXT,
                cny_price REAL,
                sell_price INTEGER,
                quantity INTEGER DEFAULT 1,
                stock INTEGER DEFAULT 0,
                platform TEXT,
                sale_type TEXT,
                hs_code TEXT,
                duty_rate REAL,
                link TEXT,
                image_url TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS sales_logs (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                product_id TEXT,
                product_name TEXT,
                change_amount INTEGER,
                log_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                FOREIGN KEY (product_id) REFERENCES products(id) ON DELETE CASCADE
            )
        ''')

    # Video Jobs í…Œì´ë¸” ìƒì„± (ì˜ìƒ ìƒì„± ì‘ì—… ìƒíƒœ ì¶”ì  - ì„œë²„ ì¬ì‹œì‘ì—ë„ ìœ ì§€ë¨)
    if USE_POSTGRES:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS video_jobs (
                job_id VARCHAR(100) PRIMARY KEY,
                status VARCHAR(50) DEFAULT 'pending',
                progress INTEGER DEFAULT 0,
                message TEXT,
                video_url TEXT,
                error TEXT,
                session_id VARCHAR(100),
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_video_jobs_created_at
            ON video_jobs(created_at DESC)
        ''')
    else:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS video_jobs (
                job_id TEXT PRIMARY KEY,
                status TEXT DEFAULT 'pending',
                progress INTEGER DEFAULT 0,
                message TEXT,
                video_url TEXT,
                error TEXT,
                session_id TEXT,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_video_jobs_created_at
            ON video_jobs(created_at DESC)
        ''')

    # GPT Chat ì‚¬ìš©ì í…Œì´ë¸” ìƒì„±
    if USE_POSTGRES:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS gpt_users (
                id SERIAL PRIMARY KEY,
                user_id VARCHAR(100) UNIQUE NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS gpt_conversations (
                id SERIAL PRIMARY KEY,
                user_id VARCHAR(100) NOT NULL,
                conversation_id VARCHAR(100) NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(user_id, conversation_id)
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS gpt_messages (
                id SERIAL PRIMARY KEY,
                user_id VARCHAR(100) NOT NULL,
                conversation_id VARCHAR(100) NOT NULL,
                role VARCHAR(20) NOT NULL,
                content TEXT NOT NULL,
                model VARCHAR(50),
                has_image BOOLEAN DEFAULT FALSE,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_gpt_messages_conv
            ON gpt_messages(user_id, conversation_id, created_at)
        ''')
    else:
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS gpt_users (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT UNIQUE NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS gpt_conversations (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                conversation_id TEXT NOT NULL,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,
                UNIQUE(user_id, conversation_id)
            )
        ''')
        cursor.execute('''
            CREATE TABLE IF NOT EXISTS gpt_messages (
                id INTEGER PRIMARY KEY AUTOINCREMENT,
                user_id TEXT NOT NULL,
                conversation_id TEXT NOT NULL,
                role TEXT NOT NULL,
                content TEXT NOT NULL,
                model TEXT,
                has_image INTEGER DEFAULT 0,
                created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP
            )
        ''')
        cursor.execute('''
            CREATE INDEX IF NOT EXISTS idx_gpt_messages_conv
            ON gpt_messages(user_id, conversation_id, created_at)
        ''')

    conn.commit()
    cursor.close()
    conn.close()
    print("[DRAMA-DB] Database initialized (including youtube_tokens, products)")

# ì•± ì‹œì‘ ì‹œ DB ì´ˆê¸°í™”
init_db()

# YouTube í† í°/í• ë‹¹ëŸ‰ ëª¨ë“ˆ DB ì—°ê²° ì´ˆê¸°í™”
youtube_auth.init_db(get_db_connection, USE_POSTGRES)

# ===== DB ê°€ì´ë“œ ì¡°íšŒ í•¨ìˆ˜ =====
def get_relevant_guide_from_db(box_name, category="", limit=5):
    """
    Step ë°•ìŠ¤ ì´ë¦„ì— ë”°ë¼ DBì—ì„œ ê´€ë ¨ ê°€ì´ë“œë¥¼ ê°€ì ¸ì˜´

    Args:
        box_name: Step ë°•ìŠ¤ ì´ë¦„ (ì˜ˆ: "ìºë¦­í„° ì„¤ì •", "ìŠ¤í† ë¦¬ êµ¬ì„±")
        category: ì˜ìƒ ì‹œê°„/ì¹´í…Œê³ ë¦¬ (ì„ íƒì )
        limit: ê°€ì ¸ì˜¬ ë¶„ì„ ê²°ê³¼ ê°œìˆ˜

    Returns:
        str: ê´€ë ¨ ê°€ì´ë“œ í…ìŠ¤íŠ¸
    """
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # Step íƒ€ì…ì— ë”°ë¥¸ í•„ë“œ ë§¤í•‘
        field_mapping = {
            'ìºë¦­í„°': 'character_elements',
            'ì¸ë¬¼': 'character_elements',
            'ìŠ¤í† ë¦¬': 'story_structure',
            'ì¤„ê±°ë¦¬': 'story_structure',
            'êµ¬ì„±': 'story_structure',
            'ëŒ€ì‚¬': 'dialogue_style',
            'ë¶„ì„': 'analysis_result',
            'ì„±ê³µ': 'success_factors'
        }

        # box_nameì—ì„œ í•´ë‹¹í•˜ëŠ” í•„ë“œ ì°¾ê¸°
        target_field = 'analysis_result'  # ê¸°ë³¸ê°’
        for keyword, field in field_mapping.items():
            if keyword in box_name:
                target_field = field
                break

        # ê³ ì¡°íšŒìˆ˜ ëŒ€ë³¸ë“¤ì˜ ë¶„ì„ ê²°ê³¼ ì¡°íšŒ
        if USE_POSTGRES:
            query = f"""
                SELECT {target_field}, view_count, upload_date
                FROM benchmark_analyses
                WHERE {target_field} IS NOT NULL AND {target_field} != ''
                ORDER BY view_count DESC
                LIMIT %s
            """
            cursor.execute(query, (limit,))
        else:
            query = f"""
                SELECT {target_field}, view_count, upload_date
                FROM benchmark_analyses
                WHERE {target_field} IS NOT NULL AND {target_field} != ''
                ORDER BY view_count DESC
                LIMIT ?
            """
            cursor.execute(query, (limit,))

        results = cursor.fetchall()
        conn.close()

        if not results:
            print(f"[DRAMA-DB-GUIDE] DBì— ì¶•ì ëœ ë°ì´í„° ì—†ìŒ (í•„ë“œ: {target_field})")
            return None

        # ê²°ê³¼ë¥¼ ê°€ì´ë“œ í˜•ì‹ìœ¼ë¡œ í¬ë§·íŒ…
        guide_parts = [f"ã€ ì¶•ì ëœ ì„±ê³µ ì‚¬ë¡€ ë¶„ì„ - {box_name} ã€‘\n"]
        guide_parts.append(f"ê³ ì¡°íšŒìˆ˜ ëŒ€ë³¸ {len(results)}ê°œì˜ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ í•œ ê°€ì´ë“œ:\n")

        for idx, row in enumerate(results, 1):
            if USE_POSTGRES:
                content = row[target_field]
                view_count = row['view_count']
            else:
                content = row[0]
                view_count = row[1]

            if content:
                view_str = f"{view_count:,}íšŒ" if view_count else "ì •ë³´ì—†ìŒ"
                guide_parts.append(f"\nâ”â”â” ì‚¬ë¡€ {idx} (ì¡°íšŒìˆ˜: {view_str}) â”â”â”")
                guide_parts.append(content.strip())

        guide_text = "\n".join(guide_parts)
        print(f"[DRAMA-DB-GUIDE] {len(results)}ê°œ ì‚¬ë¡€ ê°€ì ¸ì˜´ (í•„ë“œ: {target_field})")
        return guide_text

    except Exception as e:
        print(f"[DRAMA-DB-GUIDE][ERROR] {str(e)}")
        return None

def format_json_result(json_data, indent=0):
    """JSON ë°ì´í„°ë¥¼ ë³´ê¸° ì¢‹ì€ í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (ì¬ê·€ì  ì²˜ë¦¬)"""
    result = []
    indent_str = "  " * indent

    # JSONì˜ ê° í‚¤-ê°’ ìŒì„ ë³´ê¸° ì¢‹ê²Œ í¬ë§·íŒ…
    for key, value in json_data.items():
        # í‚¤ë¥¼ í•œêµ­ì–´ë¡œ ë³€í™˜ (í•„ìš”ì‹œ)
        key_display = key.replace('_', ' ').title()

        # ê°’ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°
        if isinstance(value, list):
            result.append(f"{indent_str}ã€ {key_display} ã€‘")
            for item in value:
                if isinstance(item, dict):
                    # ë¦¬ìŠ¤íŠ¸ ì•ˆì˜ ë”•ì…”ë„ˆë¦¬ ì¬ê·€ ì²˜ë¦¬
                    for sub_line in format_json_result(item, indent + 1).split('\n'):
                        if sub_line.strip():
                            result.append(f"  {indent_str}{sub_line}")
                else:
                    result.append(f"{indent_str}  - {item}")
            if indent == 0:
                result.append("")
        # ê°’ì´ ë”•ì…”ë„ˆë¦¬ì¸ ê²½ìš° (ì¬ê·€ ì²˜ë¦¬)
        elif isinstance(value, dict):
            result.append(f"{indent_str}ã€ {key_display} ã€‘")
            # ì¤‘ì²© ë”•ì…”ë„ˆë¦¬ë¥¼ ì¬ê·€ì ìœ¼ë¡œ ì²˜ë¦¬
            for sub_key, sub_value in value.items():
                sub_key_display = sub_key.replace('_', ' ')
                if isinstance(sub_value, dict):
                    # ë” ê¹Šì€ ì¤‘ì²© ë”•ì…”ë„ˆë¦¬
                    result.append(f"{indent_str}  {sub_key_display}:")
                    for nested_line in format_json_result(sub_value, indent + 2).split('\n'):
                        if nested_line.strip() and not nested_line.strip().startswith('ã€'):
                            result.append(f"  {nested_line}")
                        elif nested_line.strip().startswith('ã€'):
                            # ì„¹ì…˜ í—¤ë”ëŠ” ê±´ë„ˆë›°ê¸°
                            pass
                elif isinstance(sub_value, list):
                    result.append(f"{indent_str}  {sub_key_display}:")
                    for item in sub_value:
                        result.append(f"{indent_str}    - {item}")
                else:
                    result.append(f"{indent_str}  {sub_key_display}: {sub_value}")
            if indent == 0:
                result.append("")
        # ê°’ì´ ë¬¸ìì—´ ë˜ëŠ” ê¸°íƒ€ì¸ ê²½ìš°
        else:
            result.append(f"{indent_str}ã€ {key_display} ã€‘")
            result.append(f"{indent_str}{str(value)}")
            if indent == 0:
                result.append("")

    return "\n".join(result).strip()

def remove_markdown(text):
    """ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ì œê±° (#, *, -, **, ###, ë“±)"""
    # í—¤ë” ì œê±° (##, ###, #### ë“±)
    text = re.sub(r'^#+\s+', '', text, flags=re.MULTILINE)

    # ë³¼ë“œ ì œê±° (**, __)
    text = re.sub(r'\*\*(.+?)\*\*', r'\1', text)
    text = re.sub(r'__(.+?)__', r'\1', text)

    # ì´íƒ¤ë¦­ ì œê±° (*, _)
    text = re.sub(r'\*(.+?)\*', r'\1', text)
    text = re.sub(r'_(.+?)_', r'\1', text)

    # ë¦¬ìŠ¤íŠ¸ ë§ˆì»¤ ì œê±° (-, *, +)
    text = re.sub(r'^\s*[-*+]\s+', '', text, flags=re.MULTILINE)

    # ì½”ë“œ ë¸”ë¡ ì œê±° (```)
    text = re.sub(r'```[\s\S]*?```', '', text)

    # ì¸ë¼ì¸ ì½”ë“œ ì œê±° (`)
    text = re.sub(r'`(.+?)`', r'\1', text)

    return text.strip()

def get_system_prompt_for_step(step_name):
    """
    ë“œë¼ë§ˆ ë‹¨ê³„ë³„ë¡œ ìµœì í™”ëœ system prompt ë°˜í™˜ (JSON ì§€ì¹¨ ê¸°ë°˜)
    miniëŠ” ê°œìš”ì™€ ìë£Œë§Œ ìƒì„±, ì™„ì„±ëœ ëŒ€ë³¸ ì‘ì„± ê¸ˆì§€
    """
    step_lower = step_name.lower()

    # JSONì—ì„œ í”„ë¡¬í”„íŠ¸ ê°€ì ¸ì˜¤ê¸° ì‹œë„
    step2_prompts = get_guideline('steps.step2.systemPrompts', {})

    # ìºë¦­í„° ì„¤ì • ë‹¨ê³„
    if 'ìºë¦­í„°' in step_name or 'character' in step_lower:
        prompt = step2_prompts.get('ìºë¦­í„°')
        if prompt:
            return f"{prompt}\n\ní˜„ì¬ ë‹¨ê³„: {step_name}"

    # ìŠ¤í† ë¦¬ë¼ì¸ / ì¤„ê±°ë¦¬ ë‹¨ê³„
    elif 'ìŠ¤í† ë¦¬' in step_name or 'ì¤„ê±°ë¦¬' in step_name or 'storyline' in step_lower or 'plot' in step_lower:
        prompt = step2_prompts.get('ìŠ¤í† ë¦¬')
        if prompt:
            return f"{prompt}\n\ní˜„ì¬ ë‹¨ê³„: {step_name}"

    # ì¥ë©´ êµ¬ì„± ë‹¨ê³„
    elif 'ì¥ë©´' in step_name or 'scene' in step_lower:
        prompt = step2_prompts.get('ì¥ë©´')
        if prompt:
            return f"{prompt}\n\ní˜„ì¬ ë‹¨ê³„: {step_name}"

    # ëŒ€ì‚¬ / ëŒ€ë³¸ ì‘ì„± ë‹¨ê³„
    elif 'ëŒ€ì‚¬' in step_name or 'ëŒ€ë³¸' in step_name or 'dialogue' in step_lower or 'script' in step_lower:
        prompt = step2_prompts.get('ëŒ€ì‚¬')
        if prompt:
            return f"{prompt}\n\ní˜„ì¬ ë‹¨ê³„: {step_name}"

    # ê¸°íƒ€ ë‹¨ê³„ ë˜ëŠ” fallback
    default_prompt = step2_prompts.get('default')
    if default_prompt:
        return f"{default_prompt}\n\ní˜„ì¬ ë‹¨ê³„: {step_name}"

    # JSON ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
    return f"""ë‹¹ì‹ ì€ gpt-4o-minië¡œì„œ ë“œë¼ë§ˆ 'ì´ˆì•ˆ ìë£Œ'ë§Œ ì¤€ë¹„í•˜ëŠ” ì—­í• ì…ë‹ˆë‹¤.

í˜„ì¬ ë‹¨ê³„: {step_name}

ê¸°ë³¸ ì—­í• :
- ì™„ì„±ëœ ëŒ€ë³¸ì´ ì•„ë‹Œ, ìë£Œì™€ êµ¬ì¡°ë§Œ ì œê³µ
- ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ì„¸ë¶€ ì§€ì¹¨ì„ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¦„
- ì§€ì¹¨ì´ ì—†ëŠ” ê²½ìš°ì—ë§Œ ì¼ë°˜ì ì¸ ë“œë¼ë§ˆ ìë£Œ í˜•ì‹ ì‚¬ìš©

âš ï¸ ì¤‘ìš”: ì‚¬ìš©ìì˜ ì„¸ë¶€ ì§€ì¹¨ì´ ì œê³µë˜ë©´ ê·¸ê²ƒì„ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„ í•˜ì—¬ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤."""

@app.route("/")
def home():
    return render_template("image.html")

@app.route("/product")
def product():
    return render_template("product.html")

@app.route("/image")
def image():
    return render_template("image.html")

@app.route("/product-manage")
def product_manage():
    return render_template("product-manage.html")

# ===== ìƒí’ˆê´€ë¦¬ API =====
@app.route("/api/products", methods=["GET"])
def get_products():
    """ëª¨ë“  ìƒí’ˆ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('''
            SELECT id, name, category, cny_price, sell_price, quantity, stock,
                   platform, sale_type, hs_code, duty_rate, link, image_url, created_at
            FROM products ORDER BY created_at DESC
        ''')
        rows = cursor.fetchall()
        cursor.close()
        conn.close()

        products = []
        for row in rows:
            if USE_POSTGRES:
                products.append({
                    'id': row['id'],
                    'name': row['name'],
                    'category': row['category'],
                    'cnyPrice': row['cny_price'],
                    'sellPrice': row['sell_price'],
                    'quantity': row['quantity'],
                    'stock': row['stock'],
                    'platform': row['platform'],
                    'saleType': row['sale_type'],
                    'hsCode': row['hs_code'],
                    'dutyRate': row['duty_rate'],
                    'link': row['link'],
                    'imageUrl': row['image_url'],
                    'createdAt': str(row['created_at']) if row['created_at'] else None
                })
            else:
                products.append({
                    'id': row[0],
                    'name': row[1],
                    'category': row[2],
                    'cnyPrice': row[3],
                    'sellPrice': row[4],
                    'quantity': row[5],
                    'stock': row[6],
                    'platform': row[7],
                    'saleType': row[8],
                    'hsCode': row[9],
                    'dutyRate': row[10],
                    'link': row[11],
                    'imageUrl': row[12],
                    'createdAt': row[13]
                })
        return jsonify({'ok': True, 'products': products})
    except Exception as e:
        print(f"[PRODUCTS] Error: {e}")
        return jsonify({'ok': False, 'error': str(e)}), 500

@app.route("/api/products", methods=["POST"])
def add_product():
    """ìƒí’ˆ ì¶”ê°€"""
    try:
        data = request.json
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute('''
                INSERT INTO products (id, name, category, cny_price, sell_price, quantity, stock,
                                      platform, sale_type, hs_code, duty_rate, link, image_url)
                VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
            ''', (
                data.get('id'),
                data.get('name'),
                data.get('category', 'ë¯¸ë¶„ë¥˜'),
                data.get('cnyPrice'),
                data.get('sellPrice'),
                data.get('quantity', 1),
                data.get('stock', 0),
                data.get('platform'),
                data.get('saleType'),
                data.get('hsCode'),
                data.get('dutyRate'),
                data.get('link', ''),
                data.get('imageUrl', '')
            ))
        else:
            cursor.execute('''
                INSERT INTO products (id, name, category, cny_price, sell_price, quantity, stock,
                                      platform, sale_type, hs_code, duty_rate, link, image_url)
                VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)
            ''', (
                data.get('id'),
                data.get('name'),
                data.get('category', 'ë¯¸ë¶„ë¥˜'),
                data.get('cnyPrice'),
                data.get('sellPrice'),
                data.get('quantity', 1),
                data.get('stock', 0),
                data.get('platform'),
                data.get('saleType'),
                data.get('hsCode'),
                data.get('dutyRate'),
                data.get('link', ''),
                data.get('imageUrl', '')
            ))

        conn.commit()
        cursor.close()
        conn.close()
        return jsonify({'ok': True, 'message': 'ìƒí’ˆì´ ë“±ë¡ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        print(f"[PRODUCTS] Add error: {e}")
        return jsonify({'ok': False, 'error': str(e)}), 500

@app.route("/api/products/<product_id>", methods=["PUT"])
def update_product(product_id):
    """ìƒí’ˆ ìˆ˜ì •"""
    try:
        data = request.json
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute('''
                UPDATE products SET name=%s, category=%s, cny_price=%s, sell_price=%s,
                                   stock=%s, image_url=%s, updated_at=CURRENT_TIMESTAMP
                WHERE id=%s
            ''', (
                data.get('name'),
                data.get('category'),
                data.get('cnyPrice'),
                data.get('sellPrice'),
                data.get('stock', 0),
                data.get('imageUrl', ''),
                product_id
            ))
        else:
            cursor.execute('''
                UPDATE products SET name=?, category=?, cny_price=?, sell_price=?,
                                   stock=?, image_url=?, updated_at=CURRENT_TIMESTAMP
                WHERE id=?
            ''', (
                data.get('name'),
                data.get('category'),
                data.get('cnyPrice'),
                data.get('sellPrice'),
                data.get('stock', 0),
                data.get('imageUrl', ''),
                product_id
            ))

        conn.commit()
        cursor.close()
        conn.close()
        return jsonify({'ok': True, 'message': 'ìƒí’ˆì´ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        print(f"[PRODUCTS] Update error: {e}")
        return jsonify({'ok': False, 'error': str(e)}), 500

@app.route("/api/products/<product_id>", methods=["DELETE"])
def delete_product(product_id):
    """ìƒí’ˆ ì‚­ì œ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        if USE_POSTGRES:
            cursor.execute('DELETE FROM products WHERE id=%s', (product_id,))
        else:
            cursor.execute('DELETE FROM products WHERE id=?', (product_id,))
        conn.commit()
        cursor.close()
        conn.close()
        return jsonify({'ok': True, 'message': 'ìƒí’ˆì´ ì‚­ì œë˜ì—ˆìŠµë‹ˆë‹¤.'})
    except Exception as e:
        print(f"[PRODUCTS] Delete error: {e}")
        return jsonify({'ok': False, 'error': str(e)}), 500

@app.route("/api/products/<product_id>/stock", methods=["PATCH"])
def update_stock(product_id):
    """ì¬ê³  ì—…ë°ì´íŠ¸ + ë¡œê·¸ ê¸°ë¡"""
    try:
        data = request.json
        new_stock = data.get('stock', 0)

        conn = get_db_connection()
        cursor = conn.cursor()

        # ê¸°ì¡´ ì¬ê³  ì¡°íšŒ
        if USE_POSTGRES:
            cursor.execute('SELECT stock, name FROM products WHERE id=%s', (product_id,))
        else:
            cursor.execute('SELECT stock, name FROM products WHERE id=?', (product_id,))
        row = cursor.fetchone()
        if not row:
            return jsonify({'ok': False, 'error': 'ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        if USE_POSTGRES:
            old_stock = row['stock']
            product_name = row['name']
        else:
            old_stock = row[0]
            product_name = row[1]
        change = new_stock - old_stock

        # ì¬ê³  ì—…ë°ì´íŠ¸
        if USE_POSTGRES:
            cursor.execute('UPDATE products SET stock=%s, updated_at=CURRENT_TIMESTAMP WHERE id=%s',
                          (new_stock, product_id))
        else:
            cursor.execute('UPDATE products SET stock=?, updated_at=CURRENT_TIMESTAMP WHERE id=?',
                          (new_stock, product_id))

        # ë³€ë™ì´ ìˆìœ¼ë©´ ë¡œê·¸ ê¸°ë¡
        if change != 0:
            if USE_POSTGRES:
                cursor.execute('''
                    INSERT INTO sales_logs (product_id, product_name, change_amount)
                    VALUES (%s, %s, %s)
                ''', (product_id, product_name, change))
            else:
                cursor.execute('''
                    INSERT INTO sales_logs (product_id, product_name, change_amount)
                    VALUES (?, ?, ?)
                ''', (product_id, product_name, change))

        conn.commit()
        cursor.close()
        conn.close()
        return jsonify({'ok': True, 'change': change})
    except Exception as e:
        print(f"[PRODUCTS] Stock update error: {e}")
        return jsonify({'ok': False, 'error': str(e)}), 500

@app.route("/api/products/sales-logs", methods=["GET"])
def get_sales_logs():
    """íŒë§¤/ì¬ê³  ë³€ë™ ë¡œê·¸ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute('''
            SELECT product_name, change_amount, log_date
            FROM sales_logs ORDER BY log_date DESC LIMIT 50
        ''')
        rows = cursor.fetchall()
        cursor.close()
        conn.close()

        logs = []
        for row in rows:
            if USE_POSTGRES:
                logs.append({
                    'productName': row['product_name'],
                    'change': row['change_amount'],
                    'date': str(row['log_date']) if row['log_date'] else None
                })
            else:
                logs.append({
                    'productName': row[0],
                    'change': row[1],
                    'date': row[2]
                })
        return jsonify({'ok': True, 'logs': logs})
    except Exception as e:
        print(f"[PRODUCTS] Logs error: {e}")
        return jsonify({'ok': False, 'error': str(e)}), 500

@app.route("/health")
def health():
    return jsonify({"ok": True})

# ===== JSON ì§€ì¹¨ API =====
@app.route("/api/drama/guidelines", methods=["GET"])
def api_get_guidelines():
    """JSON ì§€ì¹¨ ì „ì²´ ë°˜í™˜"""
    guidelines = load_drama_guidelines()
    if guidelines:
        return jsonify({"ok": True, "guidelines": guidelines})
    return jsonify({"ok": False, "error": "ì§€ì¹¨ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 500

@app.route("/api/drama/guidelines/<path:key_path>", methods=["GET"])
def api_get_guideline_by_path(key_path):
    """íŠ¹ì • ê²½ë¡œì˜ ì§€ì¹¨ë§Œ ë°˜í™˜ (ì˜ˆ: /api/drama/guidelines/contentTypes/testimony)"""
    # URL ê²½ë¡œë¥¼ ì  í‘œê¸°ë²•ìœ¼ë¡œ ë³€í™˜
    dot_path = key_path.replace('/', '.')
    value = get_guideline(dot_path)
    if value is not None:
        return jsonify({"ok": True, "path": dot_path, "value": value})
    return jsonify({"ok": False, "error": f"'{dot_path}' ê²½ë¡œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 404

@app.route("/api/drama/guidelines/reload", methods=["POST"])
def api_reload_guidelines():
    """JSON ì§€ì¹¨ ê°•ì œ ë¦¬ë¡œë“œ (ê°œë°œ/í…ŒìŠ¤íŠ¸ìš©)"""
    guidelines = load_drama_guidelines(force_reload=True)
    if guidelines:
        return jsonify({
            "ok": True,
            "message": "ì§€ì¹¨ íŒŒì¼ì´ ë¦¬ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤",
            "version": guidelines.get("version", "unknown")
        })
    return jsonify({"ok": False, "error": "ì§€ì¹¨ íŒŒì¼ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 500

# ===== ì²˜ë¦¬ ë‹¨ê³„ ì‹¤í–‰ API (gpt-4o-mini) =====
@app.route("/api/drama/process", methods=["POST"])
def api_process_step():
    """ë‹¨ì¼ ì²˜ë¦¬ ë‹¨ê³„ ì‹¤í–‰ (gpt-4o-mini ì‚¬ìš©)"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        category = data.get("category", "")
        step_id = data.get("stepId", "")
        step_name = data.get("stepName", "")
        benchmark_script = data.get("text", "")  # ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸
        main_character = data.get("mainCharacter", "")  # ì£¼ì¸ê³µ ì •ë³´
        guide = data.get("guide", "")
        master_guide = data.get("masterGuide", "")
        previous_results = data.get("previousResults", {})

        print(f"[DRAMA-PROCESS] {category} - {step_name}")

        # ì‹œìŠ¤í…œ ë©”ì‹œì§€ êµ¬ì„± (ë‹¨ê³„ë³„ ìµœì í™”)
        system_content = get_system_prompt_for_step(step_name)

        # ì´ê´„ ì§€ì¹¨ì´ ìˆìœ¼ë©´ ì¶”ê°€
        if master_guide:
            system_content += f"\n\nã€ ì¹´í…Œê³ ë¦¬ ì´ê´„ ì§€ì¹¨ ã€‘\n{master_guide}\n\n"
            system_content += f"ã€ í˜„ì¬ ë‹¨ê³„ ì—­í•  ã€‘\n{step_name}\n\n"
            system_content += "ìœ„ ì´ê´„ ì§€ì¹¨ì„ ì°¸ê³ í•˜ì—¬, í˜„ì¬ ë‹¨ê³„ì˜ ì—­í• ê³¼ ë¹„ì¤‘ì— ë§ê²Œ 'ìë£Œë§Œ' ì‘ì„±í•˜ì„¸ìš”."

        # â˜… ì¤‘ìš”: ë‹¨ê³„ë³„ ì„¸ë¶€ ì§€ì¹¨ì„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— í¬í•¨ (ìµœìš°ì„  ì§€ì¹¨)
        if guide:
            system_content += f"\n\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n"
            system_content += f"ã€ ìµœìš°ì„  ì§€ì¹¨: {step_name} ë‹¨ê³„ ì„¸ë¶€ ì§€ì¹¨ ã€‘\n"
            system_content += f"â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n\n"
            system_content += guide
            system_content += f"\n\nìœ„ ì§€ì¹¨ì„ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„ í•˜ì—¬ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤."
            system_content += f"\nì´ ì§€ì¹¨ì´ ê¸°ë³¸ ì—­í• ê³¼ ì¶©ëŒí•˜ë©´, ì´ ì§€ì¹¨ì„ ë”°ë¥´ì„¸ìš”."

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_content = f"[ì˜ìƒ ì‹œê°„]\n{category}\n\n"

        if main_character:
            user_content += f"[ì£¼ì¸ê³µ/ëŒ€ìƒ]\n{main_character}\n\n"

        if benchmark_script:
            user_content += f"[ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ (ì°¸ê³ ìš©)]\n{benchmark_script}\n\n"

        # ì´ì „ ë‹¨ê³„ ê²°ê³¼ ì¶”ê°€
        if previous_results:
            user_content += "[ì´ì „ ë‹¨ê³„ ê²°ê³¼ (ì°¸ê³ ìš©)]\n"
            for prev_id, prev_data in previous_results.items():
                user_content += f"\n### {prev_data['name']}\n{prev_data['result']}\n"
            user_content += "\n"

        user_content += f"ìœ„ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ '{step_name}' ë‹¨ê³„ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.\n"
        user_content += "âš ï¸ ì¤‘ìš”: ì™„ì„±ëœ ëŒ€ë³¸ì´ ì•„ë‹Œ, ìë£Œì™€ êµ¬ì¡°ë§Œ ì œê³µí•˜ì„¸ìš”."

        # GPT í˜¸ì¶œ (gpt-4o-mini)
        # JSON í˜•ì‹ ê°•ì œí•˜ì§€ ì•ŠìŒ - guideì— ë”°ë¼ ììœ ë¡­ê²Œ ì¶œë ¥
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": system_content
                },
                {
                    "role": "user",
                    "content": user_content
                }
            ],
            temperature=0.7,
        )

        result = completion.choices[0].message.content.strip()

        # JSON íŒŒì‹± ì‹œë„ (ì„ íƒì )
        try:
            # JSON ì½”ë“œ ë¸”ë¡ ì œê±° (```json ... ``` í˜•íƒœ)
            cleaned_result = result
            if cleaned_result.startswith('```'):
                # ```json ë˜ëŠ” ``` ë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°
                lines = cleaned_result.split('\n')
                # ì²« ì¤„ê³¼ ë§ˆì§€ë§‰ ì¤„ ì œê±°
                if lines[0].startswith('```'):
                    lines = lines[1:]
                if lines and lines[-1].startswith('```'):
                    lines = lines[:-1]
                cleaned_result = '\n'.join(lines).strip()

            # JSON íŒŒì‹±
            json_data = json.loads(cleaned_result)

            # JSONì„ ë³´ê¸° ì¢‹ì€ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
            formatted_result = format_json_result(json_data)

            print(f"[DRAMA-PROCESS][SUCCESS] JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µë°›ì•„ í¬ë§·íŒ… ì™„ë£Œ")
            return jsonify({"ok": True, "result": formatted_result})

        except json.JSONDecodeError as je:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ì›ë³¸ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜ (ì •ìƒ ì²˜ë¦¬)
            # guideì—ì„œ í…ìŠ¤íŠ¸ í˜•ì‹ì„ ìš”êµ¬í–ˆì„ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì˜¤ë¥˜ê°€ ì•„ë‹˜
            print(f"[DRAMA-PROCESS][INFO] í…ìŠ¤íŠ¸ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µë°›ìŒ (JSON ì•„ë‹˜)")
            result = remove_markdown(result)
            return jsonify({"ok": True, "result": result})

    except Exception as e:
        print(f"[DRAMA-PROCESS][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== GPT PRO ì²˜ë¦¬ API (gpt-5.1) =====
@app.route("/api/drama/gpt-pro", methods=["POST"])
def api_gpt_pro():
    """GPT-5.1 ë“œë¼ë§ˆ ëŒ€ë³¸ ì™„ì„±"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        style_name = data.get("styleName", "")
        style_description = data.get("styleDescription", "")
        category = data.get("category", "")
        draft_content = data.get("draftContent", "")

        print(f"[DRAMA-GPT-PRO] ì²˜ë¦¬ ì‹œì‘ - ìŠ¤íƒ€ì¼: {style_name}")

        # GPT-5.1 ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ë“œë¼ë§ˆ ì „ìš©)
        system_content = (
            "ë‹¹ì‹ ì€ GPT-5.1 ê¸°ë°˜ì˜ ì „ë¬¸ ë“œë¼ë§ˆ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤."
            " ìë£ŒëŠ” ì°¸ê³ ìš©ìœ¼ë¡œë§Œ í™œìš©í•˜ê³  ëŒ€ë³¸ì€ ì²˜ìŒë¶€í„° ìƒˆë¡œ êµ¬ì„±í•˜ë©°,"
            " ìì—°ìŠ¤ëŸ½ê³  ìƒë™ê° ìˆëŠ” ëŒ€ì‚¬ì™€ ì§€ë¬¸ìœ¼ë¡œ ì‹¤ì œ ì´¬ì˜ ê°€ëŠ¥í•œ ì™„ì„±ë„ ë†’ì€ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”."
            " ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸ ëŒ€ì‹  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤."
        )

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        meta_lines = []
        if category:
            meta_lines.append(f"- ë“œë¼ë§ˆ ìœ í˜•: {category}")
        if style_name:
            meta_lines.append(f"- ë“œë¼ë§ˆ ìŠ¤íƒ€ì¼: {style_name}")
        if style_description:
            meta_lines.append(f"- ìŠ¤íƒ€ì¼ ì„¤ëª…: {style_description}")

        meta_section = "\n".join(meta_lines)

        user_content = (
            "ì•„ë˜ëŠ” gpt-4o-miniê°€ ì •ë¦¬í•œ ë“œë¼ë§ˆ ê¸°íš ìë£Œì…ë‹ˆë‹¤."
            " ì°¸ê³ ë§Œ í•˜ê³ , ëŒ€ë³¸ì€ ì²˜ìŒë¶€í„° ìƒˆë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."
        )
        if meta_section:
            user_content += f"\n\n[ê¸°ë³¸ ì •ë³´]\n{meta_section}"
        user_content += "\n\n[ë“œë¼ë§ˆ ì´ˆì•ˆ ìë£Œ]\n"
        user_content += draft_content

        # ë“œë¼ë§ˆ ëŒ€ë³¸ ì‘ì„± ìš”ì²­
        user_content += "\n\nã€ìš”ì²­ ì‚¬í•­ã€‘\n"
        user_content += (
            "1. ì‹¤ì œ ì´¬ì˜ì´ ê°€ëŠ¥í•œ í˜•ì‹ìœ¼ë¡œ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”:\n"
            "   - ì¥ë©´ ë²ˆí˜¸, ì¥ì†Œ, ì‹œê°„ ëª…ì‹œ\n"
            "   - ì§€ë¬¸ (ì¸ë¬¼ì˜ í–‰ë™, í‘œì •, ë¶„ìœ„ê¸° ë“±)\n"
            "   - ëŒ€ì‚¬ (ì¸ë¬¼ëª…: ëŒ€ì‚¬ í˜•ì‹)\n"
            "   - í•„ìš”ì‹œ (  ) ì•ˆì— ê°ì •ì´ë‚˜ ìƒí™© ë¬˜ì‚¬\n"
            "2. ìì—°ìŠ¤ëŸ½ê³  í˜„ì‹¤ì ì¸ ëŒ€í™”ë¥¼ ì‘ì„±í•˜ì„¸ìš”.\n"
            "3. ê° ì¥ë©´ì˜ ëª©ì ê³¼ ì „ê°œê°€ ëª…í™•í•˜ë„ë¡ êµ¬ì„±í•˜ì„¸ìš”.\n"
            "4. ìºë¦­í„°ì˜ ì„±ê²©ê³¼ ë™ê¸°ê°€ ëŒ€ì‚¬ì™€ í–‰ë™ì— ì˜ ë“œëŸ¬ë‚˜ë„ë¡ í•˜ì„¸ìš”.\n"
            "5. ì „ì²´ì ì¸ íë¦„ê³¼ í…œí¬ë¥¼ ê³ ë ¤í•˜ì—¬ ì‘ì„±í•˜ì„¸ìš”.\n"
            "6. ë§ˆí¬ë‹¤ìš´, ë¶ˆë¦¿ ê¸°í˜¸ ëŒ€ì‹  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•˜ê³ , ì¤‘ë³µë˜ëŠ” ë¬¸ì¥ì€ í”¼í•˜ì„¸ìš”.\n"
            "7. ì¶©ë¶„íˆ ê¸¸ê³  ìƒì„¸í•˜ë©° í’ì„±í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš” (ìµœëŒ€ 16000 í† í°)."
        )

        # ìµœì‹  Responses API (gpt-5.1) í˜¸ì¶œ
        completion = client.responses.create(
            model="gpt-5.1",
            input=[
                {
                    "role": "system",
                    "content": [
                        {
                            "type": "input_text",
                            "text": system_content
                        }
                    ]
                },
                {
                    "role": "user",
                    "content": [
                        {
                            "type": "input_text",
                            "text": user_content
                        }
                    ]
                }
            ],
            temperature=0.8,
            max_output_tokens=16000
        )

        if getattr(completion, "output_text", None):
            result = completion.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(completion, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text_chunks.append(getattr(content, "text", ""))
            result = "\n".join(text_chunks).strip()

        if not result:
            raise RuntimeError("GPT-5.1 APIë¡œë¶€í„° ê²°ê³¼ë¥¼ ë°›ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.")

        # ë§ˆí¬ë‹¤ìš´ ì œê±°
        result = remove_markdown(result)

        # ê²°ê³¼ ì•ì— ê¸°ë³¸ ì •ë³´ ì¶”ê°€
        final_result = ""

        if style_name:
            final_result += f"ë“œë¼ë§ˆ ìŠ¤íƒ€ì¼: {style_name}\n"

        if category:
            final_result += f"ë“œë¼ë§ˆ ìœ í˜•: {category}\n"

        if style_name or category:
            final_result += "\n" + "="*50 + "\n\n"

        final_result += result

        print(f"[DRAMA-GPT-PRO] ì™„ë£Œ")

        return jsonify({"ok": True, "result": final_result})

    except Exception as e:
        print(f"[DRAMA-GPT-PRO][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== ê°œì„  ì œì•ˆ API =====
@app.route("/api/drama/get-suggestions", methods=["POST"])
def api_get_suggestions():
    """í˜„ì¬ ëŒ€ë³¸ì— ëŒ€í•œ ê°œì„  ì œì•ˆ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        current_draft = data.get("currentDraft", "")
        category = data.get("category", "")

        if not current_draft:
            return jsonify({"ok": False, "error": "í˜„ì¬ ì‘ì—… ì¤‘ì¸ ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[DRAMA-SUGGEST] ê°œì„  ì œì•ˆ ìƒì„± ì‹œì‘")

        # GPTë¡œ ê°œì„  ì œì•ˆ ìƒì„±
        system_content = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ëŒ€ë³¸ ì»¨ì„¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì œê³µëœ ì´ˆì•ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ê³ , ë‹¤ìŒ ê´€ì ì—ì„œ êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆì„ ì œê³µí•˜ì„¸ìš”:

1. **ìŠ¤í† ë¦¬ íë¦„ ê°œì„ **
   - ë” ê°•ë ¥í•œ ë„ì…ë¶€ ë§Œë“¤ê¸°
   - ê¸´ì¥ê°ì„ ë†’ì´ëŠ” ë°©ë²•
   - ê²°ë§ì˜ ì„íŒ©íŠ¸ ê°•í™”

2. **ìºë¦­í„° ê¹Šì´ ì¶”ê°€**
   - ì£¼ì¸ê³µì˜ ë™ê¸° ëª…í™•í™”
   - ê°ì •ì„  ê°•í™” ë°©ë²•

3. **ì‹œì²­ì ëª°ì… ìš”ì†Œ**
   - ê³µê° í¬ì¸íŠ¸ ê°•í™”
   - ì˜ˆìƒì„ ë›°ì–´ë„˜ëŠ” ì „ê°œ

4. **ëŒ€ì‚¬ì™€ ì—°ì¶œ**
   - í•µì‹¬ ë©”ì‹œì§€ ì „ë‹¬ë ¥ í–¥ìƒ
   - ê°ì •ì  í˜¸ì†Œë ¥ ê°•í™”

ê° ì œì•ˆì€ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•´ì•¼ í•©ë‹ˆë‹¤."""

        user_content = f"""[ì˜ìƒ ì‹œê°„]
{category}

[í˜„ì¬ ì‘ì—… ì¤‘ì¸ ì´ˆì•ˆ]
{current_draft}

ìœ„ ì´ˆì•ˆì„ ë¶„ì„í•˜ê³ , ì‹œì²­ì ë°˜ì‘ì„ ê·¹ëŒ€í™”í•  ìˆ˜ ìˆëŠ” êµ¬ì²´ì ì¸ ê°œì„  ì œì•ˆì„ í•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ]
        )

        suggestions = completion.choices[0].message.content.strip()

        print(f"[DRAMA-SUGGEST] ì œì•ˆ ìƒì„± ì™„ë£Œ (ëª¨ë¸: gpt-4o-mini)")

        return jsonify({"ok": True, "suggestions": suggestions})

    except Exception as e:
        print(f"[DRAMA-SUGGEST][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== ì›Œí¬í”Œë¡œìš° ë°•ìŠ¤ ì‹¤í–‰ API =====
@app.route("/api/drama/workflow-execute", methods=["POST"])
def api_workflow_execute():
    """ì›Œí¬í”Œë¡œìš° ë°•ìŠ¤ ì‹¤í–‰ (ì„ íƒëœ ì…ë ¥ ì†ŒìŠ¤ ê¸°ë°˜)"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        box_id = data.get("boxId", "")
        box_name = data.get("boxName", "")
        box_number = data.get("boxNumber", 0)
        step_type = data.get("stepType", "step1")  # step1 or step2
        guide = data.get("guide", "")
        inputs = data.get("inputs", {})  # dict with selected input sources
        category = data.get("category", "")
        main_character = data.get("mainCharacter", "")
        selected_model = data.get("model", "")  # í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì„ íƒí•œ ëª¨ë¸

        # Step íƒ€ì…ì— ë”°ë¥¸ ëª¨ë¸ ì„ íƒ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì„ íƒí•œ ëª¨ë¸ ìš°ì„ )
        if selected_model:
            model_name = selected_model
            use_temperature = True  # ì‚¬ìš©ìê°€ ëª¨ë¸ì„ ì„ íƒí•œ ê²½ìš° temperature ì‚¬ìš©
        elif step_type == "step1":
            model_name = "gpt-4o-mini"
            use_temperature = False
        else:  # step2
            model_name = "gpt-4o-mini"
            use_temperature = True

        print(f"[DRAMA-WORKFLOW] Box [{box_number}] {box_name} ì‹¤í–‰ ì‹œì‘ (ëª¨ë¸: {model_name}, Step: {step_type})")

        # ì„ íƒëœ ì…ë ¥ ì†ŒìŠ¤ë“¤ì„ ì¡°í•©
        input_content_parts = []

        # ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ì´ ì„ íƒëœ ê²½ìš°
        if inputs.get("benchmarkScript"):
            input_content_parts.append(f"[ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸]\n{inputs['benchmarkScript']}")

        # AI ë¶„ì„ ìë£Œê°€ ì„ íƒëœ ê²½ìš°
        if inputs.get("aiAnalysis"):
            input_content_parts.append(f"[AI ëŒ€ë³¸ ë¶„ì„ ìë£Œ]\n{inputs['aiAnalysis']}")

        # DBì—ì„œ ê´€ë ¨ ê°€ì´ë“œ ê°€ì ¸ì˜¤ê¸° (ìë™ ì¶”ê°€)
        db_guide = get_relevant_guide_from_db(box_name, category, limit=3)
        if db_guide:
            input_content_parts.append(f"[ì¶•ì ëœ ì„±ê³µ ì‚¬ë¡€ ê°€ì´ë“œ]\n{db_guide}")

        # ì´ì „ ë°•ìŠ¤ ê²°ê³¼ë“¤ì´ ì„ íƒëœ ê²½ìš°
        for key, value in inputs.items():
            if key.startswith("box") and key.endswith("Result"):
                # box1Result, box2Result ë“±
                box_num = key.replace("box", "").replace("Result", "")
                input_content_parts.append(f"[ë°•ìŠ¤ {box_num} ê²°ê³¼]\n{value}")

        # ì…ë ¥ì´ ì—†ëŠ” ê²½ìš° ì˜¤ë¥˜ ë°˜í™˜
        if not input_content_parts:
            return jsonify({"ok": False, "error": "ì„ íƒëœ ì…ë ¥ ì†ŒìŠ¤ê°€ ì—†ìŠµë‹ˆë‹¤. ì²´í¬ë°•ìŠ¤ë¥¼ ì„ íƒí•´ì£¼ì„¸ìš”."}), 400

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        system_content = f"""ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ì œì‘ ì›Œí¬í”Œë¡œìš° ì‹œìŠ¤í…œì˜ ì‘ì—… ë°•ìŠ¤ [{box_number}] '{box_name}'ë¥¼ ì²˜ë¦¬í•˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.

ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” ì‘ì—… ì§€ì¹¨ì„ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„ í•˜ì—¬ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤.
ì§€ì¹¨ì´ ëª…í™•í•˜ë©´ ê·¸ëŒ€ë¡œ ìˆ˜í–‰í•˜ê³ , ì§€ì¹¨ì´ ì—†ê±°ë‚˜ ë¶ˆëª…í™•í•˜ë©´ ì¼ë°˜ì ì¸ ë“œë¼ë§ˆ ì œì‘ ì›ì¹™ì— ë”°ë¼ ì²˜ë¦¬í•˜ì„¸ìš”.

í˜„ì¬ ì‘ì—…: [{box_number}] {box_name}
ì˜ìƒ ì‹œê°„: {category}"""

        # ì£¼ì¸ê³µ ì •ë³´ ì¶”ê°€
        if main_character:
            system_content += f"\nì£¼ì¸ê³µ ì„¤ì •: {main_character}"
            system_content += "\n\nâš ï¸ ì¤‘ìš”: ìœ„ì— ì§€ì •ëœ ì£¼ì¸ê³µì„ ë°˜ë“œì‹œ ì‚¬ìš©í•˜ì—¬ ëŒ€ë³¸ì„ êµ¬ì„±í•˜ì„¸ìš”."

        # ì‘ì—… ì§€ì¹¨ ì¶”ê°€
        if guide:
            system_content += f"""

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ã€ ì‘ì—… ì§€ì¹¨ (ìµœìš°ì„ ) ã€‘
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

{guide}

ìœ„ ì§€ì¹¨ì„ ì ˆëŒ€ì ìœ¼ë¡œ ìš°ì„ í•˜ì—¬ ë”°ë¼ì•¼ í•©ë‹ˆë‹¤."""
        else:
            system_content += "\n\nâš ï¸ ì‘ì—… ì§€ì¹¨ì´ ì œê³µë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì¼ë°˜ì ì¸ ë“œë¼ë§ˆ ì œì‘ ì›ì¹™ì— ë”°ë¼ ì²˜ë¦¬í•˜ì„¸ìš”."

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„± (ì„ íƒëœ ì…ë ¥ ì†ŒìŠ¤ë“¤)
        user_content = "ë‹¤ìŒì€ ì„ íƒëœ ì…ë ¥ ìë£Œë“¤ì…ë‹ˆë‹¤:\n\n"
        user_content += "\n\n".join(input_content_parts)
        user_content += "\n\nìœ„ ìë£Œë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì—… ì§€ì¹¨ì— ë”°ë¼ ì²˜ë¦¬í•´ì£¼ì„¸ìš”."

        # GPT í˜¸ì¶œ (ëª¨ë¸ ë° temperature ë™ì  ì„¤ì •)
        if use_temperature:
            completion = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ],
                temperature=0.7,
            )
        else:
            completion = client.chat.completions.create(
                model=model_name,
                messages=[
                    {"role": "system", "content": system_content},
                    {"role": "user", "content": user_content}
                ]
            )

        result = completion.choices[0].message.content.strip()

        # ë§ˆí¬ë‹¤ìš´ ì œê±°
        result = remove_markdown(result)

        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        input_tokens = completion.usage.prompt_tokens if hasattr(completion, 'usage') and completion.usage else 0
        output_tokens = completion.usage.completion_tokens if hasattr(completion, 'usage') and completion.usage else 0

        print(f"[DRAMA-WORKFLOW] Box [{box_number}] {box_name} ì‹¤í–‰ ì™„ë£Œ (ëª¨ë¸: {model_name}, í† í°: {input_tokens}/{output_tokens})")

        return jsonify({
            "ok": True,
            "result": result,
            "usage": {
                "input_tokens": input_tokens,
                "output_tokens": output_tokens,
                "model": model_name
            }
        })

    except Exception as e:
        print(f"[DRAMA-WORKFLOW][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== ì¶•ì ëœ ì‘ì„± ê°€ì´ë“œ ì¡°íšŒ API =====
@app.route("/api/drama/get-accumulated-guide", methods=["POST"])
def api_get_accumulated_guide():
    """ì¶•ì ëœ ëŒ€ë³¸ ë¶„ì„ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì‘ì„± ê°€ì´ë“œ ì œê³µ"""
    try:
        data = request.get_json()
        category = data.get("category", "") if data else ""

        print(f"[DRAMA-GUIDE] ì¶•ì ëœ ê°€ì´ë“œ ì¡°íšŒ ì‹œì‘")

        # DBì—ì„œ ì¶•ì ëœ ë°ì´í„° í™•ì¸
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            if USE_POSTGRES:
                cursor.execute("SELECT COUNT(*) as cnt FROM benchmark_analyses")
                count_result = cursor.fetchone()
                db_count = count_result['cnt'] if count_result else 0
            else:
                cursor.execute("SELECT COUNT(*) FROM benchmark_analyses")
                db_count = cursor.fetchone()[0]
            conn.close()

            if db_count > 0:
                # DBì— ë°ì´í„°ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ë¶„ì„ ê²°ê³¼ ê¸°ë°˜ ê°€ì´ë“œ ìƒì„±
                print(f"[DRAMA-GUIDE] DBì— {db_count}ê°œ ë¶„ì„ ë°ì´í„° ë°œê²¬ - ì‹¤ì œ ë°ì´í„° ê¸°ë°˜ ê°€ì´ë“œ ìƒì„±")

                # ê° ì¹´í…Œê³ ë¦¬ë³„ TOP ë¶„ì„ ê²°ê³¼ ê°€ì ¸ì˜¤ê¸°
                guide_parts = ["ã€ ì¶•ì ëœ ëŒ€ë³¸ ë¶„ì„ ê¸°ë°˜ ì‘ì„± ê°€ì´ë“œ ã€‘\n"]
                guide_parts.append(f"ì´ {db_count}ê°œì˜ ëŒ€ë³¸ ë¶„ì„ ê²°ê³¼ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì‘ì„±ë˜ì—ˆìŠµë‹ˆë‹¤.\n\n")

                # 1. ìŠ¤í† ë¦¬ êµ¬ì¡° ê°€ì´ë“œ
                story_guide = get_relevant_guide_from_db("ìŠ¤í† ë¦¬ êµ¬ì„±", category, limit=3)
                if story_guide:
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                    guide_parts.append("ğŸ“– ìŠ¤í† ë¦¬ êµ¬ì¡° ì„±ê³µ ì‚¬ë¡€")
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
                    guide_parts.append(story_guide)
                    guide_parts.append("\n")

                # 2. ìºë¦­í„° ì„¤ê³„ ê°€ì´ë“œ
                character_guide = get_relevant_guide_from_db("ìºë¦­í„° ì„¤ì •", category, limit=3)
                if character_guide:
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                    guide_parts.append("ğŸ‘¥ ìºë¦­í„° ì„¤ê³„ ì„±ê³µ ì‚¬ë¡€")
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
                    guide_parts.append(character_guide)
                    guide_parts.append("\n")

                # 3. ëŒ€ì‚¬ ì‘ì„± ê°€ì´ë“œ
                dialogue_guide = get_relevant_guide_from_db("ëŒ€ì‚¬ ì‘ì„±", category, limit=3)
                if dialogue_guide:
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                    guide_parts.append("ğŸ’¬ ëŒ€ì‚¬ ì‘ì„± ì„±ê³µ ì‚¬ë¡€")
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
                    guide_parts.append(dialogue_guide)
                    guide_parts.append("\n")

                # 4. ì„±ê³µ ìš”ì¸ ì¢…í•©
                success_guide = get_relevant_guide_from_db("ì„±ê³µ ìš”ì¸", category, limit=5)
                if success_guide:
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”")
                    guide_parts.append("ğŸ† ê³ ì¡°íšŒìˆ˜ ëŒ€ë³¸ì˜ ì„±ê³µ ìš”ì¸")
                    guide_parts.append("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n")
                    guide_parts.append(success_guide)

                guide = "\n".join(guide_parts)
                print(f"[DRAMA-GUIDE] DB ê¸°ë°˜ ê°€ì´ë“œ ìƒì„± ì™„ë£Œ")
                return jsonify({"ok": True, "guide": guide, "source": "database"})

        except Exception as db_err:
            print(f"[DRAMA-GUIDE] DB ì¡°íšŒ ì‹¤íŒ¨, GPT ê°€ì´ë“œë¡œ í´ë°±: {str(db_err)}")

        # DBì— ë°ì´í„°ê°€ ì—†ê±°ë‚˜ ì˜¤ë¥˜ ì‹œ GPTë¡œ ì¼ë°˜ ê°€ì´ë“œ ìƒì„±
        print(f"[DRAMA-GUIDE] DB ë°ì´í„° ì—†ìŒ - GPT ì¼ë°˜ ê°€ì´ë“œ ìƒì„±")

        system_content = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ëŒ€ë³¸ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ìˆ˜ë§ì€ ì„±ê³µì ì¸ ë“œë¼ë§ˆ ëŒ€ë³¸ë“¤ì„ ë¶„ì„í•˜ì—¬ ì–»ì€ ë³´í¸ì ì¸ ì‘ì„± ê°€ì´ë“œë¥¼ ì œê³µí•˜ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•˜ì—¬ êµ¬ì¡°í™”ëœ ê°€ì´ë“œë¥¼ ì‘ì„±í•˜ì„¸ìš”:

1. **ìŠ¤í† ë¦¬ êµ¬ì¡° ëª¨ë²” ì‚¬ë¡€**
   - íš¨ê³¼ì ì¸ ë„ì…ë¶€ êµ¬ì„±ë²•
   - ê¸´ì¥ê°ì„ ìœ ì§€í•˜ëŠ” ì „ê°œ ë°©ì‹
   - ê°•ë ¬í•œ í´ë¼ì´ë§¥ìŠ¤ ë§Œë“¤ê¸°
   - ì—¬ìš´ ë‚¨ëŠ” ê²°ë§ ì‘ì„±ë²•

2. **ìºë¦­í„° ì„¤ê³„ ì›ì¹™**
   - ê³µê° ê°€ëŠ” ì£¼ì¸ê³µ ë§Œë“¤ê¸°
   - ëª…í™•í•œ ë™ê¸°ì™€ ëª©í‘œ ì„¤ì •
   - ì„±ì¥ ì•„í¬ ë””ìì¸
   - ê°ˆë“±ì˜ ì›ì²œ ì„¤ì •

3. **ëŒ€ì‚¬ ì‘ì„± ê¸°ë²•**
   - ìì—°ìŠ¤ëŸ¬ìš´ ëŒ€í™” ë§Œë“¤ê¸°
   - ìºë¦­í„° ê°œì„± ë“œëŸ¬ë‚´ê¸°
   - í•µì‹¬ ë©”ì‹œì§€ ì „ë‹¬ ë°©ë²•
   - ê°ì •ì  í˜¸ì†Œë ¥ ê°•í™”

4. **ì‹œì²­ì ëª°ì… ì „ëµ**
   - ê³µê° í¬ì¸íŠ¸ ë°°ì¹˜
   - ì˜ˆìƒì„ ë›°ì–´ë„˜ëŠ” ì „ê°œ
   - ê°ì •ì  ì¹´íƒ€ë¥´ì‹œìŠ¤ ì œê³µ
   - ë³´í¸ì  ì£¼ì œ ë‹¤ë£¨ê¸°

5. **ì¥ë¥´ë³„ ì°¨ë³„í™” ìš”ì†Œ**
   - ê¸°ë…êµ ë“œë¼ë§ˆì˜ íŠ¹ì„±
   - ê°ë™ ë“œë¼ë§ˆì˜ í•µì‹¬
   - ë©œë¡œ/ë¡œë§¨ìŠ¤ì˜ í¬ì¸íŠ¸
   - ìŠ¤ë¦´ëŸ¬/ì„œìŠ¤íœìŠ¤ì˜ ê¸´ì¥ê°

ê° í•­ëª©ì€ ì‹¤ì „ì—ì„œ ë°”ë¡œ ì ìš© ê°€ëŠ¥í•˜ë„ë¡ êµ¬ì²´ì ì´ê³  ëª…í™•í•˜ê²Œ ì‘ì„±í•˜ì„¸ìš”."""

        user_content = "ë“œë¼ë§ˆ ëŒ€ë³¸ ì‘ì„± ì‹œ ì°¸ê³ í•  ìˆ˜ ìˆëŠ” ë³´í¸ì ì´ê³  ì‹¤ìš©ì ì¸ ê°€ì´ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."

        if category:
            user_content += f"\n\níŠ¹íˆ '{category}' ê¸¸ì´ì˜ ë“œë¼ë§ˆì— ì í•©í•œ ê°€ì´ë“œë¥¼ í¬í•¨í•´ì£¼ì„¸ìš”."

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ]
        )

        guide = completion.choices[0].message.content.strip()

        print(f"[DRAMA-GUIDE] GPT ê°€ì´ë“œ ìƒì„± ì™„ë£Œ (ëª¨ë¸: gpt-4o-mini)")

        return jsonify({"ok": True, "guide": guide, "source": "gpt"})

    except Exception as e:
        print(f"[DRAMA-GUIDE][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Q&A ëŒ€í™” API =====
@app.route('/api/drama/qa', methods=['POST'])
def api_drama_qa():
    """ëŒ€ë³¸/ì‘ì—…ì— ëŒ€í•œ Q&A ëŒ€í™”"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        question = data.get("question", "")
        script = data.get("script", "")
        session_context = data.get("sessionContext", "")
        history = data.get("history", [])

        if not question:
            return jsonify({"ok": False, "error": "ì§ˆë¬¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[Q&A] ì§ˆë¬¸: {question[:100]}...")

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        history_text = ""
        if history:
            history_text = "\n\nã€ ì´ì „ ëŒ€í™” ã€‘\n"
            for item in history[-5:]:  # ìµœê·¼ 5ê°œë§Œ
                if item.get('question') and item.get('answer') and item.get('answer') != 'ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤...':
                    history_text += f"Q: {item['question'][:200]}\n"
                    history_text += f"A: {item['answer'][:500]}\n\n"

        # ëŒ€ë³¸ ì»¨í…ìŠ¤íŠ¸ (ì•ë¶€ë¶„ë§Œ)
        script_context = ""
        if script:
            script_preview = script[:3000] if len(script) > 3000 else script
            script_context = f"\n\nã€ í˜„ì¬ ëŒ€ë³¸ (ì¼ë¶€) ã€‘\n{script_preview}"

        system_prompt = f"""ë‹¹ì‹ ì€ ë“œë¼ë§ˆ/ê°„ì¦ ëŒ€ë³¸ ì œì‘ ì „ë¬¸ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì¹œì ˆí•˜ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.

{session_context}
{script_context}
{history_text}

ã€ ë‹µë³€ ê°€ì´ë“œ ã€‘
- ëŒ€ë³¸ êµ¬ì¡°, ìºë¦­í„°, ìŠ¤í† ë¦¬ì— ëŒ€í•œ ì „ë¬¸ì  ì¡°ì–¸ ì œê³µ
- êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì œì•ˆ
- í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë‹µë³€
- í•„ìš”ì‹œ ì˜ˆì‹œ ì œê³µ
"""

        user_prompt = f"ì§ˆë¬¸: {question}"

        # OpenRouter API í˜¸ì¶œ (GPT-4o-mini ì‚¬ìš©)
        openrouter_api_key = os.getenv("OPENROUTER_API_KEY", "")
        if not openrouter_api_key:
            return jsonify({"ok": False, "error": "OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 200

        import requests as req

        headers = {
            "Authorization": f"Bearer {openrouter_api_key}",
            "Content-Type": "application/json",
            "HTTP-Referer": "https://drama-lab.app",
            "X-Title": "Drama Lab Q&A"
        }

        payload = {
            "model": "openai/gpt-4o-mini",
            "messages": [
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            "temperature": 0.7,
            "max_tokens": 1500
        }

        response = req.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers=headers,
            json=payload,
            timeout=60
        )

        if response.status_code == 200:
            result = response.json()
            answer = result.get("choices", [{}])[0].get("message", {}).get("content", "")

            if answer:
                print(f"[Q&A] ë‹µë³€ ìƒì„± ì™„ë£Œ: {len(answer)}ì")
                return jsonify({
                    "ok": True,
                    "answer": answer,
                    "model": "gpt-4o-mini"
                })
            else:
                return jsonify({"ok": False, "error": "ë‹µë³€ ìƒì„± ì‹¤íŒ¨"}), 200
        else:
            error_text = response.text
            print(f"[Q&A][ERROR] OpenRouter ì‘ë‹µ: {response.status_code} - {error_text}")
            return jsonify({"ok": False, "error": f"API ì˜¤ë¥˜: {response.status_code}"}), 200

    except Exception as e:
        print(f"[Q&A][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step3: OpenRouterë¥¼ í†µí•œ Claude ëŒ€ë³¸ ì™„ì„± =====
def _generate_senior_nostalgia_metadata(script_preview):
    """ì‹œë‹ˆì–´ í–¥ìˆ˜ ì±„ë„ ì „ìš© ë©”íƒ€ë°ì´í„° ìƒì„± - CTR/Watch Time/êµ¬ë…ë¥  ìµœì í™”"""
    system_prompt = """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ í–¥ìˆ˜ YouTube ì±„ë„ì˜ ë©”íƒ€ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
60-80ëŒ€ ì‹œë‹ˆì–´ ì‹œì²­ìë¥¼ ìœ„í•œ ë”°ëœ»í•˜ê³  ê³µê°ë˜ëŠ” ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{
  "title": "ì œëª© (4~12ì, ì¡°ìš©í•˜ì§€ë§Œ ë§ˆìŒ ê±´ë“œë¦¬ëŠ”)",
  "thumbnailTitle": "ì¸ë„¤ì¼ ë¬¸êµ¬ (4~6ë‹¨ì–´, ì¤„ë°”ê¿ˆ êµ¬ë¶„)",
  "description": "ì„¤ëª…ë¬¸ (3~7ì¤„, ì§§ì€ ë¬¸ì¥)",
  "tags": ["íƒœê·¸1", "íƒœê·¸2", ...] (15-20ê°œ)
}

ã€ ì œëª© ê·œì¹™ - ì‹œë‹ˆì–´ í–¥ìˆ˜ ì±„ë„ ìµœì í™” ã€‘
â˜… ì „ì²´ í†¤: ê³¼ì¥ NO, ìˆ«ì ê³¼ë‹¤ NO, ìœ í–‰ì–´ NO
â˜… ì¡°ìš©í•˜ì§€ë§Œ ê°•í•˜ê²Œ ë§ˆìŒ ê±´ë“œë¦¬ëŠ” ì œëª©
â˜… ì‹œë‹ˆì–´ì˜ ê¸°ì–µ, ê³µê°, ê°ì •, ì”í–¥ ìê·¹

â–  ì œëª© íŒ¨í„´ 10ê°€ì§€ ì¤‘ 1ê°œ ì„ íƒ:

â‘  'ê·¸ ì‹œì ˆ' íšŒìƒí˜•
- "ê·¸ ì‹œì ˆ, ê²¨ìš¸ì´ë©´ ë“¤ë¦¬ë˜ ê·¸ ì†Œë¦¬"
- "ê·¸ë•Œ ìš°ë¦¬ ë™ë„¤ì—ëŠ” í•­ìƒ ì´ëŸ° í’ê²½ì´ ìˆì—ˆì£ "

â‘¡ 'í•œ ì¥ë©´' í¬ì°©í˜•
- "ë°¤ë§ˆë‹¤ ê³¨ëª©ì„ ë¹„ì¶”ë˜ ë…¸ë€ ê°€ë¡œë“± ì•„ë˜ì—ì„œ"
- "ì—°íƒ„ ì¬ ë‚ ë¦¬ë˜ ë¶€ì—Œ í•œì¼ ì˜ ë”°ëœ»í•¨"

â‘¢ 'ë³´ìë§ˆì ê³µê°ë˜ëŠ” ë¬¼ê±´/ì¥ì†Œ'
- "ìš”ì¦˜ ì•„ì´ë“¤ì€ ëª¨ë¥´ëŠ” ê·¸ êµ¬ë©ê°€ê²Œì˜ ëƒ„ìƒˆ"
- "ì‹œì¥ ì…êµ¬ì—ì„œ ë“¤ë¦¬ë˜ ì´ ì†Œë¦¬, ê¸°ì–µí•˜ì‹œë‚˜ìš”"

â‘£ 'ìš°ë¦¬ ì„¸ëŒ€ë§Œ ì•„ëŠ” ì€ê·¼í•œ í‘œí˜„'
- "ì°¸ ì†Œë°•í–ˆë˜ ê·¸ ì‹œì ˆ, ìš°ë¦¬ì˜ í•˜ë£¨"
- "ë§ˆìŒì´ ê´œíˆ ë”°ëœ»í•´ì§€ëŠ” ì˜›ë‚  ë™ë„¤ í’ê²½"

â‘¤ 'ê°ì • ìê·¹í˜•'
- "ë“¤ìœ¼ë©´ ê°€ë§Œíˆ ëˆˆë¬¼ì´ ë‚˜ëŠ” ê·¸ ì´ì•¼ê¸°"
- "ì˜¤ë˜ ë¬µí˜€ë‘” ê¸°ì–µì´ ìƒˆì–´ ë‚˜ì˜¤ëŠ” ë°¤"

â‘¥ 'ìƒí™© íšŒìƒí˜•'
- "ê²¨ìš¸ë§Œ ë˜ë©´ ì´ë ‡ê²Œ ëª¨ì—¬ ìˆì—ˆì£ "
- "ë¹„ ì˜¤ë˜ ë‚ , ë§ˆë£¨ ëì— ì•‰ì•„ ë°”ë¼ë³´ë˜ ê·¸ í’ê²½"

â‘¦ 'ì‚¬ë¼ì ¸ë²„ë¦° ê²ƒë“¤'
- "ì´ì œëŠ” ì–´ë””ì—ì„œë„ ë³¼ ìˆ˜ ì—†ëŠ” í’ê²½"
- "ì‚¬ë¼ì§„ ì¤„ë„ ëª°ëë˜ ê·¸ ì‹œì ˆì˜ í•˜ë£¨"

â‘§ 'ê·¸ë•Œì™€ ì§€ê¸ˆì„ ìì—° ë¹„êµ'
- "ê·¸ë•ŒëŠ” ë‹¹ì—°í–ˆë˜ ê²ƒë“¤, ì´ì œëŠ” ì¶”ì–µì´ ë˜ì—ˆìŠµë‹ˆë‹¤"
- "ì•„ë¬´ë ‡ì§€ ì•Šë˜ í‰ë²”í•œ ë‚ ë“¤ì´ ë” ê·¸ë¦¬ìš´ ìš”ì¦˜"

â‘¨ 'í•œ ë¬¸ì¥ ê°ì„±í˜•'
- "ê·¸ë‚ , ë°”ëŒ ëƒ„ìƒˆê¹Œì§€ ê¸°ì–µë‚©ë‹ˆë‹¤"
- "ì–´ì©Œë©´ ê°€ì¥ ë”°ëœ»í–ˆë˜ ì‹œê°„ë“¤"

â‘© 'ì‚¬ëŒ ì¤‘ì‹¬í˜•'
- "ì—„ë§ˆê°€ ë‚´ ì† ì¡ê³  ë‹¤ë‹ˆë˜ ê·¸ ì‹œì¥ ê¸¸"
- "ì•„ë²„ì§€ê°€ ëŠ˜ ì•‰ì•„ ê³„ì‹œë˜ ê³¨ëª© ì…êµ¬"

ã€ ì¸ë„¤ì¼ ë¬¸êµ¬ ê·œì¹™ ã€‘
â˜… 4~6ë‹¨ì–´ í•œêµ­ì–´ë§Œ
â˜… ë…¸ë€ìƒ‰/ê°ˆìƒ‰ ê°ì„±ì— ì–´ìš¸ë¦¬ëŠ” ë¬¸êµ¬
â˜… sceneì˜ í•µì‹¬ ìš”ì†Œ + ê°ì • ê²°í•©

ì˜ˆì‹œ:
- "ê·¸ ì‹œì ˆ ê·¸ ê³¨ëª©"
- "ë”°ëœ»í–ˆë˜ í•˜ë£¨"
- "ê¸°ì–µë‚˜ì‹œë‚˜ìš”?"
- "ê·¸ë•Œì˜ í’ê²½ë“¤"
- "ê·¸ ê²¨ìš¸, ìš°ë¦¬ ê³¨ëª©"
- "ì—„ë§ˆì™€ ì‹œì¥ê¸¸"

ã€ ì„¤ëª…ë¬¸ ê·œì¹™ ã€‘
â˜… ì§§ê³  ë”°ëœ»í•˜ê²Œ (3~7ì¤„)
â˜… ì‹œë‹ˆì–´ê°€ ì½ê¸° í¸í•œ ì§§ì€ ë¬¸ì¥
â˜… ê´‘ê³  ë¬¸êµ¬, ì™¸ë¶€ë§í¬ ì ˆëŒ€ ê¸ˆì§€
â˜… êµ¬ì¡°: ì˜ìƒ ë¶„ìœ„ê¸° ì†Œê°œ â†’ ê°ì • íšŒìƒ â†’ ê°ì‚¬ ì¸ì‚¬

í…œí”Œë¦¿ ì˜ˆì‹œ:
"ì˜¤ëŠ˜ì€ ê·¸ ì‹œì ˆ ìš°ë¦¬ê°€ í•¨ê»˜ ì§€ë‚˜ì™”ë˜ í’ê²½ì„ ì´ì•¼ê¸°í•©ë‹ˆë‹¤.
ë”°ëœ»í–ˆë˜ ë‚ ë“¤, ì‚¬ì†Œí•´ì„œ ìŠê³  ì§€ëƒˆë˜ ìˆœê°„ë“¤â€¦
ë‹¤ì‹œ ë– ì˜¬ë ¤ë³´ë©´ ì°¸ ì†Œì¤‘í–ˆë˜ ê¸°ì–µë“¤ì…ë‹ˆë‹¤.

í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ì²œì²œíˆ ë“¤ì–´ì£¼ì„¸ìš”.
í˜¹ì‹œ ì˜ìƒ ì† ì¥ë©´ì´ ë§ˆìŒì— ë‹¿ìœ¼ì…¨ë‹¤ë©´
ëŒ“ê¸€ë¡œ ê·¸ ì‹œì ˆì˜ ì´ì•¼ê¸°ë„ ë“¤ë ¤ì£¼ì„¸ìš”.

ì‹œì²­í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤."

ã€ íƒœê·¸ ê·œì¹™ ã€‘
â˜… í•„ìˆ˜ ê¸°ë³¸ íƒœê·¸:
ì˜›ë‚ ì´ì•¼ê¸°, ê·¸ì‹œì ˆ, í–¥ìˆ˜, ì‹œë‹ˆì–´ìœ íŠœë¸Œ, ê°ì„±ì‚¬ìš´ë“œ, íšŒìƒ, ì¶”ì–µ, 70ë…„ëŒ€, 80ë…„ëŒ€, ì˜›í’ê²½, í¸ì•ˆí•œì˜ìƒ, ë¼ë””ì˜¤ê°™ì€ì˜ìƒ

â˜… ì‹œë‹ˆì–´ ê²€ìƒ‰ íŒ¨í„´ íƒœê·¸:
ê·¸ë•Œê·¸ì‹œì ˆ, ì˜›ë‚ ì´ì•¼ê¸°ë“£ê¸°, ì‹œë‹ˆì–´íë§ì˜ìƒ, ì˜›ë‚ ê°ì„±

â˜… ëŒ€ë³¸ ë‚´ìš© ê¸°ë°˜ ë§ì¶¤ íƒœê·¸ 3~5ê°œ ì¶”ê°€"""

    user_prompt = f"ë‹¤ìŒ ì‹œë‹ˆì–´ í–¥ìˆ˜ ì½˜í…ì¸  ëŒ€ë³¸ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:\n\n{script_preview}"

    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=600
        )

        result_text = response.choices[0].message.content.strip()

        import re
        json_match = re.search(r'\{[\s\S]*\}', result_text)
        if json_match:
            metadata = json.loads(json_match.group())
            # í•„ìˆ˜ íƒœê·¸ ë³´ì¥
            required_tags = ["ì˜›ë‚ ì´ì•¼ê¸°", "ê·¸ì‹œì ˆ", "í–¥ìˆ˜", "ì‹œë‹ˆì–´ìœ íŠœë¸Œ", "ì¶”ì–µ", "íšŒìƒ", "70ë…„ëŒ€", "80ë…„ëŒ€", "ì˜›í’ê²½", "í¸ì•ˆí•œì˜ìƒ"]
            existing_tags = set(metadata.get("tags", []))
            for tag in required_tags:
                if tag not in existing_tags:
                    metadata["tags"].append(tag)

            return jsonify({
                "ok": True,
                "metadata": metadata,
                "channelType": "senior-nostalgia",
                "usage": {
                    "input_tokens": response.usage.prompt_tokens,
                    "output_tokens": response.usage.completion_tokens
                }
            })
        else:
            return jsonify({"ok": False, "error": "ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨", "raw": result_text})
    except Exception as e:
        print(f"[METADATA-NOSTALGIA] ì˜¤ë¥˜: {e}")
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/drama/generate-metadata', methods=['POST'])
def api_generate_metadata():
    """ëŒ€ë³¸ì—ì„œ YouTube ë©”íƒ€ë°ì´í„° ìë™ ìƒì„± (ì œëª©, ì„¤ëª…, íƒœê·¸)"""
    try:
        data = request.get_json()
        script = data.get('script', '')
        content_type = data.get('contentType', 'testimony')
        channel_type = data.get('channelType', 'default')  # 'default', 'senior-nostalgia'

        if not script:
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

        # ëŒ€ë³¸ ì•ë¶€ë¶„ë§Œ ì‚¬ìš© (í† í° ì ˆì•½)
        script_preview = script[:2000] if len(script) > 2000 else script

        # â­ ì‹œë‹ˆì–´ í–¥ìˆ˜ ì±„ë„ ì „ìš© ë©”íƒ€ë°ì´í„° ìƒì„±
        if channel_type == "senior-nostalgia" or content_type == "nostalgia":
            return _generate_senior_nostalgia_metadata(script_preview)

        content_type_name = "ê°„ì¦" if content_type == "testimony" else "ë“œë¼ë§ˆ"

        # â­ contentTypeì— ë”°ë¥¸ ë™ì  íƒœê·¸ ë° ì˜ˆì‹œ ì„¤ì •
        if content_type == "testimony":
            title_tag = "[ì‹ ì•™ê°„ì¦]"
            title_examples = '''- "[ì‹ ì•™ê°„ì¦] ì‹œí•œë¶€ 3ê°œì›”, ì£½ìŒì˜ ë¬¸í„±ì—ì„œ ì‚´ë ¤ì£¼ì‹  í•˜ë‚˜ë‹˜ | ê¿ˆì—ì„œ ë§Œë‚œ ì£¼ë‹˜, ê·¸ë¦¬ê³  ê¸°ì "
- "[ì‹ ì•™ê°„ì¦] êµíšŒ ê°œì²™ 5ë²ˆì´ë‚˜ ë§‰ìœ¼ì‹  í•˜ë‚˜ë‹˜ì˜ ì§„ì§œ ì´ìœ  | ë§‰íŒ ê¸¸ ë’¤ì— ì—´ë¦° ê¸°ì "
- "[ì‹ ì•™ê°„ì¦] ì™œ ì˜ ì‚¬ëŠ” ì‚¬ëŒë“¤ì˜ ê¸°ë„ë§Œ ë¹¨ë¦¬ ì‘ë‹µë ê¹Œìš”? | í•˜ë‚˜ë‹˜ì„ ë¯¿ì–´ë„ ì—¬ì „íˆ í˜ë“  ë¶„ë“¤ì—ê²Œ..."
- "[ì‹ ì•™ê°„ì¦] ìƒˆë²½ 2ì‹œ 30ë¶„ì˜ ì‹¬ë°© | ëŒ€ë¦¬ ìš´ì „ ì¤‘ ì¼ì–´ë‚œ ë†€ë¼ìš´ ê¸°ì "'''
        else:
            title_tag = ""  # ë“œë¼ë§ˆëŠ” íƒœê·¸ ì—†ì´ ì‹œì‘
            title_examples = '''- "1970ë…„ëŒ€ ì¶©ë¬´ë¡œ ì‚¬ì§„ê´€, ê·¸ ì‹œì ˆ ìš°ë¦¬ ê°€ì¡± ì´ì•¼ê¸° | ì•„ë²„ì§€ì˜ ì¹´ë©”ë¼ê°€ ë‹´ì€ ì¶”ì–µ"
- "78ì„¸ í• ë¨¸ë‹ˆì˜ ì²«ì‚¬ë‘ | 50ë…„ ë§Œì— ë‹¤ì‹œ ë§Œë‚œ ê·¸ ì‚¬ëŒ"
- "ì‹œê³¨ ë§ˆì„ì—ì„œ í¼ì³ì§„ ì‘ì€ ê¸°ì  | ì´ì›ƒì˜ ë”°ëœ»í•œ ì†ê¸¸"
- "6.25 ì „ìŸ ì† ìš°ë¦¬ ê°€ì¡± | ì•„ë²„ì§€ê°€ ë‚¨ê¸°ì‹  ë§ˆì§€ë§‰ í¸ì§€"'''

        system_prompt = f"""ë‹¹ì‹ ì€ YouTube ì½˜í…ì¸  ë©”íƒ€ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ì£¼ì–´ì§„ {content_type_name} ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ YouTube ì—…ë¡œë“œìš© ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”.

ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "title": "{title_tag + ' ' if title_tag else ''}ì‹œì²­ìì˜ í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ëŠ” ì œëª© (60ì ì´ë‚´)",
  "thumbnailTitle": "ì¸ë„¤ì¼ìš© ì œëª© (3~4ì¤„, ì¤„ë°”ê¿ˆìœ¼ë¡œ êµ¬ë¶„)",
  "description": "ì˜ìƒ ì„¤ëª… (ìŠ¤í† ë¦¬í˜• êµ¬ì¡°)",
  "tags": ["íƒœê·¸1", "íƒœê·¸2", "íƒœê·¸3", ...] (10-15ê°œ)
}}

ã€ ì œëª© ì‘ì„± ê°€ì´ë“œ - ê³ ì„±ê³¼ íŒ¨í„´ ã€‘
{f'â˜… í•„ìˆ˜: {title_tag} íƒœê·¸ë¡œ ì‹œì‘' if title_tag else 'â˜… íƒœê·¸ ì—†ì´ ë°”ë¡œ ì œëª©ìœ¼ë¡œ ì‹œì‘'}

â–  íŒ¨í„´ A: ì§ˆë¬¸í˜• í›„í‚¹
- "ì™œ ì˜ ì‚¬ëŠ” ì‚¬ëŒë“¤ì˜ ê¸°ë„ë§Œ ë¹¨ë¦¬ ì‘ë‹µë ê¹Œìš”?"
- "ì™œ ë‚˜ë§Œ ì´ë ‡ê²Œ í˜ë“¤ê¹Œ?" í•˜ê³  ì¢Œì ˆí•˜ì‹œëŠ” ë¶„
- "ê·¸ë•Œ ê·¸ ìˆœê°„, ë¬´ìŠ¨ ì¼ì´ ìˆì—ˆì„ê¹Œìš”?"

â–  íŒ¨í„´ B: ì„œì‚¬í˜• ëŒ€ë¹„ - ì¡°íšŒìˆ˜ ë†’ìŒ
- "í™”ë ¤í•œ ì‹œì ˆì—ì„œ ì«“ê²¨ë‚˜ ë‹¤ì‹œ ì‹œì‘í•œ ì´ì•¼ê¸°"
- Before(ê³ ë‚œ/ê³¼ê±°) â†’ After(ê·¹ë³µ/í˜„ì¬)ì˜ ê·¹ì  ëŒ€ë¹„

â–  í•„ìˆ˜ ìš”ì†Œ:
1. êµ¬ì²´ì  ìˆ«ì: "6ë…„ê°„", "3ê°œì›”", "5ë²ˆì´ë‚˜", "300ë§Œì›", "78ì„¸"
2. ì¸ë¬¼+êµ¬ì²´ì  ìƒí™©: "47ì„¸ ê±´ì„¤ í˜„ì¥ì†Œì¥", "í‰ìƒ ê¹Œë§‰ëˆˆìœ¼ë¡œ ì‚´ë‹¤"
3. ê°ì • í‚¤ì›Œë“œ: "ì²˜ì ˆí•œ", "ë§‰íŒ ê¸¸", "ê¸°ì ", "ë†€ë¼ìš´", "ê·¸ë¦¬ìš´"
4. | êµ¬ë¶„ìë¡œ ë¶€ì œëª© ì¶”ê°€: "| ê·¸ë•Œ ê·¸ ì‹œì ˆì˜ ì´ì•¼ê¸°"

â–  ì‹¤ì œ ê³ ì„±ê³¼ ì œëª© ì˜ˆì‹œ:
{title_examples}

ã€ ì¸ë„¤ì¼ ì œëª© ê°€ì´ë“œ ã€‘
- 3~4ì¤„ë¡œ ë‚˜ëˆ„ì–´ ì‘ì„± (ì¤„ë°”ê¿ˆ \\n ì‚¬ìš©)
- 1ì¤„: ì‹œê°„/ìˆ«ì + ìƒí™© í›… (ê·¹ì  ìƒí™©)
- 2ì¤„: í•µì‹¬ ì¸ë¬¼/ì‚¬ê±´ (êµ¬ì²´ì  ë¬˜ì‚¬)
- 3ì¤„: ê°ì • ê°•ì¡° (ìƒ‰ìƒ ê°•ì¡°ë  ë¶€ë¶„) - "ì²˜ì ˆí•œ", "ë§‰ë§‰í•œ", "ê¸°ì "
- 4ì¤„: ë°˜ì „/ê²°ê³¼ ë˜ëŠ” ê¶ê¸ˆì¦

ì˜ˆì‹œ:
"ì‹œí•œë¶€ 3ê°œì›”\\nì£½ìŒì˜ ë¬¸í„±ì—ì„œ\\nê¿ˆì—ì„œ ë§Œë‚œ ì£¼ë‹˜\\nê·¸ë¦¬ê³  ì¼ì–´ë‚œ ê¸°ì "
"ëŒ€í˜•êµíšŒì—ì„œ ì«“ê²¨ë‚˜\\nìƒê°€ 7ì¸µì—ì„œ ë‹¤ì‹œ ì‹œì‘\\në‹¨ 10ëª…ì˜ ì„±ë„\\ní•˜ë‚˜ë‹˜ì´ ì„¸ìš°ì‹  êµíšŒ"

ã€ ì„¤ëª… ì‘ì„± ê°€ì´ë“œ - ìŠ¤í† ë¦¬í˜• êµ¬ì¡° ã€‘
â–  êµ¬ì¡°:
1. ìŠ¤í† ë¦¬ ë„ì… (ì§§ì€ ë¬¸ì¥ìœ¼ë¡œ ìƒí™© ì„¤ì •)
2. ê°ˆë“±/ìœ„ê¸° ë¬˜ì‚¬ (êµ¬ì²´ì  ìˆ«ìì™€ ìƒí™©)
3. ê¶ê¸ˆì¦ ìœ ë°œ ì§ˆë¬¸ 2-3ê°œ
4. íƒ€ê²Ÿ ì‹œì²­ì ëª…ì‹œ
5. CTA (ëŒ“ê¸€, êµ¬ë…, ì¢‹ì•„ìš”)

â–  ì˜ˆì‹œ:
"47ì„¸ ê±´ì„¤ í˜„ì¥ì†Œì¥ ë°•ì§„ìˆ˜.
20ë…„ê°„ ì„±ì‹¤í•˜ê²Œ ì¼í•˜ë©° ê°€ì¡±ì„ ì±…ì„ì§€ë˜ í‰ë²”í•œ ê°€ì¥ì´ì—ˆìŠµë‹ˆë‹¤.

2023ë…„ ê°€ì„, ê°„ì•” ë§ê¸° ì§„ë‹¨.
ì´ë¯¸ íê¹Œì§€ ì „ì´ëœ 4ê¸° ì•”.
ì˜ì‚¬ëŠ” 3ê°œì›” ì‹œí•œë¶€ë¥¼ ì„ ê³ í–ˆìŠµë‹ˆë‹¤.

ì ˆë§ ì†ì—ì„œ ì²˜ìŒìœ¼ë¡œ í•˜ë‚˜ë‹˜ê»˜ ê°„ì ˆíˆ ë¶€ë¥´ì§–ì—ˆê³ ,
ê¿ˆì—ì„œ ì£¼ë‹˜ì„ ë§Œë‚¬ìŠµë‹ˆë‹¤.

ê³¼ì—° ê·¸ì—ê²Œ ë¬´ìŠ¨ ì¼ì´ ì¼ì–´ë‚¬ì„ê¹Œìš”?
ì˜ì‚¬ë“¤ë„ ë¯¿ì„ ìˆ˜ ì—†ì–´ í–ˆë˜ ê·¸ ê²°ê³¼ëŠ”?

ğŸ’¬ ì´ëŸ° ë¶„ë“¤ê»˜ ì¶”ì²œí•©ë‹ˆë‹¤:
âœ” ì˜¤ë«ë™ì•ˆ ê¸°ë„í•´ë„ ì‘ë‹µì´ ì—†ì–´ í˜ë“œì‹  ë¶„
âœ” 'ì™œ ë‚˜ë§Œ ì´ë ‡ê²Œ í˜ë“¤ê¹Œ?' í•˜ê³  ì¢Œì ˆí•˜ì‹œëŠ” ë¶„
âœ” ê°€ë‚œê³¼ ê³ í†µ ì†ì—ì„œ í•˜ë‚˜ë‹˜ì„ ì›ë§í•˜ê²Œ ë˜ì‹œëŠ” ë¶„

ğŸ™ ì˜ìƒì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ëŒ“ê¸€ë¡œ ì€í˜œë¥¼ ë‚˜ëˆ ì£¼ì„¸ìš”.
ğŸ“Œ êµ¬ë…ê³¼ ì¢‹ì•„ìš”, ì•Œë¦¼ ì„¤ì • ë¶€íƒë“œë¦½ë‹ˆë‹¤!"

ã€ íƒœê·¸ ê°€ì´ë“œ ã€‘
{f'í•„ìˆ˜ íƒœê·¸: #ì‹ ì•™ê°„ì¦ #ê¸°ë„ì‘ë‹µ #ì€í˜œê°„ì¦ #ê°ë™ê°„ì¦ #êµíšŒì´ì•¼ê¸°' if content_type == 'testimony' else 'í•„ìˆ˜ íƒœê·¸: #ê°ë™ì˜ìƒ #íë§ #ì¶”ì–µ #ê°€ì¡±ì´ì•¼ê¸° #ì¸ìƒë“œë¼ë§ˆ'}
{f'ìƒí™©ë³„ íƒœê·¸: #ëª©íšŒìê°„ì¦ #ì•”íˆ¬ë³‘ #ê¸°ì  #í•˜ë‚˜ë‹˜ì˜ì¸ë„í•˜ì‹¬ #ìƒˆë²½ê¸°ë„ #ê¸ˆì‹ê¸°ë„' if content_type == 'testimony' else 'ìƒí™©ë³„ íƒœê·¸: #ê·¸ì‹œì ˆ #70ë…„ëŒ€ #80ë…„ëŒ€ #ë ˆíŠ¸ë¡œ #ë¹ˆí‹°ì§€ #ì˜›ë‚ ì´ì•¼ê¸°'}
{f'ê°ì • íƒœê·¸: #í¬ë§ì´ì•¼ê¸° #ìœ„ë¡œ #êµ¬ì› #íšŒê°œ' if content_type == 'testimony' else 'ê°ì • íƒœê·¸: #í¬ë§ì´ì•¼ê¸° #ìœ„ë¡œ #ê·¸ë¦¬ì›€ #ê°ë™'}"""

        user_prompt = f"ë‹¤ìŒ {content_type_name} ëŒ€ë³¸ì˜ ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•˜ì„¸ìš”:\n\n{script_preview}"

        response = client.chat.completions.create(
            model="gpt-4o",  # gpt-4o ì‚¬ìš© (ì œëª©, ì„¤ëª…, íƒœê·¸ í’ˆì§ˆ í–¥ìƒ)
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹± ì‹œë„
        import re
        json_match = re.search(r'\{[\s\S]*\}', result_text)
        if json_match:
            metadata = json.loads(json_match.group())
            return jsonify({
                "ok": True,
                "metadata": metadata,
                "usage": {
                    "input_tokens": response.usage.prompt_tokens,
                    "output_tokens": response.usage.completion_tokens
                }
            })
        else:
            return jsonify({"ok": False, "error": "ë©”íƒ€ë°ì´í„° íŒŒì‹± ì‹¤íŒ¨", "raw": result_text})

    except json.JSONDecodeError as e:
        return jsonify({"ok": False, "error": f"JSON íŒŒì‹± ì˜¤ë¥˜: {str(e)}"})
    except Exception as e:
        print(f"[METADATA] ì˜¤ë¥˜: {e}")
        return jsonify({"ok": False, "error": str(e)})

@app.route('/api/drama/step3-test', methods=['GET'])
def api_drama_step3_test():
    """Step3 í…ŒìŠ¤íŠ¸ ì—”ë“œí¬ì¸íŠ¸"""
    return jsonify({
        "ok": True,
        "openrouter_configured": openrouter_client is not None,
        "message": "Step3 endpoint is reachable"
    })


@app.route('/api/drama/claude-step3', methods=['POST'])
def api_drama_claude_step3():
    """Step3: OpenRouterë¥¼ í†µí•œ ë“œë¼ë§ˆ ëŒ€ë³¸ ì™„ì„±"""
    try:
        print("[DRAMA-STEP3] ìš”ì²­ ë°›ìŒ")

        if not openrouter_client:
            print("[DRAMA-STEP3] OpenRouter í´ë¼ì´ì–¸íŠ¸ ì—†ìŒ")
            return jsonify({"ok": False, "error": "OpenRouter API key not configured. Render í™˜ê²½ë³€ìˆ˜ì— OPENROUTER_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."}), 200

        data = request.get_json()
        if not data:
            print("[DRAMA-STEP3] ë°ì´í„° ì—†ìŒ")
            return jsonify({"ok": False, "error": "No data received"}), 200

        category = data.get("category", "")
        video_category = data.get("videoCategory", "ê°„ì¦")  # ì˜ìƒ ì¹´í…Œê³ ë¦¬ (ê°„ì¦, ë“œë¼ë§ˆ, ëª…ì–¸, ë§ˆìŒ, ì² í•™, ì¸ê°„ê´€ê³„)
        custom_directive = data.get("customDirective", "")  # ì‚¬ìš©ì ì§€ì¹¨ (ì„ íƒ) - ìµœìš°ì„  ë°˜ì˜
        style_name = data.get("styleName", "")
        style_description = data.get("styleDescription", "")
        draft_content = data.get("draftContent", "")
        main_character = data.get("mainCharacter", {})
        benchmark_script = data.get("benchmarkScript", "")
        ai_analysis = data.get("aiAnalysis", "")
        step3_guide = data.get("step3Guide", "")
        selected_model = data.get("model", "anthropic/claude-sonnet-4.5")
        content_type = data.get("contentType", "testimony")  # ì½˜í…ì¸  ìœ í˜• (testimony/drama)
        content_type_prompt = data.get("contentTypePrompt", {})  # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë³´ë‚¸ í”„ë¡¬í”„íŠ¸
        duration_text = (data.get("durationText") or "").strip()
        auto_story_mode = bool(data.get("autoStoryMode", False))
        custom_json_guide_str = data.get("customJsonGuide", "")  # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë³´ë‚¸ ì»¤ìŠ¤í…€ JSON ì§€ì¹¨
        test_mode = bool(data.get("testMode", False))  # ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ (ë¹„ìš© ìµœì†Œí™”)

        # ì»¤ìŠ¤í…€ JSON ì§€ì¹¨ íŒŒì‹±
        custom_json_guide = None
        if custom_json_guide_str:
            try:
                custom_json_guide = json.loads(custom_json_guide_str)
                print(f"[DRAMA-STEP3] ì»¤ìŠ¤í…€ JSON ì§€ì¹¨ ì‚¬ìš© (v{custom_json_guide.get('version', '?')})")
            except json.JSONDecodeError as e:
                print(f"[DRAMA-STEP3] ì»¤ìŠ¤í…€ JSON íŒŒì‹± ì‹¤íŒ¨: {e}, ì„œë²„ ê¸°ë³¸ ì§€ì¹¨ ì‚¬ìš©")

        effective_category = duration_text or category
        if effective_category:
            category = effective_category

        print(f"[DRAMA-STEP3-OPENROUTER] ì²˜ë¦¬ ì‹œì‘ - ì‹œê°„: {category}, ì˜ìƒì¹´í…Œê³ ë¦¬: {video_category}, ì§€ì¹¨: {custom_directive or '(ì—†ìŒ)'}, ëª¨ë¸: {selected_model}, í…ŒìŠ¤íŠ¸ëª¨ë“œ: {test_mode}")
        print(f"[DRAMA-STEP3-DEBUG] step3_guide ê¸¸ì´: {len(step3_guide)}, ë‚´ìš©: {step3_guide[:100] if step3_guide else '(ì—†ìŒ)'}...")
        print(f"[DRAMA-STEP3-DEBUG] draft_content ê¸¸ì´: {len(draft_content)}, ë‚´ìš©: {draft_content[:300] if draft_content else '(ì—†ìŒ)'}...")

        # ì½˜í…ì¸  ìœ í˜•ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ê²°ì •
        # video_categoryì— ë”°ë¼ ë‹¤ë¥¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        user_prompt_suffix = ""

        # ì˜ìƒ ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ë§¤í•‘
        video_category_prompts = {
            "ëª…ì–¸": """ë‹¹ì‹ ì€ ê¹Šì€ ìš¸ë¦¼ì„ ì£¼ëŠ” ëª…ì–¸ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ ëª…ì–¸ ì½˜í…ì¸ ì˜ í•µì‹¬ ã€‘
ì‚¶ì˜ ì§€í˜œì™€ í†µì°°ì„ ë‹´ì€ ëª…ì–¸ì„ ì¤‘ì‹¬ìœ¼ë¡œ, ì‹œì²­ìì—ê²Œ ìƒê°í•  ê±°ë¦¬ì™€ ì˜ê°ì„ ì£¼ëŠ” ì½˜í…ì¸ ì…ë‹ˆë‹¤.

ã€ í•„ìˆ˜ ìš”ì†Œ ã€‘
1. ëª…ì–¸ì˜ ì˜ë¯¸ë¥¼ ì‹¤ìƒí™œ ì‚¬ë¡€ë¡œ í’€ì–´ì„œ ì„¤ëª…
2. 1ì¸ì¹­ ì„œìˆ ë¡œ ê°œì¸ì  ê²½í—˜ê³¼ ì—°ê²°
3. ì§§ì€ ë¬¸ì¥ê³¼ ê°•ë ¬í•œ ë©”ì‹œì§€
4. ì‹œì²­ìê°€ ê³µê°í•  ìˆ˜ ìˆëŠ” ë³´í¸ì  ì£¼ì œ

ã€ ê¸ˆì§€ ì‚¬í•­ ã€‘
- ì¶”ìƒì ì´ê³  ëª¨í˜¸í•œ í‘œí˜„
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€""",
            "ë§ˆìŒ": """ë‹¹ì‹ ì€ ë§ˆìŒ ì¹˜ìœ  ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ ë§ˆìŒ ì½˜í…ì¸ ì˜ í•µì‹¬ ã€‘
ì§€ì¹œ ë§ˆìŒì„ ìœ„ë¡œí•˜ê³  ì¹˜ìœ í•˜ëŠ” ê°ì„±ì ì¸ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ì‹œì²­ìê°€ "ë‚˜ë„ ê·¸ë¬ì–´"ë¼ê³  ê³µê°í•˜ë©° ìœ„ì•ˆì„ ë°›ì„ ìˆ˜ ìˆì–´ì•¼ í•©ë‹ˆë‹¤.

ã€ í•„ìˆ˜ ìš”ì†Œ ã€‘
1. ë¶€ë“œëŸ½ê³  ë”°ëœ»í•œ ì–´ì¡°
2. ê°ì •ì˜ êµ¬ì²´ì  ë¬˜ì‚¬
3. í¬ë§ê³¼ ì¹˜ìœ ì˜ ë©”ì‹œì§€
4. ê³µê°ì„ ì´ëŒì–´ë‚´ëŠ” ì¼ìƒ ì†Œì¬

ã€ ê¸ˆì§€ ì‚¬í•­ ã€‘
- ì„¤êµí•˜ê±°ë‚˜ ê°€ë¥´ì¹˜ë ¤ëŠ” í†¤
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€""",
            "ì² í•™": """ë‹¹ì‹ ì€ ì² í•™ì  ì‚¬ìœ  ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ ì² í•™ ì½˜í…ì¸ ì˜ í•µì‹¬ ã€‘
ì¸ìƒ, ì¡´ì¬, ì˜ë¯¸ì— ëŒ€í•œ ê¹Šì€ ì„±ì°°ì„ ë‹´ì€ ì½˜í…ì¸ ì…ë‹ˆë‹¤. ì‹œì²­ìê°€ ìƒê°ì— ì ê¸°ê²Œ ë§Œë“œëŠ” ì§ˆë¬¸ì„ ë˜ì§‘ë‹ˆë‹¤.

ã€ í•„ìˆ˜ ìš”ì†Œ ã€‘
1. ê¹Šì´ ìˆëŠ” ì§ˆë¬¸ ì œì‹œ
2. ì¼ìƒì—ì„œ ì² í•™ì  ì˜ë¯¸ ë°œê²¬
3. ë‹¤ì–‘í•œ ê´€ì  ì œì‹œ
4. ì—´ë¦° ê²°ë§ë¡œ ì‚¬ìœ  ìœ ë„

ã€ ê¸ˆì§€ ì‚¬í•­ ã€‘
- ë„ˆë¬´ ì–´ë ¤ìš´ ì² í•™ ìš©ì–´
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€""",
            "ì¸ê°„ê´€ê³„": """ë‹¹ì‹ ì€ ì¸ê°„ê´€ê³„ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ ì¸ê°„ê´€ê³„ ì½˜í…ì¸ ì˜ í•µì‹¬ ã€‘
ê°€ì¡±, ì¹œêµ¬, ì—°ì¸, ë™ë£Œ ë“± ë‹¤ì–‘í•œ ê´€ê³„ì—ì„œ ì¼ì–´ë‚˜ëŠ” ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ê´€ê³„ì˜ ì†Œì¤‘í•¨ê³¼ ì–´ë ¤ì›€ì„ í•¨ê»˜ ë‹¤ë£¹ë‹ˆë‹¤.

ã€ í•„ìˆ˜ ìš”ì†Œ ã€‘
1. êµ¬ì²´ì ì¸ ê´€ê³„ ìƒí™© ë¬˜ì‚¬
2. ê°ˆë“±ê³¼ í™”í•´ì˜ ê³¼ì •
3. ëŒ€í™”ë¥¼ í†µí•œ ê°ì • ì „ë‹¬
4. ê´€ê³„ ì† ì„±ì¥ ì´ì•¼ê¸°

ã€ ê¸ˆì§€ ì‚¬í•­ ã€‘
- ì¼ë°©ì ì¸ ì¡°ì–¸ì´ë‚˜ í›ˆê³„
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€""",

            # ===== ì‹œë‹ˆì–´ íƒ€ê²Ÿ ì‹ ê·œ ì¹´í…Œê³ ë¦¬ =====
            "ì˜›ë‚ ì´ì•¼ê¸°": """ë‹¹ì‹ ì€ ì‹œë‹ˆì–´ë¥¼ ìœ„í•œ í–¥ìˆ˜ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ëŒ€ë³¸ì„ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ì˜›ë‚ ì´ì•¼ê¸° ëŒ€ë³¸ ì‘ì„± í•µì‹¬ ì›ì¹™ ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. í™”ì: 60-70ëŒ€ ì–´ë¥´ì‹ ì´ íšŒìƒí•˜ë©° ë“¤ë ¤ì£¼ëŠ” í˜•ì‹
   - "ê·¸ë•ŒëŠ” ë§ì´ì•¼...", "ì§€ê¸ˆ ì Šì€ ì‚¬ëŒë“¤ì€ ëª¨ë¥´ê² ì§€ë§Œ..."
   - ì¹œê·¼í•˜ê³  ë”°ëœ»í•œ ë§íˆ¬ (êµ¬ì–´ì²´)

2. ì‹œëŒ€ ê³ ì¦:
   - 1960s-1980s í•œêµ­ì˜ ì‹¤ì œ ëª¨ìŠµ
   - ë‹¹ì‹œ ë¬¼ê°€, í’ìŠµ, ìƒí™œìš©í’ˆ ì •í™•íˆ
   - ì§€ì—­ë³„ íŠ¹ìƒ‰ (ì„œìš¸, ë¶€ì‚°, ì‹œê³¨ ë“±)

3. ì˜¤ê° ë¬˜ì‚¬ í•„ìˆ˜:
   - ì†Œë¦¬: ìƒˆë§ˆì„í˜¸ ê¸°ì ì†Œë¦¬, ë‘ë¶€ì¥ìˆ˜ ì¢…ì†Œë¦¬
   - ëƒ„ìƒˆ: ì—°íƒ„ ëƒ„ìƒˆ, ì–´ë¨¸ë‹ˆ ëœì¥êµ­ ëƒ„ìƒˆ
   - ì´‰ê°: í•œì—¬ë¦„ ë©ì„ ìœ„, ê²¨ìš¸ í™”ë¡¯ë¶ˆ ì˜¨ê¸°
   - ì‹œê°: í‘ë°±TV, ë‹¬ë™ë„¤ ê³¨ëª©
   - ë§›: ì«€ë“œê¸°, ì•„ì´ìŠ¤ê»˜ë¼, êµ°ê³ êµ¬ë§ˆ

4. ê°ì • ê³¡ì„ :
   - ì‹œì‘: í˜¸ê¸°ì‹¬/ê·¸ë¦¬ì›€ ìœ ë°œ (ê°•ë ¬í•œ í›„í‚¹)
   - ì¤‘ë°˜: êµ¬ì²´ì  ì¶”ì–µìœ¼ë¡œ ëª°ì…
   - ë: ë”°ëœ»í•œ ì—¬ìš´ + ê¸ì • ë§ˆë¬´ë¦¬

5. ê¸ˆì§€:
   - ì •ì¹˜ì  ë‚´ìš©
   - ì„¸ëŒ€ ë¹„í•˜/ê°ˆë“± ì¡°ì¥
   - ìš°ìš¸í•˜ê±°ë‚˜ ë¹„ê´€ì  ê²°ë§
   - ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€

ã€ í›„í‚¹ ì˜ˆì‹œ ã€‘
- "í˜¹ì‹œ ê¸°ì–µí•˜ì‹œë‚˜ìš”? ìƒˆë²½ ë‹¤ì„¯ ì‹œ, ì—°íƒ„ ê°€ìŠ¤ ëƒ„ìƒˆì— ì ì´ ê¹¨ë˜ ê·¸ ì‹œì ˆ..."
- "ì§€ê¸ˆ ì Šì€ ì‚¬ëŒë“¤ì€ ëª¨ë¥´ê² ì§€ë§Œ, ìš°ë¦¬ëŠ” ì „í™”ê¸° í•œ ëŒ€ì— ì˜¨ ë™ë„¤ê°€ ëª¨ì—¬ë“¤ì—ˆìŠµë‹ˆë‹¤."
- "ì¹ ì‹­ ë…„ëŒ€ ì—¬ë¦„, ì„ í’ê¸°ë„ ê·€í•˜ë˜ ì‹œì ˆ. ìš°ë¦¬ëŠ” ì–´ë–»ê²Œ ë”ìœ„ë¥¼ ì´ê²¼ì„ê¹Œìš”?"

ã€ ì¶œë ¥ í˜•ì‹ ã€‘
ë°˜ë“œì‹œ JSONìœ¼ë¡œ ì¶œë ¥. metadata, highlight, script, closing êµ¬ì¡° ì¤€ìˆ˜.""",

            "ë§ˆìŒìœ„ë¡œ": """ë‹¹ì‹ ì€ ì ë“¤ê¸° ì „ ë§ˆìŒ ìœ„ë¡œ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ëŒ€ë³¸ì„ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ë§ˆìŒìœ„ë¡œ ëŒ€ë³¸ ì‘ì„± í•µì‹¬ ì›ì¹™ ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. í™”ì: ì¹œê·¼í•œ ì´ì›ƒ ì–´ë¥´ì‹ ì´ ë”°ëœ»í•˜ê²Œ ë§í•´ì£¼ëŠ” í˜•ì‹
   - ë¶€ë“œëŸ½ê³  ì°¨ë¶„í•œ ì–´ì¡°
   - "ê´œì°®ì•„ìš”", "ìˆ˜ê³ í–ˆì–´ìš”" ê°™ì€ ìœ„ë¡œì˜ ë§

2. ëª©ì : ì ë“¤ê¸° ì „ í¸ì•ˆí•¨ ì œê³µ
   - ASMR ëŠë‚Œì˜ ì°¨ë¶„í•œ ë‚˜ë ˆì´ì…˜
   - ê¸´ì¥ì„ í’€ì–´ì£¼ëŠ” ë‚´ìš©
   - ë‚´ì¼ì— ëŒ€í•œ í¬ë§

3. êµ¬ì„±:
   - ì‹œì‘: ë¶€ë“œëŸ¬ìš´ ì¸ì‚¬ì™€ ê³µê°
   - ì¤‘ë°˜: ìœ„ë¡œê°€ ë˜ëŠ” ì´ì•¼ê¸°/ìƒê°
   - ë: í‰ì•ˆí•œ ì ìë¦¬ ê¸°ì›

4. ê°ì •:
   - ë”°ëœ»í•¨, í‰ì˜¨í•¨, ì•ˆì •ê°
   - ì‹œì²­ìë¥¼ íŒë‹¨í•˜ì§€ ì•ŠìŒ
   - ìˆëŠ” ê·¸ëŒ€ë¡œ ì¸ì •

5. ê¸ˆì§€:
   - ìê·¹ì ì´ê±°ë‚˜ ê¸´ì¥ë˜ëŠ” ë‚´ìš©
   - ìŠ¬í”„ê±°ë‚˜ ìš°ìš¸í•œ ê²°ë§
   - ë¹ ë¥¸ ì „ê°œ
   - ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€""",

            "ì¸ìƒëª…ì–¸": """ë‹¹ì‹ ì€ ì¸ìƒ ì§€í˜œì™€ ëª…ì–¸ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ë°˜ë“œì‹œ JSON í˜•ì‹ìœ¼ë¡œ ëŒ€ë³¸ì„ ì¶œë ¥í•´ì•¼ í•©ë‹ˆë‹¤.

â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
ã€ ì¸ìƒëª…ì–¸ ëŒ€ë³¸ ì‘ì„± í•µì‹¬ ì›ì¹™ ã€‘
â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

1. í™”ì: ì¸ìƒ ê²½í—˜ ë§ì€ ì–´ë¥´ì‹ ì´ ì§€í˜œë¥¼ ë‚˜ëˆ„ëŠ” í˜•ì‹
   - "ì‚´ë‹¤ ë³´ë‹ˆ ì´ëŸ° ê±¸ ì•Œê²Œ ëì–´ìš”"
   - ì„¤êµê°€ ì•„ë‹Œ ë‚˜ëˆ”ì˜ í†¤

2. ëª…ì–¸ í™œìš©:
   - ìœ ëª… ëª…ì–¸ + ê°œì¸ì  í•´ì„
   - ë˜ëŠ” ì‚¶ì—ì„œ ê¹¨ë‹¬ì€ ë‚˜ë§Œì˜ ëª…ì–¸
   - ì¶”ìƒì ì´ì§€ ì•Šê³  êµ¬ì²´ì  ì‚¬ë¡€ì™€ í•¨ê»˜

3. êµ¬ì„±:
   - ì‹œì‘: ê³µê°ë˜ëŠ” ìƒí™© ì œì‹œ
   - ì¤‘ë°˜: ëª…ì–¸/ì§€í˜œ ì†Œê°œ + ì‹¤ì œ ì‚¬ë¡€
   - ë: ì‹œì²­ìì—ê²Œ ì ìš©í•  ìˆ˜ ìˆëŠ” ë©”ì‹œì§€

4. ëª…ì–¸ ì¶œì²˜ ì˜ˆì‹œ:
   - ë™ì–‘ ê³ ì „ (ë…¼ì–´, ë„ë•ê²½, ëª…ì‹¬ë³´ê°)
   - ì„œì–‘ ì² í•™ì (ì†Œí¬ë¼í…ŒìŠ¤, ë‹ˆì²´, ì‡¼íœí•˜ìš°ì–´)
   - í•œêµ­ ì†ë‹´, ì–´ë¥´ì‹  ë§ì”€
   - ì‹œì²­ì ìŠ¤ìŠ¤ë¡œ ê¹¨ë‹¬ì„ ìˆ˜ ìˆê²Œ ìœ ë„

5. ê¸ˆì§€:
   - ë„ˆë¬´ ì–´ë ¤ìš´ ì² í•™ ìš©ì–´
   - ì¼ë°©ì  ì„¤êµ/í›ˆê³„
   - íŠ¹ì • ì¢…êµ ê°•ìš”
   - ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€"""
        }

        # video_categoryê°€ íŠ¹ë³„í•œ ì¹´í…Œê³ ë¦¬ë©´ í•´ë‹¹ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
        if video_category in video_category_prompts:
            system_content = video_category_prompts[video_category]
            print(f"[DRAMA-STEP3] ì˜ìƒì¹´í…Œê³ ë¦¬ '{video_category}' ì „ìš© í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
        elif video_category == "ê°„ì¦" or content_type == "testimony":
            # categoryì—ì„œ duration_minutes ì¶”ì¶œ (ì˜ˆ: "10min" -> 10, "20min" -> 20)
            duration_minutes = 20  # ê¸°ë³¸ê°’
            if category:
                duration_match = re.search(r'(\d+)', category)
                if duration_match:
                    duration_minutes = int(duration_match.group(1))

            # JSON ìŠ¤íƒ€ì¼ ê°€ì´ë“œì—ì„œ í”„ë¡¬í”„íŠ¸ êµ¬ì¶• (ì»¤ìŠ¤í…€ ê°€ì´ë“œ ìš°ì„  ì‚¬ìš©)
            guide_system, guide_suffix = build_testimony_prompt_from_guide(custom_json_guide, duration_minutes, test_mode)
            if guide_system:
                system_content = guide_system
                user_prompt_suffix = guide_suffix or ""
                guide_version = custom_json_guide.get('version', '?') if custom_json_guide else load_drama_guidelines().get('version', '?')
                guide_source = "ì»¤ìŠ¤í…€" if custom_json_guide else "ì„œë²„"
                print(f"[DRAMA-STEP3] {guide_source} JSON ìŠ¤íƒ€ì¼ ê°€ì´ë“œ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (v{guide_version})")
            else:
                # JSON ë¡œë“œ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ (í´ë°±)
                print(f"[DRAMA-STEP3] JSON ë¡œë“œ ì‹¤íŒ¨, ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©")
                system_content = """ë‹¹ì‹ ì€ ê°ë™ì ì¸ ê°„ì¦ ì½˜í…ì¸  ì „ë¬¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ ê°„ì¦ ì½˜í…ì¸ ì˜ í•µì‹¬ ã€‘
ê°„ì¦ì€ ì‹¤ì œ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì´ì•¼ê¸°ì…ë‹ˆë‹¤. ì‹œì²­ìê°€ "ì´ê±´ ì§„ì§œ ì´ì•¼ê¸°êµ¬ë‚˜"ë¼ê³  ëŠë¼ë„ë¡ ìƒìƒí•˜ê³  êµ¬ì²´ì ìœ¼ë¡œ ì‘ì„±í•´ì•¼ í•©ë‹ˆë‹¤.

ã€ í•„ìˆ˜ ìš”ì†Œ ã€‘
1. ë°˜ë“œì‹œ 1ì¸ì¹­ ì„œìˆ  ("ì €ëŠ”", "ì œê°€") - ì ˆëŒ€ 3ì¸ì¹­ ê¸ˆì§€
2. ì´ 15,000ì ì´ìƒ ë¶„ëŸ‰
3. êµ¬ì²´ì  ì´ë¦„ 5ê°œ, ìˆ«ì 10ê°œ, ì¥ì†Œ 3ê°œ ì´ìƒ
4. ì§ì ‘ ëŒ€í™” 30% í¬í•¨
5. ê°€ì¡± ë°˜ì‘ í•„ìˆ˜ í¬í•¨

ã€ ê¸ˆì§€ ì‚¬í•­ ã€‘
- 3ì¸ì¹­ ì„œìˆ  (ê·¸ëŠ”, ê·¸ë…€ëŠ”) ì ˆëŒ€ ê¸ˆì§€
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€
- ì§§ì€ ë¶„ëŸ‰"""
        elif content_type_prompt and content_type_prompt.get("systemPrompt"):
            # í´ë¼ì´ì–¸íŠ¸ì—ì„œ ë³´ë‚¸ ì½˜í…ì¸  ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            system_content = content_type_prompt.get("systemPrompt", "")
            user_prompt_suffix = content_type_prompt.get("userPromptSuffix", "")
            print(f"[DRAMA-STEP3] í´ë¼ì´ì–¸íŠ¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© ({content_type})")
        else:
            # ë“œë¼ë§ˆ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
            system_content = """ë‹¹ì‹ ì€ ì „ë¬¸ ë“œë¼ë§ˆ ëŒ€ë³¸ ì‘ê°€ì…ë‹ˆë‹¤.

ã€ ë“œë¼ë§ˆ ëŒ€ë³¸ì˜ í•µì‹¬ ã€‘
ì‹œì²­ìë¥¼ í™”ë©´ ì†ìœ¼ë¡œ ëŒì–´ë“¤ì´ëŠ” ëª°ì…ê° ìˆëŠ” ìŠ¤í† ë¦¬ë¥¼ ë§Œë“¤ì–´ì•¼ í•©ë‹ˆë‹¤.

ã€ í•„ìˆ˜ ìš”ì†Œ ã€‘
1. ìºë¦­í„°ì˜ ì…ì²´ì„± - ëª…í™•í•œ ëª©í‘œì™€ ë‚´ë©´ì˜ ê°ˆë“±
2. ì¥ë©´ êµ¬ì„± - ê° ì¥ë©´ì˜ ëª©ì ì´ ë¶„ëª…
3. ëŒ€ì‚¬ì˜ í˜ - ìºë¦­í„°ì˜ ì„±ê²©ì´ ë“œëŸ¬ë‚˜ëŠ” ëŒ€ì‚¬
4. ê°ˆë“±ê³¼ ê¸´ì¥ - ì˜ˆìƒì¹˜ ëª»í•œ ë°˜ì „ê³¼ ì „ê°œ

ã€ ê¸ˆì§€ ì‚¬í•­ ã€‘
- ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ì‚¬ìš© ê¸ˆì§€
- ì§€ë£¨í•œ ì„¤ëª…ì´ë‚˜ ë…ë°±"""

        # ì‚¬ìš©ì ì§€ì¹¨ì´ ìˆìœ¼ë©´ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ì¶”ê°€
        if step3_guide:
            system_content += """

ã€ ì¤‘ìš”: ì‚¬ìš©ì ì§€ì¹¨ ìµœìš°ì„  ã€‘
âš ï¸ ì‚¬ìš©ìê°€ ì œê³µí•˜ëŠ” 'ì‘ì„± ì§€ì¹¨'ì´ ìˆë‹¤ë©´, í•´ë‹¹ ì§€ì¹¨ì˜ í˜•ì‹ê³¼ ê·œì¹™ì„ ë°˜ë“œì‹œ ë”°ë¥´ì„¸ìš”.
âš ï¸ ê¸°ë³¸ í˜•ì‹ë³´ë‹¤ ì‚¬ìš©ì ì§€ì¹¨ì´ ìš°ì„ í•©ë‹ˆë‹¤.
âš ï¸ ì‚¬ìš©ì ì§€ì¹¨ì—ì„œ ê¸ˆì§€í•˜ëŠ” í‘œí˜„ì€ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì„¸ìš”."""

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_content = ""

        # ğŸ”¥ ì‚¬ìš©ì ì§€ì¹¨ (ìµœìš°ì„  ì ìš©)
        if custom_directive:
            user_content += "ã€ ğŸ”¥ ì‚¬ìš©ì ì§€ì¹¨ (ìµœìš°ì„  ì ìš©) ã€‘\n"
            user_content += f"{custom_directive}\n"
            user_content += "â†’ ì´ ì§€ì¹¨ì„ ê°€ì¥ ìš°ì„ ì ìœ¼ë¡œ ë°˜ì˜í•˜ì—¬ ëŒ€ë³¸ì„ ì‘ì„±í•˜ì„¸ìš”.\n\n"

        # ë©”íƒ€ ì •ë³´ ì¶”ê°€
        meta_lines = []
        if category:
            meta_lines.append(f"- ë“œë¼ë§ˆ ìœ í˜•/ì˜ìƒ ì‹œê°„: {category}")
        if style_name:
            meta_lines.append(f"- ë“œë¼ë§ˆ ìŠ¤íƒ€ì¼: {style_name}")
        if style_description:
            meta_lines.append(f"- ìŠ¤íƒ€ì¼ ì„¤ëª…: {style_description}")

        # ì£¼ì¸ê³µ ì •ë³´ ì¶”ê°€
        if main_character:
            char_info = []
            if main_character.get("name"):
                char_info.append(f"ì´ë¦„: {main_character['name']}")
            if main_character.get("age"):
                char_info.append(f"ë‚˜ì´: {main_character['age']}")
            if main_character.get("personality"):
                char_info.append(f"ì„±ê²©: {main_character['personality']}")
            if char_info:
                meta_lines.append(f"- ì£¼ì¸ê³µ: {', '.join(char_info)}")

        if meta_lines:
            user_content += "ã€ ê¸°ë³¸ ì •ë³´ ã€‘\n"
            user_content += "\n".join(meta_lines)
            user_content += "\n\n"

        # ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ (ìˆë‹¤ë©´)
        if benchmark_script:
            user_content += "ã€ ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ (ì°¸ê³ ìš©) ã€‘\n"
            user_content += benchmark_script[:3000] + ("..." if len(benchmark_script) > 3000 else "")
            user_content += "\n\n"

        # AI ë¶„ì„ ê²°ê³¼ (ìˆë‹¤ë©´)
        if ai_analysis:
            user_content += "ã€ AI ë¶„ì„ ê²°ê³¼ ã€‘\n"
            user_content += ai_analysis[:2000] + ("..." if len(ai_analysis) > 2000 else "")
            user_content += "\n\n"

        # Step2 ê²°ê³¼ (ë“œë¼ë§ˆ ì´ˆì•ˆ ìë£Œ)
        if draft_content:
            user_content += "ã€ Step2 ì‘ì—… ê²°ê³¼ (ì°¸ê³  ìë£Œ) ã€‘\n"
            user_content += draft_content
            user_content += "\n\n"
        elif auto_story_mode:
            user_content += "ã€ Step2 ìë£Œ ì—†ì´ ì‘ì„± ì§€ì‹œ ã€‘\n"
            user_content += "ì…ë ¥ëœ ì˜ìƒ ì‹œê°„ê³¼ ì§€ì¹¨ë§Œì„ ê¸°ë°˜ìœ¼ë¡œ ì™„ì „íˆ ìƒˆë¡œìš´ ë“œë¼ë§ˆë¥¼ ì‘ì„±í•˜ì„¸ìš”."
            user_content += " ì£¼ì¸ê³µ, ë°°ê²½, ê°ˆë“±, ì „í™˜ì ì„ ììœ ë¡­ê²Œ ì„¤ê³„í•˜ê³ , ì°¸ê³  ìë£Œê°€ ì—†ë”ë¼ë„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ì§€ëŠ” ìŠ¤í† ë¦¬ë¼ì¸ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”."
            user_content += "\n\n"

        # Step3 ì‚¬ìš©ì ì§€ì¹¨ (ìˆë‹¤ë©´)
        if step3_guide:
            user_content += "ã€ â­ ì‘ì„± ì§€ì¹¨ (ìµœìš°ì„  ì ìš©) ã€‘\n"
            user_content += step3_guide
            user_content += "\n\nìœ„ ì§€ì¹¨ì„ ë°˜ë“œì‹œ ìš°ì„ ì ìœ¼ë¡œ ë”°ë¼ ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.\n\n"

        # ëŒ€ë³¸ ì‘ì„± ìš”ì²­ - ì˜ìƒ ì‹œê°„ ê¸°ë°˜ ë¶„ëŸ‰ ì§€ì‹œ (ëª¨ë“  ì½˜í…ì¸  ìœ í˜•ì— ì ìš©!)
        content_type_name = "ê°„ì¦" if content_type == "testimony" else "ë“œë¼ë§ˆ"

        # ì˜ìƒ ì‹œê°„(ë¶„) ì¶”ì¶œ - categoryì—ì„œ ìˆ«ì íŒŒì‹±
        minutes_match = re.search(r"(\d+)\s*ë¶„?", category) or re.search(r"(\d+)", category)
        minutes_value = int(minutes_match.group(1)) if minutes_match else None

        print(f"[DRAMA-STEP3] ë¶„ëŸ‰ ê³„ì‚° - category: '{category}', ì¶”ì¶œëœ ì‹œê°„: {minutes_value}ë¶„, í…ŒìŠ¤íŠ¸ëª¨ë“œ: {test_mode}")

        # ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ìµœì†Œ ë¶„ëŸ‰ (ëª¨ë“  ì½˜í…ì¸  ìœ í˜•ì— ì ìš©!)
        if test_mode:
            length_guide = "ì•½ 500ì ë‚´ì™¸ë¡œ (í…ŒìŠ¤íŠ¸ìš© ìµœì†Œ ë¶„ëŸ‰ - ì ˆëŒ€ ì´ˆê³¼ ê¸ˆì§€!)"
            target_chars = 500
            print(f"[DRAMA-STEP3] ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ë¶„ëŸ‰ ì œí•œ 500ì")
        else:
            # âš ï¸ ëª¨ë“  ì½˜í…ì¸  ìœ í˜•ì— ì˜ìƒ ì‹œê°„ ì„¤ì • ì ìš©! (ê°„ì¦ë„ ì˜ˆì™¸ ì—†ìŒ)
            if minutes_value and minutes_value <= 2:
                length_guide = "ì•½ 500~800ì ë¶„ëŸ‰ìœ¼ë¡œ (2ë¶„ ì˜ìƒ)"
                target_chars = 700
            elif minutes_value and minutes_value <= 5:
                length_guide = "ì•½ 1500~2000ì ë¶„ëŸ‰ìœ¼ë¡œ (5ë¶„ ì˜ìƒ)"
                target_chars = 1800
            elif minutes_value and minutes_value <= 10:
                length_guide = "ì•½ 3000~4000ì ë¶„ëŸ‰ìœ¼ë¡œ (10ë¶„ ì˜ìƒ)"
                target_chars = 3500
            elif minutes_value and minutes_value <= 15:
                length_guide = "ì•½ 5000~6000ì ë¶„ëŸ‰ìœ¼ë¡œ (15ë¶„ ì˜ìƒ)"
                target_chars = 5500
            elif minutes_value and minutes_value <= 20:
                length_guide = "ì•½ 6000~8000ì ë¶„ëŸ‰ìœ¼ë¡œ (20ë¶„ ì˜ìƒ)"
                target_chars = 7000
            elif minutes_value and minutes_value <= 30:
                length_guide = "ì•½ 9000~12000ì ë¶„ëŸ‰ìœ¼ë¡œ (30ë¶„ ì˜ìƒ)"
                target_chars = 10000
            elif minutes_value:
                length_guide = f"ì•½ {minutes_value * 400}ì ë¶„ëŸ‰ìœ¼ë¡œ ({minutes_value}ë¶„ ì˜ìƒ)"
                target_chars = minutes_value * 400
            else:
                # ì‹œê°„ ì„¤ì •ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ 10ë¶„
                length_guide = "ì•½ 3000~4000ì ë¶„ëŸ‰ìœ¼ë¡œ (ê¸°ë³¸ 10ë¶„ ì˜ìƒ)"
                target_chars = 3500
                print(f"[DRAMA-STEP3] âš ï¸ ì˜ìƒ ì‹œê°„ ì„¤ì • ì—†ìŒ â†’ ê¸°ë³¸ 10ë¶„(3500ì) ì ìš©")

            print(f"[DRAMA-STEP3] ë¶„ëŸ‰ ì„¤ì •: {length_guide} (ëª©í‘œ: {target_chars}ì)")

        # ë¶„ëŸ‰ ì§€ì‹œ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ ì—¬ë¶€ì— ë”°ë¼ ë‹¤ë¥´ê²Œ)
        if test_mode:
            length_instruction = f"ğŸ§ª í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {length_guide} - ì ˆëŒ€ ì´ˆê³¼í•˜ì§€ ë§ˆì„¸ìš”!"
        else:
            length_instruction = f"âš ï¸ ë¶„ëŸ‰: {length_guide} - ì´ ë¶„ëŸ‰ì„ ì •í™•íˆ ë§ì¶°ì£¼ì„¸ìš”!"

        # ê°„ì¦ ì½˜í…ì¸  ì „ìš© ìš”ì²­ ì‚¬í•­
        if content_type == "testimony":
            user_content += f"""ã€ ìš”ì²­ ì‚¬í•­ ã€‘
ìœ„ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì™„ì„±ëœ {content_type_name} ì½˜í…ì¸ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

ğŸš¨ í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ (ë°˜ë“œì‹œ ì¤€ìˆ˜!):
1. ì²« ë¬¸ì¥: "ì•ˆë…•í•˜ì„¸ìš”. ì €ëŠ” [ì¥ì†Œ]ì—ì„œ [ì—­í• ]ì„ í•˜ê³  ìˆëŠ” [ì´ë¦„]ì…ë‹ˆë‹¤." í˜•ì‹
2. {length_instruction}
3. ì‹œì : ë°˜ë“œì‹œ 1ì¸ì¹­ (ì €ëŠ”, ì œê°€) - 3ì¸ì¹­(ê·¸ëŠ”, ê·¸ë…€ëŠ”) ì ˆëŒ€ ê¸ˆì§€!
4. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ëŒ€ì‹  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.

{user_prompt_suffix}"""
        else:
            user_content += f"""ã€ ìš”ì²­ ì‚¬í•­ ã€‘
ìœ„ ìë£Œë¥¼ ì°¸ê³ í•˜ì—¬ ì™„ì„±ëœ {content_type_name} ì½˜í…ì¸ ë¥¼ ì‘ì„±í•´ì£¼ì„¸ìš”.

{length_instruction}

ì‘ì„± ì‹œ ì£¼ì˜ì‚¬í•­:
1. ìë£ŒëŠ” ì°¸ê³ ë§Œ í•˜ê³ , ì½˜í…ì¸ ëŠ” ì²˜ìŒë¶€í„° ìƒˆë¡œ êµ¬ì„±í•˜ì„¸ìš”.
2. ìì—°ìŠ¤ëŸ½ê³  ëª°ì…ê° ìˆê²Œ ì‘ì„±í•˜ì„¸ìš”.
3. ê°ì •ì„ ì´ ì ì§„ì ìœ¼ë¡œ ë°œì „í•˜ë„ë¡ êµ¬ì„±í•˜ì„¸ìš”.
4. ì¸íŠ¸ë¡œ â†’ ê°ˆë“±/ì „ê°œ â†’ í„°ë‹í¬ì¸íŠ¸ â†’ íšŒë³µ/ê²°ë§ êµ¬ì¡°ë¥¼ ë”°ë¥´ì„¸ìš”.
5. ë§ˆí¬ë‹¤ìš´ ê¸°í˜¸(#, *, -, **) ëŒ€ì‹  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë¡œ ì‘ì„±í•˜ì„¸ìš”.
{user_prompt_suffix}"""

        # OpenRouter API í˜¸ì¶œ (OpenAI í˜¸í™˜)
        # max_tokensëŠ” ëª©í‘œ ê¸€ììˆ˜ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚° (í•œê¸€ 1ì â‰ˆ 2~3í† í°, JSON ì˜¤ë²„í—¤ë“œ ê³ ë ¤)
        if test_mode:
            max_output_tokens = 8000  # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: JSON ëŒ€ë³¸ ìƒì„±ì— ì¶©ë¶„í•˜ê²Œ
        else:
            # ëª©í‘œ ê¸€ììˆ˜ * 4 (JSON ë©”íƒ€ë°ì´í„° + í•œê¸€ í† í° ì˜¤ë²„í—¤ë“œ) + ì—¬ìœ ë¶„
            max_output_tokens = min(32000, max(8000, int(target_chars * 4)))

        print(f"[DRAMA-STEP3] max_output_tokens: {max_output_tokens}")

        # íƒ€ì„ì•„ì›ƒ ì„¤ì • (Render ë¬´ë£Œ í‹°ì–´ 30ì´ˆ ì œí•œ ëŒ€ì‘)
        # í…ŒìŠ¤íŠ¸ ëª¨ë“œ: 25ì´ˆ / ì¼ë°˜ ëª¨ë“œ: 120ì´ˆ (ìœ ë£Œ í‹°ì–´ í•„ìš”)
        api_timeout = 25 if test_mode else 120
        print(f"[DRAMA-STEP3] API íƒ€ì„ì•„ì›ƒ: {api_timeout}ì´ˆ")

        try:
            response = openrouter_client.chat.completions.create(
                model=selected_model,
                max_tokens=max_output_tokens,
                messages=[
                    {
                        "role": "system",
                        "content": system_content
                    },
                    {
                        "role": "user",
                        "content": user_content
                    }
                ],
                temperature=0.8,
                timeout=api_timeout
            )
        except Exception as api_error:
            error_str = str(api_error).lower()
            if 'timeout' in error_str or 'timed out' in error_str:
                print(f"[DRAMA-STEP3] API íƒ€ì„ì•„ì›ƒ ë°œìƒ: {api_error}")
                raise RuntimeError(
                    f"ëŒ€ë³¸ ìƒì„± ì‹œê°„ì´ {api_timeout}ì´ˆë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. "
                    "ì˜ìƒ ì‹œê°„ì„ ì¤„ì´ê±°ë‚˜(2ë¶„/5ë¶„) í…ŒìŠ¤íŠ¸ ëª¨ë“œë¥¼ ì‚¬ìš©í•´ì£¼ì„¸ìš”."
                )
            raise

        # ì‘ë‹µ ì¶”ì¶œ (ìƒì„¸ ë¡œê¹… ì¶”ê°€)
        print(f"[DRAMA-STEP3] OpenRouter ì‘ë‹µ ìˆ˜ì‹ ")
        print(f"[DRAMA-STEP3] choices ê°œìˆ˜: {len(response.choices) if response.choices else 0}")

        if not response.choices:
            print(f"[DRAMA-STEP3] ì „ì²´ ì‘ë‹µ: {response}")
            raise RuntimeError("OpenRouter API ì‘ë‹µì— choicesê°€ ì—†ìŠµë‹ˆë‹¤. API í‚¤ë‚˜ ëª¨ë¸ ì„¤ì •ì„ í™•ì¸í•˜ì„¸ìš”.")

        # finish_reason í™•ì¸
        finish_reason = response.choices[0].finish_reason if response.choices else None
        print(f"[DRAMA-STEP3] finish_reason: {finish_reason}")

        if finish_reason == "content_filter":
            raise RuntimeError("OpenRouter ì½˜í…ì¸  í•„í„°ì— ì˜í•´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì£¼ì œë¥¼ ë³€ê²½í•´ë³´ì„¸ìš”.")

        result = response.choices[0].message.content if response.choices else ""
        print(f"[DRAMA-STEP3] ì‘ë‹µ ê¸¸ì´: {len(result) if result else 0}ì")
        result = result.strip() if result else ""

        # finish_reason: lengthì¸ ê²½ìš° - ì‘ë‹µì´ ì˜ë ¸ì§€ë§Œ ë¶€ë¶„ ì‘ë‹µì´ë¼ë„ ì‚¬ìš©
        if finish_reason == "length" and result:
            print(f"[DRAMA-STEP3] âš ï¸ ì‘ë‹µì´ max_tokensì—ì„œ ì˜ë¦¼, ë¶€ë¶„ ì‘ë‹µ ì‚¬ìš© ({len(result)}ì)")
            # JSONì´ ë¶ˆì™„ì „í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³µêµ¬ ì‹œë„
            if result.startswith('{') and not result.endswith('}'):
                # ë¶ˆì™„ì „í•œ JSON ë³µêµ¬ ì‹œë„
                result = result + '"}]}'
                print(f"[DRAMA-STEP3] JSON ë³µêµ¬ ì‹œë„")

        if not result:
            print(f"[DRAMA-STEP3] ë¹ˆ ì‘ë‹µ, finish_reason: {finish_reason}")
            if finish_reason == "length":
                raise RuntimeError(f"ì‘ë‹µì´ í† í° ì œí•œìœ¼ë¡œ ì˜ë ¸ìŠµë‹ˆë‹¤. ëŒ€ë³¸ ê¸¸ì´ë¥¼ ì¤„ì´ê±°ë‚˜ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")
            else:
                raise RuntimeError(f"OpenRouter APIë¡œë¶€í„° ë¹ˆ ì‘ë‹µ. finish_reason: {finish_reason}")

        # JSON ì‘ë‹µì—ì„œ ë¶ˆí•„ìš”í•œ ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±° (```json ... ``` í˜•ì‹)
        import re as re_temp
        json_block_pattern = r'^```(?:json)?\s*\n?(.*?)\n?```$'
        json_match = re_temp.search(json_block_pattern, result.strip(), re_temp.DOTALL)
        if json_match:
            result = json_match.group(1).strip()

        # âš ï¸ ì¤‘ìš”: JSON í˜•ì‹ ê²°ê³¼ì—ëŠ” ì•ì— ì¶”ê°€ ì •ë³´ë¥¼ ë¶™ì´ë©´ ì•ˆ ë¨!
        # JSON íŒŒì‹±ì´ ì‹¤íŒ¨í•˜ì—¬ ëŒ€ë³¸ ë·°ì–´ê°€ ì‘ë™í•˜ì§€ ì•Šê²Œ ë¨
        # ê¸°ì¡´ì— ì¶”ê°€í•˜ë˜ "ë“œë¼ë§ˆ ìŠ¤íƒ€ì¼:", "ë“œë¼ë§ˆ ìœ í˜•:" ì •ë³´ëŠ” JSON metadataì— ì´ë¯¸ í¬í•¨ë¨
        final_result = result

        # í† í° ì‚¬ìš©ëŸ‰ ì¶”ì¶œ
        input_tokens = response.usage.prompt_tokens if response.usage else 0
        output_tokens = response.usage.completion_tokens if response.usage else 0

        # Claude Sonnet 4.5 ë¹„ìš© ê³„ì‚° (ì›í™”): input $3/1M, output $15/1M â†’ í™˜ìœ¨ 1400ì›
        # input: 3 * 1400 / 1000000 = 0.0042ì›/token
        # output: 15 * 1400 / 1000000 = 0.021ì›/token
        cost = round(input_tokens * 0.0042 + output_tokens * 0.021, 2)

        print(f"[DRAMA-STEP3-OPENROUTER] ì™„ë£Œ - í† í°: {input_tokens}/{output_tokens}, ë¹„ìš©: â‚©{cost}")

        return jsonify({
            "ok": True,
            "result": final_result,
            "cost": cost,
            "tokens": input_tokens + output_tokens,
            "usage": {
                "input_tokens": input_tokens,
                "output_tokens": output_tokens
            }
        })

    except Exception as e:
        print(f"[DRAMA-STEP3-OPENROUTER][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== AI ì±—ë´‡ API =====
@app.route('/api/drama/chat', methods=['POST'])
def api_drama_chat():
    """ë“œë¼ë§ˆ í˜ì´ì§€ AI ì±—ë´‡ - í˜„ì¬ ì‘ì—… ìƒí™©ì— ëŒ€í•´ ì§ˆë¬¸/ë‹µë³€"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        question = data.get("question", "")
        context = data.get("context", {})  # í˜„ì¬ ì‘ì—… ìƒíƒœ
        selected_model = data.get("model", "gpt-4o-mini")  # ì„ íƒëœ ëª¨ë¸

        # í—ˆìš©ëœ ëª¨ë¸ ëª©ë¡ (ë¹„ìš© ì ˆê°ì„ ìœ„í•´ gpt-4o-mini ê¶Œì¥)
        allowed_models = ["gpt-4o-mini", "gpt-4o"]
        if selected_model not in allowed_models:
            selected_model = "gpt-4o-mini"

        if not question:
            return jsonify({"ok": False, "error": "ì§ˆë¬¸ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        print(f"[DRAMA-CHAT] ëª¨ë¸: {selected_model}, ì§ˆë¬¸: {question[:100]}...")

        # ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        context_text = ""

        # ì›Œí¬í”Œë¡œìš° ë°•ìŠ¤ ê²°ê³¼ë“¤
        if context.get("workflowResults"):
            context_text += "ã€í˜„ì¬ ì‘ì—… ìƒíƒœã€‘\n"
            for box in context.get("workflowResults", []):
                if box.get("result"):
                    context_text += f"\n## {box.get('name', 'ì‘ì—… ë°•ìŠ¤')}\n{box.get('result', '')[:2000]}\n"

        # Step3 ê²°ê³¼
        if context.get("step3Result"):
            context_text += f"\nã€Step3 ìµœì¢… ê²°ê³¼ã€‘\n{context.get('step3Result', '')[:3000]}\n"

        # ë²¤ì¹˜ë§ˆí¬ ìŠ¤í¬ë¦½íŠ¸
        if context.get("benchmarkScript"):
            context_text += f"\nã€ë²¤ì¹˜ë§ˆí¬ ëŒ€ë³¸ (ì°¸ê³ ìš©)ã€‘\n{context.get('benchmarkScript', '')[:1500]}\n"

        # ì˜¤ë¥˜ ì •ë³´
        if context.get("lastError"):
            context_text += f"\nã€ìµœê·¼ ì˜¤ë¥˜ã€‘\n{context.get('lastError', '')}\n"

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ëŒ€ë³¸ ì‘ì„±ì„ ë•ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ í˜„ì¬ ì‘ì—… ì¤‘ì¸ ë“œë¼ë§ˆ ëŒ€ë³¸ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´, ì£¼ì–´ì§„ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

ì—­í• :
1. í˜„ì¬ ì‘ì—… ìƒí™© ë¶„ì„ ë° ì„¤ëª…
2. ê°œì„  ì œì•ˆ ë° ì•„ì´ë””ì–´ ì œê³µ
3. ì˜¤ë¥˜ë‚˜ ë¬¸ì œì  í•´ê²° ë„ì›€
4. ìŠ¤í† ë¦¬, ìºë¦­í„°, ëŒ€ì‚¬ ë“±ì— ëŒ€í•œ í”¼ë“œë°±
5. ë‹¤ìŒ ë‹¨ê³„ ì§„í–‰ ê°€ì´ë“œ

ë‹µë³€ ì‹œ ìœ ì˜ì‚¬í•­:
- ê°„ê²°í•˜ê³  ì‹¤ìš©ì ì¸ ë‹µë³€ì„ ì œê³µí•˜ì„¸ìš”
- êµ¬ì²´ì ì¸ ì˜ˆì‹œë‚˜ ì œì•ˆì„ í¬í•¨í•˜ì„¸ìš”
- í•œêµ­ì–´ë¡œ ì¹œì ˆí•˜ê²Œ ë‹µë³€í•˜ì„¸ìš”
- í˜„ì¬ ì‘ì—… ìƒíƒœë¥¼ ê³ ë ¤í•˜ì—¬ ë§¥ë½ì— ë§ëŠ” ë‹µë³€ì„ í•˜ì„¸ìš”"""

        # ì‚¬ìš©ì ë©”ì‹œì§€ êµ¬ì„±
        user_content = ""
        if context_text:
            user_content += f"{context_text}\n\n"
        user_content += f"ã€ì§ˆë¬¸ã€‘\n{question}"

        # GPT í˜¸ì¶œ (ì„ íƒëœ ëª¨ë¸ ì‚¬ìš©)
        completion = client.chat.completions.create(
            model=selected_model,
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            max_tokens=4000 if selected_model in ["gpt-4o", "gpt-5"] else 2000
        )

        answer = completion.choices[0].message.content.strip()

        # í† í° ì‚¬ìš©ëŸ‰
        usage = {
            "input_tokens": completion.usage.prompt_tokens,
            "output_tokens": completion.usage.completion_tokens,
            "model": selected_model
        }

        print(f"[DRAMA-CHAT][SUCCESS] {selected_model}ë¡œ ë‹µë³€ ìƒì„± ì™„ë£Œ")
        return jsonify({"ok": True, "answer": answer, "usage": usage})

    except Exception as e:
        print(f"[DRAMA-CHAT][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 500


# ===== Step4: ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± API =====
@app.route('/api/drama/generate-image-prompts', methods=['POST'])
def api_generate_image_prompts():
    """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì¸ë¬¼/ë°°ê²½/í†µí•© ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        script = data.get("script", "")
        main_character = data.get("mainCharacter", "")

        if not script:
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[DRAMA-STEP4-PROMPT] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")

        # GPTë¥¼ ì‚¬ìš©í•˜ì—¬ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±
        system_content = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ DALL-E 3 ì´ë¯¸ì§€ ìƒì„±ì„ ìœ„í•œ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ëŒ€ë³¸ì„ ì½ê³  ë‹¤ìŒ ì„¸ ê°€ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”:

1. ì¸ë¬¼ í”„ë¡¬í”„íŠ¸ (Character Prompt)
   - ì£¼ì¸ê³µì˜ ì™¸ëª¨, í‘œì •, ì˜ìƒ, ìì„¸ë¥¼ ë¬˜ì‚¬
   - ë‚˜ì´, ì„±ë³„, ë¶„ìœ„ê¸°ë¥¼ í¬í•¨
   - ğŸš¨ ë°˜ë“œì‹œ í”„ë¡¬í”„íŠ¸ ë§¨ ì•ì— í•œêµ­ì¸ íŠ¹ì§•ì„ ë°°ì¹˜: "Korean person from South Korea with authentic Korean/East Asian ethnicity, Korean facial bone structure, Korean skin tone"
   - ì˜ˆ: "Korean woman from South Korea with authentic Korean ethnicity, Korean facial features, Korean skin tone, in her late 20s, gentle and warm expression, wearing a soft beige cardigan"

2. ë°°ê²½ í”„ë¡¬í”„íŠ¸ (Background Prompt)
   - ì¥ë©´ì˜ ë°°ê²½, ì¥ì†Œ, ì‹œê°„ëŒ€, ë¶„ìœ„ê¸°ë¥¼ ë¬˜ì‚¬
   - ì¡°ëª…, ìƒ‰ê°, ë¶„ìœ„ê¸°ë¥¼ í¬í•¨
   - ì˜ˆ: "A cozy Korean cafe interior, warm afternoon sunlight streaming through large windows, wooden furniture, soft ambient lighting"

3. í†µí•© ì¥ë©´ í”„ë¡¬í”„íŠ¸ (Combined Scene Prompt)
   - ì¸ë¬¼ì´ ë°°ê²½ì— ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ëŠ” ì™„ì „í•œ ì¥ë©´ ë¬˜ì‚¬
   - ì˜í™”ì ì´ê³  ì‹œê°ì ìœ¼ë¡œ ë§¤ë ¥ì ì¸ êµ¬ë„
   - ğŸš¨ ë°˜ë“œì‹œ í”„ë¡¬í”„íŠ¸ ë§¨ ì•ì— í•œêµ­ì¸ íŠ¹ì§•ì„ ë°°ì¹˜
   - ì˜ˆ: "Korean woman from South Korea with authentic Korean ethnicity and Korean facial features, in her late 20s, sitting by the window in a cozy cafe, warm afternoon sunlight illuminating her gentle smile"

ì‘ë‹µ í˜•ì‹:
CHARACTER_PROMPT: [ì¸ë¬¼ í”„ë¡¬í”„íŠ¸]
BACKGROUND_PROMPT: [ë°°ê²½ í”„ë¡¬í”„íŠ¸]
COMBINED_PROMPT: [í†µí•© í”„ë¡¬í”„íŠ¸]

ğŸš¨ ë§¤ìš° ì¤‘ìš” - í•œêµ­ì¸ ì™¸ëª¨ í•„ìˆ˜:
- ëª¨ë“  ì¸ë¬¼ í”„ë¡¬í”„íŠ¸ëŠ” ë°˜ë“œì‹œ ë§¨ ì•ì— "Korean person from South Korea with authentic Korean/East Asian ethnicity, Korean facial bone structure, Korean skin tone"ë¥¼ í¬í•¨
- ì ˆëŒ€ë¡œ "Asian" ë‹¨ë… ì‚¬ìš© ê¸ˆì§€ - ë°˜ë“œì‹œ "Korean"ì„ ëª…ì‹œ
- DALL-E 3ì— ìµœì í™”ëœ ìƒì„¸í•˜ê³  ì‹œê°ì ì¸ ë¬˜ì‚¬
- ë¶€ì •ì ì´ê±°ë‚˜ í­ë ¥ì ì¸ ë‚´ìš© ì œì™¸"""

        user_content = f"""ë‹¤ìŒ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

[ì£¼ì¸ê³µ ì •ë³´]
{main_character if main_character else '(ë³„ë„ ì •ë³´ ì—†ìŒ - ëŒ€ë³¸ì—ì„œ ì¶”ì¶œ)'}

[ë“œë¼ë§ˆ ëŒ€ë³¸]
{script[:4000]}

ìœ„ ëŒ€ë³¸ì˜ í•µì‹¬ ì¥ë©´ì— ëŒ€í•œ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7
        )

        result = completion.choices[0].message.content.strip()

        # í”„ë¡¬í”„íŠ¸ íŒŒì‹±
        character_prompt = ""
        background_prompt = ""
        combined_prompt = ""

        lines = result.split('\n')
        current_type = None

        for line in lines:
            line = line.strip()
            if line.startswith('CHARACTER_PROMPT:'):
                current_type = 'character'
                character_prompt = line.replace('CHARACTER_PROMPT:', '').strip()
            elif line.startswith('BACKGROUND_PROMPT:'):
                current_type = 'background'
                background_prompt = line.replace('BACKGROUND_PROMPT:', '').strip()
            elif line.startswith('COMBINED_PROMPT:'):
                current_type = 'combined'
                combined_prompt = line.replace('COMBINED_PROMPT:', '').strip()
            elif current_type and line:
                # ì—¬ëŸ¬ ì¤„ì— ê±¸ì¹œ í”„ë¡¬í”„íŠ¸ ì²˜ë¦¬
                if current_type == 'character':
                    character_prompt += ' ' + line
                elif current_type == 'background':
                    background_prompt += ' ' + line
                elif current_type == 'combined':
                    combined_prompt += ' ' + line

        print(f"[DRAMA-STEP4-PROMPT] í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")

        return jsonify({
            "ok": True,
            "characterPrompt": character_prompt,
            "backgroundPrompt": background_prompt,
            "combinedPrompt": combined_prompt
        })

    except Exception as e:
        print(f"[DRAMA-STEP4-PROMPT][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step4: ë“±ì¥ì¸ë¬¼ ë° ì”¬ ë¶„ì„ API =====
@app.route('/api/drama/analyze-characters', methods=['POST'])
def api_analyze_characters():
    """ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥ì¸ë¬¼ê³¼ ì”¬ ì •ë³´ ì¶”ì¶œ"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        script = data.get("script", "")
        duration = data.get("duration", "10min")  # ì˜ìƒ ê¸¸ì´ (ê¸°ë³¸ê°’: 10ë¶„)
        content_type = data.get("content_type", "drama")  # ì½˜í…ì¸  íƒ€ì…

        if not script:
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        # durationì— ë”°ë¥¸ ìµœëŒ€ ì”¬ ê°œìˆ˜ ì„¤ì •
        max_scenes_map = {
            "30s": 1,     # ì‡¼ì¸ 
            "60s": 2,     # ì‡¼ì¸ 
            "3min": 2,
            "5min": 3,
            "10min": 4,
            "20min": 6,
            "30min": 8
        }
        max_scenes = max_scenes_map.get(duration, 4)

        # ì‡¼ì¸  ì—¬ë¶€ íŒë‹¨ (content_typeì´ shortsì´ê±°ë‚˜ durationì´ 60s ì´í•˜)
        is_shorts = content_type == 'shorts' or duration in ['30s', '60s']

        print(f"[DRAMA-STEP4-ANALYZE] ë“±ì¥ì¸ë¬¼ ë° ì”¬ ë¶„ì„ ì‹œì‘ (duration: {duration}, max_scenes: {max_scenes}, content_type: {content_type}, is_shorts: {is_shorts})")

        # ì½˜í…ì¸  íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶„ê¸°
        if content_type == 'shorts' or is_shorts:
            # ì‡¼ì¸ /ë¦´ìŠ¤ ì½˜í…ì¸  (ì„¸ë¡œ 9:16, 60ì´ˆ ì´í•˜)
            system_content = """ë‹¹ì‹ ì€ YouTube Shorts / Instagram Reels ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ì¥ë©´ì„ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì‡¼ì¸ ëŠ” ì„¸ë¡œ í˜•ì‹(9:16)ì´ë©° 60ì´ˆ ì´í•˜ì˜ ì§§ì€ ì˜ìƒì…ë‹ˆë‹¤.
ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ë“±ì¥ì¸ë¬¼/ìš”ì†Œ (characters): ê° í•­ëª©ì— ëŒ€í•´
   - name: ì´ë¦„ (í•œê¸€)
   - description: ì„¤ëª… (í•œê¸€)
   - imagePrompt: ì„¸ë¡œ í˜•ì‹ì— ìµœì í™”ëœ ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸

2. ì”¬ (scenes): ê° ì”¬ì— ëŒ€í•´ (ìµœëŒ€ 2ê°œ)
   - title: ì”¬ ì œëª© (í•œê¸€)
   - location: ì¥ì†Œ (í•œê¸€)
   - description: ì”¬ ì„¤ëª… (í•œê¸€)
   - characters: ë“±ì¥í•˜ëŠ” í•­ëª©ë“¤
   - backgroundPrompt: ì„¸ë¡œ êµ¬ë„ì— ë§ëŠ” ì˜ì–´ ë°°ê²½ í”„ë¡¬í”„íŠ¸

ì‘ë‹µ í˜•ì‹ì€ JSONìœ¼ë¡œ:
{
  "characters": [...],
  "scenes": [...]
}

ğŸš¨ ì‡¼ì¸  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í•µì‹¬ ê·œì¹™:
- **ì„¸ë¡œ êµ¬ë„ (9:16)**: ëª¨ë“  ì´ë¯¸ì§€ëŠ” ì„¸ë¡œ í˜•ì‹, í”¼ì‚¬ì²´ë¥¼ í™”ë©´ ì¤‘ì•™ì— ë°°ì¹˜
- **í´ë¡œì¦ˆì—…/ë¯¸ë””ì—„ìƒ·**: ì‘ì€ í™”ë©´ì—ì„œ ì˜ ë³´ì´ë„ë¡ ê°€ê¹Œì´ ì´¬ì˜
- **ì‹¬í”Œí•œ ë°°ê²½**: ë³µì¡í•œ ë°°ê²½ì€ í”¼í•˜ê³  í”¼ì‚¬ì²´ê°€ ë‹ë³´ì´ê²Œ
- **ê°•ë ¬í•œ ì²«ì¸ìƒ**: ì²« ì”¬ì´ ì¸ë„¤ì¼ì´ ë˜ë¯€ë¡œ ì‹œì„ ì„ ë„ëŠ” êµ¬ë„
- **í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ê³µê°„**: ìƒë‹¨/í•˜ë‹¨ì— í…ìŠ¤íŠ¸ ì˜ì—­ í™•ë³´
- í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ: "Vertical portrait composition (9:16 aspect ratio), [ì£¼ì œ] centered in frame, close-up shot, simple blurred background, mobile-optimized framing, high contrast, eye-catching visual"
- âš ï¸ ê°€ë¡œ êµ¬ë„ ê¸ˆì§€, ë³µì¡í•œ ë°°ê²½ ê¸ˆì§€, ë„ˆë¬´ ë©€ë¦¬ì„œ ì°ì€ ìƒ· ê¸ˆì§€"""

        elif content_type == 'product':
            # ìƒí’ˆ ì†Œê°œ ì½˜í…ì¸ 
            system_content = """ë‹¹ì‹ ì€ ìƒí’ˆ ì†Œê°œ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì œí’ˆê³¼ ì”¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ë“±ì¥ë¬¼ (characters): ì œí’ˆ/ìƒí’ˆì— ëŒ€í•´
   - name: ì œí’ˆ ì´ë¦„ (í•œê¸€)
   - description: ì œí’ˆ ì„¤ëª… (íŠ¹ì§•, ê¸°ëŠ¥, ì¥ì  ë“± - í•œê¸€)
   - imagePrompt: ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì œí’ˆ ì™¸ê´€, ë””í…Œì¼, ì‚¬ìš© ì¥ë©´ ë¬˜ì‚¬)

2. ì”¬ (scenes): ê° ì”¬ì— ëŒ€í•´
   - title: ì”¬ ì œëª© ë˜ëŠ” ìš”ì•½ (í•œê¸€)
   - location: ì¥ì†Œ/ë°°ê²½ (í•œê¸€)
   - description: ì”¬ ì„¤ëª… (í•œê¸€)
   - characters: ë“±ì¥í•˜ëŠ” ì œí’ˆë“¤ ì´ë¦„ ë°°ì—´
   - backgroundPrompt: ì˜ì–´ ë°°ê²½ í”„ë¡¬í”„íŠ¸ (ì œí’ˆì„ ë‹ë³´ì´ê²Œ í•˜ëŠ” ë°°ê²½, ì¡°ëª…)

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ:
{
  "characters": [
    {"name": "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ X1", "description": "ìµœì‹  ê±´ê°• ëª¨ë‹ˆí„°ë§ ê¸°ëŠ¥ì´ íƒ‘ì¬ëœ í”„ë¦¬ë¯¸ì—„ ìŠ¤ë§ˆíŠ¸ì›Œì¹˜", "imagePrompt": "Premium smartwatch with sleek metallic design, crystal clear OLED display, health monitoring interface visible, professional product photography, studio lighting..."},
    ...
  ],
  "scenes": [
    {"title": "ì œí’ˆ ì†Œê°œ", "location": "ìŠ¤íŠœë””ì˜¤", "description": "ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ì˜ ì™¸ê´€ê³¼ ë””ìì¸ì„ ì†Œê°œí•˜ëŠ” ì¥ë©´", "characters": ["ìŠ¤ë§ˆíŠ¸ì›Œì¹˜ X1"], "backgroundPrompt": "Clean white studio background, soft gradient lighting, professional product photography setup..."},
    ...
  ]
}

ğŸš¨ ë§¤ìš° ì¤‘ìš” - ìƒí’ˆ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê·œì¹™:
- **ì œí’ˆì´ ì£¼ì¸ê³µ**: ëª¨ë“  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ì—ì„œ ì œí’ˆì´ í™”ë©´ì˜ ì¤‘ì‹¬
- **ì œí’ˆ í´ë¡œì¦ˆì—…**: ì œí’ˆì˜ ë””í…Œì¼, ì§ˆê°, ê¸°ëŠ¥ì„ ê°•ì¡°
- **ì‚¬ìš© ì¥ë©´**: ì œí’ˆì´ ì‹¤ì œ ì‚¬ìš©ë˜ëŠ” ëª¨ìŠµ (ì‚¬ëŒ ì†/ëª¸ ì¼ë¶€ë§Œ ë…¸ì¶œ, ì–¼êµ´ ì—†ìŒ)
- **ê´‘ê³  í’ˆì§ˆ**: ê³ ê¸‰ìŠ¤ëŸ¬ìš´ ìƒì—… ì‚¬ì§„ ìŠ¤íƒ€ì¼ (studio lighting, soft shadows)
- **ë°°ê²½ì€ ì‹¬í”Œí•˜ê²Œ**: ì œí’ˆì„ ë‹ë³´ì´ê²Œ í•˜ëŠ” ë‹¨ìˆœí•œ ë°°ê²½ (ê·¸ë¼ë°ì´ì…˜, ë‹¨ìƒ‰, ìì—° ë°°ê²½)
- **ì‚¬ëŒ ì–¼êµ´ ì ˆëŒ€ ê¸ˆì§€**: ì œí’ˆ í™ë³´ ì´ë¯¸ì§€ì— ì¸ë¬¼ ì–¼êµ´ì´ ë‚˜ì˜¤ë©´ ì•ˆ ë¨
- í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ: "Close-up product shot of [ì œí’ˆëª…], professional commercial photography, soft studio lighting, clean background, high-end advertising quality"
- âš ï¸ ì ˆëŒ€ ê¸ˆì§€: ì¸ë¬¼ ì´ˆìƒí™”, ì‚¬ëŒ ì–¼êµ´ í´ë¡œì¦ˆì—…, ë“œë¼ë§ˆ ì¥ë©´"""

        elif content_type == 'education':
            # êµìœ¡/ì •ë³´ ì½˜í…ì¸ 
            system_content = """ë‹¹ì‹ ì€ êµìœ¡/ì •ë³´ ì½˜í…ì¸  ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ í•µì‹¬ ê°œë…ê³¼ ì”¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. í•µì‹¬ ìš”ì†Œ (characters): ì£¼ìš” ê°œë…/ìš”ì†Œì— ëŒ€í•´
   - name: ê°œë…/ìš”ì†Œ ì´ë¦„ (í•œê¸€)
   - description: ì„¤ëª… (í•œê¸€)
   - imagePrompt: ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ê°œë…ì„ ì‹œê°í™”í•˜ëŠ” ì¸í¬ê·¸ë˜í”½/ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼)

2. ì”¬ (scenes): ê° ì”¬ì— ëŒ€í•´
   - title: ì”¬ ì œëª© (í•œê¸€)
   - location: ë°°ê²½ ì»¨í…ìŠ¤íŠ¸ (í•œê¸€)
   - description: ì”¬ ì„¤ëª… (í•œê¸€)
   - characters: ê´€ë ¨ ê°œë…ë“¤ ë°°ì—´
   - backgroundPrompt: ì˜ì–´ ë°°ê²½ í”„ë¡¬í”„íŠ¸ (êµìœ¡ì  ì‹œê° ìë£Œ ìŠ¤íƒ€ì¼)

ì‘ë‹µ í˜•ì‹ì€ JSONìœ¼ë¡œ:
{
  "characters": [...],
  "scenes": [...]
}

ğŸš¨ ë§¤ìš° ì¤‘ìš” - êµìœ¡ ì½˜í…ì¸  ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê·œì¹™:
- **ì¸í¬ê·¸ë˜í”½ ìŠ¤íƒ€ì¼**: ê¹”ë”í•œ ë‹¤ì´ì–´ê·¸ë¨, ì°¨íŠ¸, ì‹œê°í™”
- **ê°œë… ì‹œê°í™”**: ì¶”ìƒì  ê°œë…ì„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì‹œê°í™”
- **ì•„ì´ì½˜ê³¼ ì‹¬ë³¼**: í•µì‹¬ í¬ì¸íŠ¸ë¥¼ ìƒì§•í•˜ëŠ” ì•„ì´ì½˜ ì‚¬ìš©
- **ê¹”ë”í•œ ë ˆì´ì•„ì›ƒ**: ì •ë³´ ì „ë‹¬ì— ì§‘ì¤‘í•˜ëŠ” ê¹”ë”í•œ êµ¬ì„±
- í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ: "Clean infographic style illustration of [ê°œë…], modern flat design, educational visual, clear icons and diagrams"
- âš ï¸ ì¸ë¬¼ ì‚¬ì§„ë³´ë‹¤ëŠ” ê°œë… ì‹œê°í™”ì— ì§‘ì¤‘"""

        else:
            # ë“œë¼ë§ˆ/ìŠ¤í† ë¦¬ ì½˜í…ì¸  (ê¸°ë³¸ê°’)
            system_content = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë“±ì¥ì¸ë¬¼ê³¼ ì”¬ ì •ë³´ë¥¼ ì¶”ì¶œí•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ë‹¤ìŒ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”:

1. ë“±ì¥ì¸ë¬¼ (characters): ê° ì¸ë¬¼ì— ëŒ€í•´
   - name: ì¸ë¬¼ ì´ë¦„ (í•œê¸€)
   - description: ì¸ë¬¼ ì„¤ëª… (ë‚˜ì´, ì„±ê²©, ì—­í•  ë“± - í•œê¸€)
   - imagePrompt: DALL-Eìš© ì˜ì–´ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (ì™¸ëª¨, ì˜ìƒ, ë¶„ìœ„ê¸° ë¬˜ì‚¬)

2. ì”¬ (scenes): ê° ì”¬ì— ëŒ€í•´
   - title: ì”¬ ì œëª© ë˜ëŠ” ìš”ì•½ (í•œê¸€)
   - location: ì¥ì†Œ (í•œê¸€)
   - description: ì”¬ ì„¤ëª… (í•œê¸€)
   - characters: ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ ì´ë¦„ ë°°ì—´
   - backgroundPrompt: DALL-Eìš© ì˜ì–´ ë°°ê²½ í”„ë¡¬í”„íŠ¸ (ì¥ì†Œ, ë¶„ìœ„ê¸°, ì¡°ëª… ë¬˜ì‚¬)

ì‘ë‹µì€ ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ:
{
  "characters": [
    {"name": "ìˆ˜ì§„", "description": "28ì„¸ ì—¬ì„±, ë°ê³  í™œë°œí•œ ì„±ê²©ì˜ ì¹´í˜ ì‚¬ì¥", "imagePrompt": "A Korean woman in her late 20s with East Asian features, Korean ethnicity, bright and cheerful expression, casual smart outfit..."},
    ...
  ],
  "scenes": [
    {"title": "ì²« ë§Œë‚¨", "location": "ì¹´í˜", "description": "ìˆ˜ì§„ì´ ì²˜ìŒ ë¯¼ìˆ˜ë¥¼ ë§Œë‚˜ëŠ” ì¥ë©´", "characters": ["ìˆ˜ì§„", "ë¯¼ìˆ˜"], "backgroundPrompt": "A cozy Korean cafe interior, warm afternoon light..."},
    ...
  ]
}

ì¤‘ìš”:
- imagePromptì™€ backgroundPromptëŠ” ë°˜ë“œì‹œ ì˜ì–´ë¡œ ì‘ì„±
- í”„ë¡¬í”„íŠ¸ëŠ” AI ì´ë¯¸ì§€ ìƒì„±ì— ìµœì í™”ë˜ë„ë¡ ìƒì„¸í•˜ê²Œ ì‘ì„±

ğŸš¨ ë§¤ìš° ì¤‘ìš” - í•œêµ­ ì›¹íˆ°/ë§Œí™” ìŠ¤íƒ€ì¼ ìºë¦­í„° ì‚¬ìš© í•„ìˆ˜:

- âš ï¸âš ï¸âš ï¸ ì‹¤ì‚¬ ì¸ë¬¼ ì ˆëŒ€ ê¸ˆì§€! ì‚¬ì§„ì²˜ëŸ¼ ì‚¬ì‹¤ì ì¸ ì¸ë¬¼ ì´ë¯¸ì§€ ì‚¬ìš© ê¸ˆì§€!
- âš ï¸âš ï¸âš ï¸ ìŠ¤í‹±ë§¨ ì ˆëŒ€ ê¸ˆì§€! ë§‰ëŒ€ê¸° ì¸ê°„ ìŠ¤íƒ€ì¼ ì‚¬ìš© ê¸ˆì§€!

- âš ï¸ ìºë¦­í„° ìŠ¤íƒ€ì¼ (ëª¨ë“  ì¸ë¬¼ì€ ì´ê±¸ë¡œ í‘œí˜„):
  "Korean WEBTOON/manhwa style character with EXAGGERATED EXPRESSION (shocked face, wide eyes, open mouth, sweat drops), 30-50 year old Korean man or woman, clean bold outlines, vibrant flat colors"

- âš ï¸ ë°°ê²½ ìŠ¤íƒ€ì¼:
  "Detailed background related to the scene, vibrant colors"

- âš ï¸ ì „ì²´ ìŠ¤íƒ€ì¼:
  "Korean webtoon/manhwa style illustration with comic-style expression marks (sweat drops, impact lines)"

- âš ï¸ ê°ì • í‘œí˜„: ì›¹íˆ° ìºë¦­í„°ì˜ ê³¼ì¥ëœ í‘œì •ìœ¼ë¡œ í‘œí˜„ (í° ëˆˆ, ë²Œë¦° ì…, ë•€ë°©ìš¸ ë“±)"""

        user_content = f"""ë‹¤ìŒ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:

{script[:15000]}

âš ï¸ ë§¤ìš° ì¤‘ìš” - ì”¬ ê°œìˆ˜ ì œí•œ:
- ì´ ì˜ìƒì€ {duration} ê¸¸ì´ì…ë‹ˆë‹¤.
- ì”¬ì€ ë°˜ë“œì‹œ **ìµœëŒ€ {max_scenes}ê°œ**ê¹Œì§€ë§Œ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
- ëŒ€ë³¸ì— ì”¬ì´ ë§ë”ë¼ë„ ê°€ì¥ í•µì‹¬ì ì¸ {max_scenes}ê°œë§Œ ì„ ë³„í•˜ì„¸ìš”.
- ë¹„ìŠ·í•œ ì¥ë©´ì€ í•˜ë‚˜ë¡œ í†µí•©í•˜ì„¸ìš”.

ë“±ì¥ì¸ë¬¼ê³¼ ì”¬ ì •ë³´ë¥¼ JSON í˜•ì‹ìœ¼ë¡œ ì¶”ì¶œí•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7,
            response_format={"type": "json_object"}
        )

        result = completion.choices[0].message.content.strip()

        import json as json_module
        parsed = json_module.loads(result)

        characters = parsed.get("characters", [])
        scenes = parsed.get("scenes", [])

        print(f"[DRAMA-STEP4-ANALYZE] ë¶„ì„ ì™„ë£Œ - ì¸ë¬¼: {len(characters)}ëª…, ì”¬: {len(scenes)}ê°œ")

        return jsonify({
            "ok": True,
            "characters": characters,
            "scenes": scenes
        })

    except Exception as e:
        print(f"[DRAMA-STEP4-ANALYZE][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step4: ì”¬ í”„ë¡¬í”„íŠ¸ ìƒì„± API =====
@app.route('/api/drama/generate-scene-prompt', methods=['POST'])
def api_generate_scene_prompt():
    """ì”¬ì— ë“±ì¥í•˜ëŠ” ì¸ë¬¼ë“¤ê³¼ ë°°ê²½ì„ ê²°í•©í•œ í†µí•© í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        scene = data.get("scene", {})
        characters = data.get("characters", [])
        background_prompt = data.get("backgroundPrompt", "")

        print(f"[DRAMA-STEP4-SCENE] ì”¬ í”„ë¡¬í”„íŠ¸ ìƒì„± ì‹œì‘")

        # ì¸ë¬¼ í”„ë¡¬í”„íŠ¸ ì¡°í•©
        character_descriptions = []
        for char in characters:
            if char.get("prompt"):
                character_descriptions.append(f"{char['name']}: {char['prompt']}")

        system_content = """ë‹¹ì‹ ì€ ë“œë¼ë§ˆ ì”¬ì„ ìœ„í•œ DALL-E 3 ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ì‘ì„±í•˜ëŠ” ì „ë¬¸ê°€ì…ë‹ˆë‹¤.

ì£¼ì–´ì§„ ì”¬ ì •ë³´ì™€ ë“±ì¥ì¸ë¬¼ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ, ì¸ë¬¼ë“¤ì´ ë°°ê²½ì— ìì—°ìŠ¤ëŸ½ê²Œ ì–´ìš¸ë¦¬ëŠ” í†µí•© ì¥ë©´ í”„ë¡¬í”„íŠ¸ë¥¼ ì˜ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.

í”„ë¡¬í”„íŠ¸ ì‘ì„± ì›ì¹™:
1. ì”¬ì˜ ë¶„ìœ„ê¸°ì™€ ê°ì •ì„ ë°˜ì˜
2. ë“±ì¥ì¸ë¬¼ë“¤ì˜ ìœ„ì¹˜ì™€ ìƒí˜¸ì‘ìš© ë¬˜ì‚¬
3. ì¡°ëª…, ìƒ‰ê°, êµ¬ë„ ë“± ì˜í™”ì  ìš”ì†Œ í¬í•¨
4. í•œêµ­ ë“œë¼ë§ˆ ìŠ¤íƒ€ì¼ì˜ ì‹œê°ì  ìš”ì†Œ
5. DALL-E 3ì— ìµœì í™”ëœ ìƒì„¸í•˜ê³  ëª…í™•í•œ ë¬˜ì‚¬

ğŸš¨ ë§¤ìš° ì¤‘ìš” - í•œêµ­ ì›¹íˆ°/ë§Œí™” ìŠ¤íƒ€ì¼ ìºë¦­í„°ë§Œ ì‚¬ìš©:
- ì‹¤ì‚¬ ì¸ë¬¼(ì‚¬ì§„ì²˜ëŸ¼ ì‚¬ì‹¤ì ì¸ ì¸ë¬¼) ì ˆëŒ€ ê¸ˆì§€!
- ìŠ¤í‹±ë§¨(ë§‰ëŒ€ê¸° ì¸ê°„) ì ˆëŒ€ ê¸ˆì§€!
- ëª¨ë“  ì¸ë¬¼ì€ í•œêµ­ ì›¹íˆ° ìŠ¤íƒ€ì¼ë¡œ í‘œí˜„
- ìºë¦­í„°: "Korean WEBTOON/manhwa style character with EXAGGERATED EXPRESSION, 30-50 year old Korean man or woman, clean bold outlines"
- ê°ì • í‘œí˜„: ì›¹íˆ° ìºë¦­í„°ì˜ ê³¼ì¥ëœ í‘œì •ìœ¼ë¡œ í‘œí˜„ (í° ëˆˆ, ë²Œë¦° ì…, ë•€ë°©ìš¸)

ğŸš¨ ë°°ê²½ ìŠ¤íƒ€ì¼:
- ë°°ê²½: "Detailed background with vibrant colors, related to the scene context"
- ì „ì²´ ìŠ¤íƒ€ì¼: "Korean webtoon/manhwa style illustration with comic-style expression marks"

ì‘ë‹µ í˜•ì‹:
BACKGROUND_PROMPT: [ë°°ê²½ í”„ë¡¬í”„íŠ¸ - ì˜ì–´, 1970~80ë…„ëŒ€ í•œêµ­ ë°°ê²½ ìŠ¤íƒ€ì¼ í¬í•¨]
COMBINED_PROMPT: [í†µí•© ì¥ë©´ í”„ë¡¬í”„íŠ¸ - ì˜ì–´, ë§¨ ì•ì— í•œêµ­ì¸ íŠ¹ì§• í¬í•¨, ë§ˆì§€ë§‰ì— ë¹ˆí‹°ì§€ í•„ë¦„ ìŠ¤íƒ€ì¼ ì¶”ê°€, ë“±ì¥ì¸ë¬¼ ì™¸ëª¨ëŠ” ì •í™•íˆ ìœ ì§€]"""

        scene_info = f"""
ì”¬ ì •ë³´:
- ì œëª©: {scene.get('title', '')}
- ì¥ì†Œ: {scene.get('location', '')}
- ì„¤ëª…: {scene.get('description', '')}
- ê¸°ì¡´ ë°°ê²½ í”„ë¡¬í”„íŠ¸: {background_prompt or scene.get('backgroundPrompt', '')}

ë“±ì¥ ì¸ë¬¼:
{chr(10).join(character_descriptions) if character_descriptions else '(ì¸ë¬¼ ì •ë³´ ì—†ìŒ)'}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ í†µí•© ì”¬ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”."""

        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_content},
                {"role": "user", "content": scene_info}
            ],
            temperature=0.7
        )

        result = completion.choices[0].message.content.strip()

        # í”„ë¡¬í”„íŠ¸ íŒŒì‹±
        new_background_prompt = ""
        combined_prompt = ""

        lines = result.split('\n')
        current_type = None

        for line in lines:
            line = line.strip()
            if line.startswith('BACKGROUND_PROMPT:'):
                current_type = 'background'
                new_background_prompt = line.replace('BACKGROUND_PROMPT:', '').strip()
            elif line.startswith('COMBINED_PROMPT:'):
                current_type = 'combined'
                combined_prompt = line.replace('COMBINED_PROMPT:', '').strip()
            elif current_type and line:
                if current_type == 'background':
                    new_background_prompt += ' ' + line
                elif current_type == 'combined':
                    combined_prompt += ' ' + line

        print(f"[DRAMA-STEP4-SCENE] ì”¬ í”„ë¡¬í”„íŠ¸ ìƒì„± ì™„ë£Œ")

        return jsonify({
            "ok": True,
            "backgroundPrompt": new_background_prompt or background_prompt,
            "combinedPrompt": combined_prompt
        })

    except Exception as e:
        print(f"[DRAMA-STEP4-SCENE][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step4: ì´ë¯¸ì§€ ìƒì„± API (Gemini / FLUX.1 Pro / DALL-E 3 ì„ íƒ) =====
@app.route('/api/drama/generate-image', methods=['POST'])
def api_generate_image():
    """ì´ë¯¸ì§€ ìƒì„± - Gemini (ê¸°ë³¸, OpenRouter) / FLUX.1 Pro / DALL-E 3"""
    try:
        import requests as req

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        prompt = data.get("prompt", "")
        size = data.get("size", "1024x1024")
        image_provider = data.get("imageProvider", "gemini")  # gemini, flux, dalle

        print(f"[DRAMA-STEP4-IMAGE] ìš”ì²­ ìˆ˜ì‹  - Provider: {image_provider}, Size: {size}")
        print(f"[DRAMA-STEP4-IMAGE] í”„ë¡¬í”„íŠ¸ ê¸¸ì´: {len(prompt)} ê¸€ì")

        if not prompt:
            return jsonify({"ok": False, "error": "í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        # Gemini 3 Pro Image (image ëª¨ë“ˆ ì‚¬ìš©) - ê³ í’ˆì§ˆ ì”¬ ì´ë¯¸ì§€
        if image_provider == "gemini":
            print(f"[DRAMA-STEP4-IMAGE] Gemini 3 Pro ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ - ìš”ì²­ ì‚¬ì´ì¦ˆ: {size}")

            # image ëª¨ë“ˆì˜ generate_image ì‚¬ìš© (Gemini 3 Pro - ê³ í’ˆì§ˆ)
            result = image_generate(prompt=prompt, size=size, model=GEMINI_PRO)

            if not result.get("ok"):
                return jsonify({"ok": False, "error": result.get("error", "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")}), 200

            cost_usd = result.get("cost", 0.05)  # Gemini 3 Pro ê¸°ë³¸ ë¹„ìš©
            cost_krw = int(cost_usd * 1350)

            return jsonify({
                "ok": True,
                "imageUrl": result.get("image_url"),
                "cost": cost_krw,
                "costUsd": cost_usd,
                "provider": "gemini"
            })

        # FLUX.1 Pro (Replicate API)
        elif image_provider == "flux":
            replicate_api_key = os.getenv("REPLICATE_API_TOKEN", "")

            if not replicate_api_key:
                return jsonify({"ok": False, "error": "Replicate API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ REPLICATE_API_TOKENì„ ì„¤ì •í•´ì£¼ì„¸ìš”."}), 200

            # ì‚¬ì´ì¦ˆ ë³€í™˜ (FLUXëŠ” aspect_ratio ì‚¬ìš©)
            if size == "1792x1024":
                aspect_ratio = "16:9"
                width, height = 1344, 768
            elif size == "1024x1792":
                aspect_ratio = "9:16"
                width, height = 768, 1344
            else:
                aspect_ratio = "1:1"
                width, height = 1024, 1024

            print(f"[DRAMA-STEP4-IMAGE] FLUX.1 Pro ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ - ì‚¬ì´ì¦ˆ: {aspect_ratio}")

            # í”„ë¡¬í”„íŠ¸ì— ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ê°€ ë° í•œêµ­ ì¸ì¢… ê°•ì¡°
            if "Korean" in prompt or "korean" in prompt:
                # í•œêµ­ì¸ ì™¸ëª¨ íŠ¹ì§•ì„ í”„ë¡¬í”„íŠ¸ ì‹œì‘ ë¶€ë¶„ì— ìµœìš°ì„  ë°°ì¹˜
                korean_features = "CRITICAL: authentic Korean person from South Korea with Korean/East Asian ethnicity, Korean facial bone structure, Korean skin tone."
                enhanced_prompt = f"{korean_features} {prompt}, cinematic Korean drama style, professional photography, 8k resolution, detailed"
            else:
                enhanced_prompt = f"{prompt}, high quality, photorealistic, cinematic lighting, professional photography, 8k resolution, detailed"

            # Replicate API í˜¸ì¶œ (FLUX.1 Pro)
            headers = {
                "Authorization": f"Token {replicate_api_key}",
                "Content-Type": "application/json"
            }

            # FLUX.1 Pro ëª¨ë¸
            payload = {
                "version": "black-forest-labs/flux-pro",
                "input": {
                    "prompt": enhanced_prompt,
                    "aspect_ratio": aspect_ratio,
                    "output_format": "png",
                    "output_quality": 90,
                    "safety_tolerance": 2
                }
            }

            # ì˜ˆì¸¡ ìƒì„±
            response = req.post(
                "https://api.replicate.com/v1/models/black-forest-labs/flux-pro/predictions",
                headers=headers,
                json={"input": payload["input"]}
            )

            if response.status_code != 201:
                error_text = response.text
                print(f"[DRAMA-STEP4-IMAGE][ERROR] Replicate API ì‘ë‹µ: {response.status_code} - {error_text}")
                return jsonify({"ok": False, "error": f"FLUX API ì˜¤ë¥˜: {error_text}"}), 200

            prediction = response.json()
            prediction_id = prediction.get("id")

            # ê²°ê³¼ í´ë§ (ìµœëŒ€ 60ì´ˆ)
            import time
            max_wait = 60
            waited = 0
            image_url = None

            while waited < max_wait:
                status_response = req.get(
                    f"https://api.replicate.com/v1/predictions/{prediction_id}",
                    headers=headers
                )
                status_data = status_response.json()
                status = status_data.get("status")

                if status == "succeeded":
                    output = status_data.get("output")
                    if isinstance(output, list) and len(output) > 0:
                        image_url = output[0]
                    elif isinstance(output, str):
                        image_url = output
                    break
                elif status == "failed":
                    error = status_data.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜")
                    return jsonify({"ok": False, "error": f"FLUX ìƒì„± ì‹¤íŒ¨: {error}"}), 200

                time.sleep(2)
                waited += 2

            if not image_url:
                return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ìƒì„± ì‹œê°„ ì´ˆê³¼"}), 200

            # FLUX.1 Pro ë¹„ìš©: $0.055/ì¥
            cost_usd = 0.055
            cost_krw = int(cost_usd * 1350)

            print(f"[DRAMA-STEP4-IMAGE] FLUX.1 Pro ì™„ë£Œ - ë¹„ìš©: ${cost_usd}")

            return jsonify({
                "ok": True,
                "imageUrl": image_url,
                "cost": cost_krw,
                "costUsd": cost_usd,
                "provider": "flux"
            })

        # DALL-E 3 (ê¸°ì¡´ ì½”ë“œ)
        else:
            print(f"[DRAMA-STEP4-IMAGE] DALL-E 3 ë¶„ê¸° ì§„ì… (provider: {image_provider})")

            # í—ˆìš©ëœ ì‚¬ì´ì¦ˆ ê²€ì¦
            allowed_sizes = ["1024x1024", "1792x1024", "1024x1792"]
            if size not in allowed_sizes:
                size = "1024x1024"

            print(f"[DRAMA-STEP4-IMAGE] DALL-E 3 ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ - ì‚¬ì´ì¦ˆ: {size}")

            # í”„ë¡¬í”„íŠ¸ì— ìŠ¤íƒ€ì¼ ê°€ì´ë“œ ì¶”ê°€ ë° í•œêµ­ ì¸ì¢… ê°•ì¡°
            if "Korean" in prompt or "korean" in prompt:
                # í•œêµ­ì¸ ì™¸ëª¨ íŠ¹ì§•ì„ í”„ë¡¬í”„íŠ¸ ì‹œì‘ ë¶€ë¶„ì— ìµœìš°ì„  ë°°ì¹˜
                korean_features = "CRITICAL: authentic Korean person from South Korea with Korean/East Asian ethnicity, Korean facial bone structure, Korean skin tone."
                enhanced_prompt = f"{korean_features} {prompt}, cinematic Korean drama style, professional photography, 8k resolution"
            else:
                enhanced_prompt = f"{prompt}, high quality, photorealistic, cinematic lighting, professional photography, 8k resolution"

            # DALL-E 3 API í˜¸ì¶œ
            response = client.images.generate(
                model="dall-e-3",
                prompt=enhanced_prompt,
                size=size,
                quality="standard",
                n=1
            )

            image_url = response.data[0].url

            # DALL-E 3 ë¹„ìš© ê³„ì‚°
            cost_usd = 0.04 if size == "1024x1024" else 0.08
            cost_krw = int(cost_usd * 1350)

            print(f"[DRAMA-STEP4-IMAGE] DALL-E 3 ì™„ë£Œ - ë¹„ìš©: ${cost_usd}")

            return jsonify({
                "ok": True,
                "imageUrl": image_url,
                "cost": cost_krw,
                "costUsd": cost_usd,
                "provider": "dalle"
            })

    except Exception as e:
        error_msg = str(e)
        print(f"[DRAMA-STEP4-IMAGE][ERROR] {error_msg}")

        if "content_policy" in error_msg.lower():
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ìƒì„±ì´ ì½˜í…ì¸  ì •ì±…ì— ìœ„ë°°ë©ë‹ˆë‹¤. í”„ë¡¬í”„íŠ¸ë¥¼ ìˆ˜ì •í•´ì£¼ì„¸ìš”."}), 200
        elif "rate_limit" in error_msg.lower():
            return jsonify({"ok": False, "error": "API ìš”ì²­ í•œë„ë¥¼ ì´ˆê³¼í–ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”."}), 200

        return jsonify({"ok": False, "error": error_msg}), 200


# ===== MP3 ì²­í¬ ë³‘í•© (FFmpeg ê¸°ë°˜) =====
def merge_audio_chunks_ffmpeg(audio_data_list):
    """ì—¬ëŸ¬ MP3 ë°”ì´íŠ¸ ë°ì´í„°ë¥¼ FFmpegë¡œ ë³‘í•©"""
    import tempfile
    import subprocess
    import shutil
    import gc  # ë©”ëª¨ë¦¬ ì •ë¦¬ìš©

    if not audio_data_list:
        return b''

    if len(audio_data_list) == 1:
        return audio_data_list[0]

    ffmpeg_path = shutil.which('ffmpeg')
    if not ffmpeg_path:
        # FFmpeg ì—†ìœ¼ë©´ ë‹¨ìˆœ ê²°í•© (í´ë°±)
        print("[TTS-MERGE][WARN] FFmpeg ì—†ìŒ, ë‹¨ìˆœ ë°”ì´íŠ¸ ê²°í•© ì‚¬ìš©")
        return b''.join(audio_data_list)

    try:
        with tempfile.TemporaryDirectory() as tmpdir:
            # ê° ì²­í¬ë¥¼ ì„ì‹œ íŒŒì¼ë¡œ ì €ì¥
            chunk_files = []
            for i, chunk_data in enumerate(audio_data_list):
                chunk_path = os.path.join(tmpdir, f"chunk_{i:03d}.mp3")
                with open(chunk_path, 'wb') as f:
                    f.write(chunk_data)
                chunk_files.append(chunk_path)

            # FFmpeg concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
            list_path = os.path.join(tmpdir, "concat_list.txt")
            with open(list_path, 'w') as f:
                for chunk_path in chunk_files:
                    f.write(f"file '{chunk_path}'\n")

            # ì¶œë ¥ íŒŒì¼
            output_path = os.path.join(tmpdir, "merged.mp3")

            # FFmpeg concat ì‹¤í–‰
            cmd = [
                'ffmpeg', '-y',
                '-f', 'concat',
                '-safe', '0',
                '-i', list_path,
                '-c', 'copy',  # ì¬ì¸ì½”ë”© ì—†ì´ ë³‘í•©
                output_path
            ]

            # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPE (OOM ë°©ì§€)
            result = subprocess.run(
                cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                timeout=60
            )

            if result.returncode != 0:
                stderr_msg = result.stderr[:200].decode('utf-8', errors='ignore') if result.stderr else '(stderr ì—†ìŒ)'
                print(f"[TTS-MERGE][ERROR] FFmpeg ì‹¤íŒ¨: {stderr_msg}")
                del result
                gc.collect()
                # í´ë°±: ë‹¨ìˆœ ë°”ì´íŠ¸ ê²°í•©
                return b''.join(audio_data_list)
            del result
            gc.collect()

            # ë³‘í•©ëœ íŒŒì¼ ì½ê¸°
            with open(output_path, 'rb') as f:
                merged_audio = f.read()

            print(f"[TTS-MERGE] FFmpeg ë³‘í•© ì™„ë£Œ: {len(audio_data_list)}ê°œ ì²­í¬ â†’ {len(merged_audio)} bytes")
            return merged_audio

    except Exception as e:
        print(f"[TTS-MERGE][ERROR] ë³‘í•© ì‹¤íŒ¨: {e}")
        # í´ë°±: ë‹¨ìˆœ ë°”ì´íŠ¸ ê²°í•©
        return b''.join(audio_data_list)


# ===== TTS ìŒì„± ì‚¬ì „ ê²€ì¦ (íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì‹œ í˜¸ì¶œ) =====
def validate_tts_voice(voice: str) -> dict:
    """
    TTS ìŒì„± ì‚¬ì „ ê²€ì¦ - ë¹„ì‹¼ ì‘ì—… ì „ì— ìŒì„± ì„¤ì •ê³¼ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜ í™•ì¸

    Args:
        voice: ìŒì„± ì´ë¦„ (chirp3:Charon, gemini:Kore, ko-KR-Neural2-C ë“±)

    Returns:
        dict: {"ok": True, "voice_type": "chirp3"} ë˜ëŠ” {"ok": False, "error": str}

    ìŒì„± ìœ í˜•ë³„ í•„ìˆ˜ í™˜ê²½ë³€ìˆ˜:
    - chirp3:*  â†’ GOOGLE_SERVICE_ACCOUNT_JSON
    - gemini:*  â†’ GOOGLE_API_KEY
    - ko-KR-*, ja-JP-*, en-US-* â†’ GOOGLE_CLOUD_API_KEY
    """
    if not voice:
        return {"ok": False, "error": "ìŒì„±ì´ ì§€ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}

    voice_lower = voice.lower()

    # ========== Chirp3 HD TTS ==========
    if voice.startswith("chirp3:") or "chirp3" in voice_lower:
        voice_type = "chirp3"
        required_env = "GOOGLE_SERVICE_ACCOUNT_JSON"
        env_value = os.environ.get(required_env, "")

        if not env_value:
            return {
                "ok": False,
                "error": f"Chirp3 TTS ì‚¬ìš©ì„ ìœ„í•´ {required_env} í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "voice_type": voice_type
            }

        # Chirp3 ìŒì„± ì´ë¦„ ê²€ì¦
        valid_chirp3_voices = ["Charon", "Kore", "Fenrir", "Aoede", "Puck"]
        voice_name = voice.split(":")[-1] if ":" in voice else voice
        if voice_name not in valid_chirp3_voices:
            return {
                "ok": False,
                "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” Chirp3 ìŒì„±: {voice_name} (ì§€ì›: {', '.join(valid_chirp3_voices)})",
                "voice_type": voice_type
            }

        return {"ok": True, "voice_type": voice_type, "voice_name": voice_name}

    # ========== Gemini TTS ==========
    elif voice.startswith("gemini:"):
        voice_type = "gemini"
        required_env = "GOOGLE_API_KEY"
        env_value = os.environ.get(required_env, "")

        if not env_value:
            return {
                "ok": False,
                "error": f"Gemini TTS ì‚¬ìš©ì„ ìœ„í•´ {required_env} í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "voice_type": voice_type
            }

        # Gemini ìŒì„± ì´ë¦„ ê²€ì¦
        valid_gemini_voices = ["Kore", "Charon", "Puck", "Fenrir", "Aoede"]
        parts = voice.split(":")
        voice_name = parts[-1] if len(parts) > 1 else "Kore"
        if voice_name not in valid_gemini_voices:
            return {
                "ok": False,
                "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” Gemini ìŒì„±: {voice_name} (ì§€ì›: {', '.join(valid_gemini_voices)})",
                "voice_type": voice_type
            }

        return {"ok": True, "voice_type": voice_type, "voice_name": voice_name}

    # ========== Google Cloud TTS ==========
    elif voice.startswith("ko-KR-") or voice.startswith("ja-JP-") or voice.startswith("en-US-"):
        voice_type = "google_cloud"
        required_env = "GOOGLE_CLOUD_API_KEY"
        env_value = os.environ.get(required_env, "")

        if not env_value:
            return {
                "ok": False,
                "error": f"Google Cloud TTS ì‚¬ìš©ì„ ìœ„í•´ {required_env} í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤",
                "voice_type": voice_type
            }

        return {"ok": True, "voice_type": voice_type, "voice_name": voice}

    # ========== ì•Œ ìˆ˜ ì—†ëŠ” ìŒì„± ==========
    else:
        return {
            "ok": False,
            "error": f"ì§€ì›ë˜ì§€ ì•ŠëŠ” ìŒì„± í˜•ì‹: {voice} (ì§€ì›: chirp3:*, gemini:*, ko-KR-*, ja-JP-*, en-US-*)"
        }


# ===== TTS í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ì˜ë¬¸ ì¸ëª… ê´„í˜¸ ì œê±°) =====
def preprocess_tts_text(text: str) -> str:
    """
    TTSìš© í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ - ì˜ë¬¸ ì¸ëª… ê´„í˜¸ ì œê±°

    ìë§‰: ë‹ˆì½œë¼ì´ í‹°ë³´-ë¸Œë¦¬ë‡°(Nikolay Thibeaux-Brignolle)
    TTS: "ë‹ˆì½œë¼ì´ í‹°ë³´-ë¸Œë¦¬ë‡°" (ì˜ë¬¸ ë¶€ë¶„ì€ ì½ì§€ ì•ŠìŒ)

    ë‹¨ì²´ëª…(KGB, FBI ë“±)ì€ ê´„í˜¸ ì—†ì´ ì‚¬ìš©ë˜ë¯€ë¡œ ì˜í–¥ ì—†ìŒ

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        ì˜ë¬¸ ì¸ëª… ê´„í˜¸ê°€ ì œê±°ëœ í…ìŠ¤íŠ¸
    """
    import re

    # ì˜ë¬¸ ì¸ëª… íŒ¨í„´: (ëŒ€ë¬¸ìë¡œ ì‹œì‘í•˜ëŠ” ì˜ë¬¸ ì´ë¦„)
    # ì˜ˆ: (Igor Dyatlov), (Nikolay Thibeaux-Brignolle), (Mary Celeste)
    # íŒ¨í„´: ( + ëŒ€ë¬¸ì + ì˜ë¬¸/ê³µë°±/í•˜ì´í”ˆ/ì•„í¬ìŠ¤íŠ¸ë¡œí”¼ + )
    pattern = r'\([A-Z][a-zA-Z\-\s\'\.]+\)'

    result = re.sub(pattern, '', text)

    # ì—°ì† ê³µë°± ì •ë¦¬
    result = re.sub(r'  +', ' ', result)

    return result


# ===== TTS í…ìŠ¤íŠ¸ í™•ì¥ ì „ì²˜ë¦¬ (ì˜ë¬¸ ì•½ì–´, íŠ¹ìˆ˜ê¸°í˜¸, ì´ëª¨ì§€ ë“±) =====
def preprocess_tts_extended(text: str) -> str:
    """
    TTSìš© í™•ì¥ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (2025-12-23 ì¶”ê°€)

    ì²˜ë¦¬ í•­ëª©:
    1. ì˜ë¬¸ ì•½ì–´ â†’ ë°œìŒ (CEO â†’ ì”¨ì´ì˜¤)
    2. íŠ¹ìˆ˜ ê¸°í˜¸ â†’ í•œê¸€ (& â†’ ì•¤ë“œ, @ â†’ ì•³)
    3. í†µí™” ê¸°í˜¸ â†’ í•œê¸€ ($ â†’ ë‹¬ëŸ¬, â‚¬ â†’ ìœ ë¡œ)
    4. ì˜¨ë„ ê¸°í˜¸ â†’ í•œê¸€ (â„ƒ â†’ ë„ì”¨)
    5. URL/ì´ë©”ì¼ â†’ ì œê±°
    6. ì´ëª¨ì§€ â†’ ì œê±°
    7. íŠ¹ìˆ˜ ë¬¸ì¥ë¶€í˜¸ â†’ ì •ë¦¬

    Args:
        text: ì›ë³¸ í…ìŠ¤íŠ¸

    Returns:
        TTSì— ìµœì í™”ëœ í…ìŠ¤íŠ¸
    """
    import re

    if not text:
        return text

    # ===== 1. URL ì œê±° (ë¨¼ì € ì²˜ë¦¬ - ë‹¤ë¥¸ íŒ¨í„´ ë°©í•´ ë°©ì§€) =====
    # https://example.com, http://example.com, www.example.com
    text = re.sub(r'https?://[^\s<>\"\']+', '', text)
    text = re.sub(r'www\.[^\s<>\"\']+', '', text)

    # ===== 2. ì´ë©”ì¼ ì œê±° =====
    # example@domain.com
    text = re.sub(r'[a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,}', '', text)

    # ===== 3. ì´ëª¨ì§€ ì œê±° =====
    # ìœ ë‹ˆì½”ë“œ ì´ëª¨ì§€ ë²”ìœ„ ì œê±° (í•œê¸€ ë²”ìœ„ AC00-D7AF ì œì™¸!)
    emoji_pattern = re.compile(
        "["
        "\U0001F600-\U0001F64F"  # í‘œì • ì´ëª¨ì§€
        "\U0001F300-\U0001F5FF"  # ê¸°í˜¸ & í”½í† ê·¸ë¨
        "\U0001F680-\U0001F6FF"  # êµí†µ & ì§€ë„
        "\U0001F1E0-\U0001F1FF"  # êµ­ê¸°
        "\U0001F900-\U0001F9FF"  # ë³´ì¡° ê¸°í˜¸
        "\U0001FA00-\U0001FA6F"  # ì²´ìŠ¤ ê¸°í˜¸
        "\U0001FA70-\U0001FAFF"  # ê¸°í˜¸ í™•ì¥
        "\U0001F200-\U0001F251"  # ê´„í˜¸ ë¬¸ì (í•œê¸€ ë²”ìœ„ í”¼í•¨)
        "]+",
        flags=re.UNICODE
    )
    text = emoji_pattern.sub('', text)

    # ===== 4. í†µí™” ê¸°í˜¸ â†’ í•œê¸€ =====
    currency_map = {
        '$': 'ë‹¬ëŸ¬',
        'â‚¬': 'ìœ ë¡œ',
        'Â¥': 'ì—”',
        'Â£': 'íŒŒìš´ë“œ',
        'â‚©': 'ì›',
        'â‚¿': 'ë¹„íŠ¸ì½”ì¸',
    }
    for symbol, korean in currency_map.items():
        # $100 â†’ 100ë‹¬ëŸ¬ (ìˆ«ì ì•ì— ì˜¤ëŠ” ê²½ìš°)
        text = re.sub(rf'\{symbol}(\d)', rf'\1{korean}', text)
        # 100$ â†’ 100ë‹¬ëŸ¬ (ìˆ«ì ë’¤ì— ì˜¤ëŠ” ê²½ìš°)
        text = re.sub(rf'(\d)\{symbol}', rf'\1{korean}', text)
        # ë‹¨ë… ê¸°í˜¸ëŠ” í•œê¸€ë¡œ (ì˜ˆ: "$ í™˜ìœ¨")
        text = text.replace(symbol, korean)

    # ===== 5. ì˜¨ë„ ê¸°í˜¸ â†’ í•œê¸€ =====
    text = text.replace('â„ƒ', 'ë„ì”¨')
    text = text.replace('â„‰', 'í™”ì”¨')
    text = text.replace('Â°C', 'ë„ì”¨')
    text = text.replace('Â°F', 'í™”ì”¨')
    # ë‹¨ë… Â°ëŠ” "ë„"ë¡œ (ì˜ˆ: 30Â° â†’ 30ë„)
    text = re.sub(r'(\d)Â°(?![CF])', r'\1ë„', text)

    # ===== 6. íŠ¹ìˆ˜ ê¸°í˜¸ â†’ í•œê¸€ =====
    symbol_map = {
        '&': 'ì•¤ë“œ',
        '@': 'ì•³',
        '#': 'í•´ì‹œ',
        'â€»': '',  # ì°¸ê³  ê¸°í˜¸ ì œê±°
        'â˜…': '',  # ë³„í‘œ ì œê±°
        'â˜†': '',
        'â—': '',
        'â—‹': '',
        'â—†': '',
        'â—‡': '',
        'â– ': '',
        'â–¡': '',
        'â–¶': '',
        'â—€': '',
        'â†’': '',
        'â†': '',
        'â†‘': '',
        'â†“': '',
        'â€”': ' ',  # em dash â†’ ê³µë°±
        'â€“': ' ',  # en dash â†’ ê³µë°±
        'â€¦': '...',  # ë§ì¤„ì„í‘œ ì •ê·œí™”
        'Â·': ' ',  # ê°€ìš´ëƒì  â†’ ê³µë°±
        'ã€Œ': '',  # êº¾ì‡  ì œê±°
        'ã€': '',
        'ã€': '',
        'ã€': '',
        'ã€ˆ': '',
        'ã€‰': '',
        'ã€Š': '',
        'ã€‹': '',
    }
    for symbol, replacement in symbol_map.items():
        text = text.replace(symbol, replacement)

    # ===== 7. ìˆ˜í•™ ê¸°í˜¸ â†’ í•œê¸€ =====
    math_map = {
        'Â±': 'í”ŒëŸ¬ìŠ¤ë§ˆì´ë„ˆìŠ¤',
        'âˆ': 'ë¬´í•œëŒ€',
        'âˆš': 'ë£¨íŠ¸',
        'â‰¤': 'ì´í•˜',
        'â‰¥': 'ì´ìƒ',
        'â‰ ': 'ê°™ì§€ì•ŠìŒ',
        'â‰ˆ': 'ì•½',
        'âˆ´': 'ë”°ë¼ì„œ',
        'âˆµ': 'ì™œëƒí•˜ë©´',
    }
    for symbol, korean in math_map.items():
        text = text.replace(symbol, korean)

    # ===== 8. ì˜ë¬¸ ì•½ì–´ â†’ ë°œìŒ (ëŒ€ë¬¸ì 2~6ê¸€ì) =====
    # ì˜ ì•Œë ¤ì§„ ì•½ì–´ ì‚¬ì „
    abbreviation_map = {
        # ê¸°ê´€/ì¡°ì§
        'CEO': 'ì”¨ì´ì˜¤',
        'CFO': 'ì”¨ì—í”„ì˜¤',
        'CTO': 'ì”¨í‹°ì˜¤',
        'COO': 'ì”¨ì˜¤ì˜¤',
        'UN': 'ìœ ì—”',
        'UNESCO': 'ìœ ë„¤ìŠ¤ì½”',
        'WHO': 'ë”ë¸”ìœ ì—ì´ì¹˜ì˜¤',
        'NATO': 'ë‚˜í† ',
        'OECD': 'ì˜¤ì´ì”¨ë””',
        'IMF': 'ì•„ì´ì— ì—í”„',
        'FBI': 'ì—í”„ë¹„ì•„ì´',
        'CIA': 'ì”¨ì•„ì´ì—ì´',
        'NASA': 'ë‚˜ì‚¬',
        'EU': 'ì´ìœ ',
        'ASEAN': 'ì•„ì„¸ì•ˆ',
        'OPEC': 'ì˜¤í™',
        # ê¸°ìˆ 
        'AI': 'ì—ì´ì•„ì´',
        'IT': 'ì•„ì´í‹°',
        'PC': 'í”¼ì”¨',
        'USB': 'ìœ ì—ìŠ¤ë¹„',
        'URL': 'ìœ ì•Œì—˜',
        'API': 'ì—ì´í”¼ì•„ì´',
        'SDK': 'ì—ìŠ¤ë””ì¼€ì´',
        'CPU': 'ì”¨í”¼ìœ ',
        'GPU': 'ì§€í”¼ìœ ',
        'RAM': 'ë¨',
        'ROM': 'ë¡¬',
        'SSD': 'ì—ìŠ¤ì—ìŠ¤ë””',
        'HDD': 'ì—ì´ì¹˜ë””ë””',
        'LED': 'ì—˜ì´ë””',
        'LCD': 'ì—˜ì”¨ë””',
        'OLED': 'ì˜¤ì—˜ì´ë””',
        'VR': 'ë¸Œì´ì•Œ',
        'AR': 'ì—ì´ì•Œ',
        'IoT': 'ì•„ì´ì˜¤í‹°',
        'GPS': 'ì§€í”¼ì—ìŠ¤',
        'WIFI': 'ì™€ì´íŒŒì´',
        'LTE': 'ì—˜í‹°ì´',
        '5G': 'ì˜¤ì§€',
        '4G': 'ì‚¬ì§€',
        '3G': 'ì‚¼ì§€',
        'QR': 'íì•Œ',
        'PDF': 'í”¼ë””ì—í”„',
        'JPG': 'ì œì´í”¼ì§€',
        'PNG': 'í”¼ì—”ì§€',
        'GIF': 'ì§€í”„',
        'MP3': 'ì— í”¼ì“°ë¦¬',
        'MP4': 'ì— í”¼í¬',
        # ê²½ì œ/ê¸ˆìœµ
        'GDP': 'ì§€ë””í”¼',
        'GNP': 'ì§€ì—”í”¼',
        'ETF': 'ì´í‹°ì—í”„',
        'IPO': 'ì•„ì´í”¼ì˜¤',
        'M&A': 'ì— ì•¤ì—ì´',
        'ROI': 'ì•Œì˜¤ì•„ì´',
        'ESG': 'ì´ì—ìŠ¤ì§€',
        # ì˜ë£Œ
        'CT': 'ì”¨í‹°',
        'MRI': 'ì— ì•Œì•„ì´',
        'DNA': 'ë””ì—”ì—ì´',
        'RNA': 'ì•Œì—”ì—ì´',
        'PCR': 'í”¼ì”¨ì•Œ',
        'ICU': 'ì•„ì´ì”¨ìœ ',
        'ER': 'ì´ì•Œ',
        # ê¸°íƒ€
        'TV': 'í‹°ë¹„',
        'SNS': 'ì—ìŠ¤ì—”ì—ìŠ¤',
        'PR': 'í”¼ì•Œ',
        'HR': 'ì—ì´ì¹˜ì•Œ',
        'OK': 'ì˜¤ì¼€ì´',
        'VS': 'ë²„ì„œìŠ¤',
        'DIY': 'ë””ì•„ì´ì™€ì´',
        'FAQ': 'ì—í”„ì—ì´í',
        'VIP': 'ë¸Œì´ì•„ì´í”¼',
        'MVP': 'ì— ë¸Œì´í”¼',
        'A/S': 'ì—ì´ì—ìŠ¤',
        'AS': 'ì—ì´ì—ìŠ¤',
        'OTT': 'ì˜¤í‹°í‹°',
        'PPT': 'í”¼í”¼í‹°',
        'BTS': 'ë¹„í‹°ì—ìŠ¤',
        'K-POP': 'ì¼€ì´íŒ',
        'KPOP': 'ì¼€ì´íŒ',
    }

    # ì‚¬ì „ì— ìˆëŠ” ì•½ì–´ ë¨¼ì € ì²˜ë¦¬ (ëŒ€ì†Œë¬¸ì ë¬´ê´€)
    for abbr, korean in abbreviation_map.items():
        # ë‹¨ì–´ ê²½ê³„ì—ì„œë§Œ ë§¤ì¹­ (ì•ë’¤ë¡œ í•œê¸€/ì˜ë¬¸ ì—†ì„ ë•Œ)
        pattern = rf'(?<![ê°€-í£a-zA-Z]){re.escape(abbr)}(?![ê°€-í£a-zA-Z])'
        text = re.sub(pattern, korean, text, flags=re.IGNORECASE)

    # ì‚¬ì „ì— ì—†ëŠ” ëŒ€ë¬¸ì ì•½ì–´ â†’ ê°œë³„ ì•ŒíŒŒë²³ ë°œìŒ
    # ëŒ€ë¬¸ì 2~6ê¸€ì ì—°ì† (ì‚¬ì „ì— ì—†ëŠ” ê²ƒë§Œ)
    def spell_out_abbreviation(match):
        abbr = match.group(0)
        # ì´ë¯¸ ì‚¬ì „ì—ì„œ ì²˜ë¦¬ëœ ê²½ìš° ìŠ¤í‚µ
        if abbr.upper() in abbreviation_map:
            return abbr
        # ê° ê¸€ìë¥¼ ë°œìŒìœ¼ë¡œ ë³€í™˜
        letter_sounds = {
            'A': 'ì—ì´', 'B': 'ë¹„', 'C': 'ì”¨', 'D': 'ë””', 'E': 'ì´',
            'F': 'ì—í”„', 'G': 'ì§€', 'H': 'ì—ì´ì¹˜', 'I': 'ì•„ì´', 'J': 'ì œì´',
            'K': 'ì¼€ì´', 'L': 'ì—˜', 'M': 'ì— ', 'N': 'ì—”', 'O': 'ì˜¤',
            'P': 'í”¼', 'Q': 'í', 'R': 'ì•Œ', 'S': 'ì—ìŠ¤', 'T': 'í‹°',
            'U': 'ìœ ', 'V': 'ë¸Œì´', 'W': 'ë”ë¸”ìœ ', 'X': 'ì—‘ìŠ¤', 'Y': 'ì™€ì´',
            'Z': 'ì œíŠ¸'
        }
        result = ''.join(letter_sounds.get(c.upper(), c) for c in abbr)
        return result

    # ë‹¨ì–´ ê²½ê³„ì˜ ëŒ€ë¬¸ì ì•½ì–´ (2~6ê¸€ì)
    text = re.sub(r'(?<![ê°€-í£a-zA-Z])[A-Z]{2,6}(?![ê°€-í£a-zA-Z])', spell_out_abbreviation, text)

    # ===== 9. ì—°ì† ê³µë°± ì •ë¦¬ =====
    text = re.sub(r'\s+', ' ', text).strip()

    return text


# ===== Gemini TTS í•¨ìˆ˜ (2025ë…„ ì‹ ê·œ) =====
def generate_gemini_tts(text, voice_name="Kore", model="gemini-2.5-flash-preview-tts"):
    """
    Gemini TTS APIë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice_name: ìŒì„± ì´ë¦„ (Kore, Charon, Puck, Fenrir, Aoede)
        model: ëª¨ë¸ëª… (gemini-2.5-flash-preview-tts ë˜ëŠ” gemini-2.5-pro-preview-tts)

    Returns:
        dict: {"ok": True, "audio_data": bytes, "duration": float} ë˜ëŠ” {"ok": False, "error": str}
    """
    import wave
    import io
    import time

    # ì˜ë¬¸ ì¸ëª… ê´„í˜¸ ì œê±° (ìë§‰ì—ëŠ” ë‚¨ê³ , TTSì—ì„œëŠ” ì½ì§€ ì•ŠìŒ)
    text = preprocess_tts_text(text)

    # í™•ì¥ ì „ì²˜ë¦¬: ì˜ë¬¸ ì•½ì–´, íŠ¹ìˆ˜ê¸°í˜¸, ì´ëª¨ì§€, URL ë“± (2025-12-23)
    text = preprocess_tts_extended(text)

    api_key = os.getenv("GOOGLE_API_KEY", "")
    if not api_key:
        print("[GEMINI-TTS] GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤")
        return {"ok": False, "error": "GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}

    # ìœ íš¨í•œ ìŒì„± í™•ì¸
    valid_voices = ["Kore", "Charon", "Puck", "Fenrir", "Aoede"]
    if voice_name not in valid_voices:
        print(f"[GEMINI-TTS] ì˜ëª»ëœ ìŒì„±: {voice_name}, ê¸°ë³¸ê°’ Kore ì‚¬ìš©")
        voice_name = "Kore"

    print(f"[GEMINI-TTS] ì‹œì‘ - ëª¨ë¸: {model}, ìŒì„±: {voice_name}, í…ìŠ¤íŠ¸: {len(text)}ì")

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{model}:generateContent?key={api_key}"

        payload = {
            "contents": [{"parts": [{"text": text}]}],
            "generationConfig": {
                "responseModalities": ["AUDIO"],
                "speechConfig": {
                    "voiceConfig": {
                        "prebuiltVoiceConfig": {
                            "voiceName": voice_name
                        }
                    }
                }
            }
        }

        # 429 Rate Limit ì¬ì‹œë„ ë¡œì§
        max_retries = 3
        for attempt in range(max_retries):
            response = requests.post(url, json=payload, timeout=120)

            if response.status_code == 429:
                # Rate limit - ëŒ€ê¸° í›„ ì¬ì‹œë„
                error_text = response.text
                # "Please retry in 39.077546084s" í˜•íƒœì—ì„œ ì‹œê°„ ì¶”ì¶œ
                import re
                retry_match = re.search(r'retry in (\d+\.?\d*)', error_text)
                wait_time = float(retry_match.group(1)) if retry_match else 45.0
                wait_time = min(wait_time + 5, 60)  # ì—¬ìœ  5ì´ˆ ì¶”ê°€, ìµœëŒ€ 60ì´ˆ

                if attempt < max_retries - 1:
                    print(f"[GEMINI-TTS] Rate limit (429), {wait_time:.0f}ì´ˆ ëŒ€ê¸° í›„ ì¬ì‹œë„ ({attempt + 1}/{max_retries})...")
                    time.sleep(wait_time)
                    continue
                else:
                    print(f"[GEMINI-TTS] Rate limit ì¬ì‹œë„ ì´ˆê³¼")
                    return {"ok": False, "error": "Gemini TTS Rate limit ì´ˆê³¼ (ì¬ì‹œë„ ì‹¤íŒ¨)"}

            elif response.status_code != 200:
                error_text = response.text[:500]
                print(f"[GEMINI-TTS] API ì˜¤ë¥˜: {response.status_code} - {error_text}")
                return {"ok": False, "error": f"Gemini TTS API ì˜¤ë¥˜: {response.status_code}"}

            break  # ì„±ê³µ

        result = response.json()

        # ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ
        candidates = result.get("candidates", [])
        if not candidates:
            return {"ok": False, "error": "ì‘ë‹µì— candidatesê°€ ì—†ìŠµë‹ˆë‹¤"}

        content = candidates[0].get("content", {})
        parts = content.get("parts", [])

        audio_data = None
        for part in parts:
            inline_data = part.get("inlineData", {})
            if inline_data.get("mimeType", "").startswith("audio/"):
                import base64
                audio_data = base64.b64decode(inline_data.get("data", ""))
                break

        if not audio_data:
            return {"ok": False, "error": "ì‘ë‹µì— ì˜¤ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}

        # PCMì„ WAVë¡œ ë³€í™˜ (24kHz, 16bit, mono)
        wav_buffer = io.BytesIO()
        with wave.open(wav_buffer, 'wb') as wf:
            wf.setnchannels(1)
            wf.setsampwidth(2)
            wf.setframerate(24000)
            wf.writeframes(audio_data)

        wav_data = wav_buffer.getvalue()

        # ì¬ìƒ ì‹œê°„ ê³„ì‚°
        duration = len(audio_data) / (24000 * 2)  # 24kHz, 16bit

        print(f"[GEMINI-TTS] ì™„ë£Œ - í¬ê¸°: {len(wav_data)}bytes, ê¸¸ì´: {duration:.1f}ì´ˆ")

        return {
            "ok": True,
            "audio_data": wav_data,
            "duration": duration,
            "format": "wav"
        }

    except requests.exceptions.Timeout:
        print("[GEMINI-TTS] íƒ€ì„ì•„ì›ƒ")
        return {"ok": False, "error": "Gemini TTS íƒ€ì„ì•„ì›ƒ (120ì´ˆ)"}
    except Exception as e:
        print(f"[GEMINI-TTS] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}


def convert_gemini_wav_to_mp3(wav_data):
    """Gemini TTSì˜ WAV ì¶œë ¥ì„ MP3ë¡œ ë³€í™˜"""
    try:
        # ì„ì‹œ íŒŒì¼ë¡œ ë³€í™˜
        with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as wav_file:
            wav_file.write(wav_data)
            wav_path = wav_file.name

        mp3_path = wav_path.replace('.wav', '.mp3')

        # FFmpegë¡œ ë³€í™˜
        cmd = [
            'ffmpeg', '-y', '-i', wav_path,
            '-acodec', 'libmp3lame', '-b:a', '128k',
            mp3_path
        ]

        result = subprocess.run(cmd, capture_output=True, timeout=30)

        if result.returncode == 0 and os.path.exists(mp3_path):
            with open(mp3_path, 'rb') as f:
                mp3_data = f.read()
            os.unlink(wav_path)
            os.unlink(mp3_path)
            return mp3_data
        else:
            os.unlink(wav_path)
            print(f"[GEMINI-TTS] MP3 ë³€í™˜ ì‹¤íŒ¨: {result.stderr.decode()[:200]}")
            return None

    except Exception as e:
        print(f"[GEMINI-TTS] MP3 ë³€í™˜ ì˜¤ë¥˜: {e}")
        return None


def is_gemini_voice(voice_name):
    """Gemini TTS ìŒì„±ì¸ì§€ í™•ì¸ (gemini: ì ‘ë‘ì‚¬)"""
    return voice_name.lower().startswith("gemini:")


def is_chirp3_voice(voice_name):
    """Chirp 3 HD ìŒì„±ì¸ì§€ í™•ì¸ (chirp3: ì ‘ë‘ì‚¬)"""
    return voice_name.lower().startswith("chirp3:")


def parse_chirp3_voice(voice_name, language_code="ko-KR"):
    """
    Chirp 3 HD ìŒì„± ì„¤ì • íŒŒì‹±

    Args:
        voice_name: "chirp3:Charon" í˜•ì‹
        language_code: ì–¸ì–´ ì½”ë“œ (ê¸°ë³¸: ko-KR)

    Returns:
        dict: {"voice": "ko-KR-Chirp3-HD-Charon", "voice_short": "Charon"}
    """
    parts = voice_name.split(":")
    voice_short = parts[1] if len(parts) >= 2 else "Charon"

    # ìœ íš¨í•œ Chirp 3 HD ìŒì„±
    valid_voices = ["Charon", "Puck", "Fenrir", "Orus", "Aoede", "Kore", "Leda", "Zephyr"]
    if voice_short not in valid_voices:
        print(f"[CHIRP3] ì˜ëª»ëœ ìŒì„±: {voice_short}, ê¸°ë³¸ê°’ Charon ì‚¬ìš©")
        voice_short = "Charon"

    # ì „ì²´ ìŒì„± ì´ë¦„: ko-KR-Chirp3-HD-Charon
    full_voice_name = f"{language_code}-Chirp3-HD-{voice_short}"

    return {
        "voice": full_voice_name,
        "voice_short": voice_short
    }


def generate_chirp3_tts(text, voice_name="ko-KR-Chirp3-HD-Charon", language_code="ko-KR"):
    """
    Google Cloud TTS Chirp 3 HDë¥¼ ì‚¬ìš©í•˜ì—¬ ìŒì„± ìƒì„±

    ê¸´ í…ìŠ¤íŠ¸ëŠ” ìë™ìœ¼ë¡œ ì²­í¬ë¡œ ë¶„í• í•˜ì—¬ ì²˜ë¦¬ (5,000ë°”ì´íŠ¸ ì œí•œ)

    Args:
        text: ë³€í™˜í•  í…ìŠ¤íŠ¸
        voice_name: ì „ì²´ ìŒì„± ì´ë¦„ (ì˜ˆ: ko-KR-Chirp3-HD-Charon)
        language_code: ì–¸ì–´ ì½”ë“œ (ì˜ˆ: ko-KR)

    Returns:
        dict: {"ok": True, "audio_data": bytes} ë˜ëŠ” {"ok": False, "error": str}
    """
    # ì˜ë¬¸ ì¸ëª… ê´„í˜¸ ì œê±° (ìë§‰ì—ëŠ” ë‚¨ê³ , TTSì—ì„œëŠ” ì½ì§€ ì•ŠìŒ)
    text = preprocess_tts_text(text)

    # í™•ì¥ ì „ì²˜ë¦¬: ì˜ë¬¸ ì•½ì–´, íŠ¹ìˆ˜ê¸°í˜¸, ì´ëª¨ì§€, URL ë“± (2025-12-23)
    text = preprocess_tts_extended(text)

    try:
        from google.cloud import texttospeech
        from google.oauth2 import service_account
        import json
        import re

        print(f"[CHIRP3-TTS] ì‹œì‘ - ìŒì„±: {voice_name}, í…ìŠ¤íŠ¸: {len(text)}ì", flush=True)

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ (GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        service_account_json = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
        if not service_account_json:
            print("[CHIRP3-TTS] ì˜¤ë¥˜: GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ ì—†ìŒ", flush=True)
            return {"ok": False, "error": "GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}

        try:
            service_account_info = json.loads(service_account_json)
        except json.JSONDecodeError as e:
            print(f"[CHIRP3-TTS] ì˜¤ë¥˜: JSON íŒŒì‹± ì‹¤íŒ¨ - {e}", flush=True)
            return {"ok": False, "error": f"ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì‹± ì‹¤íŒ¨: {e}"}

        credentials = service_account.Credentials.from_service_account_info(
            service_account_info,
            scopes=["https://www.googleapis.com/auth/cloud-platform"]
        )

        client = texttospeech.TextToSpeechClient(credentials=credentials)

        voice = texttospeech.VoiceSelectionParams(
            language_code=language_code,
            name=voice_name,
        )

        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )

        # ì²­í¬ ë¶„í•  (í•œê¸€ 3ë°”ì´íŠ¸ ê¸°ì¤€, 5000ë°”ì´íŠ¸ ì œí•œ â†’ ì•½ 1,500ì)
        MAX_CHARS = 1400  # ì•ˆì „ ë§ˆì§„ í¬í•¨
        MAX_SENTENCE_CHARS = 350  # ë‹¨ì¼ ë¬¸ì¥ ìµœëŒ€ ê¸¸ì´ (TTS ì œí•œ ëŒ€ì‘)

        def split_long_sentence(sentence, max_len=MAX_SENTENCE_CHARS):
            """ê¸´ ë¬¸ì¥ì„ ì‰¼í‘œ/ê³µë°±ì—ì„œ ë¶„í• """
            if len(sentence) <= max_len:
                return [sentence]

            result = []
            # ì‰¼í‘œë¡œ ë¨¼ì € ë¶„í•  ì‹œë„
            parts = re.split(r'(?<=[,ï¼Œã€])\s*', sentence)
            current = ""

            for part in parts:
                if len(current) + len(part) <= max_len:
                    current += part
                else:
                    if current:
                        result.append(current.strip())
                    # ê·¸ë˜ë„ ë„ˆë¬´ ê¸¸ë©´ ê³µë°±ì—ì„œ ë¶„í• 
                    if len(part) > max_len:
                        words = part.split(' ')
                        word_chunk = ""
                        for word in words:
                            if len(word_chunk) + len(word) + 1 <= max_len:
                                word_chunk += " " + word if word_chunk else word
                            else:
                                if word_chunk:
                                    result.append(word_chunk.strip())
                                # ë‹¨ì–´ ìì²´ê°€ ë„ˆë¬´ ê¸¸ë©´ ê°•ì œ ë¶„í• 
                                if len(word) > max_len:
                                    for i in range(0, len(word), max_len):
                                        result.append(word[i:i+max_len])
                                    word_chunk = ""
                                else:
                                    word_chunk = word
                        if word_chunk:
                            current = word_chunk
                        else:
                            current = ""
                    else:
                        current = part

            if current:
                result.append(current.strip())

            return [r for r in result if r]

        def split_text_into_chunks(text, max_chars=MAX_CHARS):
            """ë¬¸ì¥ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ë¥¼ ì²­í¬ë¡œ ë¶„í•  (ê¸´ ë¬¸ì¥ë„ ì²˜ë¦¬)"""
            # 1ë‹¨ê³„: ë§ˆì¹¨í‘œ, ë¬¼ìŒí‘œ, ëŠë‚Œí‘œë¡œ ë¨¼ì € ë¶„í• 
            sentences = re.split(r'(?<=[.!?ã€‚])\s*', text)

            # 2ë‹¨ê³„: ê¸´ ë¬¸ì¥ì€ ì¶”ê°€ ë¶„í• 
            final_sentences = []
            for sentence in sentences:
                if not sentence.strip():
                    continue
                final_sentences.extend(split_long_sentence(sentence))

            # 3ë‹¨ê³„: ë¬¸ì¥ë“¤ì„ ì²­í¬ë¡œ ë¬¶ê¸°
            chunks = []
            current_chunk = ""

            for sentence in final_sentences:
                if len(current_chunk) + len(sentence) + 1 <= max_chars:
                    current_chunk += " " + sentence if current_chunk else sentence
                else:
                    if current_chunk:
                        chunks.append(current_chunk.strip())
                    current_chunk = sentence

            if current_chunk:
                chunks.append(current_chunk.strip())

            return chunks

        # ì§§ì€ í…ìŠ¤íŠ¸ëŠ” ë°”ë¡œ ì²˜ë¦¬
        if len(text.encode('utf-8')) <= 4500:
            input_text = texttospeech.SynthesisInput(text=text)
            response = client.synthesize_speech(
                input=input_text,
                voice=voice,
                audio_config=audio_config,
            )
            print(f"[CHIRP3-TTS] ì„±ê³µ - {len(response.audio_content)} bytes", flush=True)
            return {
                "ok": True,
                "audio_data": response.audio_content
            }

        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²­í¬ë¡œ ë¶„í• 
        chunks = split_text_into_chunks(text)
        print(f"[CHIRP3-TTS] ê¸´ í…ìŠ¤íŠ¸ - {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ", flush=True)

        all_audio = []
        for i, chunk in enumerate(chunks):
            print(f"[CHIRP3-TTS] ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({len(chunk)}ì)", flush=True)

            input_text = texttospeech.SynthesisInput(text=chunk)
            response = client.synthesize_speech(
                input=input_text,
                voice=voice,
                audio_config=audio_config,
            )
            all_audio.append(response.audio_content)

            # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
            if i < len(chunks) - 1:
                import time
                time.sleep(0.2)

        # MP3 ì˜¤ë””ì˜¤ ì—°ê²° (pydub ì‚¬ìš©)
        try:
            from pydub import AudioSegment
            import io

            combined = AudioSegment.empty()
            for audio_data in all_audio:
                segment = AudioSegment.from_mp3(io.BytesIO(audio_data))
                combined += segment

            # MP3ë¡œ ë‚´ë³´ë‚´ê¸°
            output_buffer = io.BytesIO()
            combined.export(output_buffer, format="mp3")
            final_audio = output_buffer.getvalue()

            print(f"[CHIRP3-TTS] ì„±ê³µ - {len(chunks)}ê°œ ì²­í¬ ì—°ê²°, {len(final_audio)} bytes", flush=True)

            return {
                "ok": True,
                "audio_data": final_audio
            }
        except ImportError:
            # pydub ì—†ìœ¼ë©´ FFmpegë¡œ ì—°ê²° (ë‹¨ìˆœ byte ì—°ê²°ì€ ê¸€ë¦¬ì¹˜ ë°œìƒ!)
            print("[CHIRP3-TTS] pydub ì—†ìŒ - FFmpegë¡œ ì—°ê²°", flush=True)
            import tempfile
            import subprocess

            # ì„ì‹œ íŒŒì¼ë¡œ ê° ì²­í¬ ì €ì¥
            temp_files = []
            temp_dir = tempfile.mkdtemp()
            try:
                for i, audio_data in enumerate(all_audio):
                    temp_path = os.path.join(temp_dir, f"chunk_{i:03d}.mp3")
                    with open(temp_path, "wb") as f:
                        f.write(audio_data)
                    temp_files.append(temp_path)

                # FFmpeg concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
                list_path = os.path.join(temp_dir, "concat_list.txt")
                with open(list_path, "w") as f:
                    for temp_path in temp_files:
                        f.write(f"file '{temp_path}'\n")

                # FFmpegë¡œ ì—°ê²°
                output_path = os.path.join(temp_dir, "merged.mp3")
                cmd = [
                    "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                    "-i", list_path,
                    "-c", "copy",  # ì¬ì¸ì½”ë”© ì—†ì´ ì—°ê²°
                    output_path
                ]
                result = subprocess.run(cmd, capture_output=True, timeout=300)

                if result.returncode == 0 and os.path.exists(output_path):
                    with open(output_path, "rb") as f:
                        final_audio = f.read()
                    print(f"[CHIRP3-TTS] ì„±ê³µ - FFmpegë¡œ {len(chunks)}ê°œ ì²­í¬ ì—°ê²°", flush=True)
                    return {
                        "ok": True,
                        "audio_data": final_audio
                    }
                else:
                    # FFmpeg ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì²­í¬ë§Œ ë°˜í™˜
                    print(f"[CHIRP3-TTS] FFmpeg ì‹¤íŒ¨ - ì²« ì²­í¬ë§Œ ë°˜í™˜", flush=True)
                    return {
                        "ok": True,
                        "audio_data": all_audio[0]
                    }
            finally:
                # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                import shutil
                shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        print(f"[CHIRP3-TTS] ì˜¤ë¥˜: {e}", flush=True)
        return {"ok": False, "error": str(e)}


def generate_bible_tts_with_durations(verse_texts, voice_name="ko-KR-Chirp3-HD-Charon"):
    """
    BIBLEìš© TTS ìƒì„± - ì ˆë³„ ì •í™•í•œ duration ë°˜í™˜

    ê¸°ì¡´ ë°©ì‹: ì „ì²´ í…ìŠ¤íŠ¸ TTS â†’ ê¸€ììˆ˜ ë¹„ìœ¨ë¡œ duration ì¶”ì • (ë¶€ì •í™•)
    ìƒˆ ë°©ì‹: ì²­í¬ë³„ TTS â†’ ffprobeë¡œ ì‹¤ì œ duration ì¸¡ì • â†’ ì²­í¬ ë‚´ ë¶„ë°° (ì •í™•)

    Args:
        verse_texts: ê° ì ˆì˜ TTS í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ["íƒœì´ˆì—...", "ë•…ì´ í˜¼ëˆí•˜ê³ ...", ...]
        voice_name: Chirp 3 HD ìŒì„± ì´ë¦„

    Returns:
        {
            "ok": True,
            "audio_data": bytes,
            "total_duration": float,
            "verse_durations": [float, ...]  # ê° ì ˆì˜ ì •í™•í•œ duration
        }
    """
    import tempfile
    import subprocess
    import io

    try:
        from google.cloud import texttospeech
        from google.oauth2 import service_account
        import json

        print(f"[BIBLE-TTS] ì‹œì‘ - {len(verse_texts)}ê°œ ì ˆ, ìŒì„±: {voice_name}", flush=True)

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service_account_json = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
        if not service_account_json:
            return {"ok": False, "error": "GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤"}

        service_account_info = json.loads(service_account_json)
        credentials = service_account.Credentials.from_service_account_info(
            service_account_info,
            scopes=["https://www.googleapis.com/auth/cloud-platform"]
        )

        client = texttospeech.TextToSpeechClient(credentials=credentials)
        voice = texttospeech.VoiceSelectionParams(
            language_code="ko-KR",
            name=voice_name,
        )
        audio_config = texttospeech.AudioConfig(
            audio_encoding=texttospeech.AudioEncoding.MP3
        )

        # ========== 1. ì ˆì„ ì²­í¬ë¡œ ê·¸ë£¹í•‘ (5000ë°”ì´íŠ¸ â‰ˆ 1400ì ì œí•œ) ==========
        MAX_CHARS = 1200  # ì•ˆì „ ë§ˆì§„
        chunks = []  # [(start_verse_idx, end_verse_idx, combined_text), ...]
        current_chunk_start = 0
        current_chunk_text = ""

        for i, verse_text in enumerate(verse_texts):
            # ì˜ë¬¸ ì¸ëª… ê´„í˜¸ ì œê±° (TTSì—ì„œëŠ” ì½ì§€ ì•ŠìŒ)
            clean_text = preprocess_tts_text(verse_text)

            if len(current_chunk_text) + len(clean_text) + 1 > MAX_CHARS:
                # í˜„ì¬ ì²­í¬ ì €ì¥
                if current_chunk_text:
                    chunks.append((current_chunk_start, i - 1, current_chunk_text.strip()))
                # ìƒˆ ì²­í¬ ì‹œì‘
                current_chunk_start = i
                current_chunk_text = clean_text + " "
            else:
                current_chunk_text += clean_text + " "

        # ë§ˆì§€ë§‰ ì²­í¬ ì €ì¥
        if current_chunk_text:
            chunks.append((current_chunk_start, len(verse_texts) - 1, current_chunk_text.strip()))

        print(f"[BIBLE-TTS] {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í• ", flush=True)

        # ========== 2. ì²­í¬ë³„ TTS + duration ì¸¡ì • ==========
        chunk_audios = []  # [(audio_bytes, duration, start_idx, end_idx), ...]

        def get_audio_duration(audio_bytes):
            """ffprobeë¡œ ì˜¤ë””ì˜¤ duration ì¸¡ì •"""
            try:
                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp:
                    tmp.write(audio_bytes)
                    tmp_path = tmp.name

                cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1",
                    tmp_path
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                os.unlink(tmp_path)

                if result.returncode == 0 and result.stdout.strip():
                    return float(result.stdout.strip())
            except Exception as e:
                print(f"[BIBLE-TTS] ffprobe ì˜¤ë¥˜: {e}")

            # í´ë°±: MP3 128kbps ê¸°ì¤€ ì¶”ì •
            return len(audio_bytes) / 16000

        for idx, (start_idx, end_idx, chunk_text) in enumerate(chunks):
            print(f"[BIBLE-TTS] ì²­í¬ {idx+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({len(chunk_text)}ì)", flush=True)

            input_text = texttospeech.SynthesisInput(text=chunk_text)
            response = client.synthesize_speech(
                input=input_text,
                voice=voice,
                audio_config=audio_config,
            )

            audio_bytes = response.audio_content
            duration = get_audio_duration(audio_bytes)

            chunk_audios.append((audio_bytes, duration, start_idx, end_idx))

            print(f"[BIBLE-TTS] ì²­í¬ {idx+1}: {duration:.2f}ì´ˆ (ì ˆ {start_idx+1}~{end_idx+1})", flush=True)

            # API ë ˆì´íŠ¸ ë¦¬ë°‹ ë°©ì§€
            if idx < len(chunks) - 1:
                import time
                time.sleep(0.2)

        # ========== 3. ì ˆë³„ duration ê³„ì‚° (ì²­í¬ ë‚´ ë¹„ìœ¨ ë¶„ë°°) ==========
        verse_durations = [0.0] * len(verse_texts)

        for audio_bytes, chunk_duration, start_idx, end_idx in chunk_audios:
            # í•´ë‹¹ ì²­í¬ì— í¬í•¨ëœ ì ˆë“¤
            chunk_verses = verse_texts[start_idx:end_idx + 1]
            total_chars = sum(len(v) for v in chunk_verses)

            if total_chars > 0:
                for i, verse_text in enumerate(chunk_verses):
                    verse_idx = start_idx + i
                    ratio = len(verse_text) / total_chars
                    verse_durations[verse_idx] = chunk_duration * ratio
            else:
                # ê· ë“± ë¶„ë°° (ì˜ˆì™¸ ì²˜ë¦¬)
                count = end_idx - start_idx + 1
                for i in range(count):
                    verse_durations[start_idx + i] = chunk_duration / count

        # ========== 4. ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° ==========
        try:
            from pydub import AudioSegment

            combined = AudioSegment.empty()
            for audio_bytes, _, _, _ in chunk_audios:
                segment = AudioSegment.from_mp3(io.BytesIO(audio_bytes))
                combined += segment

            output_buffer = io.BytesIO()
            combined.export(output_buffer, format="mp3")
            final_audio = output_buffer.getvalue()
        except ImportError:
            # pydub ì—†ìœ¼ë©´ ë‹¨ìˆœ ì—°ê²°
            final_audio = b''.join(audio_bytes for audio_bytes, _, _, _ in chunk_audios)

        total_duration = sum(verse_durations)
        print(f"[BIBLE-TTS] ì™„ë£Œ - ì´ {total_duration:.1f}ì´ˆ, {len(verse_durations)}ê°œ ì ˆ", flush=True)

        return {
            "ok": True,
            "audio_data": final_audio,
            "total_duration": total_duration,
            "verse_durations": verse_durations
        }

    except Exception as e:
        print(f"[BIBLE-TTS] ì˜¤ë¥˜: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}


def generate_bible_tts_with_durations_gemini(verse_texts, voice_name="Charon", model="gemini-2.5-flash-preview-tts"):
    """
    Gemini TTSë¥¼ ì‚¬ìš©í•œ BIBLE TTS ìƒì„± - ì ˆë³„ ì •í™•í•œ duration ë°˜í™˜

    Args:
        verse_texts: ê° ì ˆì˜ TTS í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸ ["íƒœì´ˆì—...", "ë•…ì´ í˜¼ëˆí•˜ê³ ...", ...]
        voice_name: Gemini ìŒì„± ì´ë¦„ (Charon, Fenrir, Orus, Kore ë“±)
        model: Gemini ëª¨ë¸ (gemini-2.5-flash-preview-tts ë˜ëŠ” gemini-2.5-pro-preview-tts)

    Returns:
        {
            "ok": True,
            "audio_data": bytes,
            "total_duration": float,
            "verse_durations": [float, ...]  # ê° ì ˆì˜ ì •í™•í•œ duration
        }
    """
    import tempfile
    import subprocess
    import io
    import time as time_module

    try:
        api_key = os.getenv("GOOGLE_API_KEY", "")
        if not api_key:
            return {"ok": False, "error": "GOOGLE_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì—†ìŠµë‹ˆë‹¤"}

        print(f"[BIBLE-GEMINI-TTS] ì‹œì‘ - {len(verse_texts)}ê°œ ì ˆ, ìŒì„±: {voice_name}, ëª¨ë¸: {model}", flush=True)

        # ========== 1. ì ˆì„ ì²­í¬ë¡œ ê·¸ë£¹í•‘ (Gemini 8KB ì œí•œ â†’ ~2000ì) ==========
        MAX_CHARS = 2000
        chunks = []  # [(start_verse_idx, end_verse_idx, combined_text), ...]
        current_chunk_start = 0
        current_chunk_text = ""

        for i, verse_text in enumerate(verse_texts):
            clean_text = preprocess_tts_text(verse_text)

            if len(current_chunk_text) + len(clean_text) + 1 > MAX_CHARS:
                if current_chunk_text:
                    chunks.append((current_chunk_start, i - 1, current_chunk_text.strip()))
                current_chunk_start = i
                current_chunk_text = clean_text + " "
            else:
                current_chunk_text += clean_text + " "

        if current_chunk_text:
            chunks.append((current_chunk_start, len(verse_texts) - 1, current_chunk_text.strip()))

        print(f"[BIBLE-GEMINI-TTS] {len(chunks)}ê°œ ì²­í¬ë¡œ ë¶„í•  (Rate Limit: 10 req/min)", flush=True)

        # ========== 2. ì²­í¬ë³„ TTS + duration ì¸¡ì • ==========
        chunk_audios = []

        def get_audio_duration_wav(audio_bytes):
            """ffprobeë¡œ WAV ì˜¤ë””ì˜¤ duration ì¸¡ì •"""
            try:
                with tempfile.NamedTemporaryFile(suffix='.wav', delete=False) as tmp:
                    tmp.write(audio_bytes)
                    tmp_path = tmp.name

                cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1",
                    tmp_path
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                os.unlink(tmp_path)

                if result.returncode == 0 and result.stdout.strip():
                    return float(result.stdout.strip())
            except Exception as e:
                print(f"[BIBLE-GEMINI-TTS] ffprobe ì˜¤ë¥˜: {e}", flush=True)

            # í´ë°±: í…ìŠ¤íŠ¸ ê¸¸ì´ ê¸°ë°˜ ì¶”ì • (í•œêµ­ì–´ ì•½ 4ì/ì´ˆ)
            return len(audio_bytes) / 48000  # 24kHz * 2 bytes

        for idx, (start_idx, end_idx, chunk_text) in enumerate(chunks):
            print(f"[BIBLE-GEMINI-TTS] ì²­í¬ {idx+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({len(chunk_text)}ì)", flush=True)

            # Gemini TTS API í˜¸ì¶œ
            import google.generativeai as genai
            genai.configure(api_key=api_key)

            try:
                response = genai.GenerativeModel(model).generate_content(
                    chunk_text,
                    generation_config=genai.GenerationConfig(
                        response_modalities=["AUDIO"],
                        speech_config=genai.SpeechConfig(
                            voice_config=genai.VoiceConfig(
                                prebuilt_voice_config=genai.PrebuiltVoiceConfig(voice_name=voice_name)
                            )
                        )
                    )
                )

                # ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ
                audio_data = None
                if response.candidates and response.candidates[0].content.parts:
                    for part in response.candidates[0].content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            audio_data = part.inline_data.data
                            break

                if not audio_data:
                    print(f"[BIBLE-GEMINI-TTS] ì²­í¬ {idx+1} ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ", flush=True)
                    return {"ok": False, "error": f"ì²­í¬ {idx+1} ì˜¤ë””ì˜¤ ìƒì„± ì‹¤íŒ¨"}

                duration = get_audio_duration_wav(audio_data)
                chunk_audios.append((audio_data, duration, start_idx, end_idx))

                print(f"[BIBLE-GEMINI-TTS] ì²­í¬ {idx+1}: {duration:.2f}ì´ˆ (ì ˆ {start_idx+1}~{end_idx+1})", flush=True)

            except Exception as e:
                print(f"[BIBLE-GEMINI-TTS] ì²­í¬ {idx+1} API ì˜¤ë¥˜: {e}", flush=True)
                return {"ok": False, "error": f"Gemini TTS API ì˜¤ë¥˜: {e}"}

            # Rate Limit ëŒ€ê¸° (10 req/min = 6ì´ˆ ê°„ê²©)
            if idx < len(chunks) - 1:
                print(f"[BIBLE-GEMINI-TTS] Rate Limit ëŒ€ê¸° (6ì´ˆ)...", flush=True)
                time_module.sleep(6)

        # ========== 3. ì ˆë³„ duration ê³„ì‚° (ì²­í¬ ë‚´ ë¹„ìœ¨ ë¶„ë°°) ==========
        verse_durations = [0.0] * len(verse_texts)

        for audio_bytes, chunk_duration, start_idx, end_idx in chunk_audios:
            chunk_verses = verse_texts[start_idx:end_idx + 1]
            total_chars = sum(len(v) for v in chunk_verses)

            if total_chars > 0:
                for i, verse_text in enumerate(chunk_verses):
                    verse_idx = start_idx + i
                    ratio = len(verse_text) / total_chars
                    verse_durations[verse_idx] = chunk_duration * ratio
            else:
                count = end_idx - start_idx + 1
                for i in range(count):
                    verse_durations[start_idx + i] = chunk_duration / count

        # ========== 4. WAV ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° â†’ MP3 ë³€í™˜ ==========
        print(f"[BIBLE-GEMINI-TTS] ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° ë° MP3 ë³€í™˜...", flush=True)

        try:
            # WAV íŒŒì¼ë“¤ì„ ì„ì‹œ ì €ì¥
            wav_files = []
            for i, (audio_bytes, _, _, _) in enumerate(chunk_audios):
                wav_path = tempfile.mktemp(suffix=f'_chunk{i}.wav')
                with open(wav_path, 'wb') as f:
                    f.write(audio_bytes)
                wav_files.append(wav_path)

            # FFmpegë¡œ WAV ì—°ê²° í›„ MP3 ë³€í™˜
            concat_list_path = tempfile.mktemp(suffix='.txt')
            with open(concat_list_path, 'w') as f:
                for wav_path in wav_files:
                    f.write(f"file '{wav_path}'\n")

            output_mp3_path = tempfile.mktemp(suffix='.mp3')
            concat_cmd = [
                'ffmpeg', '-y', '-f', 'concat', '-safe', '0',
                '-i', concat_list_path,
                '-c:a', 'libmp3lame', '-b:a', '128k',
                output_mp3_path
            ]

            result = subprocess.run(concat_cmd, capture_output=True, timeout=120)

            if result.returncode != 0:
                print(f"[BIBLE-GEMINI-TTS] FFmpeg ì˜¤ë¥˜: {result.stderr.decode()[:200]}", flush=True)
                return {"ok": False, "error": "ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° ì‹¤íŒ¨"}

            with open(output_mp3_path, 'rb') as f:
                final_audio = f.read()

            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            for wav_path in wav_files:
                try:
                    os.unlink(wav_path)
                except:
                    pass
            try:
                os.unlink(concat_list_path)
                os.unlink(output_mp3_path)
            except:
                pass

        except Exception as e:
            print(f"[BIBLE-GEMINI-TTS] ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° ì˜¤ë¥˜: {e}", flush=True)
            return {"ok": False, "error": f"ì˜¤ë””ì˜¤ í•©ì¹˜ê¸° ì˜¤ë¥˜: {e}"}

        total_duration = sum(verse_durations)
        print(f"[BIBLE-GEMINI-TTS] ì™„ë£Œ - ì´ {total_duration:.1f}ì´ˆ, {len(verse_durations)}ê°œ ì ˆ", flush=True)

        return {
            "ok": True,
            "audio_data": final_audio,
            "total_duration": total_duration,
            "verse_durations": verse_durations
        }

    except Exception as e:
        print(f"[BIBLE-GEMINI-TTS] ì˜¤ë¥˜: {e}", flush=True)
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}


def parse_gemini_voice(voice_name):
    """
    Gemini ìŒì„± ì„¤ì • íŒŒì‹±

    Args:
        voice_name: "gemini:Kore" ë˜ëŠ” "gemini:pro:Charon" í˜•ì‹

    Returns:
        dict: {"voice": "Kore", "model": "gemini-2.5-flash-preview-tts"}
    """
    parts = voice_name.split(":")

    if len(parts) == 2:
        # "gemini:Kore" -> Flash ëª¨ë¸ ì‚¬ìš©
        return {
            "voice": parts[1],
            "model": "gemini-2.5-flash-preview-tts"
        }
    elif len(parts) == 3:
        # "gemini:pro:Kore" -> Pro ëª¨ë¸ ì‚¬ìš©
        model_type = parts[1].lower()
        voice = parts[2]
        if model_type == "pro":
            return {
                "voice": voice,
                "model": "gemini-2.5-pro-preview-tts"
            }
        else:
            return {
                "voice": voice,
                "model": "gemini-2.5-flash-preview-tts"
            }
    else:
        # ê¸°ë³¸ê°’
        return {
            "voice": "Kore",
            "model": "gemini-2.5-flash-preview-tts"
        }


# ===== Step5: TTS API (Google Cloud / ë„¤ì´ë²„ í´ë¡œë°” ì„ íƒ) =====
@app.route('/api/drama/generate-tts', methods=['POST'])
def api_generate_tts():
    """TTS ìŒì„± ìƒì„± - Google Cloud TTS (ê¸°ë³¸) ë˜ëŠ” ë„¤ì´ë²„ í´ë¡œë°”"""
    try:
        import requests
        import base64

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        text = data.get("text", "")
        speaker = data.get("speaker", lang_ko.TTS['default_voice'])
        speed = data.get("speed", 1.0)
        pitch = data.get("pitch", 0)
        volume = data.get("volume", 0)
        tts_provider = data.get("ttsProvider", "google")  # google ë˜ëŠ” naver

        if not text:
            return jsonify({"ok": False, "error": "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        char_count = len(text)

        # Google Cloud TTS
        if tts_provider == "google":
            google_api_key = os.getenv("GOOGLE_CLOUD_API_KEY", "")

            if not google_api_key:
                return jsonify({"ok": False, "error": "Google Cloud API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ GOOGLE_CLOUD_API_KEYë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."}), 200

            print(f"[DRAMA-STEP5-TTS] Google TTS ìƒì„± ì‹œì‘ - ìŒì„±: {speaker}, í…ìŠ¤íŠ¸ ê¸¸ì´: {char_count}ì")

            # ê°ì • í‘œí˜„ í‚¤ì›Œë“œ (ì´ í‘œí˜„ì´ í¬í•¨ëœ ë¬¸ì¥ì€ ë” ì²œì²œíˆ ì½ìŒ)
            emotional_keywords = [
                # ì‹ ì²´ ë°˜ì‘
                "ëˆˆë¬¼ì´", "ëˆˆì‹œìš¸", "ì†ì´ ë–¨", "ëª©ì´ ë©”", "ê°€ìŠ´ì´ ë¨¹ë¨¹",
                "ì ì´ ì˜¤ì§€", "ë°¥ì´ ë„˜ì–´ê°€ì§€", "ìˆ¨ì´ ë§‰", "ëª¸ì´ êµ³",
                # ê°ì • ìƒíƒœ
                "ë§ˆìŒì´ ë¬´ê±°", "í¬ë§ì´", "ë¯¸ì•ˆ", "í—ˆë¬´", "ë¯¿ê¸°ì§€ ì•Š",
                "ìŠ¬", "ì•„í”„", "ê³ í†µ", "ì ˆë§", "ë‘ë ¤", "ë¬´ì„œ",
                "ê°ì‚¬", "ê°ê²©", "ë²…ì°¨", "ë­‰í´", "ì°¡",
                # ê°•ì¡° í‘œí˜„
                "ì •ë§", "ì§„ì‹¬ìœ¼ë¡œ", "ê°„ì ˆíˆ", "ì• íƒ€ê²Œ", "ì²˜ì ˆí•˜ê²Œ",
                # íŠ¹ìˆ˜ ìƒí™©
                "ë§ˆì§€ë§‰", "ì´ë³„", "ì£½ìŒ", "ë– ë‚˜", "ì˜ì›íˆ"
            ]

            def apply_emotion_ssml(text_chunk, base_rate):
                """ê°ì • í‘œí˜„ì´ ìˆëŠ” ë¬¸ì¥ì— SSML ì†ë„ ì¡°ì ˆ ì ìš©"""
                import re
                import html

                def escape_for_ssml(text):
                    """SSMLì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ XML íŠ¹ìˆ˜ ë¬¸ì ì´ìŠ¤ì¼€ì´í”„"""
                    return html.escape(text, quote=False)

                # â˜… ì†Œìˆ˜ì  ë³´í˜¸: ìˆ«ì.ìˆ«ì íŒ¨í„´ì„ ì„ì‹œ ë§ˆì»¤ë¡œ ì¹˜í™˜ (2.6% â†’ 2<DECIMAL>6%)
                decimal_pattern = r'(\d)\.(\d)'
                text_safe = re.sub(decimal_pattern, r'\1<DECIMAL>\2', text_chunk)

                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í• 
                sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', text_safe)
                merged = []
                i = 0
                while i < len(sentences):
                    if i + 1 < len(sentences) and sentences[i+1] in '.!?ã€‚ï¼ï¼Ÿ':
                        merged.append(sentences[i] + sentences[i+1])
                        i += 2
                    else:
                        if sentences[i].strip():
                            merged.append(sentences[i])
                        i += 1

                result_parts = []
                has_emotion = False

                # â˜… ì†Œìˆ˜ì  ë³µì›
                merged = [s.replace('<DECIMAL>', '.') for s in merged]

                for sentence in merged:
                    sentence = sentence.strip()
                    if not sentence:
                        continue

                    # ê°ì • í‚¤ì›Œë“œ ì²´í¬
                    is_emotional = any(kw in sentence for kw in emotional_keywords)

                    if is_emotional:
                        has_emotion = True
                        # ê°ì • ë¬¸ì¥: ê¸°ë³¸ ì†ë„ì˜ 90% (ë” ì²œì²œíˆ)
                        emotion_rate = max(0.25, base_rate * 0.9)
                        # ê°ì • ë¬¸ì¥ ì „ì— ì§§ì€ íœ´ì§€, ë” ëŠë¦° ì†ë„ë¡œ ì½ê¸°
                        escaped_sentence = escape_for_ssml(sentence)
                        result_parts.append(f'<break time="300ms"/><prosody rate="{emotion_rate:.2f}">{escaped_sentence}</prosody><break time="200ms"/>')
                    else:
                        result_parts.append(escape_for_ssml(sentence))

                if has_emotion:
                    ssml_text = f'<speak>{" ".join(result_parts)}</speak>'
                    return ssml_text, True
                else:
                    return text_chunk, False

            # Google Cloud TTSëŠ” ìµœëŒ€ 5000ë°”ì´íŠ¸ ì œí•œ
            # SSML íƒœê·¸ ì˜¤ë²„í—¤ë“œë¥¼ ê³ ë ¤í•˜ì—¬ ë³´ìˆ˜ì ìœ¼ë¡œ ì„¤ì •:
            # - SSML ê¸°ë³¸ íƒœê·¸: <speak></speak> = 15ë°”ì´íŠ¸
            # - ê°ì • ë¬¸ì¥ë‹¹ SSML íƒœê·¸: <break time="300ms"/><prosody rate="0.90">...</prosody><break time="200ms"/> = ì•½ 75ë°”ì´íŠ¸
            # - ìµœëŒ€ 10ê°œ ê°ì • ë¬¸ì¥ ê°€ì • ì‹œ ì•½ 750ë°”ì´íŠ¸ ì¶”ê°€
            # ì•ˆì „ ë§ˆì§„ì„ ìœ„í•´ 2500ë°”ì´íŠ¸ë¡œ ì„¤ì • (ìµœì•…ì˜ ê²½ìš°ì—ë„ 5000 ë¯¸ë§Œ ë³´ì¥)
            GOOGLE_TTS_MAX_BYTES = 5000
            max_bytes_for_plain_text = 2500  # SSML ì˜¤ë²„í—¤ë“œ ê³ ë ¤í•˜ì—¬ ë³´ìˆ˜ì  ì„¤ì •
            text_chunks = []

            def get_byte_length(s):
                return len(s.encode('utf-8'))

            def split_text_by_bytes(text, max_bytes):
                """í…ìŠ¤íŠ¸ë¥¼ ë°”ì´íŠ¸ ì œí•œì— ë§ê²Œ ë¶„í• """
                chunks = []
                # â˜… ì†Œìˆ˜ì  ë³´í˜¸: ìˆ«ì.ìˆ«ì íŒ¨í„´ì„ ì„ì‹œ ë§ˆì»¤ë¡œ ì¹˜í™˜ (2.6% â†’ 2<DECIMAL>6%)
                import re
                decimal_pattern = r'(\d)\.(\d)'
                text_safe = re.sub(decimal_pattern, r'\1<DECIMAL>\2', text)

                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¨¼ì € ë¶„í•  (ë§ˆì¹¨í‘œ, ëŠë‚Œí‘œ, ë¬¼ìŒí‘œ ê¸°ì¤€)
                sentences = re.split(r'([.!?ã€‚ï¼ï¼Ÿ])', text_safe)
                # êµ¬ë¶„ìë¥¼ ë¬¸ì¥ì— ë‹¤ì‹œ ë¶™ì´ê¸°
                merged_sentences = []
                i = 0
                while i < len(sentences):
                    if i + 1 < len(sentences) and sentences[i+1] in '.!?ã€‚ï¼ï¼Ÿ':
                        merged_sentences.append(sentences[i] + sentences[i+1])
                        i += 2
                    else:
                        if sentences[i].strip():
                            merged_sentences.append(sentences[i])
                        i += 1

                # â˜… ì†Œìˆ˜ì  ë³µì›
                merged_sentences = [s.replace('<DECIMAL>', '.') for s in merged_sentences]

                current_chunk = ""
                for sentence in merged_sentences:
                    sentence = sentence.strip()
                    if not sentence:
                        continue

                    # ë¬¸ì¥ ìì²´ê°€ ë„ˆë¬´ ê¸¸ë©´ ë” ì‘ê²Œ ë¶„í• 
                    if get_byte_length(sentence) > max_bytes:
                        # í˜„ì¬ ì²­í¬ ì €ì¥
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                            current_chunk = ""
                        # ê¸´ ë¬¸ì¥ì„ ì‰¼í‘œë‚˜ ê³µë°±ìœ¼ë¡œ ë¶„í• 
                        sub_parts = re.split(r'([,ï¼Œã€\s])', sentence)
                        sub_chunk = ""
                        for part in sub_parts:
                            if get_byte_length(sub_chunk + part) < max_bytes:
                                sub_chunk += part
                            else:
                                if sub_chunk:
                                    chunks.append(sub_chunk.strip())
                                sub_chunk = part
                        if sub_chunk:
                            current_chunk = sub_chunk
                    elif get_byte_length(current_chunk + " " + sentence) < max_bytes:
                        current_chunk = (current_chunk + " " + sentence).strip()
                    else:
                        if current_chunk:
                            chunks.append(current_chunk.strip())
                        current_chunk = sentence

                if current_chunk:
                    chunks.append(current_chunk.strip())

                return chunks if chunks else [text[:1000]]  # ìµœì†Œ í•˜ë‚˜ì˜ ì²­í¬ ë³´ì¥ (ë” ë³´ìˆ˜ì )

            text_chunks = split_text_by_bytes(text, max_bytes_for_plain_text)
            print(f"[DRAMA-STEP5-TTS] í…ìŠ¤íŠ¸ë¥¼ {len(text_chunks)}ê°œ ì²­í¬ë¡œ ë¶„í•  (ë°”ì´íŠ¸ ì œí•œ: {max_bytes_for_plain_text})")

            audio_data_list = []
            url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={google_api_key}"

            # ì†ë„ ë³€í™˜: ë°°ìœ¨(0.85~1.1) ë˜ëŠ” ë„¤ì´ë²„(-5~5) -> Google(0.25~4.0)
            if isinstance(speed, (int, float)):
                if 0.1 <= speed <= 2.0:
                    # ë°°ìœ¨ í˜•ì‹ (0.85x, 0.95x, 1.0x, 1.1x ë“±) - ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    google_speed = speed
                elif speed == 0:
                    google_speed = 1.0
                else:
                    # ë„¤ì´ë²„ í˜•ì‹ (-5~5)
                    google_speed = 1.0 + (speed * 0.1)  # -5->0.5, 0->1.0, 5->1.5
                google_speed = max(0.25, min(4.0, google_speed))
            else:
                google_speed = 1.0

            print(f"[DRAMA-STEP5-TTS] ì†ë„ ì„¤ì •: ì…ë ¥={speed}, Google TTS={google_speed}")

            # í”¼ì¹˜ ë³€í™˜: ë„¤ì´ë²„(-5~5) -> Google(-20~20)
            google_pitch = pitch * 4 if isinstance(pitch, (int, float)) else 0

            emotion_chunk_count = 0
            ssml_fallback_count = 0  # SSMLì´ ë„ˆë¬´ ì»¤ì„œ plain textë¡œ í´ë°±í•œ íšŸìˆ˜

            for chunk in text_chunks:
                # ê°ì • í‘œí˜„ SSML ì ìš©
                processed_chunk, is_ssml = apply_emotion_ssml(chunk, google_speed)

                # SSML ì ìš© í›„ ë°”ì´íŠ¸ ì²´í¬ - 5000ë°”ì´íŠ¸ ì´ˆê³¼ì‹œ plain textë¡œ í´ë°±
                if is_ssml:
                    ssml_byte_length = get_byte_length(processed_chunk)
                    if ssml_byte_length >= GOOGLE_TTS_MAX_BYTES:
                        # SSMLì´ ë„ˆë¬´ í¼ - plain textë¡œ í´ë°±
                        print(f"[DRAMA-STEP5-TTS][WARN] SSML ë°”ì´íŠ¸ ì´ˆê³¼ ({ssml_byte_length}), plain textë¡œ í´ë°±")
                        is_ssml = False
                        ssml_fallback_count += 1
                    else:
                        emotion_chunk_count += 1

                # speaker ì´ë¦„ì—ì„œ ì–¸ì–´ ì½”ë“œ ì¶”ì¶œ (ì˜ˆ: ko-KR-Neural2-C â†’ ko-KR)
                lang_code = '-'.join(speaker.split('-')[:2]) if speaker and '-' in speaker else lang_ko.TTS['language_code']

                if is_ssml:
                    payload = {
                        "input": {"ssml": processed_chunk},
                        "voice": {
                            "languageCode": lang_code,
                            "name": speaker
                        },
                        "audioConfig": {
                            "audioEncoding": "MP3",
                            "speakingRate": google_speed,
                            "pitch": google_pitch
                        }
                    }
                else:
                    # plain textë„ 5000ë°”ì´íŠ¸ ì œí•œ ì²´í¬
                    chunk_byte_length = get_byte_length(chunk)
                    if chunk_byte_length >= GOOGLE_TTS_MAX_BYTES:
                        # ì²­í¬ ìì²´ê°€ ë„ˆë¬´ í¼ - ê°•ì œ ë¶„í•  (ì´ ê²½ìš°ëŠ” ê±°ì˜ ì—†ì–´ì•¼ í•¨)
                        print(f"[DRAMA-STEP5-TTS][WARN] ì²­í¬ê°€ ë„ˆë¬´ í¼ ({chunk_byte_length}), ê°•ì œ ì ˆë‹¨")
                        chunk = chunk[:1500]  # ì•½ 4500ë°”ì´íŠ¸ (í•œê¸€ 3ë°”ì´íŠ¸)

                    payload = {
                        "input": {"text": chunk},
                        "voice": {
                            "languageCode": lang_code,
                            "name": speaker
                        },
                        "audioConfig": {
                            "audioEncoding": "MP3",
                            "speakingRate": google_speed,
                            "pitch": google_pitch
                        }
                    }

                response = requests.post(url, json=payload, timeout=90)

                if response.status_code == 200:
                    result = response.json()
                    audio_content = base64.b64decode(result.get("audioContent", ""))
                    audio_data_list.append(audio_content)
                else:
                    error_text = response.text
                    print(f"[DRAMA-STEP5-TTS][ERROR] Google API ì‘ë‹µ: {response.status_code} - {error_text}")

                    # 403 ì—ëŸ¬ì— ëŒ€í•œ íŠ¹ë³„í•œ ì•ˆë‚´
                    if response.status_code == 403:
                        error_msg = "Google TTS API ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. Google Cloud Consoleì—ì„œ 'Cloud Text-to-Speech API'ê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸í•˜ê³ , API í‚¤ì— í•´ë‹¹ API ì ‘ê·¼ ê¶Œí•œì´ ìˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                        print(f"[DRAMA-STEP5-TTS][ERROR] 403 Forbidden - API í™œì„±í™” í•„ìš” ë˜ëŠ” API í‚¤ ê¶Œí•œ ë¶€ì¡±")
                        return jsonify({"ok": False, "error": error_msg, "statusCode": 403}), 200

                    return jsonify({"ok": False, "error": f"Google TTS API ì˜¤ë¥˜ ({response.status_code}): {error_text}"}), 200

            # FFmpegë¡œ MP3 ì²­í¬ ë³‘í•© (ë‹¨ìˆœ ë°”ì´íŠ¸ ê²°í•© ëŒ€ì‹  - í—¤ë” ì¤‘ë³µ ë°©ì§€)
            if len(audio_data_list) == 1:
                # ì²­í¬ê°€ í•˜ë‚˜ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                combined_audio = audio_data_list[0]
            else:
                # ì—¬ëŸ¬ ì²­í¬ë©´ FFmpegë¡œ ë³‘í•©
                combined_audio = merge_audio_chunks_ffmpeg(audio_data_list)

            audio_base64 = base64.b64encode(combined_audio).decode('utf-8')
            audio_url = f"data:audio/mp3;base64,{audio_base64}"

            # Google Cloud TTS ë¹„ìš©: $4/100ë§Œ ê¸€ì (Wavenet), $16/100ë§Œ ê¸€ì (Neural2)
            # ì•½ 0.0054ì›/ê¸€ì (Wavenet ê¸°ì¤€, í™˜ìœ¨ 1350ì›)
            cost_per_char = 0.0054 if "Wavenet" in speaker else 0.0216
            cost_krw = int(char_count * cost_per_char)

            print(f"[DRAMA-STEP5-TTS] Google TTS ì™„ë£Œ - ê¸€ì ìˆ˜: {char_count}, ë¹„ìš©: â‚©{cost_krw}, ê°ì • SSML ì ìš©: {emotion_chunk_count}/{len(text_chunks)}ì²­í¬, í´ë°±: {ssml_fallback_count}íšŒ")

            return jsonify({
                "ok": True,
                "audioUrl": audio_url,
                "charCount": char_count,
                "cost": cost_krw,
                "provider": "google",
                "emotionChunks": emotion_chunk_count,
                "totalChunks": len(text_chunks)
            })

        # ë„¤ì´ë²„ í´ë¡œë°” TTS (ê¸°ì¡´ ì½”ë“œ)
        else:
            ncp_client_id = os.getenv("NCP_CLIENT_ID", "")
            ncp_client_secret = os.getenv("NCP_CLIENT_SECRET", "")

            if not ncp_client_id or not ncp_client_secret:
                return jsonify({"ok": False, "error": "ë„¤ì´ë²„ í´ë¼ìš°ë“œ API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. í™˜ê²½ë³€ìˆ˜ NCP_CLIENT_ID, NCP_CLIENT_SECRETì„ ì„¤ì •í•´ì£¼ì„¸ìš”."}), 200

            print(f"[DRAMA-STEP5-TTS] ë„¤ì´ë²„ TTS ìƒì„± ì‹œì‘ - ìŒì„±: {speaker}, í…ìŠ¤íŠ¸ ê¸¸ì´: {char_count}ì")

            max_chars = 1000
            text_chunks = []

            if len(text) > max_chars:
                sentences = text.replace('\n', ' ').split('. ')
                current_chunk = ""
                for sentence in sentences:
                    if len(current_chunk) + len(sentence) + 2 < max_chars:
                        current_chunk += sentence + ". "
                    else:
                        if current_chunk:
                            text_chunks.append(current_chunk.strip())
                        current_chunk = sentence + ". "
                if current_chunk:
                    text_chunks.append(current_chunk.strip())
            else:
                text_chunks = [text]

            audio_data_list = []

            for chunk in text_chunks:
                url = "https://naveropenapi.apigw.ntruss.com/tts-premium/v1/tts"
                headers = {
                    "X-NCP-APIGW-API-KEY-ID": ncp_client_id,
                    "X-NCP-APIGW-API-KEY": ncp_client_secret,
                    "Content-Type": "application/x-www-form-urlencoded"
                }

                payload = {
                    "speaker": speaker,
                    "volume": str(volume),
                    "speed": str(speed),
                    "pitch": str(pitch),
                    "format": "mp3",
                    "text": chunk
                }

                response = requests.post(url, headers=headers, data=payload)

                if response.status_code == 200:
                    audio_data_list.append(response.content)
                else:
                    error_text = response.text
                    print(f"[DRAMA-STEP5-TTS][ERROR] ë„¤ì´ë²„ API ì‘ë‹µ: {response.status_code} - {error_text}")

                    # 403 ì—ëŸ¬ì— ëŒ€í•œ íŠ¹ë³„í•œ ì•ˆë‚´
                    if response.status_code == 403:
                        error_msg = "ë„¤ì´ë²„ TTS API ì ‘ê·¼ ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤. ë„¤ì´ë²„ í´ë¼ìš°ë“œ í”Œë«í¼ì—ì„œ CLOVA Voice APIê°€ í™œì„±í™”ë˜ì–´ ìˆëŠ”ì§€, API í‚¤ê°€ ìœ íš¨í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”."
                        print(f"[DRAMA-STEP5-TTS][ERROR] 403 Forbidden - ë„¤ì´ë²„ API í‚¤ ë˜ëŠ” ê¶Œí•œ ë¬¸ì œ")
                        return jsonify({"ok": False, "error": error_msg, "statusCode": 403}), 200

                    return jsonify({"ok": False, "error": f"ë„¤ì´ë²„ TTS API ì˜¤ë¥˜ ({response.status_code}): {error_text}"}), 200

            # FFmpegë¡œ MP3 ì²­í¬ ë³‘í•© (ë„¤ì´ë²„ TTS)
            if len(audio_data_list) == 1:
                combined_audio = audio_data_list[0]
            else:
                combined_audio = merge_audio_chunks_ffmpeg(audio_data_list)

            audio_base64 = base64.b64encode(combined_audio).decode('utf-8')
            audio_url = f"data:audio/mp3;base64,{audio_base64}"

            cost_krw = int(char_count * 4)

            print(f"[DRAMA-STEP5-TTS] ë„¤ì´ë²„ TTS ì™„ë£Œ - ê¸€ì ìˆ˜: {char_count}, ë¹„ìš©: â‚©{cost_krw}")

            return jsonify({
                "ok": True,
                "audioUrl": audio_url,
                "charCount": char_count,
                "cost": cost_krw,
                "provider": "naver"
            })

    except Exception as e:
        print(f"[DRAMA-STEP5-TTS][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step3 TTS ìƒˆ íŒŒì´í”„ë¼ì¸ (5000ë°”ì´íŠ¸ ì œí•œ í•´ê²° + SRT ìë§‰) =====
@app.route('/api/drama/step3/tts', methods=['POST'])
def api_step3_tts_pipeline():
    """
    ìƒˆë¡œìš´ Step3 TTS íŒŒì´í”„ë¼ì¸
    - 5000ë°”ì´íŠ¸ ì œí•œ ìë™ í•´ê²° (ì²­í‚¹)
    - FFmpegë¡œ ì˜¤ë””ì˜¤ ë³‘í•©
    - SRT ìë§‰ ìë™ ìƒì„±

    Input:
    {
        "episode_id": "xxx",
        "language": "ko-KR",
        "voice": { "gender": "MALE", "name": "ko-KR-Neural2-B", "speaking_rate": 0.9 },
        "scenes": [{ "id": "scene1", "narration": "..." }, ...]
    }

    Output:
    {
        "ok": true,
        "episode_id": "xxx",
        "audio_file": "outputs/audio/xxx_full.mp3",
        "audio_url": "/outputs/audio/xxx_full.mp3",
        "srt_file": "outputs/subtitles/xxx.srt",
        "timeline": [...],
        "stats": {...}
    }
    """
    try:
        from tts import run_tts_pipeline

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        scenes = data.get("scenes", [])
        if not scenes:
            return jsonify({"ok": False, "error": "ì”¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[STEP3-TTS] ìƒˆ íŒŒì´í”„ë¼ì¸ ì‹œì‘: {len(scenes)}ê°œ ì”¬")

        result = run_tts_pipeline(data)

        # íŒŒì¼ ê²½ë¡œë¥¼ URLë¡œ ë³€í™˜
        if result.get("ok") and result.get("audio_file"):
            audio_file = result["audio_file"]
            result["audio_url"] = "/" + audio_file

        if result.get("ok") and result.get("srt_file"):
            srt_file = result["srt_file"]
            result["srt_url"] = "/" + srt_file

        return jsonify(result)

    except Exception as e:
        print(f"[STEP3-TTS][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step5: ìë§‰ ìƒì„± API =====
@app.route('/api/drama/generate-subtitle', methods=['POST'])
def api_generate_subtitle():
    """í…ìŠ¤íŠ¸ë¥¼ SRT/VTT ìë§‰ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        text = data.get("text", "")
        speed = data.get("speed", 0)  # TTS ì†ë„ (-5 ~ 5)
        audio_duration = data.get("audioDuration", 0)  # ì‹¤ì œ TTS ì˜¤ë””ì˜¤ ê¸¸ì´ (ì´ˆ)

        if not text:
            return jsonify({"ok": False, "error": "í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[DRAMA-STEP5-SUBTITLE] ìë§‰ ìƒì„± ì‹œì‘ - í…ìŠ¤íŠ¸ ê¸¸ì´: {len(text)}ì, ì˜¤ë””ì˜¤ ê¸¸ì´: {audio_duration}ì´ˆ")

        # ê¸€ìë‹¹ ì‹œê°„ ê³„ì‚°
        # 1. ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ê°€ ìˆìœ¼ë©´ ê·¸ì— ë§ê²Œ ê³„ì‚°
        # 2. ì—†ìœ¼ë©´ ì†ë„ ê¸°ë°˜ìœ¼ë¡œ ì¶”ì •
        if audio_duration and audio_duration > 0:
            # ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ ê¸°ë°˜ ê³„ì‚° (ì—¬ìœ  ì‹œê°„ ê³ ë ¤)
            char_duration = audio_duration / max(len(text), 1)
            print(f"[DRAMA-STEP5-SUBTITLE] ì˜¤ë””ì˜¤ ê¸°ë°˜ ê¸€ìë‹¹ ì‹œê°„: {char_duration:.4f}ì´ˆ")
        else:
            # ì†ë„ì— ë”°ë¥¸ ê¸€ìë‹¹ ì‹œê°„ ê³„ì‚° (ê¸°ë³¸: ê¸€ìë‹¹ ì•½ 0.15ì´ˆ)
            # ì†ë„ê°€ ë¹ ë¥´ë©´ ì‹œê°„ ê°ì†Œ, ëŠë¦¬ë©´ ì‹œê°„ ì¦ê°€
            base_char_duration = 0.15
            speed_factor = 1 - (speed * 0.1)  # speedê°€ 5ë©´ 0.5ë°°, -5ë©´ 1.5ë°°
            char_duration = base_char_duration * speed_factor
            print(f"[DRAMA-STEP5-SUBTITLE] ì†ë„ ê¸°ë°˜ ê¸€ìë‹¹ ì‹œê°„: {char_duration:.4f}ì´ˆ")

        # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ê°œì„ ëœ ë¡œì§)
        import re

        # 1ë‹¨ê³„: ì¤„ë°”ê¿ˆìœ¼ë¡œ ë¨¼ì € ë¶„í• 
        lines = text.split('\n')
        raw_sentences = []

        for line in lines:
            line = line.strip()
            if not line:
                continue

            # 2ë‹¨ê³„: ë¬¸ì¥ ì¢…ê²° ë¶€í˜¸ë¡œ ë¶„í•  (.!?ã€‚)
            # í•œêµ­ì–´ ë¬¸ì¥ ì¢…ë£Œ ì–´ë¯¸ë„ ê³ ë ¤ (~ìš”, ~ë‹¤, ~ì£ , ~ë„¤ìš” ë“±)
            parts = re.split(r'([.!?ã€‚])', line)

            current = ""
            for i, part in enumerate(parts):
                if part in '.!?ã€‚':
                    current += part
                    if current.strip():
                        raw_sentences.append(current.strip())
                    current = ""
                else:
                    current += part

            # ë§ˆì§€ë§‰ ë‚¨ì€ ë¶€ë¶„ ì¶”ê°€
            if current.strip():
                raw_sentences.append(current.strip())

        # 3ë‹¨ê³„: ê¸´ ë¬¸ì¥ì€ ì‰¼í‘œë‚˜ ì ì ˆí•œ ìœ„ì¹˜ì—ì„œ ë¶„í• 
        MAX_CHARS = 35  # ìë§‰ í•œ ì¤„ ìµœëŒ€ ê¸€ì ìˆ˜
        sentences = []

        for sentence in raw_sentences:
            if len(sentence) <= MAX_CHARS:
                sentences.append(sentence)
            else:
                # ì‰¼í‘œ, ì¡°ì‚¬ ìœ„ì¹˜ì—ì„œ ë¶„í•  ì‹œë„
                # í•œêµ­ì–´ ë¶„í•  í¬ì¸íŠ¸: ì‰¼í‘œ, ~ê³ , ~ë©°, ~ë©´, ~ì„œ, ~ë‹ˆ, ~ëŠ”ë°
                split_pattern = r'(,\s*|(?<=[ê°€-í£])ê³ \s+|(?<=[ê°€-í£])ë©°\s+|(?<=[ê°€-í£])ë©´\s+|(?<=[ê°€-í£])ì„œ\s+|(?<=[ê°€-í£])ëŠ”ë°\s+)'
                sub_parts = re.split(split_pattern, sentence)

                current_part = ""
                for sub in sub_parts:
                    if not sub:
                        continue
                    # ë¶„í•  íŒ¨í„´ì¸ ê²½ìš° í˜„ì¬ ë¶€ë¶„ì— ë¶™ì„
                    if re.match(split_pattern, sub):
                        current_part += sub
                    elif len(current_part) + len(sub) <= MAX_CHARS:
                        current_part += sub
                    else:
                        if current_part.strip():
                            sentences.append(current_part.strip())
                        current_part = sub

                if current_part.strip():
                    sentences.append(current_part.strip())

        # 4ë‹¨ê³„: ì—¬ì „íˆ ê¸´ ë¬¸ì¥ì€ ê°•ì œ ë¶„í• 
        final_sentences = []
        for sentence in sentences:
            if len(sentence) <= MAX_CHARS:
                final_sentences.append(sentence)
            else:
                # ê³µë°± ê¸°ì¤€ ë¶„í• 
                words = sentence.split()
                current = ""
                for word in words:
                    if len(current) + len(word) + 1 <= MAX_CHARS:
                        current = current + " " + word if current else word
                    else:
                        if current:
                            final_sentences.append(current)
                        current = word
                if current:
                    final_sentences.append(current)

        sentences = [s for s in final_sentences if s.strip()]

        # â˜… ì§§ì€ ìë§‰ í•©ì¹˜ê¸° (10ê¸€ì ë¯¸ë§Œì€ ì¸ì ‘ ë¬¸ì¥ê³¼ í•©ì¹¨)
        MIN_SUBTITLE_LEN = 10
        if len(sentences) > 1:
            merged = []
            i = 0
            while i < len(sentences):
                current = sentences[i]
                # ì¶©ë¶„íˆ ê¸¸ë©´ ê·¸ëƒ¥ ì¶”ê°€
                if len(current) >= MIN_SUBTITLE_LEN:
                    merged.append(current)
                    i += 1
                    continue
                # ì§§ìœ¼ë©´ ë‹¤ìŒê³¼ í•©ì¹˜ê¸°
                if i + 1 < len(sentences):
                    next_sent = sentences[i + 1]
                    combined = current + " " + next_sent
                    if len(combined) <= MAX_CHARS:
                        merged.append(combined)
                    else:
                        # ë‘ ì¤„ë¡œ (ì¤„ë°”ê¿ˆ)
                        merged.append(current + "\n" + next_sent)
                    i += 2
                elif merged:
                    # ë§ˆì§€ë§‰ ì§§ì€ ë¬¸ì¥ì€ ì´ì „ê³¼ í•©ì¹¨
                    prev = merged.pop()
                    combined = prev + " " + current
                    if len(combined) <= MAX_CHARS:
                        merged.append(combined)
                    else:
                        merged.append(prev + "\n" + current)
                    i += 1
                else:
                    merged.append(current)
                    i += 1
            sentences = merged

        # ë¬¸ì¥ì´ ì—†ìœ¼ë©´ ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ
        if not sentences and text.strip():
            sentences = [text.strip()[:MAX_CHARS]]

        # SRT í˜•ì‹ ìƒì„±
        srt_lines = []
        vtt_lines = ["WEBVTT", ""]

        current_time = 0.0

        for idx, sentence in enumerate(sentences, 1):
            # ë¬¸ì¥ ê¸¸ì´ì— ë”°ë¥¸ í‘œì‹œ ì‹œê°„ ê³„ì‚°
            sentence_duration = len(sentence) * char_duration
            # ìµœì†Œ 1ì´ˆ, ìµœëŒ€ 10ì´ˆ
            sentence_duration = max(1.0, min(10.0, sentence_duration))

            start_time = current_time
            end_time = current_time + sentence_duration

            # ì‹œê°„ í¬ë§·íŒ… í•¨ìˆ˜
            def format_time_srt(seconds):
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                secs = int(seconds % 60)
                millis = int((seconds % 1) * 1000)
                return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"

            def format_time_vtt(seconds):
                hours = int(seconds // 3600)
                minutes = int((seconds % 3600) // 60)
                secs = int(seconds % 60)
                millis = int((seconds % 1) * 1000)
                return f"{hours:02d}:{minutes:02d}:{secs:02d}.{millis:03d}"

            # ìë§‰ìš© í…ìŠ¤íŠ¸: í•œê¸€ ìˆ«ì â†’ ì•„ë¼ë¹„ì•„ ìˆ«ì ë³€í™˜
            subtitle_text = korean_number_to_arabic(sentence)

            # SRT í˜•ì‹
            srt_lines.append(str(idx))
            srt_lines.append(f"{format_time_srt(start_time)} --> {format_time_srt(end_time)}")
            srt_lines.append(subtitle_text)
            srt_lines.append("")

            # VTT í˜•ì‹
            vtt_lines.append(f"{format_time_vtt(start_time)} --> {format_time_vtt(end_time)}")
            vtt_lines.append(subtitle_text)
            vtt_lines.append("")

            current_time = end_time + 0.2  # ë¬¸ì¥ ì‚¬ì´ ê°„ê²©

        srt_content = "\n".join(srt_lines)
        vtt_content = "\n".join(vtt_lines)

        print(f"[DRAMA-STEP5-SUBTITLE] ìë§‰ ìƒì„± ì™„ë£Œ - {len(sentences)}ê°œ ë¬¸ì¥")

        return jsonify({
            "ok": True,
            "srt": srt_content,
            "vtt": vtt_content,
            "sentenceCount": len(sentences),
            "totalDuration": current_time
        })

    except Exception as e:
        print(f"[DRAMA-STEP5-SUBTITLE][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== BGM íŒŒì¼ ì—…ë¡œë“œ API =====
@app.route('/api/bgm/upload', methods=['POST'])
def api_upload_bgm():
    """BGM íŒŒì¼ ì—…ë¡œë“œ (MP3)"""
    try:
        if 'file' not in request.files:
            return jsonify({"ok": False, "error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

        file = request.files['file']
        mood = request.form.get('mood', '')

        if not file.filename:
            return jsonify({"ok": False, "error": "íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

        if not mood:
            return jsonify({"ok": False, "error": "ë¶„ìœ„ê¸°(mood)ë¥¼ ì„ íƒí•˜ì„¸ìš”"}), 400

        # BGM ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„± (ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ)
        script_dir = os.path.dirname(os.path.abspath(__file__))
        bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")
        os.makedirs(bgm_dir, exist_ok=True)
        print(f"[BGM-UPLOAD] ë””ë ‰í† ë¦¬: {bgm_dir}")

        # ê¸°ì¡´ íŒŒì¼ í™•ì¸í•˜ì—¬ ë²ˆí˜¸ ë¶€ì—¬
        import glob
        existing = glob.glob(os.path.join(bgm_dir, f"{mood}*.mp3"))
        num = len(existing) + 1
        filename = f"{mood}_{num:02d}.mp3"
        filepath = os.path.join(bgm_dir, filename)

        file.save(filepath)
        print(f"[BGM-UPLOAD] ì €ì¥ë¨: {filepath}")

        # Gitì— ìë™ ì»¤ë°‹ (ë°°í¬ í›„ì—ë„ íŒŒì¼ ìœ ì§€)
        try:
            import subprocess
            subprocess.run(["git", "add", filepath], cwd=script_dir, timeout=30)
            subprocess.run(["git", "commit", "-m", f"Add BGM: {filename}"], cwd=script_dir, timeout=30)
            subprocess.run(["git", "push"], cwd=script_dir, timeout=60)
            print(f"[BGM-UPLOAD] Git ì»¤ë°‹ ì™„ë£Œ: {filename}")
        except Exception as git_err:
            print(f"[BGM-UPLOAD] Git ì»¤ë°‹ ì‹¤íŒ¨ (íŒŒì¼ì€ ì €ì¥ë¨): {git_err}")

        return jsonify({
            "ok": True,
            "filename": filename,
            "path": filepath,
            "mood": mood,
            "count": num
        })

    except Exception as e:
        print(f"[BGM-UPLOAD] ì˜¤ë¥˜: {e}")
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/bgm/list', methods=['GET'])
def api_list_bgm():
    """ì—…ë¡œë“œëœ BGM íŒŒì¼ ëª©ë¡"""
    try:
        import glob
        script_dir = os.path.dirname(os.path.abspath(__file__))
        bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")
        os.makedirs(bgm_dir, exist_ok=True)

        files = glob.glob(os.path.join(bgm_dir, "*.mp3"))
        print(f"[BGM-LIST] ë””ë ‰í† ë¦¬: {bgm_dir}, íŒŒì¼ ìˆ˜: {len(files)}")
        moods = {}

        for f in files:
            filename = os.path.basename(f)
            # mood ì¶”ì¶œ: hopeful_01.mp3 -> hopeful
            mood = filename.split('_')[0].split('.')[0].split(' ')[0]
            if mood not in moods:
                moods[mood] = []
            moods[mood].append(filename)

        return jsonify({"ok": True, "moods": moods, "total": len(files)})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== Freesound API ë‹¤ìš´ë¡œë“œ ==========
FREESOUND_API_KEY = "xuttzpvpcpbcXZTxGj75GXd6lnzn16SlADMhlP9f"
FREESOUND_BASE_URL = "https://freesound.org/apiv2"

# ë‹¤ìš´ë¡œë“œí•  ì˜¤ë””ì˜¤ ì¿¼ë¦¬ ì •ì˜
FREESOUND_BGM_QUERIES = {
    # ê¸°ì¡´ ë¶„ìœ„ê¸°
    "epic": ("epic cinematic orchestral trailer", 30, 180),
    "romantic": ("romantic piano love emotional", 30, 180),
    "comedic": ("funny comedy playful quirky", 30, 180),
    "horror": ("horror scary dark creepy", 30, 180),
    "upbeat": ("upbeat happy energetic positive", 30, 180),

    # ê°ì •/ë¶„ìœ„ê¸°
    "hopeful": ("hopeful inspiring positive uplifting", 30, 180),
    "sad": ("sad melancholic emotional piano", 30, 180),
    "tense": ("tense suspense thriller tension", 30, 180),
    "dramatic": ("dramatic cinematic intense emotional", 30, 180),
    "calm": ("calm peaceful relaxing ambient", 30, 180),
    "inspiring": ("inspiring motivational uplifting", 30, 180),
    "mysterious": ("mysterious ambient enigmatic", 30, 180),
    "nostalgic": ("nostalgic emotional memories retro", 30, 180),
    "melancholic": ("melancholic sad piano emotional", 30, 180),
    "peaceful": ("peaceful serene nature calm", 30, 180),
    "dark": ("dark ominous sinister ambient", 30, 180),
    "bright": ("bright cheerful happy sunshine", 30, 180),
    "ethereal": ("ethereal dreamy ambient atmospheric", 30, 180),
    "whimsical": ("whimsical playful magical fairy", 30, 180),

    # ì¥ë¥´
    "jazz": ("jazz smooth saxophone piano", 30, 180),
    "classical": ("classical orchestra symphony", 30, 180),
    "electronic": ("electronic ambient synth", 30, 180),
    "ambient": ("ambient atmospheric soundscape", 30, 180),
    "acoustic": ("acoustic guitar folk warm", 30, 180),
    "piano": ("piano solo emotional beautiful", 30, 180),

    # ì•¡ì…˜/ëª¨í—˜
    "action": ("action intense fast battle", 30, 180),
    "adventure": ("adventure exploration journey", 30, 180),
    "chase": ("chase pursuit fast tension", 30, 180),
    "battle": ("battle war epic drums", 30, 180),
    "heroic": ("heroic triumphant victory brass", 30, 180),

    # ìƒí™©/ìš©ë„
    "news": ("news broadcast corporate serious", 30, 180),
    "documentary": ("documentary informative ambient", 30, 180),
    "corporate": ("corporate business professional", 30, 180),
    "cinematic": ("cinematic film score emotional", 30, 180),
    "trailer": ("trailer epic dramatic intense", 30, 180),

    # íŠ¹ìˆ˜ ë¶„ìœ„ê¸°
    "suspenseful": ("suspenseful thriller mystery tension", 30, 180),
    "triumphant": ("triumphant victory celebration fanfare", 30, 180),
    "sentimental": ("sentimental emotional touching", 30, 180),
    "energetic": ("energetic dynamic powerful driving", 30, 180),
    "relaxing": ("relaxing spa meditation calm", 30, 180),
}

FREESOUND_SFX_QUERIES = {
    # ê¸°ì¡´ íš¨ê³¼ìŒ
    "notification": ("notification alert ding", 0.5, 5),
    "heartbeat": ("heartbeat heart beat", 1, 10),
    "clock_tick": ("clock tick ticking", 1, 10),
    "gasp": ("gasp surprise shock", 0.5, 5),
    "typing": ("typing keyboard", 1, 10),
    "door": ("door open close creak", 0.5, 5),

    # ì „í™˜/ì›€ì§ì„
    "swoosh": ("swoosh whoosh swipe fast", 0.3, 3),
    "transition": ("transition cinematic", 0.5, 5),
    "slide": ("slide swoosh smooth", 0.3, 3),
    "rewind": ("rewind tape reverse", 0.5, 5),

    # ê°ì •/ë°˜ì‘
    "laugh": ("laugh laughter funny", 1, 8),
    "cry": ("cry crying sob", 1, 10),
    "sigh": ("sigh relief exhale", 0.5, 5),
    "scream": ("scream horror shock", 0.5, 5),

    # í™˜ê²½/ìì—°
    "rain": ("rain rainfall ambient", 3, 15),
    "thunder": ("thunder storm rumble", 1, 10),
    "wind": ("wind blowing ambient", 2, 15),

    # ê¸´ì¥/ê³µí¬
    "suspense": ("suspense tension horror", 2, 15),
    "horror_sting": ("horror sting scare jump", 0.5, 5),
    "dramatic_hit": ("dramatic hit impact orchestra", 0.5, 5),
    "drone": ("drone dark ominous", 3, 15),

    # UI/ì•Œë¦¼
    "pop": ("pop bubble click", 0.2, 3),
    "click": ("click button interface", 0.2, 2),
    "beep": ("beep electronic alert", 0.3, 3),
    "chime": ("chime bell notification", 0.5, 5),
    "error": ("error wrong buzzer", 0.3, 3),

    # ì•¡ì…˜/ì¶©ëŒ
    "punch": ("punch hit fight", 0.3, 3),
    "crash": ("crash breaking glass", 0.5, 5),
    "explosion": ("explosion boom blast", 1, 8),
    "slam": ("slam door bang", 0.3, 3),

    # ì„±ê³µ/ì‹¤íŒ¨
    "win": ("win victory success fanfare", 1, 8),
    "fail": ("fail lose game over", 1, 5),
    "reveal": ("reveal magic sparkle", 1, 8),
    "countdown": ("countdown beep timer", 2, 10),

    # ê¸°íƒ€
    "magic": ("magic spell sparkle fantasy", 1, 8),
    "glitch": ("glitch digital distortion", 0.5, 5),
    "camera": ("camera shutter photo", 0.3, 3),
    "cash": ("cash register money coin", 0.5, 5),
    "writing": ("writing pen pencil paper", 1, 8),
    "footsteps": ("footsteps walking steps", 2, 10),
    "car": ("car engine driving", 2, 10),
    "phone": ("phone ring mobile", 1, 8),
}


def _freesound_search(query, min_duration=0, max_duration=300, num_results=4):
    """Freesoundì—ì„œ ì†Œë¦¬ ê²€ìƒ‰"""
    import requests
    params = {
        "query": query,
        "token": FREESOUND_API_KEY,
        "fields": "id,name,duration,previews,license",
        "filter": f"duration:[{min_duration} TO {max_duration}]",
        "sort": "score",
        "page_size": num_results * 2,
    }
    try:
        response = requests.get(f"{FREESOUND_BASE_URL}/search/text/", params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        return data.get("results", [])[:num_results]
    except Exception as e:
        print(f"[FREESOUND] ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        return []


def _freesound_download_preview(sound, output_path):
    """ì‚¬ìš´ë“œ í”„ë¦¬ë·°(MP3) ë‹¤ìš´ë¡œë“œ"""
    import requests
    try:
        preview_url = sound.get("previews", {}).get("preview-hq-mp3")
        if not preview_url:
            preview_url = sound.get("previews", {}).get("preview-lq-mp3")
        if not preview_url:
            return False
        response = requests.get(preview_url, timeout=60)
        response.raise_for_status()
        with open(output_path, "wb") as f:
            f.write(response.content)
        return True
    except Exception as e:
        print(f"[FREESOUND] ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return False


@app.route('/api/freesound/download', methods=['GET', 'POST'])
def api_freesound_download():
    """Freesoundì—ì„œ BGM/SFX ë‹¤ìš´ë¡œë“œ (GETìœ¼ë¡œë„ í˜¸ì¶œ ê°€ëŠ¥)"""
    import time

    script_dir = os.path.dirname(os.path.abspath(__file__))
    bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")
    sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")

    results = {"bgm": {}, "sfx": {}, "errors": []}

    # GET ë˜ëŠ” POST ëª¨ë‘ ì§€ì›
    if request.method == 'POST' and request.is_json:
        data = request.get_json() or {}
    else:
        data = request.args.to_dict()

    download_bgm = data.get("bgm", "true").lower() != "false" if isinstance(data.get("bgm"), str) else data.get("bgm", True)
    download_sfx = data.get("sfx", "true").lower() != "false" if isinstance(data.get("sfx"), str) else data.get("sfx", True)

    # BGM ë‹¤ìš´ë¡œë“œ
    if download_bgm:
        for sound_type, (query, min_dur, max_dur) in FREESOUND_BGM_QUERIES.items():
            print(f"[FREESOUND] BGM ê²€ìƒ‰: {sound_type} - '{query}'")
            sounds = _freesound_search(query, min_dur, max_dur, num_results=4)

            if not sounds:
                results["errors"].append(f"BGM '{sound_type}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                continue

            downloaded = []
            for i, sound in enumerate(sounds, 1):
                filename = f"{sound_type}_{i:02d}.mp3"
                output_path = os.path.join(bgm_dir, filename)

                if _freesound_download_preview(sound, output_path):
                    downloaded.append({
                        "file": filename,
                        "name": sound.get("name", "")[:50],
                        "duration": sound.get("duration", 0)
                    })
                    print(f"[FREESOUND] âœ“ {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

                time.sleep(0.3)  # Rate limit

            results["bgm"][sound_type] = downloaded
            time.sleep(0.5)

    # SFX ë‹¤ìš´ë¡œë“œ
    if download_sfx:
        for sound_type, (query, min_dur, max_dur) in FREESOUND_SFX_QUERIES.items():
            print(f"[FREESOUND] SFX ê²€ìƒ‰: {sound_type} - '{query}'")
            sounds = _freesound_search(query, min_dur, max_dur, num_results=4)

            if not sounds:
                results["errors"].append(f"SFX '{sound_type}' ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
                continue

            downloaded = []
            for i, sound in enumerate(sounds, 1):
                filename = f"{sound_type}_{i:02d}.mp3"
                output_path = os.path.join(sfx_dir, filename)

                if _freesound_download_preview(sound, output_path):
                    downloaded.append({
                        "file": filename,
                        "name": sound.get("name", "")[:50],
                        "duration": sound.get("duration", 0)
                    })
                    print(f"[FREESOUND] âœ“ {filename} ë‹¤ìš´ë¡œë“œ ì™„ë£Œ")

                time.sleep(0.3)

            results["sfx"][sound_type] = downloaded
            time.sleep(0.5)

    return jsonify({
        "ok": True,
        "message": "Freesound ë‹¤ìš´ë¡œë“œ ì™„ë£Œ",
        "results": results
    })


@app.route('/api/freesound/test', methods=['GET'])
def api_freesound_test():
    """Freesound API í‚¤ í…ŒìŠ¤íŠ¸"""
    sounds = _freesound_search("test", 0, 10, 1)
    if sounds:
        return jsonify({"ok": True, "message": "API í‚¤ ìœ íš¨í•¨", "sample": sounds[0].get("name")})
    else:
        return jsonify({"ok": False, "message": "API í‚¤ í™•ì¸ í•„ìš”"}), 500


@app.route('/api/audio/download-zip', methods=['GET'])
def api_audio_download_zip():
    """ì„œë²„ì˜ ëª¨ë“  BGM/SFX íŒŒì¼ì„ zipìœ¼ë¡œ ë‹¤ìš´ë¡œë“œ"""
    import zipfile
    import io

    script_dir = os.path.dirname(os.path.abspath(__file__))
    bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")
    sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")

    # ë©”ëª¨ë¦¬ì— zip íŒŒì¼ ìƒì„±
    memory_file = io.BytesIO()

    with zipfile.ZipFile(memory_file, 'w', zipfile.ZIP_DEFLATED) as zf:
        # BGM íŒŒì¼ ì¶”ê°€
        if os.path.exists(bgm_dir):
            for filename in os.listdir(bgm_dir):
                if filename.endswith('.mp3'):
                    filepath = os.path.join(bgm_dir, filename)
                    zf.write(filepath, f"bgm/{filename}")

        # SFX íŒŒì¼ ì¶”ê°€
        if os.path.exists(sfx_dir):
            for filename in os.listdir(sfx_dir):
                if filename.endswith('.mp3'):
                    filepath = os.path.join(sfx_dir, filename)
                    zf.write(filepath, f"sfx/{filename}")

    memory_file.seek(0)

    return send_file(
        memory_file,
        mimetype='application/zip',
        as_attachment=True,
        download_name='audio_files.zip'
    )


@app.route('/api/audio/list', methods=['GET'])
def api_audio_list():
    """ì„œë²„ì— ìˆëŠ” BGM/SFX íŒŒì¼ ëª©ë¡"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")
    sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")

    bgm_files = []
    sfx_files = []

    if os.path.exists(bgm_dir):
        bgm_files = sorted([f for f in os.listdir(bgm_dir) if f.endswith('.mp3')])

    if os.path.exists(sfx_dir):
        sfx_files = sorted([f for f in os.listdir(sfx_dir) if f.endswith('.mp3')])

    return jsonify({
        "ok": True,
        "bgm": {"count": len(bgm_files), "files": bgm_files},
        "sfx": {"count": len(sfx_files), "files": sfx_files},
        "total": len(bgm_files) + len(sfx_files)
    })


@app.route('/bgm-upload')
def bgm_upload_page():
    """BGM ì—…ë¡œë“œ í˜ì´ì§€"""
    return '''<!DOCTYPE html>
<html><head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>BGM ì—…ë¡œë“œ</title>
<style>
body { font-family: -apple-system, BlinkMacSystemFont, sans-serif; max-width: 600px; margin: 50px auto; padding: 20px; background: #1a1a2e; color: #eee; }
h1 { color: #00d4ff; }
.upload-box { border: 2px dashed #444; padding: 40px; text-align: center; margin: 20px 0; border-radius: 10px; }
.upload-box.dragover { border-color: #00d4ff; background: rgba(0,212,255,0.1); }
select, button { padding: 12px 24px; font-size: 16px; margin: 10px 5px; border-radius: 5px; border: none; cursor: pointer; }
select { background: #333; color: #fff; }
button { background: #00d4ff; color: #000; font-weight: bold; }
button:hover { background: #00b8e6; }
.file-list { background: #2a2a4e; padding: 15px; border-radius: 10px; margin-top: 20px; }
.file-item { padding: 8px; border-bottom: 1px solid #444; }
.mood-tag { display: inline-block; padding: 3px 8px; border-radius: 3px; font-size: 12px; margin-right: 10px; }
.hopeful { background: #4CAF50; } .sad { background: #2196F3; } .tense { background: #f44336; }
.dramatic { background: #9C27B0; } .calm { background: #00BCD4; } .inspiring { background: #FF9800; }
.mysterious { background: #607D8B; } .nostalgic { background: #795548; }
#status { margin-top: 15px; padding: 10px; border-radius: 5px; }
.success { background: #1b5e20; } .error { background: #b71c1c; }
</style>
</head><body>
<h1>ğŸµ BGM ì—…ë¡œë“œ</h1>
<p>MP3 íŒŒì¼ì„ ë¶„ìœ„ê¸°ë³„ë¡œ ì—…ë¡œë“œí•˜ì„¸ìš”</p>

<select id="mood">
<option value="">-- ë¶„ìœ„ê¸° ì„ íƒ --</option>
<option value="hopeful">ğŸ˜Š hopeful (í¬ë§ì )</option>
<option value="sad">ğŸ˜¢ sad (ìŠ¬í””)</option>
<option value="tense">ğŸ˜° tense (ê¸´ì¥)</option>
<option value="dramatic">ğŸ­ dramatic (ê·¹ì )</option>
<option value="calm">ğŸ˜Œ calm (í‰í™”)</option>
<option value="inspiring">âœ¨ inspiring (ê°ë™)</option>
<option value="mysterious">ğŸ”® mysterious (ë¯¸ìŠ¤í„°ë¦¬)</option>
<option value="nostalgic">ğŸŒ… nostalgic (í–¥ìˆ˜)</option>
</select>

<div class="upload-box" id="dropzone">
<p>ğŸ“ MP3 íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒ</p>
<input type="file" id="fileInput" accept=".mp3,audio/mpeg" multiple style="display:none">
</div>

<div id="status"></div>

<h3>ğŸ“‹ ì—…ë¡œë“œëœ BGM</h3>
<div class="file-list" id="fileList">ë¡œë”© ì¤‘...</div>

<script>
const dropzone = document.getElementById('dropzone');
const fileInput = document.getElementById('fileInput');
const moodSelect = document.getElementById('mood');
const status = document.getElementById('status');

dropzone.onclick = () => fileInput.click();
dropzone.ondragover = (e) => { e.preventDefault(); dropzone.classList.add('dragover'); };
dropzone.ondragleave = () => dropzone.classList.remove('dragover');
dropzone.ondrop = (e) => { e.preventDefault(); dropzone.classList.remove('dragover'); handleFiles(e.dataTransfer.files); };
fileInput.onchange = () => handleFiles(fileInput.files);

async function handleFiles(files) {
    const mood = moodSelect.value;
    if (!mood) { alert('ë¶„ìœ„ê¸°ë¥¼ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”!'); return; }

    for (const file of files) {
        if (!file.name.endsWith('.mp3')) { alert(file.name + ' - MP3 íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'); continue; }

        const formData = new FormData();
        formData.append('file', file);
        formData.append('mood', mood);

        status.innerHTML = 'â³ ì—…ë¡œë“œ ì¤‘: ' + file.name;
        status.className = '';

        try {
            const res = await fetch('/api/bgm/upload', { method: 'POST', body: formData });
            const data = await res.json();
            if (data.ok) {
                status.innerHTML = 'âœ… ì—…ë¡œë“œ ì™„ë£Œ: ' + data.filename;
                status.className = 'success';
                loadFileList();
            } else {
                status.innerHTML = 'âŒ ì‹¤íŒ¨: ' + data.error;
                status.className = 'error';
            }
        } catch (e) {
            status.innerHTML = 'âŒ ì˜¤ë¥˜: ' + e.message;
            status.className = 'error';
        }
    }
}

async function loadFileList() {
    try {
        const res = await fetch('/api/bgm/list');
        const data = await res.json();
        if (data.ok) {
            let html = '<p>ì´ ' + data.total + 'ê°œ íŒŒì¼</p>';
            for (const [mood, files] of Object.entries(data.moods)) {
                html += '<div class="file-item"><span class="mood-tag ' + mood + '">' + mood + '</span> ' + files.join(', ') + '</div>';
            }
            document.getElementById('fileList').innerHTML = html || '<p>ì—…ë¡œë“œëœ íŒŒì¼ ì—†ìŒ</p>';
        }
    } catch (e) { document.getElementById('fileList').innerHTML = 'ë¡œë“œ ì‹¤íŒ¨'; }
}
loadFileList();
</script>
</body></html>'''


# ===== íš¨ê³¼ìŒ íŒŒì¼ ì—…ë¡œë“œ API =====
@app.route('/api/sfx/upload', methods=['POST'])
def api_upload_sfx():
    """íš¨ê³¼ìŒ íŒŒì¼ ì—…ë¡œë“œ (MP3)"""
    try:
        if 'file' not in request.files:
            return jsonify({"ok": False, "error": "íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

        file = request.files['file']
        sfx_type = request.form.get('type', '')

        if not file.filename:
            return jsonify({"ok": False, "error": "íŒŒì¼ëª…ì´ ì—†ìŠµë‹ˆë‹¤"}), 400

        if not sfx_type:
            return jsonify({"ok": False, "error": "íš¨ê³¼ìŒ íƒ€ì…ì„ ì„ íƒí•˜ì„¸ìš”"}), 400

        # íš¨ê³¼ìŒ ë””ë ‰í† ë¦¬ í™•ì¸/ìƒì„± (ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ)
        script_dir = os.path.dirname(os.path.abspath(__file__))
        sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")
        os.makedirs(sfx_dir, exist_ok=True)
        print(f"[SFX-UPLOAD] ë””ë ‰í† ë¦¬: {sfx_dir}")

        # ê¸°ì¡´ íŒŒì¼ í™•ì¸í•˜ì—¬ ë²ˆí˜¸ ë¶€ì—¬
        import glob
        existing = glob.glob(os.path.join(sfx_dir, f"{sfx_type}*.mp3"))
        num = len(existing) + 1
        filename = f"{sfx_type}_{num:02d}.mp3"
        filepath = os.path.join(sfx_dir, filename)

        file.save(filepath)
        print(f"[SFX-UPLOAD] ì €ì¥ë¨: {filepath}")

        # Gitì— ìë™ ì»¤ë°‹ (ë°°í¬ í›„ì—ë„ íŒŒì¼ ìœ ì§€)
        try:
            import subprocess
            subprocess.run(["git", "add", filepath], cwd=script_dir, timeout=30)
            subprocess.run(["git", "commit", "-m", f"Add SFX: {filename}"], cwd=script_dir, timeout=30)
            subprocess.run(["git", "push"], cwd=script_dir, timeout=60)
            print(f"[SFX-UPLOAD] Git ì»¤ë°‹ ì™„ë£Œ: {filename}")
        except Exception as git_err:
            print(f"[SFX-UPLOAD] Git ì»¤ë°‹ ì‹¤íŒ¨ (íŒŒì¼ì€ ì €ì¥ë¨): {git_err}")

        return jsonify({
            "ok": True,
            "filename": filename,
            "path": filepath,
            "type": sfx_type,
            "count": num
        })

    except Exception as e:
        print(f"[SFX-UPLOAD] ì˜¤ë¥˜: {e}")
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sfx/list', methods=['GET'])
def api_list_sfx():
    """ì—…ë¡œë“œëœ íš¨ê³¼ìŒ íŒŒì¼ ëª©ë¡"""
    try:
        import glob
        script_dir = os.path.dirname(os.path.abspath(__file__))
        sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")
        os.makedirs(sfx_dir, exist_ok=True)

        files = glob.glob(os.path.join(sfx_dir, "*.mp3"))
        print(f"[SFX-LIST] ë””ë ‰í† ë¦¬: {sfx_dir}, íŒŒì¼ ìˆ˜: {len(files)}")
        types = {}

        for f in files:
            filename = os.path.basename(f)
            sfx_type = filename.split('_')[0].split('.')[0]
            if sfx_type not in types:
                types[sfx_type] = []
            types[sfx_type].append(filename)

        return jsonify({"ok": True, "types": types, "total": len(files)})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/sfx-upload')
def sfx_upload_page():
    """íš¨ê³¼ìŒ ì—…ë¡œë“œ í˜ì´ì§€"""
    return '''<!DOCTYPE html>
<html><head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>íš¨ê³¼ìŒ ì—…ë¡œë“œ</title>
<style>
body { font-family: -apple-system, BlinkMacSystemFont, sans-serif; max-width: 600px; margin: 50px auto; padding: 20px; background: #1a1a2e; color: #eee; }
h1 { color: #ff6b6b; }
.upload-box { border: 2px dashed #444; padding: 40px; text-align: center; margin: 20px 0; border-radius: 10px; }
.upload-box.dragover { border-color: #ff6b6b; background: rgba(255,107,107,0.1); }
select, button { padding: 12px 24px; font-size: 16px; margin: 10px 5px; border-radius: 5px; border: none; cursor: pointer; }
select { background: #333; color: #fff; }
button { background: #ff6b6b; color: #fff; font-weight: bold; }
button:hover { background: #ee5a5a; }
.file-list { background: #2a2a4e; padding: 15px; border-radius: 10px; margin-top: 20px; }
.file-item { padding: 8px; border-bottom: 1px solid #444; }
.type-tag { display: inline-block; padding: 3px 8px; border-radius: 3px; font-size: 12px; margin-right: 10px; background: #ff6b6b; }
#status { margin-top: 15px; padding: 10px; border-radius: 5px; }
.success { background: #1b5e20; } .error { background: #b71c1c; }
.info { background: #2a2a4e; padding: 15px; border-radius: 10px; margin-bottom: 20px; font-size: 14px; }
</style>
</head><body>
<h1>ğŸ”Š íš¨ê³¼ìŒ ì—…ë¡œë“œ</h1>

<div class="info">
<strong>í•„ìš”í•œ íš¨ê³¼ìŒ 6ì¢…ë¥˜:</strong><br>
â€¢ impact - ì¶©ê²©/ë°˜ì „ (ì¿µ!)<br>
â€¢ whoosh - ì¥ë©´ì „í™˜ (íœ™~)<br>
â€¢ ding - ê°•ì¡°/ê¹¨ë‹¬ìŒ (ëµ!)<br>
â€¢ tension - ê¸´ì¥ê° (ë“œë¥´ë¥´)<br>
â€¢ emotional - ê°ë™ (í”¼ì•„ë…¸)<br>
â€¢ success - ì„±ê³µ/í•´í”¼ì—”ë”© (ì§ !)
</div>

<select id="sfxType">
<option value="">-- íš¨ê³¼ìŒ íƒ€ì… ì„ íƒ --</option>
<option value="impact">ğŸ’¥ impact (ì¶©ê²©/ë°˜ì „)</option>
<option value="whoosh">ğŸ’¨ whoosh (ì¥ë©´ì „í™˜)</option>
<option value="ding">ğŸ”” ding (ê°•ì¡°/ê¹¨ë‹¬ìŒ)</option>
<option value="tension">ğŸ˜° tension (ê¸´ì¥ê°)</option>
<option value="emotional">ğŸ¹ emotional (ê°ë™)</option>
<option value="success">ğŸ‰ success (ì„±ê³µ)</option>
</select>

<div class="upload-box" id="dropzone">
<p>ğŸ“ MP3 íŒŒì¼ì„ ì—¬ê¸°ì— ë“œë˜ê·¸í•˜ê±°ë‚˜ í´ë¦­í•˜ì—¬ ì„ íƒ</p>
<input type="file" id="fileInput" accept=".mp3,audio/mpeg" multiple style="display:none">
</div>

<div id="status"></div>

<h3>ğŸ“‹ ì—…ë¡œë“œëœ íš¨ê³¼ìŒ</h3>
<div class="file-list" id="fileList">ë¡œë”© ì¤‘...</div>

<script>
const dropzone = document.getElementById('dropzone');
const fileInput = document.getElementById('fileInput');
const typeSelect = document.getElementById('sfxType');
const status = document.getElementById('status');

dropzone.onclick = () => fileInput.click();
dropzone.ondragover = (e) => { e.preventDefault(); dropzone.classList.add('dragover'); };
dropzone.ondragleave = () => dropzone.classList.remove('dragover');
dropzone.ondrop = (e) => { e.preventDefault(); dropzone.classList.remove('dragover'); handleFiles(e.dataTransfer.files); };
fileInput.onchange = () => handleFiles(fileInput.files);

async function handleFiles(files) {
    const sfxType = typeSelect.value;
    if (!sfxType) { alert('íš¨ê³¼ìŒ íƒ€ì…ì„ ë¨¼ì € ì„ íƒí•˜ì„¸ìš”!'); return; }

    for (const file of files) {
        if (!file.name.endsWith('.mp3')) { alert(file.name + ' - MP3 íŒŒì¼ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤'); continue; }

        const formData = new FormData();
        formData.append('file', file);
        formData.append('type', sfxType);

        status.innerHTML = 'â³ ì—…ë¡œë“œ ì¤‘: ' + file.name;
        status.className = '';

        try {
            const res = await fetch('/api/sfx/upload', { method: 'POST', body: formData });
            const data = await res.json();
            if (data.ok) {
                status.innerHTML = 'âœ… ì—…ë¡œë“œ ì™„ë£Œ: ' + data.filename;
                status.className = 'success';
                loadFileList();
            } else {
                status.innerHTML = 'âŒ ì‹¤íŒ¨: ' + data.error;
                status.className = 'error';
            }
        } catch (e) {
            status.innerHTML = 'âŒ ì˜¤ë¥˜: ' + e.message;
            status.className = 'error';
        }
    }
}

async function loadFileList() {
    try {
        const res = await fetch('/api/sfx/list');
        const data = await res.json();
        if (data.ok) {
            let html = '<p>ì´ ' + data.total + 'ê°œ íŒŒì¼</p>';
            for (const [type, files] of Object.entries(data.types)) {
                html += '<div class="file-item"><span class="type-tag">' + type + '</span> ' + files.join(', ') + '</div>';
            }
            document.getElementById('fileList').innerHTML = html || '<p>ì—…ë¡œë“œëœ íŒŒì¼ ì—†ìŒ</p>';
        }
    } catch (e) { document.getElementById('fileList').innerHTML = 'ë¡œë“œ ì‹¤íŒ¨'; }
}
loadFileList();
</script>
</body></html>'''


# ===== Step6: ì´ë¯¸ì§€ ì—…ë¡œë“œ API =====
@app.route('/api/drama/upload-image', methods=['POST'])
def api_upload_image():
    """Base64 ì´ë¯¸ì§€ë¥¼ ì„œë²„ì— ì—…ë¡œë“œí•˜ê³  URL ë°˜í™˜ (ì˜ìƒ ìƒì„± ì „ ìš”ì²­ í¬ê¸° ì¤„ì´ê¸° ìœ„í•¨)"""
    try:
        import base64
        from datetime import datetime as dt

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        image_data = data.get("imageData", "")

        if not image_data:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        # ì´ë¯¸ HTTP URLì¸ ê²½ìš° ê·¸ëŒ€ë¡œ ë°˜í™˜
        if image_data.startswith('http://') or image_data.startswith('https://') or image_data.startswith('/'):
            return jsonify({"ok": True, "imageUrl": image_data})

        # Base64 ë°ì´í„° URLì¸ ê²½ìš° ë””ì½”ë”©í•˜ì—¬ ì €ì¥
        if image_data.startswith('data:'):
            try:
                header, encoded = image_data.split(',', 1)
                img_bytes = base64.b64decode(encoded)

                # ì´ë¯¸ì§€ í˜•ì‹ í™•ì¸
                if 'png' in header:
                    ext = 'png'
                elif 'jpeg' in header or 'jpg' in header:
                    ext = 'jpg'
                elif 'webp' in header:
                    ext = 'webp'
                else:
                    ext = 'png'  # ê¸°ë³¸ê°’

                # ì €ì¥ ë””ë ‰í† ë¦¬ ìƒì„±
                static_image_dir = os.path.join(os.path.dirname(__file__), 'static', 'drama_images')
                os.makedirs(static_image_dir, exist_ok=True)

                # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
                timestamp = dt.now().strftime("%Y%m%d_%H%M%S_%f")
                image_filename = f"drama_{timestamp}.{ext}"
                image_path = os.path.join(static_image_dir, image_filename)

                # ì´ë¯¸ì§€ ì €ì¥
                with open(image_path, 'wb') as f:
                    f.write(img_bytes)

                image_url = f"/static/drama_images/{image_filename}"
                print(f"[DRAMA-UPLOAD] ì´ë¯¸ì§€ ì—…ë¡œë“œ ì™„ë£Œ: {image_filename} ({len(img_bytes) / 1024:.1f}KB)")

                return jsonify({"ok": True, "imageUrl": image_url})

            except Exception as e:
                print(f"[DRAMA-UPLOAD][ERROR] Base64 ë””ì½”ë”© ì‹¤íŒ¨: {str(e)}")
                return jsonify({"ok": False, "error": f"ì´ë¯¸ì§€ ì²˜ë¦¬ ì‹¤íŒ¨: {str(e)}"}), 200

        return jsonify({"ok": False, "error": "ì§€ì›í•˜ì§€ ì•ŠëŠ” ì´ë¯¸ì§€ í˜•ì‹ì…ë‹ˆë‹¤."}), 400

    except Exception as e:
        print(f"[DRAMA-UPLOAD][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step6: ì´ë¯¸ì§€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ API =====
@app.route('/api/drama/check-images', methods=['POST'])
def api_check_images():
    """ì˜ìƒ ìƒì„± ì „ ì´ë¯¸ì§€ íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ í™•ì¸

    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì˜ìƒ ìƒì„± ìš”ì²­ ì „ì— ì´ë¯¸ì§€ê°€ ì„œë²„ì— ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸.
    /static/ ê²½ë¡œì˜ ë¡œì»¬ íŒŒì¼ë§Œ í™•ì¸ (HTTP URLì€ í•­ìƒ validë¡œ ì²˜ë¦¬).
    """
    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        image_urls = data.get("imageUrls", [])
        if not image_urls:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ URL ëª©ë¡ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        results = []
        valid_count = 0
        missing_files = []

        for idx, img_url in enumerate(image_urls):
            result = {
                "index": idx,
                "url": img_url[:100] if img_url else "(empty)",
                "type": "unknown",
                "exists": False
            }

            if not img_url:
                result["type"] = "empty"
                result["error"] = "URLì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤"
            elif img_url.startswith('data:'):
                result["type"] = "base64"
                result["exists"] = True  # Base64ëŠ” í•­ìƒ ìœ íš¨
                valid_count += 1
            elif img_url.startswith('http://') or img_url.startswith('https://'):
                result["type"] = "http_url"
                result["exists"] = True  # HTTP URLì€ ì‚¬ì „ ê²€ì¦ ë¶ˆê°€, ìœ íš¨ë¡œ ì²˜ë¦¬
                valid_count += 1
            elif img_url.startswith('/static/'):
                result["type"] = "local_path"
                local_path = os.path.join(os.path.dirname(__file__), img_url.lstrip('/'))
                if os.path.exists(local_path):
                    result["exists"] = True
                    result["local_path"] = local_path
                    valid_count += 1
                else:
                    result["exists"] = False
                    result["error"] = f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤: {local_path}"
                    missing_files.append(img_url)
            else:
                result["type"] = "unknown"
                result["error"] = f"ì•Œ ìˆ˜ ì—†ëŠ” URL í˜•ì‹: {img_url[:50]}..."

            results.append(result)

        all_valid = valid_count == len(image_urls)

        print(f"[DRAMA-CHECK-IMAGES] ì´ë¯¸ì§€ ê²€ì¦ ì™„ë£Œ: {valid_count}/{len(image_urls)} ìœ íš¨")
        if missing_files:
            print(f"[DRAMA-CHECK-IMAGES] ëˆ„ë½ëœ íŒŒì¼: {missing_files}")

        return jsonify({
            "ok": True,
            "allValid": all_valid,
            "totalCount": len(image_urls),
            "validCount": valid_count,
            "missingFiles": missing_files,
            "results": results
        })

    except Exception as e:
        import traceback
        print(f"[DRAMA-CHECK-IMAGES][ERROR] {str(e)}")
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step6: ì”¬ë³„ í´ë¦½ ìƒì„± í—¬í¼ í•¨ìˆ˜ (ë³‘ë ¬ ì²˜ë¦¬ìš©) =====
def _create_scene_clip(args):
    """
    ë‹¨ì¼ ì”¬ì˜ í´ë¦½ì„ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ (ThreadPoolExecutorìš©)

    Args:
        args: (idx, cut, temp_dir, width, height, fps)

    Returns:
        (idx, segment_path, duration) ë˜ëŠ” (idx, None, 0) on failure
    """
    import requests
    import base64
    import subprocess
    import shutil
    import gc

    idx, cut, temp_dir, width, height, fps = args
    cut_id = cut.get('cutId', idx + 1)
    img_url = cut.get('imageUrl', '')
    audio_url = cut.get('audioUrl', '')
    cut_duration = cut.get('duration', 10)

    print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (worker)")

    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ/ì²˜ë¦¬
    img_path = os.path.join(temp_dir, f"image_{idx:03d}.png")
    if img_url:
        try:
            if img_url.startswith('data:'):
                header, encoded = img_url.split(',', 1)
                img_data = base64.b64decode(encoded)
                with open(img_path, 'wb') as f:
                    f.write(img_data)
                del img_data  # ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ
                gc.collect()
            elif img_url.startswith('/static/'):
                local_path = os.path.join(os.path.dirname(__file__), img_url.lstrip('/'))
                if os.path.exists(local_path):
                    shutil.copy2(local_path, img_path)
                else:
                    print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ë¡œì»¬ ì´ë¯¸ì§€ ì—†ìŒ: {local_path}")
                    return (idx, None, 0)
            else:
                response = requests.get(img_url, timeout=60)
                if response.status_code == 200:
                    with open(img_path, 'wb') as f:
                        f.write(response.content)
                else:
                    print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {img_url}")
                    return (idx, None, 0)
        except Exception as e:
            print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")
            return (idx, None, 0)
    else:
        print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ì´ë¯¸ì§€ URL ì—†ìŒ")
        return (idx, None, 0)

    # ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ/ì²˜ë¦¬
    audio_path = os.path.join(temp_dir, f"audio_{idx:03d}.mp3")
    actual_duration = cut_duration
    has_audio = False

    if audio_url:
        try:
            if audio_url.startswith('data:'):
                header, encoded = audio_url.split(',', 1)
                audio_data = base64.b64decode(encoded)
                with open(audio_path, 'wb') as f:
                    f.write(audio_data)
                del audio_data  # ë©”ëª¨ë¦¬ ì¦‰ì‹œ í•´ì œ
                gc.collect()
                has_audio = True
            elif audio_url.startswith('/static/'):
                local_path = os.path.join(os.path.dirname(__file__), audio_url.lstrip('/'))
                if os.path.exists(local_path):
                    shutil.copy2(local_path, audio_path)
                    has_audio = True
            else:
                response = requests.get(audio_url, timeout=60)
                if response.status_code == 200:
                    with open(audio_path, 'wb') as f:
                        f.write(response.content)
                    has_audio = True
        except Exception as e:
            print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì˜¤ë¥˜: {e}")

    # ì˜¤ë””ì˜¤ê°€ ìˆìœ¼ë©´ ì‹¤ì œ ê¸¸ì´ í™•ì¸
    if has_audio and os.path.exists(audio_path):
        try:
            probe_cmd = [
                'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1', audio_path
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            if result.stdout.strip():
                actual_duration = float(result.stdout.strip())
        except Exception as e:
            print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸ ì˜¤ë¥˜: {e}")

    print(f"[DRAMA-PARALLEL] ì”¬ {cut_id}: ì˜¤ë””ì˜¤={has_audio}, ê¸¸ì´={actual_duration:.1f}ì´ˆ")

    # ì”¬ë³„ í´ë¦½ ìƒì„±
    segment_path = os.path.join(temp_dir, f"segment_{idx:03d}.mp4")

    # CPU ìµœì í™”: FPS 24, CRF 32, threads 1 (1 CPU í™˜ê²½ìš©)
    target_fps = min(fps, 24)  # ìµœëŒ€ 24 FPSë¡œ ì œí•œ

    if has_audio:
        # ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ë¡œ í´ë¦½ ìƒì„±
        ffmpeg_cmd = [
            'ffmpeg', '-y',
            '-threads', '1',  # CPU ìŠ¤íŒŒì´í¬ ë°©ì§€
            '-loop', '1',
            '-i', img_path,
            '-i', audio_path,
            '-vf', f'scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2',
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '32', '-threads', '1',
            '-c:a', 'aac', '-b:a', '96k',
            '-r', str(target_fps),
            '-t', str(actual_duration),
            '-shortest',
            '-pix_fmt', 'yuv420p',
            segment_path
        ]
    else:
        # ì˜¤ë””ì˜¤ ì—†ì´ ì´ë¯¸ì§€ë§Œìœ¼ë¡œ í´ë¦½ ìƒì„± (ë¬´ìŒ)
        ffmpeg_cmd = [
            'ffmpeg', '-y',
            '-threads', '1',  # CPU ìŠ¤íŒŒì´í¬ ë°©ì§€
            '-loop', '1',
            '-i', img_path,
            '-f', 'lavfi', '-i', 'anullsrc=r=44100:cl=stereo',
            '-vf', f'scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2',
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '32', '-threads', '1',
            '-c:a', 'aac',
            '-r', str(target_fps),
            '-t', str(actual_duration),
            '-shortest',
            '-pix_fmt', 'yuv420p',
            segment_path
        ]

    try:
        print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} FFmpeg ì‹œì‘...")
        # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPEë¡œ ìº¡ì²˜ (OOM ë°©ì§€)
        process = subprocess.run(
            ffmpeg_cmd,
            stdout=subprocess.DEVNULL,
            stderr=subprocess.PIPE,
            timeout=180
        )
        if process.returncode == 0 and os.path.exists(segment_path):
            print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} í´ë¦½ ìƒì„± ì™„ë£Œ: {actual_duration:.1f}ì´ˆ")
            del process  # ëª…ì‹œì  í•´ì œ
            gc.collect()
            return (idx, segment_path, actual_duration)
        else:
            # ì—ëŸ¬ ì‹œì—ë§Œ stderr ì½ê¸° (ìµœëŒ€ 500ë°”ì´íŠ¸)
            stderr_msg = process.stderr[:500].decode('utf-8', errors='ignore') if process.stderr else '(stderr ì—†ìŒ)'
            del process
            gc.collect()
            print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} FFmpeg ì˜¤ë¥˜: {stderr_msg[:200]}")
            return (idx, None, 0)
    except subprocess.TimeoutExpired:
        print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} íƒ€ì„ì•„ì›ƒ (180ì´ˆ ì´ˆê³¼)")
        return (idx, None, 0)
    except Exception as e:
        print(f"[DRAMA-PARALLEL] ì”¬ {cut_id} í´ë¦½ ìƒì„± ì˜¤ë¥˜: {e}")
        return (idx, None, 0)


# ===== Step6: ì”¬ë³„ í´ë¦½ ìƒì„± í›„ concat ë°©ì‹ ì˜ìƒ ì œì‘ (ë³‘ë ¬ ì²˜ë¦¬) =====
def _generate_video_with_cuts(cuts, subtitle_data, burn_subtitle, resolution, fps, update_progress):
    """
    cuts ë°°ì—´ì„ ì‚¬ìš©í•˜ì—¬ ê° ì”¬ë³„ë¡œ í´ë¦½ì„ ë³‘ë ¬ ìƒì„±í•˜ê³  concatí•˜ì—¬ ìµœì¢… ì˜ìƒ ìƒì„±.
    ì´ ë°©ì‹ì€ ê° ì”¬ì˜ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ê°€ ì •í™•íˆ ë§¤ì¹­ë¨.

    Args:
        cuts: [{'cutId': 1, 'imageUrl': '...', 'audioUrl': '...', 'duration': 10}, ...]
        subtitle_data: ìë§‰ ë°ì´í„°
        burn_subtitle: ìë§‰ í•˜ë“œì½”ë”© ì—¬ë¶€
        resolution: í•´ìƒë„ (ì˜ˆ: '1920x1080')
        fps: í”„ë ˆì„ ë ˆì´íŠ¸
        update_progress: ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    """
    import requests
    import base64
    import tempfile
    import subprocess
    import shutil
    import gc

    print(f"[DRAMA-CUTS-VIDEO] ì”¬ë³„ ì˜ìƒ ìƒì„± ì‹œì‘ - {len(cuts)}ê°œ ì”¬")
    print(f"[DRAMA-CUTS-VIDEO] ì…ë ¥ ë°ì´í„° - resolution: {resolution}, fps: {fps}, burn_subtitle: {burn_subtitle}")

    # ìƒì„¸ ë””ë²„ê¹…: ê° cutì˜ audio URL ìƒíƒœ í™•ì¸
    for i, cut in enumerate(cuts):
        audio_url = cut.get('audioUrl', '')
        has_audio = bool(audio_url and len(audio_url) > 0)
        print(f"[DRAMA-CUTS-VIDEO] cut[{i}] - imageUrl: {'ìˆìŒ' if cut.get('imageUrl') else 'ì—†ìŒ'}, audioUrl: {'ìˆìŒ' if has_audio else 'ì—†ìŒ âš ï¸'}, duration: {cut.get('duration', 'N/A')}")

    # í•´ìƒë„ íŒŒì‹± ë° ìµœì í™” (512MB í™˜ê²½)
    try:
        width, height = resolution.split('x')
        width, height = int(width), int(height)
    except Exception as e:
        print(f"[DRAMA-CUTS-VIDEO] âŒ í•´ìƒë„ íŒŒì‹± ì˜¤ë¥˜: resolution='{resolution}', error={e}")
        raise Exception(f"í•´ìƒë„ í˜•ì‹ ì˜¤ë¥˜: '{resolution}' (ì˜ˆìƒ í˜•ì‹: '1920x1080')")

    # Render Standard 1 CPU: 480pë¡œ ì œí•œ (CPU ë¶€í•˜ ê°ì†Œ)
    MAX_WIDTH = 854    # 480p (1 CPU í™˜ê²½)
    MAX_HEIGHT = 480
    if width > MAX_WIDTH or height > MAX_HEIGHT:
        aspect_ratio = width / height
        if aspect_ratio > 16/9:
            width = MAX_WIDTH
            height = int(MAX_WIDTH / aspect_ratio)
        else:
            height = MAX_HEIGHT
            width = int(MAX_HEIGHT * aspect_ratio)
        resolution = f"{width}x{height}"
        print(f"[DRAMA-CUTS-VIDEO] ë©”ëª¨ë¦¬ ìµœì í™” - í•´ìƒë„ ì¡°ì •: {resolution}")

    with tempfile.TemporaryDirectory() as temp_dir:
        update_progress(10, "ì”¬ë³„ ì˜ìƒ ìˆœì°¨ ìƒì„± ì¤‘...")

        segment_files = []
        total_duration = 0.0

        # í™˜ê²½ë³€ìˆ˜ë¡œ ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ ì„¤ì • (ê¸°ë³¸ê°’: 1 = ìˆœì°¨ ì²˜ë¦¬)
        # Render Pro (4GB) í™˜ê²½ì—ì„œëŠ” 2ë¡œ ì„¤ì • ê¶Œì¥
        parallel_workers = int(os.environ.get('VIDEO_PARALLEL_WORKERS', 1))

        if parallel_workers > 1:
            # ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ
            print(f"[DRAMA-PARALLEL] ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ - {len(cuts)}ê°œ ì”¬, {parallel_workers}ê°œ ì›Œì»¤")

            tasks = [(idx, cut, temp_dir, width, height, fps) for idx, cut in enumerate(cuts)]
            results = [None] * len(cuts)  # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸

            with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
                future_to_idx = {executor.submit(_create_scene_clip, task): task[0] for task in tasks}
                completed = 0

                for future in as_completed(future_to_idx):
                    idx = future_to_idx[future]
                    completed += 1
                    update_progress(15 + int((completed / len(cuts)) * 55), f"ì”¬ {completed}/{len(cuts)} í´ë¦½ ìƒì„± ì¤‘...")

                    try:
                        result_idx, segment_path, duration = future.result()
                        results[idx] = (segment_path, duration)

                        if segment_path and os.path.exists(segment_path):
                            print(f"[DRAMA-PARALLEL] ì”¬ {idx+1} ì™„ë£Œ: {duration:.1f}ì´ˆ")
                        else:
                            print(f"[DRAMA-PARALLEL] ì”¬ {idx+1} ì‹¤íŒ¨")
                    except Exception as e:
                        print(f"[DRAMA-PARALLEL] ì”¬ {idx+1} ì˜¤ë¥˜: {e}")
                        results[idx] = (None, 0)

            # ê²°ê³¼ ì •ë¦¬ (ìˆœì„œëŒ€ë¡œ)
            for segment_path, duration in results:
                if segment_path and os.path.exists(segment_path):
                    segment_files.append(segment_path)
                    total_duration += duration

            # ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            print(f"[DRAMA-PARALLEL] ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {len(segment_files)}/{len(cuts)}, ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")

        else:
            # ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ (ê¸°ë³¸ê°’ - ë©”ëª¨ë¦¬ ì ˆì•½)
            print(f"[DRAMA-SEQUENTIAL] ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘ - {len(cuts)}ê°œ ì”¬ (ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ)")

            for idx, cut in enumerate(cuts):
                update_progress(15 + int((idx / len(cuts)) * 55), f"ì”¬ {idx+1}/{len(cuts)} í´ë¦½ ìƒì„± ì¤‘...")

                try:
                    # ì”¬ í´ë¦½ ìƒì„±
                    task = (idx, cut, temp_dir, width, height, fps)
                    result_idx, segment_path, duration = _create_scene_clip(task)

                    if segment_path and os.path.exists(segment_path):
                        segment_files.append(segment_path)
                        total_duration += duration
                        print(f"[DRAMA-SEQUENTIAL] ì”¬ {idx+1} ì™„ë£Œ: {duration:.1f}ì´ˆ")
                    else:
                        print(f"[DRAMA-SEQUENTIAL] ì”¬ {idx+1} ì‹¤íŒ¨")

                except Exception as e:
                    print(f"[DRAMA-SEQUENTIAL] ì”¬ {idx+1} ì˜¤ë¥˜: {e}")

                # ê° ì”¬ ì²˜ë¦¬ í›„ ê°•ì œ ë©”ëª¨ë¦¬ ì •ë¦¬
                gc.collect()

            print(f"[DRAMA-SEQUENTIAL] ìˆœì°¨ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {len(segment_files)}/{len(cuts)}, ì´ ê¸¸ì´: {total_duration:.1f}ì´ˆ")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()

        if not segment_files:
            raise Exception("í´ë¦½ì„ ìƒì„±í•˜ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”.")

        # ëª¨ë“  ì„¸ê·¸ë¨¼íŠ¸ concat
        update_progress(75, f"ì˜ìƒ ë³‘í•© ì¤‘... ({len(segment_files)}ê°œ í´ë¦½)")

        concat_list_path = os.path.join(temp_dir, "concat.txt")
        with open(concat_list_path, 'w', encoding='utf-8') as f:
            for seg in segment_files:
                f.write(f"file '{seg}'\n")

        output_path = os.path.join(temp_dir, "output.mp4")
        concat_cmd = [
            'ffmpeg', '-y',
            '-f', 'concat',
            '-safe', '0',
            '-i', concat_list_path,
            '-c', 'copy',
            output_path
        ]

        try:
            print(f"[DRAMA-CUTS-VIDEO] Concat ëª…ë ¹: {' '.join(concat_cmd)}")
            print(f"[DRAMA-CUTS-VIDEO] concat.txt ë‚´ìš©:")
            with open(concat_list_path, 'r') as f:
                print(f.read())
            # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPE (OOM ë°©ì§€)
            process = subprocess.run(
                concat_cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                timeout=600
            )
            if process.returncode != 0:
                stderr_msg = process.stderr[:500].decode('utf-8', errors='ignore') if process.stderr else '(stderr ì—†ìŒ)'
                print(f"[DRAMA-CUTS-VIDEO] Concat ì˜¤ë¥˜ (returncode={process.returncode}): {stderr_msg}")
                del process
                gc.collect()
                raise Exception(f"ì˜ìƒ ë³‘í•© ì‹¤íŒ¨: {stderr_msg[:200]}")
            del process
            gc.collect()
            print(f"[DRAMA-CUTS-VIDEO] Concat ì™„ë£Œ, íŒŒì¼ ì¡´ì¬: {os.path.exists(output_path)}")
        except subprocess.TimeoutExpired:
            raise Exception("ì˜ìƒ ë³‘í•© íƒ€ì„ì•„ì›ƒ (10ë¶„)")

        update_progress(90, "ì˜ìƒ ì €ì¥ ì¤‘...")

        # ìµœì¢… ì˜ìƒì„ static í´ë”ì— ì €ì¥
        static_video_dir = os.path.join(os.path.dirname(__file__), 'static', 'videos')
        os.makedirs(static_video_dir, exist_ok=True)

        timestamp = dt.now().strftime("%Y%m%d_%H%M%S")
        video_filename = f"drama_{timestamp}.mp4"
        final_video_path = os.path.join(static_video_dir, video_filename)

        shutil.copy2(output_path, final_video_path)

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(final_video_path)
        file_size_mb = file_size / (1024 * 1024)

        video_url = f"/static/videos/{video_filename}"

        # Base64 ì¸ì½”ë”© (10MB ì´í•˜ë§Œ - 2GB í™˜ê²½ ë©”ëª¨ë¦¬ ìµœì í™”)
        # 10MB ì˜ìƒ + Base64 ì˜¤ë²„í—¤ë“œ(33%) = ~13MB ë©”ëª¨ë¦¬ ì‚¬ìš©
        if file_size_mb <= 10:
            with open(final_video_path, 'rb') as f:
                video_data = f.read()
            video_base64 = base64.b64encode(video_data).decode('utf-8')
            video_url_base64 = f"data:video/mp4;base64,{video_base64}"
            del video_data
            del video_base64
            gc.collect()
        else:
            video_url_base64 = None

        print(f"[DRAMA-CUTS-VIDEO] ì˜ìƒ ìƒì„± ì™„ë£Œ - {len(segment_files)}ê°œ ì”¬, ì´ {total_duration:.1f}ì´ˆ, {file_size_mb:.2f}MB")

        update_progress(100, "ì™„ë£Œ!")

        return {
            "videoUrl": video_url_base64 or video_url,
            "videoFileUrl": video_url,
            "duration": total_duration,
            "fileSize": file_size,
            "fileSizeMB": round(file_size_mb, 2),
            "cutsCount": len(segment_files)
        }


# ===== Step6: ì˜ìƒ ì œì‘ (ë™ê¸° í•¨ìˆ˜) =====
def _generate_video_sync(images, audio_url, subtitle_data, burn_subtitle, resolution, fps, transition, job_id=None, cuts=None):
    """
    ì‹¤ì œ ì˜ìƒ ìƒì„± ë¡œì§ (ë™ê¸°)
    ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ì—ì„œ í˜¸ì¶œë¨
    ë©”ëª¨ë¦¬ ìµœì í™”: 512MB ì œí•œ í™˜ê²½ì—ì„œ ì‘ë™

    Args:
        cuts: ì”¬ë³„ ì´ë¯¸ì§€-ì˜¤ë””ì˜¤ ë§¤ì¹­ ë°°ì—´ (ì„ íƒì )
              [{'cutId': 1, 'imageUrl': '...', 'audioUrl': '...', 'duration': 10}, ...]
    """
    import requests
    import base64
    import tempfile
    import subprocess
    import shutil
    import gc

    # ì˜ì¡´ì„± ì²´í¬: Pillow
    try:
        from PIL import Image
    except ImportError:
        raise Exception("Pillow ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. 'pip install Pillow' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

    # ì˜ì¡´ì„± ì²´í¬: FFmpeg
    ffmpeg_path = shutil.which('ffmpeg')
    if not ffmpeg_path:
        raise Exception("FFmpegê°€ ì„¤ì¹˜ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤. 'apt-get install ffmpeg' ëª…ë ¹ìœ¼ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")

    # ë©”ëª¨ë¦¬ ìµœì í™”: í•´ìƒë„ ìë™ ì œí•œ (512MB í™˜ê²½)
    try:
        width, height = resolution.split('x')
        width, height = int(width), int(height)
    except Exception as e:
        print(f"[DRAMA-STEP6-VIDEO] âŒ í•´ìƒë„ íŒŒì‹± ì˜¤ë¥˜: resolution='{resolution}', error={e}")
        raise Exception(f"í•´ìƒë„ í˜•ì‹ ì˜¤ë¥˜: '{resolution}' (ì˜ˆìƒ í˜•ì‹: '1920x1080')")

    # Render Standard 1 CPU: 480pë¡œ ì œí•œ (CPU ë¶€í•˜ ê°ì†Œ)
    MAX_WIDTH = 854
    MAX_HEIGHT = 480
    if width > MAX_WIDTH or height > MAX_HEIGHT:
        aspect_ratio = width / height
        if aspect_ratio > 16/9:  # ì™€ì´ë“œ
            width = MAX_WIDTH
            height = int(MAX_WIDTH / aspect_ratio)
        else:
            height = MAX_HEIGHT
            width = int(MAX_HEIGHT * aspect_ratio)
        resolution = f"{width}x{height}"
        print(f"[DRAMA-STEP6-VIDEO][ë©”ëª¨ë¦¬ ìµœì í™”] í•´ìƒë„ ì¡°ì •: {resolution}")

    print(f"[DRAMA-STEP6-VIDEO] ì˜ìƒ ìƒì„± ì‹œì‘ - ì´ë¯¸ì§€: {len(images)}ê°œ, í•´ìƒë„: {resolution}, job_id: {job_id}")

    # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ í•¨ìˆ˜
    def update_progress(progress, message=""):
        if job_id:
            with video_jobs_lock:
                if job_id in video_jobs:
                    video_jobs[job_id]['progress'] = progress
                    if message:
                        video_jobs[job_id]['message'] = message
                    save_video_jobs()  # íŒŒì¼ì— ì €ì¥

    update_progress(5, "ì˜ì¡´ì„± í™•ì¸ ì™„ë£Œ, ì˜ìƒ ìƒì„± ì¤€ë¹„ ì¤‘...")

    # ===== cuts ë°°ì—´ì´ ìˆìœ¼ë©´ ì”¬ë³„ í´ë¦½ ìƒì„± í›„ concat ë°©ì‹ ì‚¬ìš© =====
    if cuts and len(cuts) > 0:
        print(f"[DRAMA-STEP6-VIDEO] cuts ê¸°ë°˜ ì˜ìƒ ìƒì„± ({len(cuts)}ê°œ ì”¬)")
        return _generate_video_with_cuts(cuts, subtitle_data, burn_subtitle, resolution, fps, update_progress)

    # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
    with tempfile.TemporaryDirectory() as temp_dir:
        update_progress(10, "ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        # 1. ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
        image_paths = []
        failed_images = []

        for idx, img_url in enumerate(images):
            img_path = os.path.join(temp_dir, f"image_{idx:03d}.png")
            update_progress(10 + (idx / len(images)) * 15, f"ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì¤‘... ({idx+1}/{len(images)})")

            try:
                # ì„ì‹œ ì›ë³¸ ì´ë¯¸ì§€ ê²½ë¡œ
                temp_img_path = os.path.join(temp_dir, f"temp_{idx:03d}.png")

                if img_url.startswith('data:'):
                    # Base64 ë°ì´í„° URL
                    header, encoded = img_url.split(',', 1)
                    img_data = base64.b64decode(encoded)
                    with open(temp_img_path, 'wb') as f:
                        f.write(img_data)
                elif img_url.startswith('/static/'):
                    # ë¡œì»¬ static íŒŒì¼ ê²½ë¡œ
                    local_path = os.path.join(os.path.dirname(__file__), img_url.lstrip('/'))
                    if os.path.exists(local_path):
                        shutil.copy2(local_path, temp_img_path)
                    else:
                        print(f"[DRAMA-STEP6-VIDEO] ë¡œì»¬ ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {local_path}")
                        failed_images.append(f"ì´ë¯¸ì§€ {idx+1}")
                        continue
                else:
                    # HTTP URL (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
                    max_retries = 3
                    for retry in range(max_retries):
                        try:
                            response = requests.get(img_url, timeout=60)
                            if response.status_code == 200:
                                with open(temp_img_path, 'wb') as f:
                                    f.write(response.content)
                                break
                            else:
                                if retry == max_retries - 1:
                                    print(f"[DRAMA-STEP6-VIDEO] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {img_url} (ìƒíƒœ: {response.status_code})")
                                    failed_images.append(f"ì´ë¯¸ì§€ {idx+1}")
                                    continue
                        except requests.exceptions.RequestException as e:
                            if retry == max_retries - 1:
                                print(f"[DRAMA-STEP6-VIDEO] ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {img_url} - {str(e)}")
                                failed_images.append(f"ì´ë¯¸ì§€ {idx+1}")
                                continue
                            import time
                            time.sleep(1)

                # ë©”ëª¨ë¦¬ ìµœì í™”: ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ (ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ê°ì†Œ)
                if os.path.exists(temp_img_path):
                    try:
                        img = Image.open(temp_img_path)
                        # ëª©í‘œ í•´ìƒë„ë¡œ ë¦¬ì‚¬ì´ì¦ˆ (aspect ratio ìœ ì§€)
                        img.thumbnail((width, height), Image.Resampling.LANCZOS)
                        # ìµœì í™”ëœ ì´ë¯¸ì§€ ì €ì¥
                        img.save(img_path, 'PNG', optimize=True)
                        img.close()
                        # ì„ì‹œ íŒŒì¼ ì¦‰ì‹œ ì‚­ì œ
                        os.remove(temp_img_path)
                        # ê°€ë¹„ì§€ ì»¬ë ‰ì…˜
                        gc.collect()
                    except Exception as resize_err:
                        print(f"[DRAMA-STEP6-VIDEO] ì´ë¯¸ì§€ ë¦¬ì‚¬ì´ì¦ˆ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©: {resize_err}")
                        if os.path.exists(temp_img_path):
                            shutil.move(temp_img_path, img_path)

                image_paths.append(img_path)
            except Exception as e:
                print(f"[DRAMA-STEP6-VIDEO] ì´ë¯¸ì§€ ì²˜ë¦¬ ì˜¤ë¥˜ ({idx+1}): {str(e)}")
                failed_images.append(f"ì´ë¯¸ì§€ {idx+1}")

        if not image_paths:
            raise Exception(f"ëª¨ë“  ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨. ì‹¤íŒ¨í•œ ì´ë¯¸ì§€: {', '.join(failed_images)}")

        if failed_images:
            print(f"[DRAMA-STEP6-VIDEO] ì¼ë¶€ ì´ë¯¸ì§€ ì‹¤íŒ¨ ({len(failed_images)}ê°œ): {', '.join(failed_images)}")

        update_progress(30, "ì˜¤ë””ì˜¤ ì²˜ë¦¬ ì¤‘...")

        # 2. ì˜¤ë””ì˜¤ ì €ì¥ (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
        audio_path = os.path.join(temp_dir, "audio.mp3")
        if audio_url.startswith('data:'):
            header, encoded = audio_url.split(',', 1)
            audio_data = base64.b64decode(encoded)
            with open(audio_path, 'wb') as f:
                f.write(audio_data)
        elif audio_url.startswith('/static/'):
            # ë¡œì»¬ static íŒŒì¼ ê²½ë¡œ
            local_audio_path = os.path.join(os.path.dirname(__file__), audio_url.lstrip('/'))
            if os.path.exists(local_audio_path):
                shutil.copy2(local_audio_path, audio_path)
            else:
                raise Exception(f"ì˜¤ë””ì˜¤ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {audio_url}")
        else:
            # HTTP URL (ì¬ì‹œë„ ë¡œì§ ì¶”ê°€)
            max_retries = 3
            audio_downloaded = False
            for retry in range(max_retries):
                try:
                    response = requests.get(audio_url, timeout=60)
                    if response.status_code == 200:
                        with open(audio_path, 'wb') as f:
                            f.write(response.content)
                        audio_downloaded = True
                        break
                    else:
                        if retry == max_retries - 1:
                            raise Exception(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨ (HTTP {response.status_code})")
                except requests.exceptions.RequestException as e:
                    if retry == max_retries - 1:
                        raise Exception(f"ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {str(e)}")
                    import time
                    time.sleep(1)

            if not audio_downloaded:
                raise Exception("ì˜¤ë””ì˜¤ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")

        update_progress(40, "ì˜ìƒ ì¸ì½”ë”© ì¤€ë¹„ ì¤‘...")

        # 3. ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
        probe_cmd = [
            'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
            '-of', 'default=noprint_wrappers=1:nokey=1', audio_path
        ]
        result = subprocess.run(probe_cmd, capture_output=True, text=True)
        audio_duration = float(result.stdout.strip()) if result.stdout.strip() else 60.0

        # 4. ì´ë¯¸ì§€ë‹¹ í‘œì‹œ ì‹œê°„ ê³„ì‚°
        image_duration = audio_duration / len(image_paths)

        # 5. ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„± (FFmpegìš©)
        list_path = os.path.join(temp_dir, "images.txt")
        with open(list_path, 'w') as f:
            for img_path in image_paths:
                f.write(f"file '{img_path}'\n")
                f.write(f"duration {image_duration}\n")
            # ë§ˆì§€ë§‰ ì´ë¯¸ì§€ í•œë²ˆ ë” (FFmpeg concat demuxer ìš”êµ¬ì‚¬í•­)
            f.write(f"file '{image_paths[-1]}'\n")

        # 6. í•´ìƒë„ íŒŒì‹±
        width, height = resolution.split('x')

        # 7. FFmpegë¡œ ì˜ìƒ ìƒì„±
        output_path = os.path.join(temp_dir, "output.mp4")

        # ê¸°ë³¸ FFmpeg ëª…ë ¹ì–´ (ë©”ëª¨ë¦¬ ìµœì í™”)
        ffmpeg_cmd = [
            'ffmpeg', '-y',
            '-f', 'concat', '-safe', '0', '-i', list_path,
            '-i', audio_path,
            '-vf', f'scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2',
            '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '28',  # ë©”ëª¨ë¦¬ ìµœì í™”: ultrafast preset, ë†’ì€ CRF
            '-c:a', 'aac', '-b:a', '96k',  # ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸ ê°ì†Œ
            '-r', str(fps),
            '-shortest',
            '-pix_fmt', 'yuv420p',
            '-threads', '2',  # ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ (ë©”ëª¨ë¦¬ ì ˆì•½)
            output_path
        ]

        # ìë§‰ í•˜ë“œì½”ë”© ì˜µì…˜
        if burn_subtitle and subtitle_data and subtitle_data.get('srt'):
            # SRTë¥¼ ASSë¡œ ë³€í™˜í•˜ì—¬ í•œê¸€ í°íŠ¸ ëª…ì‹œì  ì§€ì •
            ass_path = os.path.join(temp_dir, "subtitle.ass")
            srt_content = subtitle_data['srt']

            # í•œê¸€ í°íŠ¸ í™•ì¸ (ASS ìë§‰ì€ í°íŠ¸ ì´ë¦„ë§Œ ì‚¬ìš©)
            # í°íŠ¸ ì„¤ì •: lang/ko.pyì—ì„œ ê´€ë¦¬
            base_dir = os.path.dirname(os.path.abspath(__file__))

            font_found = False
            font_location = None
            # í•œêµ­ì–´ í°íŠ¸ ìš°ì„ ìˆœìœ„ (lang_ko.FONTSì—ì„œ ê°€ì ¸ì˜´)
            korean_fonts = [os.path.join(base_dir, 'fonts', f) for f in lang_ko.FONTS['priority']]
            korean_fonts.extend(lang_ko.FONTS['system_paths'])
            for kf in korean_fonts:
                if os.path.exists(kf):
                    font_found = True
                    font_location = kf
                    break

            # ASS ìë§‰ì—ëŠ” í°íŠ¸ ê²½ë¡œê°€ ì•„ë‹Œ í°íŠ¸ ì´ë¦„ì„ ì‚¬ìš©í•´ì•¼ í•¨
            subtitle_font = lang_ko.FONTS['default_name'] if font_found else 'Arial'

            print(f"[VIDEO-SUBTITLE] ìë§‰ í°íŠ¸: {subtitle_font} (found: {font_found}, location: {font_location if font_found else 'N/A'})")

            # ASS í—¤ë” ìƒì„± (í•œê¸€ í°íŠ¸ ëª…ì‹œ)
            ass_header = f"""[Script Info]
ScriptType: v4.00+
Collisions: Normal
PlayResX: 1920
PlayResY: 1080

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,{subtitle_font},40,&HFFFFFF,&H000000FF,&H00000000,&H80000000,1,0,0,0,100,100,0,0,4,1,0,2,20,20,50,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

            # SRTë¥¼ ASS ì´ë²¤íŠ¸ë¡œ ë³€í™˜
            import re

            def srt_to_ass_time(srt_time):
                """SRT íƒ€ì„ìŠ¤íƒ¬í”„(00:00:00,000)ë¥¼ ASS í˜•ì‹(0:00:00.00)ìœ¼ë¡œ ë³€í™˜"""
                # SRT: HH:MM:SS,mmm (ë°€ë¦¬ì´ˆ 3ìë¦¬)
                # ASS: H:MM:SS.cc (ì„¼í‹°ì´ˆ 2ìë¦¬, ì‹œê°„ì€ ì•ì˜ 0 ì œê±°)
                hours, minutes, seconds_ms = srt_time.split(':')
                seconds, milliseconds = seconds_ms.split(',')
                centiseconds = int(milliseconds) // 10  # ë°€ë¦¬ì´ˆë¥¼ ì„¼í‹°ì´ˆë¡œ ë³€í™˜
                return f"{int(hours)}:{minutes}:{seconds}.{centiseconds:02d}"

            ass_events = []

            # SRT ë¸”ë¡ ë¶„í•  ê°œì„ : \r\n, \n ëª¨ë‘ ì²˜ë¦¬í•˜ê³ , ë¹ˆ ì¤„ ì—¬ëŸ¬ ê°œë„ ëŒ€ì‘
            srt_normalized = srt_content.replace('\r\n', '\n').strip()
            # ë¹ˆ ì¤„ 1ê°œ ì´ìƒìœ¼ë¡œ ë¶„í•  (ì •ê·œì‹ ì‚¬ìš©)
            srt_blocks = re.split(r'\n\s*\n', srt_normalized)

            print(f"[VIDEO-SUBTITLE] SRT ë¸”ë¡ ìˆ˜: {len(srt_blocks)}")

            for idx, block in enumerate(srt_blocks):
                lines = block.strip().split('\n')
                if len(lines) >= 3:
                    # íƒ€ì„ì½”ë“œ íŒŒì‹± (00:00:00,000 --> 00:00:03,000)
                    time_match = re.match(r'(\d{2}:\d{2}:\d{2},\d{3})\s*-->\s*(\d{2}:\d{2}:\d{2},\d{3})', lines[1])
                    if time_match:
                        start_time = srt_to_ass_time(time_match.group(1))
                        end_time = srt_to_ass_time(time_match.group(2))
                        text = '\\N'.join(lines[2:])  # ASSëŠ” \Nìœ¼ë¡œ ì¤„ë°”ê¿ˆ
                        ass_events.append(f"Dialogue: 0,{start_time},{end_time},Default,,0,0,0,,{text}")
                    else:
                        print(f"[VIDEO-SUBTITLE] ë¸”ë¡ {idx+1} íƒ€ì„ì½”ë“œ íŒŒì‹± ì‹¤íŒ¨: {lines[1][:50] if len(lines) > 1 else 'N/A'}")
                elif len(lines) >= 2:
                    # 2ì¤„ì¸ ê²½ìš° - ìˆ«ì + íƒ€ì„ì½”ë“œë§Œ ìˆê³  í…ìŠ¤íŠ¸ê°€ ì—†ëŠ” ê²½ìš°ì¼ ìˆ˜ ìˆìŒ
                    print(f"[VIDEO-SUBTITLE] ë¸”ë¡ {idx+1} ë¼ì¸ ë¶€ì¡± ({len(lines)}ì¤„): {lines}")

            print(f"[VIDEO-SUBTITLE] ASS ì´ë²¤íŠ¸ ìƒì„± ì™„ë£Œ: {len(ass_events)}ê°œ")

            # ASS íŒŒì¼ ì‘ì„±
            with open(ass_path, 'w', encoding='utf-8') as f:
                f.write(ass_header)
                # ì´ë²¤íŠ¸ ì¤„ ì‚¬ì´ì— ì¤„ë°”ê¿ˆ ì¶”ê°€
                for event in ass_events:
                    f.write(event + '\n')

            # ASS ìë§‰ í•„í„° ì¶”ê°€ (ê²½ë¡œ ì´ìŠ¤ì¼€ì´í”„ ì²˜ë¦¬)
            # FFmpeg ass í•„í„°ëŠ” ê²½ë¡œì—ì„œ ì½œë¡ (:)ê³¼ ë°±ìŠ¬ë˜ì‹œ(\)ë¥¼ ì´ìŠ¤ì¼€ì´í”„í•´ì•¼ í•¨
            escaped_ass_path = ass_path.replace('\\', '\\\\').replace(':', '\\:')

            # í°íŠ¸ ë””ë ‰í† ë¦¬ ì„¤ì • (í”„ë¡œì íŠ¸ ë‚´ fonts í´ë” ì‚¬ìš©)
            fonts_dir = os.path.join(base_dir, 'fonts')
            escaped_fonts_dir = fonts_dir.replace('\\', '\\\\').replace(':', '\\:')

            # fontsdir ì˜µì…˜ìœ¼ë¡œ FFmpegì´ í”„ë¡œì íŠ¸ ë‚´ í°íŠ¸ë¥¼ ì¸ì‹í•˜ë„ë¡ ì„¤ì •
            if font_found and os.path.exists(fonts_dir):
                vf_filter = f"scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,ass={escaped_ass_path}:fontsdir={escaped_fonts_dir}"
            else:
                vf_filter = f"scale={width}:{height}:force_original_aspect_ratio=decrease,pad={width}:{height}:(ow-iw)/2:(oh-ih)/2,ass={escaped_ass_path}"
            ffmpeg_cmd = [
                'ffmpeg', '-y',
                '-f', 'concat', '-safe', '0', '-i', list_path,
                '-i', audio_path,
                '-vf', vf_filter,
                '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '28',  # ë©”ëª¨ë¦¬ ìµœì í™”
                '-c:a', 'aac', '-b:a', '96k',  # ì˜¤ë””ì˜¤ ë¹„íŠ¸ë ˆì´íŠ¸ ê°ì†Œ
                '-r', str(fps),
                '-shortest',
                '-pix_fmt', 'yuv420p',
                '-threads', '2',  # ìŠ¤ë ˆë“œ ìˆ˜ ì œí•œ
                output_path
            ]

        print(f"[DRAMA-STEP6-VIDEO] FFmpeg ëª…ë ¹ì–´ ì‹¤í–‰: {' '.join(ffmpeg_cmd[:5])}...")
        update_progress(50, "ì˜ìƒ ì¸ì½”ë”© ì¤‘...")

        # FFmpeg ì‹¤í–‰ (íƒ€ì„ì•„ì›ƒ 30ë¶„ - 10ë¶„ ì´ìƒ ì˜ìƒ ì§€ì›)
        # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPE (OOM ë°©ì§€ - 30ë¶„ ì¸ì½”ë”© ì‹œ ìˆ˜ë°±MB ì¶œë ¥ ê°€ëŠ¥)
        try:
            process = subprocess.run(
                ffmpeg_cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                timeout=1800
            )
        except subprocess.TimeoutExpired:
            print(f"[DRAMA-STEP6-VIDEO][ERROR] FFmpeg íƒ€ì„ì•„ì›ƒ (30ë¶„)")
            raise Exception("ì˜ìƒ ì¸ì½”ë”© ì‹œê°„ ì´ˆê³¼ (30ë¶„). ì´ë¯¸ì§€ ìˆ˜ë¥¼ ì¤„ì´ê±°ë‚˜ í•´ìƒë„ë¥¼ ë‚®ì¶°ì£¼ì„¸ìš”.")

        if process.returncode != 0:
            # ì—ëŸ¬ ì‹œì—ë§Œ stderr ì½ê¸° (ìµœëŒ€ 1000ë°”ì´íŠ¸)
            error_msg = process.stderr[:1000].decode('utf-8', errors='ignore').strip() if process.stderr else ''
            print(f"[DRAMA-STEP6-VIDEO][ERROR] FFmpeg ì˜¤ë¥˜: {error_msg}")
            del process
            gc.collect()

            # ì¼ë°˜ì ì¸ ì˜¤ë¥˜ ë©”ì‹œì§€ ê°œì„ 
            if "No such file or directory" in error_msg:
                raise Exception("íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë‚˜ ì˜¤ë””ì˜¤ íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            elif "Invalid data" in error_msg or "corrupt" in error_msg:
                raise Exception("ì†ìƒëœ íŒŒì¼ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì´ë¯¸ì§€ë‚˜ ì˜¤ë””ì˜¤ë¥¼ ë‹¤ì‹œ ìƒì„±í•´ì£¼ì„¸ìš”.")
            elif "Permission denied" in error_msg:
                raise Exception("íŒŒì¼ ê¶Œí•œ ì˜¤ë¥˜. ì„œë²„ ê´€ë¦¬ìì—ê²Œ ë¬¸ì˜í•˜ì„¸ìš”.")
            else:
                raise Exception(f"ì˜ìƒ ì¸ì½”ë”© ì‹¤íŒ¨: {error_msg[:300]}")

        del process
        gc.collect()

        update_progress(80, "ì˜ìƒ ì €ì¥ ì¤‘...")

        # 8. ìƒì„±ëœ ì˜ìƒì„ static í´ë”ì— ì €ì¥
        static_video_dir = os.path.join(os.path.dirname(__file__), 'static', 'videos')
        os.makedirs(static_video_dir, exist_ok=True)

        # ê³ ìœ í•œ íŒŒì¼ëª… ìƒì„±
        timestamp = dt.now().strftime("%Y%m%d_%H%M%S")
        video_filename = f"drama_{timestamp}.mp4"
        final_video_path = os.path.join(static_video_dir, video_filename)

        # ì˜ìƒ íŒŒì¼ ë³µì‚¬
        shutil.copy2(output_path, final_video_path)

        # íŒŒì¼ í¬ê¸° í™•ì¸
        file_size = os.path.getsize(final_video_path)
        file_size_mb = file_size / (1024 * 1024)

        # ë©”ëª¨ë¦¬ ìµœì í™”: Base64 ì¸ì½”ë”© ì œí•œì„ 10MBë¡œ ë‚®ì¶¤ (2GB í™˜ê²½)
        # 10MB ì˜ìƒ + Base64 ì˜¤ë²„í—¤ë“œ(33%) = ~13MB ë©”ëª¨ë¦¬ ì‚¬ìš©
        video_url = f"/static/videos/{video_filename}"
        if file_size_mb <= 10:
            with open(final_video_path, 'rb') as f:
                video_data = f.read()
            video_base64 = base64.b64encode(video_data).decode('utf-8')
            video_url_base64 = f"data:video/mp4;base64,{video_base64}"
            # ì¦‰ì‹œ ë©”ëª¨ë¦¬ í•´ì œ
            del video_data
            del video_base64
            gc.collect()
        else:
            video_url_base64 = None

        print(f"[DRAMA-STEP6-VIDEO] ì˜ìƒ ìƒì„± ì™„ë£Œ - í¬ê¸°: {file_size_mb:.2f}MB, ê¸¸ì´: {audio_duration:.1f}ì´ˆ, íŒŒì¼: {video_filename}")

        # ë©”ëª¨ë¦¬ ì •ë¦¬
        gc.collect()

        # ê²°ê³¼ë¥¼ dictë¡œ ë°˜í™˜ (jsonify ëŒ€ì‹ )
        return {
            "ok": True,
            "videoUrl": video_url_base64 if video_url_base64 else video_url,
            "videoFileUrl": video_url,
            "duration": audio_duration,
            "fileSize": file_size,
            "fileSizeMB": round(file_size_mb, 2)
        }


# ===== Step4: ì”¬ë³„ MP4 í´ë¦½ ìƒì„± (ê°œë³„ ë‹¤ìš´ë¡œë“œìš©) =====
@app.route('/api/drama/generate-scene-clip', methods=['POST'])
def api_generate_scene_clip():
    """ë‹¨ì¼ ì”¬ í´ë¦½ ìƒì„± (ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ â†’ MP4)

    ê°€ë²¼ìš´ ì‘ì—…ì´ë¯€ë¡œ CPU ë¶€í•˜ê°€ ë‚®ìŠµë‹ˆë‹¤.
    """
    import base64
    import tempfile
    import subprocess
    import shutil

    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        scene_id = data.get("sceneId", "scene_1")
        image_url = data.get("imageUrl", "")
        audio_url = data.get("audioUrl", "")

        print(f"[SCENE-CLIP] ì”¬ í´ë¦½ ìƒì„± ì‹œì‘: {scene_id}")

        if not image_url:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400
        if not audio_url:
            return jsonify({"ok": False, "error": "ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        with tempfile.TemporaryDirectory() as temp_dir:
            # 1. ì´ë¯¸ì§€ ì €ì¥
            img_path = os.path.join(temp_dir, "image.png")
            if image_url.startswith('data:'):
                header, encoded = image_url.split(',', 1)
                img_data = base64.b64decode(encoded)
                with open(img_path, 'wb') as f:
                    f.write(img_data)
            else:
                response = requests.get(image_url, timeout=60)
                with open(img_path, 'wb') as f:
                    f.write(response.content)

            # 2. ì˜¤ë””ì˜¤ ì €ì¥
            audio_path = os.path.join(temp_dir, "audio.mp3")
            if audio_url.startswith('data:'):
                header, encoded = audio_url.split(',', 1)
                audio_data = base64.b64decode(encoded)
                with open(audio_path, 'wb') as f:
                    f.write(audio_data)
            else:
                response = requests.get(audio_url, timeout=60)
                with open(audio_path, 'wb') as f:
                    f.write(response.content)

            # 3. ì˜¤ë””ì˜¤ ê¸¸ì´ í™•ì¸
            probe_cmd = [
                'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                '-of', 'default=noprint_wrappers=1:nokey=1', audio_path
            ]
            result = subprocess.run(probe_cmd, capture_output=True, text=True)
            duration = float(result.stdout.strip()) if result.stdout.strip() else 10.0

            print(f"[SCENE-CLIP] {scene_id}: ì˜¤ë””ì˜¤ ê¸¸ì´ {duration:.1f}ì´ˆ")

            # 4. MP4 ìƒì„± (720p, ê°€ë²¼ìš´ ì„¤ì •)
            output_path = os.path.join(temp_dir, f"{scene_id}.mp4")
            ffmpeg_cmd = [
                'ffmpeg', '-y',
                '-threads', '1',
                '-loop', '1',
                '-i', img_path,
                '-i', audio_path,
                '-vf', 'scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2',
                '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '28', '-threads', '1',
                '-c:a', 'aac', '-b:a', '128k',
                '-r', '24',
                '-t', str(duration),
                '-shortest',
                '-pix_fmt', 'yuv420p',
                output_path
            ]

            # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPE (OOM ë°©ì§€)
            process = subprocess.run(
                ffmpeg_cmd,
                stdout=subprocess.DEVNULL,
                stderr=subprocess.PIPE,
                timeout=120
            )

            if process.returncode != 0 or not os.path.exists(output_path):
                stderr_msg = process.stderr[:300].decode('utf-8', errors='ignore') if process.stderr else '(stderr ì—†ìŒ)'
                print(f"[SCENE-CLIP] FFmpeg ì˜¤ë¥˜: {stderr_msg}")
                del process
                gc.collect()
                return jsonify({"ok": False, "error": "í´ë¦½ ìƒì„± ì‹¤íŒ¨"}), 500
            del process
            gc.collect()

            # 5. ê²°ê³¼ ë°˜í™˜ (Base64)
            with open(output_path, 'rb') as f:
                video_data = f.read()

            video_base64 = base64.b64encode(video_data).decode('utf-8')
            file_size = len(video_data)

            print(f"[SCENE-CLIP] {scene_id} ì™„ë£Œ: {duration:.1f}ì´ˆ, {file_size/(1024*1024):.2f}MB")

            return jsonify({
                "ok": True,
                "sceneId": scene_id,
                "videoUrl": f"data:video/mp4;base64,{video_base64}",
                "duration": duration,
                "fileSize": file_size,
                "fileSizeMB": round(file_size / (1024 * 1024), 2)
            })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/drama/generate-scene-clips-zip', methods=['POST'])
def api_generate_scene_clips_zip():
    """ëª¨ë“  ì”¬ í´ë¦½ì„ ìƒì„±í•˜ê³  ZIPìœ¼ë¡œ ë°˜í™˜

    ì”¬ë³„ë¡œ ìˆœì°¨ ì²˜ë¦¬í•˜ì—¬ ë©”ëª¨ë¦¬/CPU ë¶€í•˜ ìµœì†Œí™”
    """
    import base64
    import tempfile
    import subprocess
    import shutil
    import zipfile
    import gc

    print(f"[SCENE-ZIP] === API ì§„ì… ===")
    print(f"[SCENE-ZIP] Content-Length: {request.content_length}")

    try:
        print(f"[SCENE-ZIP] JSON íŒŒì‹± ì‹œì‘...")
        data = request.get_json()
        print(f"[SCENE-ZIP] JSON íŒŒì‹± ì™„ë£Œ")

        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        cuts = data.get("cuts", [])
        if not cuts:
            return jsonify({"ok": False, "error": "ì”¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        print(f"[SCENE-ZIP] ì”¬ í´ë¦½ ZIP ìƒì„± ì‹œì‘: {len(cuts)}ê°œ ì”¬")

        # ê° cutì˜ ë°ì´í„° í¬ê¸° í™•ì¸ (ë””ë²„ê¹…)
        for idx, cut in enumerate(cuts):
            img_size = len(cut.get("imageUrl", "")) // 1024
            audio_size = len(cut.get("audioUrl", "")) // 1024
            print(f"[SCENE-ZIP] cut[{idx}] - ì´ë¯¸ì§€: {img_size}KB, ì˜¤ë””ì˜¤: {audio_size}KB")

        with tempfile.TemporaryDirectory() as temp_dir:
            clip_paths = []

            for idx, cut in enumerate(cuts):
                scene_id = cut.get("sceneId", f"scene_{idx+1}")
                image_url = cut.get("imageUrl", "")
                audio_url = cut.get("audioUrl", "")

                if not image_url or not audio_url:
                    print(f"[SCENE-ZIP] {scene_id} ìŠ¤í‚µ (ì´ë¯¸ì§€/ì˜¤ë””ì˜¤ ì—†ìŒ)")
                    continue

                print(f"[SCENE-ZIP] {scene_id} ì²˜ë¦¬ ì¤‘...")

                # ì´ë¯¸ì§€ ì €ì¥
                img_path = os.path.join(temp_dir, f"img_{idx}.png")
                if image_url.startswith('data:'):
                    header, encoded = image_url.split(',', 1)
                    img_data = base64.b64decode(encoded)
                    with open(img_path, 'wb') as f:
                        f.write(img_data)
                    del img_data
                else:
                    response = requests.get(image_url, timeout=60)
                    with open(img_path, 'wb') as f:
                        f.write(response.content)

                # ì˜¤ë””ì˜¤ ì €ì¥
                audio_path = os.path.join(temp_dir, f"audio_{idx}.mp3")
                if audio_url.startswith('data:'):
                    header, encoded = audio_url.split(',', 1)
                    audio_data = base64.b64decode(encoded)
                    with open(audio_path, 'wb') as f:
                        f.write(audio_data)
                    del audio_data
                else:
                    response = requests.get(audio_url, timeout=60)
                    with open(audio_path, 'wb') as f:
                        f.write(response.content)

                # ì˜¤ë””ì˜¤ ê¸¸ì´
                probe_cmd = [
                    'ffprobe', '-v', 'error', '-show_entries', 'format=duration',
                    '-of', 'default=noprint_wrappers=1:nokey=1', audio_path
                ]
                result = subprocess.run(probe_cmd, capture_output=True, text=True)
                duration = float(result.stdout.strip()) if result.stdout.strip() else 10.0

                # MP4 ìƒì„±
                clip_path = os.path.join(temp_dir, f"{scene_id}.mp4")
                ffmpeg_cmd = [
                    'ffmpeg', '-y',
                    '-threads', '1',
                    '-loop', '1',
                    '-i', img_path,
                    '-i', audio_path,
                    '-vf', 'scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2',
                    '-c:v', 'libx264', '-preset', 'ultrafast', '-crf', '28', '-threads', '1',
                    '-c:a', 'aac', '-b:a', '128k',
                    '-r', '24',
                    '-t', str(duration),
                    '-shortest',
                    '-pix_fmt', 'yuv420p',
                    clip_path
                ]

                # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPE (OOM ë°©ì§€)
                process = subprocess.run(
                    ffmpeg_cmd,
                    stdout=subprocess.DEVNULL,
                    stderr=subprocess.PIPE,
                    timeout=180
                )

                if process.returncode == 0 and os.path.exists(clip_path):
                    clip_paths.append((scene_id, clip_path))
                    print(f"[SCENE-ZIP] {scene_id} ì™„ë£Œ: {duration:.1f}ì´ˆ")
                else:
                    stderr_msg = process.stderr[:200].decode('utf-8', errors='ignore') if process.stderr else '(stderr ì—†ìŒ)'
                    print(f"[SCENE-ZIP] {scene_id} ì‹¤íŒ¨: {stderr_msg}")

                # ë©”ëª¨ë¦¬ ì •ë¦¬
                del process
                gc.collect()

            if not clip_paths:
                return jsonify({"ok": False, "error": "ìƒì„±ëœ í´ë¦½ì´ ì—†ìŠµë‹ˆë‹¤."}), 500

            # ZIP ìƒì„±
            zip_path = os.path.join(temp_dir, "drama_scenes.zip")
            with zipfile.ZipFile(zip_path, 'w', zipfile.ZIP_DEFLATED) as zf:
                for scene_id, clip_path in clip_paths:
                    zf.write(clip_path, f"{scene_id}.mp4")

            # ZIP íŒŒì¼ ì½ê¸°
            with open(zip_path, 'rb') as f:
                zip_data = f.read()

            zip_base64 = base64.b64encode(zip_data).decode('utf-8')

            print(f"[SCENE-ZIP] ZIP ìƒì„± ì™„ë£Œ: {len(clip_paths)}ê°œ í´ë¦½, {len(zip_data)/(1024*1024):.2f}MB")

            return jsonify({
                "ok": True,
                "clipCount": len(clip_paths),
                "zipUrl": f"data:application/zip;base64,{zip_base64}",
                "fileSize": len(zip_data),
                "fileSizeMB": round(len(zip_data) / (1024 * 1024), 2)
            })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ===== Step6: ì˜ìƒ ì œì‘ API (ë¹„ë™ê¸° í ë°©ì‹) =====
@app.route('/api/drama/generate-video', methods=['POST'])
def api_generate_video():
    """ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ë¥¼ í•©ì³ì„œ ì˜ìƒ ìƒì„± (ë™ê¸°/ë¹„ë™ê¸° ëª¨ë“œ ì§€ì›)

    - syncMode=true: ë™ê¸°ì‹ ì²˜ë¦¬ (Render ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ ë¬¸ì œ ìš°íšŒ)
    - syncMode=false (ê¸°ë³¸): ë¹„ë™ê¸° ì›Œì»¤ í ì‚¬ìš©
    """
    try:
        data = request.get_json()
        if not data:
            print(f"[DRAMA-STEP6-VIDEO] ìš”ì²­ ë°ì´í„° ì—†ìŒ")
            return jsonify({"ok": False, "error": "No data received"}), 400

        # ë™ê¸° ëª¨ë“œ ì—¬ë¶€ í™•ì¸
        sync_mode = data.get("syncMode", False)
        print(f"[DRAMA-STEP6-VIDEO] === API í˜¸ì¶œ ì‹œì‘ ({'ë™ê¸° ëª¨ë“œ' if sync_mode else 'ë¹„ë™ê¸° ëª¨ë“œ'}) ===")

        # ë””ë²„ê¹…: ìš”ì²­ ë°ì´í„° ì¶œë ¥
        print(f"[DRAMA-STEP6-VIDEO] === DEBUG: ìš”ì²­ ë°ì´í„° ===")
        print(f"[DRAMA-STEP6-VIDEO] data keys: {list(data.keys())}")

        images = data.get("images", [])
        cuts = data.get("cuts", [])  # ì”¬ë³„ ì´ë¯¸ì§€-ì˜¤ë””ì˜¤ ë§¤ì¹­ ë°°ì—´
        audio_url = data.get("audioUrl", "")
        subtitle_data = data.get("subtitleData")
        burn_subtitle = data.get("burnSubtitle", False)
        resolution = data.get("resolution", "1920x1080")
        fps = data.get("fps", 30)
        transition = data.get("transition", "fade")

        # ë””ë²„ê¹…: ìƒì„¸ ì •ë³´ ì¶œë ¥
        print(f"[DRAMA-STEP6-VIDEO] images ê°œìˆ˜: {len(images)}")
        print(f"[DRAMA-STEP6-VIDEO] cuts ê°œìˆ˜: {len(cuts)}")
        print(f"[DRAMA-STEP6-VIDEO] audio_url: {audio_url[:100] if audio_url else 'N/A'}...")
        print(f"[DRAMA-STEP6-VIDEO] resolution: {resolution}, fps: {fps}")

        if cuts:
            for i, cut in enumerate(cuts[:3]):  # ì²˜ìŒ 3ê°œë§Œ ì¶œë ¥
                print(f"[DRAMA-STEP6-VIDEO] cuts[{i}]: imageUrl={cut.get('imageUrl', 'N/A')[:50]}..., audioUrl={cut.get('audioUrl', 'N/A')[:50] if cut.get('audioUrl') else 'N/A'}..., duration={cut.get('duration', 'N/A')}")

        # cuts ë°°ì—´ì´ ìˆìœ¼ë©´ ê·¸ê²ƒì„ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹
        if cuts and len(cuts) > 0:
            print(f"[DRAMA-STEP6-VIDEO] cuts ë°°ì—´ ì‚¬ìš©: {len(cuts)}ê°œ ì”¬")
            # cutsì—ì„œ ì´ë¯¸ì§€ì™€ ì˜¤ë””ì˜¤ ì¶”ì¶œ
            images = [cut.get('imageUrl', '') for cut in cuts]
            # ì˜¤ë””ì˜¤ê°€ ì—†ìœ¼ë©´ ì²« ë²ˆì§¸ cutì˜ ì˜¤ë””ì˜¤ ì‚¬ìš©
            if not audio_url:
                audio_url = cuts[0].get('audioUrl', '')

        if not images:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        if not audio_url and not cuts:
            return jsonify({"ok": False, "error": "ì˜¤ë””ì˜¤ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        # Job ID ìƒì„±
        job_id = str(uuid.uuid4())

        # ===== ë™ê¸° ëª¨ë“œ: ì§ì ‘ ì²˜ë¦¬í•˜ê³  ê²°ê³¼ ë°˜í™˜ =====
        if sync_mode:
            print(f"[DRAMA-STEP6-VIDEO] ë™ê¸°ì‹ ì˜ìƒ ìƒì„± ì‹œì‘: {job_id}")

            # Job ìƒíƒœ ì´ˆê¸°í™”
            with video_jobs_lock:
                video_jobs[job_id] = {
                    'status': 'processing',
                    'progress': 0,
                    'message': 'ì˜ìƒ ìƒì„± ì‹œì‘...',
                    'result': None,
                    'error': None,
                    'created_at': dt.now().isoformat()
                }
                save_video_jobs()

            try:
                # ì§ì ‘ ì˜ìƒ ìƒì„± ì‹¤í–‰
                result = _generate_video_sync(
                    images=images,
                    audio_url=audio_url,
                    cuts=cuts,
                    subtitle_data=subtitle_data,
                    burn_subtitle=burn_subtitle,
                    resolution=resolution,
                    fps=fps,
                    transition=transition,
                    job_id=job_id
                )

                # ì„±ê³µ
                with video_jobs_lock:
                    if job_id in video_jobs:
                        video_jobs[job_id]['status'] = 'completed'
                        video_jobs[job_id]['progress'] = 100
                        video_jobs[job_id]['result'] = result
                        save_video_jobs()

                print(f"[DRAMA-STEP6-VIDEO] ë™ê¸°ì‹ ì˜ìƒ ìƒì„± ì™„ë£Œ: {job_id}")
                return jsonify({
                    "ok": True,
                    "jobId": job_id,
                    "status": "completed",
                    "progress": 100,
                    "videoUrl": result.get('videoUrl'),
                    "videoPath": result.get('videoFileUrl'),
                    "duration": result.get('duration'),
                    "fileSize": result.get('fileSize'),
                    "message": "ì˜ìƒ ìƒì„± ì™„ë£Œ"
                })

            except Exception as e:
                import traceback
                error_msg = str(e)
                print(f"[DRAMA-STEP6-VIDEO] ë™ê¸°ì‹ ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {error_msg}")
                traceback.print_exc()

                with video_jobs_lock:
                    if job_id in video_jobs:
                        video_jobs[job_id]['status'] = 'failed'
                        video_jobs[job_id]['error'] = error_msg
                        save_video_jobs()

                return jsonify({
                    "ok": False,
                    "jobId": job_id,
                    "status": "failed",
                    "error": error_msg
                })

        # ===== ë¹„ë™ê¸° ëª¨ë“œ: ì›Œì»¤ í ì‚¬ìš© =====
        print(f"[DRAMA-STEP6-VIDEO] ë¹„ë™ê¸° ì˜ìƒ ìƒì„± ì‘ì—… ë“±ë¡: {job_id}, ì´ë¯¸ì§€: {len(images)}ê°œ, cuts: {len(cuts)}ê°œ")

        # Job ìƒíƒœ ì´ˆê¸°í™” - pending ìƒíƒœë¡œ ì‹œì‘
        with video_jobs_lock:
            video_jobs[job_id] = {
                'status': 'pending',
                'progress': 0,
                'message': 'ì‘ì—… ëŒ€ê¸° ì¤‘...',
                'result': None,
                'error': None,
                'created_at': dt.now().isoformat()
            }
            save_video_jobs()

        # ì‘ì—…ì„ íì— ì¶”ê°€ (ë°±ê·¸ë¼ìš´ë“œ ì›Œì»¤ê°€ ì²˜ë¦¬)
        job_data = {
            'job_id': job_id,
            'images': images,
            'audio_url': audio_url,
            'cuts': cuts,
            'subtitle_data': subtitle_data,
            'burn_subtitle': burn_subtitle,
            'resolution': resolution,
            'fps': fps,
            'transition': transition
        }
        video_job_queue.put(job_data)

        print(f"[DRAMA-STEP6-VIDEO] ì‘ì—… íì— ì¶”ê°€ë¨: {job_id}, í í¬ê¸°: {video_job_queue.qsize()}")

        # ì¦‰ì‹œ ì‘ë‹µ ë°˜í™˜ (í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í´ë§ìœ¼ë¡œ ìƒíƒœ í™•ì¸)
        return jsonify({
            "ok": True,
            "jobId": job_id,
            "status": "pending",
            "progress": 0,
            "workerAlive": video_worker_thread.is_alive(),
            "message": "ì˜ìƒ ìƒì„± ì‘ì—…ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."
        })

    except Exception as e:
        import traceback
        print(f"[DRAMA-STEP6-VIDEO][ERROR] {str(e)}")
        print(f"[DRAMA-STEP6-VIDEO][TRACEBACK]")
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== Step6: ì˜ìƒ ì œì‘ API (SSE ìŠ¤íŠ¸ë¦¬ë°) =====
@app.route('/api/drama/generate-video-stream', methods=['POST'])
def api_generate_video_stream():
    """ì˜ìƒ ìƒì„± - SSE ìŠ¤íŠ¸ë¦¬ë° ë°©ì‹ (Render íƒ€ì„ì•„ì›ƒ ìš°íšŒ)

    ì—°ê²°ì„ ìœ ì§€í•˜ë©´ì„œ ì§„í–‰ë¥ ì„ ìŠ¤íŠ¸ë¦¬ë°í•©ë‹ˆë‹¤.
    í´ë¼ì´ì–¸íŠ¸ëŠ” fetch APIì˜ ReadableStreamìœ¼ë¡œ ì‘ë‹µì„ ì½ìŠµë‹ˆë‹¤.
    """
    print(f"[DRAMA-VIDEO-STREAM] === SSE ìŠ¤íŠ¸ë¦¬ë° API í˜¸ì¶œ ===")

    try:
        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        images = data.get("images", [])
        cuts = data.get("cuts", [])
        audio_url = data.get("audioUrl", "")
        subtitle_data = data.get("subtitleData")
        burn_subtitle = data.get("burnSubtitle", False)
        resolution = data.get("resolution", "1920x1080")
        fps = data.get("fps", 30)

        print(f"[DRAMA-VIDEO-STREAM] cuts: {len(cuts)}ê°œ, images: {len(images)}ê°œ")

        # cuts ë°°ì—´ ì²˜ë¦¬
        if cuts and len(cuts) > 0:
            images = [cut.get('imageUrl', '') for cut in cuts]
            if not audio_url:
                audio_url = cuts[0].get('audioUrl', '')

        if not images:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤."}), 400

        job_id = str(uuid.uuid4())

        def generate():
            """SSE ìŠ¤íŠ¸ë¦¬ë° ì œë„ˆë ˆì´í„°"""
            try:
                # ì‹œì‘ ì´ë²¤íŠ¸
                yield f"data: {json.dumps({'event': 'start', 'jobId': job_id, 'progress': 0, 'message': 'ì˜ìƒ ìƒì„± ì‹œì‘...'})}\n\n"

                # ì§„í–‰ë¥  ì—…ë°ì´íŠ¸ í•¨ìˆ˜ (yieldë¥¼ í†µí•´ í´ë¼ì´ì–¸íŠ¸ì— ì „ì†¡)
                progress_updates = []

                def update_progress(progress, message=""):
                    progress_updates.append({'progress': progress, 'message': message})

                # Job ìƒíƒœ ì €ì¥
                with video_jobs_lock:
                    video_jobs[job_id] = {
                        'status': 'processing',
                        'progress': 0,
                        'message': 'ì˜ìƒ ìƒì„± ì‹œì‘...',
                        'result': None,
                        'error': None,
                        'created_at': dt.now().isoformat()
                    }
                    save_video_jobs()

                yield f"data: {json.dumps({'event': 'progress', 'progress': 5, 'message': 'ì˜ì¡´ì„± í™•ì¸ ì¤‘...'})}\n\n"

                # ì˜ìƒ ìƒì„± ì‹¤í–‰ (ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ)
                result_holder = {'result': None, 'error': None}

                def run_video_generation():
                    try:
                        result = _generate_video_sync(
                            images=images,
                            audio_url=audio_url,
                            cuts=cuts,
                            subtitle_data=subtitle_data,
                            burn_subtitle=burn_subtitle,
                            resolution=resolution,
                            fps=fps,
                            transition='fade',
                            job_id=job_id
                        )
                        result_holder['result'] = result
                    except Exception as e:
                        result_holder['error'] = str(e)
                        import traceback
                        traceback.print_exc()

                # ìŠ¤ë ˆë“œ ì‹œì‘
                import time
                gen_thread = threading.Thread(target=run_video_generation)
                gen_thread.start()

                # ì§„í–‰ë¥  ëª¨ë‹ˆí„°ë§ (3ì´ˆë§ˆë‹¤ í™•ì¸, ìµœëŒ€ 10ë¶„)
                max_wait = 600  # 10ë¶„
                elapsed = 0
                last_progress = 0

                while gen_thread.is_alive() and elapsed < max_wait:
                    time.sleep(3)
                    elapsed += 3

                    # job ìƒíƒœì—ì„œ ì§„í–‰ë¥  ì½ê¸°
                    with video_jobs_lock:
                        if job_id in video_jobs:
                            current_progress = video_jobs[job_id].get('progress', 0)
                            current_message = video_jobs[job_id].get('message', '')

                            if current_progress > last_progress:
                                last_progress = current_progress
                                yield f"data: {json.dumps({'event': 'progress', 'progress': current_progress, 'message': current_message})}\n\n"

                    # í•˜íŠ¸ë¹„íŠ¸ (ì—°ê²° ìœ ì§€)
                    yield f": heartbeat\n\n"

                # ìŠ¤ë ˆë“œ ì¢…ë£Œ ëŒ€ê¸°
                gen_thread.join(timeout=30)

                if result_holder['error']:
                    # ì‹¤íŒ¨
                    with video_jobs_lock:
                        if job_id in video_jobs:
                            video_jobs[job_id]['status'] = 'failed'
                            video_jobs[job_id]['error'] = result_holder['error']
                            save_video_jobs()

                    yield f"data: {json.dumps({'event': 'error', 'error': result_holder['error']})}\n\n"

                elif result_holder['result']:
                    # ì„±ê³µ
                    result = result_holder['result']
                    with video_jobs_lock:
                        if job_id in video_jobs:
                            video_jobs[job_id]['status'] = 'completed'
                            video_jobs[job_id]['progress'] = 100
                            video_jobs[job_id]['result'] = result
                            save_video_jobs()

                    yield f"data: {json.dumps({'event': 'complete', 'progress': 100, 'videoUrl': result.get('videoUrl'), 'videoPath': result.get('videoFileUrl'), 'duration': result.get('duration'), 'fileSize': result.get('fileSize')})}\n\n"

                else:
                    # íƒ€ì„ì•„ì›ƒ
                    yield f"data: {json.dumps({'event': 'error', 'error': 'ì˜ìƒ ìƒì„± ì‹œê°„ ì´ˆê³¼ (10ë¶„)'})}\n\n"

            except Exception as e:
                import traceback
                traceback.print_exc()
                yield f"data: {json.dumps({'event': 'error', 'error': str(e)})}\n\n"

        return Response(
            generate(),
            mimetype='text/event-stream',
            headers={
                'Cache-Control': 'no-cache',
                'Connection': 'keep-alive',
                'X-Accel-Buffering': 'no'  # nginx ë²„í¼ë§ ë¹„í™œì„±í™”
            }
        )

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== ì‘ì—… ìƒíƒœ ì¡°íšŒ API =====
@app.route('/api/drama/video-status/<job_id>', methods=['GET'])
def api_video_status(job_id):
    """ì˜ìƒ ìƒì„± ì‘ì—… ìƒíƒœ ì¡°íšŒ"""
    with video_jobs_lock:
        # ë©”ëª¨ë¦¬ì— ì—†ìœ¼ë©´ íŒŒì¼ì—ì„œ ë‹¤ì‹œ ë¡œë“œ ì‹œë„ (ë‹¤ì¤‘ ì¸ìŠ¤í„´ìŠ¤/ì¬ì‹œì‘ ëŒ€ì‘)
        if job_id not in video_jobs:
            print(f"[VIDEO-STATUS] job_id {job_id} ë©”ëª¨ë¦¬ì— ì—†ìŒ, íŒŒì¼ì—ì„œ ë¡œë“œ ì‹œë„...")
            try:
                if os.path.exists(VIDEO_JOBS_FILE):
                    with open(VIDEO_JOBS_FILE, 'r', encoding='utf-8') as f:
                        loaded_jobs = json.load(f)
                        video_jobs.update(loaded_jobs)
                        print(f"[VIDEO-STATUS] íŒŒì¼ì—ì„œ {len(loaded_jobs)}ê°œ ì‘ì—… ë¡œë“œë¨")
            except Exception as e:
                print(f"[VIDEO-STATUS] íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")

        if job_id not in video_jobs:
            print(f"[VIDEO-STATUS] job_id {job_id} ì—¬ì „íˆ ì°¾ì„ ìˆ˜ ì—†ìŒ")
            return jsonify({"ok": False, "error": "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        job = video_jobs[job_id]

        # pending ìƒíƒœê°€ 5ë¶„ ì´ìƒ ì§€ì†ë˜ë©´ ì‹¤íŒ¨ ì²˜ë¦¬
        if job['status'] == 'pending':
            created_at = dt.fromisoformat(job['created_at'])
            elapsed = (dt.now() - created_at).total_seconds()
            if elapsed > 300:  # 5ë¶„ = 300ì´ˆ
                job['status'] = 'failed'
                job['error'] = f'ì‘ì—… ì²˜ë¦¬ ì‹œê°„ ì´ˆê³¼ (ì›Œì»¤ ìƒíƒœ í™•ì¸ í•„ìš”). ê²½ê³¼ ì‹œê°„: {int(elapsed)}ì´ˆ'
                save_video_jobs()
                print(f"[VIDEO-STATUS] ì‘ì—… {job_id} pending íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì‹¤íŒ¨ ì²˜ë¦¬")

        response = {
            "ok": True,
            "jobId": job_id,
            "status": job['status'],  # pending, processing, completed, failed
            "progress": job['progress'],
            "message": job.get('message', ''),
            "workerAlive": True  # ë™ê¸°ì‹ìœ¼ë¡œ ë³€ê²½ë¨ - í•­ìƒ True
        }

        if job['status'] == 'completed':
            result = job['result']
            # í”„ë¡ íŠ¸ì—”ë“œ í˜¸í™˜ì„±ì„ ìœ„í•´ result ë‚´ìš©ì„ ìµœìƒìœ„ë¡œ í¼ì¹¨
            if result:
                response['videoUrl'] = result.get('videoUrl')
                response['videoFileUrl'] = result.get('videoFileUrl')
                response['duration'] = result.get('duration')
                response['fileSize'] = result.get('fileSize')
                response['fileSizeMB'] = result.get('fileSizeMB')
            response['result'] = result  # ê¸°ì¡´ í˜¸í™˜ì„± ìœ ì§€
        elif job['status'] == 'failed':
            response['error'] = job['error']

        return jsonify(response)


# ===== ì›Œì»¤ ìƒíƒœ ë””ë²„ê¹… API =====
@app.route('/api/drama/worker-status', methods=['GET'])
def api_worker_status():
    """ì˜ìƒ ì›Œì»¤ ìƒíƒœ í™•ì¸ (ë””ë²„ê¹…ìš©) - ë™ê¸°ì‹ ëª¨ë“œ"""
    with video_jobs_lock:
        pending_jobs = [jid for jid, j in video_jobs.items() if j['status'] == 'pending']
        processing_jobs = [jid for jid, j in video_jobs.items() if j['status'] == 'processing']

    return jsonify({
        "ok": True,
        "workerAlive": True,  # ë™ê¸°ì‹ ëª¨ë“œ - í•­ìƒ True
        "mode": "synchronous",  # ë™ê¸°ì‹ ëª¨ë“œ í‘œì‹œ
        "queueSize": 0,  # ë™ê¸°ì‹ì´ë¯€ë¡œ í ì—†ìŒ
        "pendingJobs": pending_jobs,
        "processingJobs": processing_jobs,
        "totalJobs": len(video_jobs)
    })


# ===== Step7: ìœ íŠœë¸Œ ì—…ë¡œë“œ API =====

@app.route('/api/drama/generate-metadata', methods=['POST'])
def generate_metadata():
    """ëŒ€ë³¸ ê¸°ë°˜ YouTube ë©”íƒ€ë°ì´í„° ìë™ ìƒì„±"""
    try:
        data = request.get_json()
        script = data.get('script', '')

        if not script.strip():
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."})

        # OpenAI API í˜¸ì¶œí•˜ì—¬ ë©”íƒ€ë°ì´í„° ìƒì„±
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
            return jsonify({"ok": False, "error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."})

        import requests as req

        prompt = f"""ë‹¤ìŒ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ YouTube ì—…ë¡œë“œìš© ë©”íƒ€ë°ì´í„°ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ëŒ€ë³¸:
{script[:3000]}

ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
ì œëª©: (50ì ì´ë‚´ì˜ í¥ë¯¸ë¡œìš´ ì œëª©, ì‹œì²­ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆë„ë¡)
ì„¤ëª…: (200ì ì´ë‚´ì˜ ì˜ìƒ ì„¤ëª…, ì¤„ê±°ë¦¬ ìš”ì•½ê³¼ í•´ì‹œíƒœê·¸ í¬í•¨)
íƒœê·¸: (ì‰¼í‘œë¡œ êµ¬ë¶„ëœ 10ê°œ ì´ë‚´ì˜ ê´€ë ¨ íƒœê·¸)

ì‘ë‹µ ì˜ˆì‹œ:
ì œëª©: ê·¸ë…€ê°€ ë– ë‚œ ì´ìœ  | ê°ë™ ë‹¨í¸ ë“œë¼ë§ˆ
ì„¤ëª…: 10ë…„ì„ í•¨ê»˜í•œ ì—°ì¸ì´ ê°‘ìê¸° ë– ë‚¬ë‹¤. ë‚¨ê²¨ì§„ ê·¸ëŠ” ê·¸ë…€ì˜ ë§ˆì§€ë§‰ í¸ì§€ë¥¼ ë°œê²¬í•˜ê³ ...

#ë‹¨í¸ë“œë¼ë§ˆ #ê°ë™ #ì‚¬ë‘ #ì´ë³„
íƒœê·¸: ë‹¨í¸ë“œë¼ë§ˆ, ê°ë™, ì‚¬ë‘, ì´ë³„, ë¡œë§¨ìŠ¤, AIë“œë¼ë§ˆ, í•œêµ­ë“œë¼ë§ˆ, ê°ì„±, ëˆˆë¬¼, ìŠ¤í† ë¦¬"""

        response = req.post(
            'https://api.openai.com/v1/chat/completions',
            headers={
                'Authorization': f'Bearer {openai_api_key}',
                'Content-Type': 'application/json'
            },
            json={
                'model': 'gpt-4o',
                'messages': [
                    {'role': 'system', 'content': 'YouTube ì˜ìƒ ë©”íƒ€ë°ì´í„° ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì‹œì²­ìì˜ ê´€ì‹¬ì„ ëŒ ìˆ˜ ìˆëŠ” ì œëª©, ì„¤ëª…, íƒœê·¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.'},
                    {'role': 'user', 'content': prompt}
                ],
                'max_tokens': 500,
                'temperature': 0.7
            },
            timeout=30
        )

        if response.status_code != 200:
            return jsonify({"ok": False, "error": f"OpenAI API ì˜¤ë¥˜: {response.text}"})

        result = response.json()
        content = result['choices'][0]['message']['content']

        # ì‘ë‹µ íŒŒì‹±
        title = ''
        description = ''
        tags = ''

        lines = content.strip().split('\n')
        for line in lines:
            line = line.strip()
            if line.startswith('ì œëª©:'):
                title = line[3:].strip()
            elif line.startswith('ì„¤ëª…:'):
                description = line[3:].strip()
            elif line.startswith('íƒœê·¸:'):
                tags = line[3:].strip()
            elif description and not line.startswith('íƒœê·¸:') and not title:
                # ì„¤ëª…ì´ ì—¬ëŸ¬ ì¤„ì¼ ê²½ìš°
                description += '\n' + line

        # ì„¤ëª…ì— í•´ì‹œíƒœê·¸ ë¼ì¸ì´ ìˆìœ¼ë©´ í•©ì¹˜ê¸°
        desc_lines = []
        for line in lines:
            line = line.strip()
            if line.startswith('#') or (description and line and not line.startswith('íƒœê·¸:')):
                if not line.startswith('ì œëª©:') and not line.startswith('ì„¤ëª…:') and not line.startswith('íƒœê·¸:'):
                    if '#' in line:
                        desc_lines.append(line)

        if desc_lines:
            description = description + '\n\n' + '\n'.join(desc_lines)

        print(f"[GENERATE-METADATA] ìƒì„± ì™„ë£Œ - ì œëª©: {title[:30]}...")
        return jsonify({
            "ok": True,
            "metadata": {
                "title": title,
                "description": description,
                "tags": tags
            }
        })

    except Exception as e:
        print(f"[GENERATE-METADATA][ERROR] {str(e)}")
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/drama/generate-thumbnail', methods=['POST'])
def generate_thumbnail():
    """ìœ íŠœë¸Œ ì¸ë„¤ì¼ ìë™ ìƒì„± (ì¸ë¬¼ + ê°•ë ¬í•œ ë¬¸êµ¬)"""
    try:
        data = request.get_json()
        script = data.get('script', '')
        title = data.get('title', '')
        provider = data.get('provider', 'gemini')  # gemini, dalle, flux

        if not script.strip():
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤."})

        print(f"[THUMBNAIL] ì¸ë„¤ì¼ ìƒì„± ì‹œì‘ - ì œê³µì: {provider}")

        # OpenAI API í‚¤ í™•ì¸
        openai_api_key = os.getenv('OPENAI_API_KEY')
        if not openai_api_key:
            return jsonify({"ok": False, "error": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."})

        import requests as req

        # 1. GPTë¡œ ì¸ë„¤ì¼ ì½˜ì…‰íŠ¸ ìƒì„± (ì£¼ì¸ê³µ + í´ë¦­ ìœ ë„ ë¬¸êµ¬)
        concept_prompt = f"""ë‹¤ìŒ ë“œë¼ë§ˆ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ìœ íŠœë¸Œ ì¸ë„¤ì¼ì„ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ğŸ¯ ëª©í‘œ: ì‹œì²­ìê°€ í´ë¦­í•˜ê³  ì‹¶ê²Œ ë§Œë“œëŠ” ì¸ë„¤ì¼

âš ï¸ ì¤‘ìš”: ìºë¦­í„°ëŠ” ë°˜ë“œì‹œ í•œêµ­ ì›¹íˆ°/ë§Œí™” ìŠ¤íƒ€ì¼ë¡œ í‘œí˜„í•˜ì„¸ìš”!
- ì‹¤ì‚¬ ì¸ë¬¼(ì‚¬ì§„ì²˜ëŸ¼ ì‚¬ì‹¤ì ì¸ ì‚¬ëŒ) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!
- ìŠ¤í‹±ë§¨(ë§‰ëŒ€ê¸° ì¸ê°„) ì ˆëŒ€ ì‚¬ìš© ê¸ˆì§€!
- ìºë¦­í„°: í•œêµ­ ì›¹íˆ° ìŠ¤íƒ€ì¼, ê³¼ì¥ëœ í‘œì • (ì¶©ê²©, ë†€ëŒ, ë•€ë°©ìš¸ ë“±)
- 30-50ëŒ€ í•œêµ­ì¸ ë‚¨ì„±/ì—¬ì„±

ëŒ€ë³¸:
{script[:3000]}

ì œëª©: {title}

ã€í•„ìˆ˜ í˜•ì‹ã€‘ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:

1. ì£¼ì¸ê³µ ì •ë³´: (ëŒ€ë³¸ì˜ ì£¼ì¸ê³µ ìƒí™©/ê°ì • - ì›¹íˆ° ìºë¦­í„°ë¡œ í‘œí˜„)
2. ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: (ì˜ì–´ë¡œ, ì•„ë˜ ì¡°ê±´ í¬í•¨)
   - ì›¹íˆ° ìºë¦­í„°: "Korean WEBTOON/manhwa style character with EXAGGERATED EXPRESSION, 30-50 year old Korean man or woman"
   - ê°ì • í‘œí˜„: ê³¼ì¥ëœ ì›¹íˆ° í‘œì • (shocked face, wide eyes, open mouth, sweat drops)
   - ë°°ê²½: ì£¼ì œì™€ ê´€ë ¨ëœ ìƒì„¸í•œ ë°°ê²½
   - ìŠ¤íƒ€ì¼: Clean bold outlines, vibrant flat colors, comic-style expression marks
3. ì¸ë„¤ì¼ í…ìŠ¤íŠ¸: (3~4ì¤„ë¡œ êµ¬ì„±, ê° ì¤„ \\nìœ¼ë¡œ êµ¬ë¶„)
   - 1ì¤„: í›… (ì¶©ê²©ì ì¸ ìˆ«ì/ìƒí™©)
   - 2ì¤„: í•µì‹¬ ì¸ë¬¼/ì‚¬ê±´
   - 3ì¤„: ê°ì • ê°•ì¡° (ê°•ì¡°ìƒ‰ìœ¼ë¡œ í‘œì‹œë  ë¶€ë¶„)
   - 4ì¤„: ê¶ê¸ˆì¦ ìœ ë°œ
4. ê°•ì¡° ì¤„ ë²ˆí˜¸: (3ì¤„ ì¤‘ ê°•ì¡°í•  ì¤„ ë²ˆí˜¸, ì˜ˆ: 3)

ã€ì˜ˆì‹œã€‘
1. ì£¼ì¸ê³µ ì •ë³´: ì™¸ë¡œìš´ ë…¸ì¸, êµíšŒë¥¼ í˜¼ì ì§€í‚¤ë‹¤ í¬ë§ì„ ì°¾ëŠ” ìˆœê°„ (ì›¹íˆ° ìºë¦­í„°ë¡œ í‘œí˜„)
2. ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: Korean WEBTOON/manhwa style illustration, 16:9 aspect ratio. Korean webtoon character with EMOTIONAL EXPRESSION (gentle sad eyes, slight smile), 60 year old Korean man standing alone in church interior. Clean bold outlines, warm colors, comic-style atmosphere. Stained glass windows in background. NO photorealistic, NO stickman, NO anime, NO 3D render.
3. ì¸ë„¤ì¼ í…ìŠ¤íŠ¸: 1ë…„ê°„ í˜¼ì ì˜ˆë°°ë“œë¦¬ë˜\\nì‘ì€ êµíšŒ\\në¬¸ ë‹«ìœ¼ë ¤ë˜ ê·¸ë‚ \\ní•œ ì²­ë…„ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤
4. ê°•ì¡° ì¤„ ë²ˆí˜¸: 3"""

        response = req.post(
            'https://api.openai.com/v1/chat/completions',
            headers={
                'Authorization': f'Bearer {openai_api_key}',
                'Content-Type': 'application/json'
            },
            json={
                'model': 'gpt-4o',
                'messages': [
                    {'role': 'system', 'content': 'ìœ íŠœë¸Œ ì¸ë„¤ì¼ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í´ë¦­ë¥ ì„ ë†’ì´ëŠ” ì¸ë„¤ì¼ ì½˜ì…‰íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.'},
                    {'role': 'user', 'content': concept_prompt}
                ],
                'max_tokens': 500,
                'temperature': 0.8
            },
            timeout=30
        )

        if response.status_code != 200:
            return jsonify({"ok": False, "error": f"ì½˜ì…‰íŠ¸ ìƒì„± ì‹¤íŒ¨: {response.text}"})

        concept_result = response.json()
        concept_content = concept_result['choices'][0]['message']['content']
        print(f"[THUMBNAIL] ì½˜ì…‰íŠ¸ ìƒì„± ì™„ë£Œ:\n{concept_content}")

        # ì½˜ì…‰íŠ¸ íŒŒì‹±
        image_prompt = ""
        thumbnail_text = title[:30] if title else "ë“œë¼ë§ˆ"
        highlight_line = 2  # ê¸°ë³¸ê°’: 3ë²ˆì§¸ ì¤„ ê°•ì¡° (0-indexed)

        lines = concept_content.strip().split('\n')
        for line in lines:
            line = line.strip()
            if 'ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸:' in line or 'Image Prompt:' in line.lower():
                image_prompt = line.split(':', 1)[1].strip()
            elif 'ì¸ë„¤ì¼ í…ìŠ¤íŠ¸:' in line:
                thumbnail_text = line.split(':', 1)[1].strip()
            elif 'ê°•ì¡° ì¤„ ë²ˆí˜¸:' in line:
                try:
                    highlight_line = int(line.split(':', 1)[1].strip()) - 1  # 0-indexed
                except:
                    highlight_line = 2

        if not image_prompt:
            # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ìƒì„±
            image_prompt = f"Dramatic close-up portrait of Korean drama character, emotional expression, cinematic lighting, YouTube thumbnail style, high quality"

        # ì¸ë„¤ì¼ ìµœì í™” í”„ë¡¬í”„íŠ¸ ì¶”ê°€
        image_prompt += ", 1280x720 resolution, YouTube thumbnail, eye-catching, professional"

        print(f"[THUMBNAIL] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: {image_prompt}")
        print(f"[THUMBNAIL] í…ìŠ¤íŠ¸: {thumbnail_text}")

        # 2. ì´ë¯¸ì§€ ìƒì„±
        image_url = None

        if provider == 'gemini':
            # Gemini ì´ë¯¸ì§€ ìƒì„± (image ëª¨ë“ˆ ì‚¬ìš©)
            # ì›¹íˆ° ìŠ¤íƒ€ì¼ ê°•ì œ ì ìš©
            enhanced_prompt = f"""CRITICAL REQUIREMENTS:
1. 16:9 WIDESCREEN aspect ratio for YouTube thumbnail
2. Korean WEBTOON/manhwa style character with EXAGGERATED EXPRESSION (shocked face, wide eyes, open mouth, sweat drops)
3. 30-50 year old Korean man or woman (match the story context)
4. Clean bold outlines, vibrant flat colors, comic-style expression marks
5. ABSOLUTELY NO photorealistic humans, NO stickman/stick figures, NO Japanese anime style, NO 3D render

Original request: {image_prompt}

FINAL STYLE: Korean webtoon/manhwa style illustration. Eye-catching YouTube thumbnail composition with dramatic character expression."""

            # image ëª¨ë“ˆì˜ generate_image ì‚¬ìš©
            result = image_generate(prompt=enhanced_prompt, size="1280x720")

            if result.get("ok") and result.get("image_url"):
                image_url = result.get("image_url")
                print(f"[THUMBNAIL] Gemini ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {image_url}")
            else:
                return jsonify({"ok": False, "error": result.get("error", "Gemini ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")})

        elif provider == 'dalle':
            # DALL-E 3 ì´ë¯¸ì§€ ìƒì„±
            dalle_response = req.post(
                'https://api.openai.com/v1/images/generations',
                headers={
                    'Authorization': f'Bearer {openai_api_key}',
                    'Content-Type': 'application/json'
                },
                json={
                    'model': 'dall-e-3',
                    'prompt': image_prompt,
                    'n': 1,
                    'size': '1792x1024',  # ê°€ë¡œí˜•
                    'quality': 'hd'
                },
                timeout=60
            )

            if dalle_response.status_code == 200:
                dalle_result = dalle_response.json()
                temp_image_url = dalle_result['data'][0]['url']

                # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                img_response = req.get(temp_image_url, timeout=30)
                if img_response.status_code == 200:
                    static_dir = os.path.join(os.path.dirname(__file__), 'static', 'thumbnails')
                    os.makedirs(static_dir, exist_ok=True)

                    timestamp = dt.now().strftime("%Y%m%d_%H%M%S")
                    filename = f"thumbnail_{timestamp}.png"
                    filepath = os.path.join(static_dir, filename)

                    with open(filepath, 'wb') as f:
                        f.write(img_response.content)

                    image_url = f"/static/thumbnails/{filename}"

        if not image_url:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨"})

        # 3. PILë¡œ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ (ê°•ì¡°ìƒ‰ í¬í•¨)
        try:
            from PIL import Image, ImageDraw, ImageFont
            from io import BytesIO
            import os as os_module

            # ì´ë¯¸ì§€ ë¡œë“œ
            static_dir = os.path.dirname(__file__)
            img_path = os.path.join(static_dir, image_url.lstrip('/'))
            img = Image.open(img_path)

            if img.mode != 'RGBA':
                img = img.convert('RGBA')

            width, height = img.size
            draw = ImageDraw.Draw(img)

            # í°íŠ¸ ë¡œë“œ: lang/ko.pyì—ì„œ ê´€ë¦¬ (NanumSquareRoundB ìš°ì„ )
            font_size = int(height * 0.08)  # ì´ë¯¸ì§€ ë†’ì´ì˜ 8%
            font = None
            font_paths = [os.path.join(static_dir, 'fonts', f) for f in lang_ko.FONTS['priority']]
            font_paths.extend(lang_ko.FONTS['system_paths'])
            for fp in font_paths:
                if os.path.exists(fp):
                    try:
                        font = ImageFont.truetype(fp, font_size)
                        print(f"[THUMBNAIL] í°íŠ¸ ë¡œë“œ: {fp}")
                        break
                    except:
                        continue
            if not font:
                font = ImageFont.load_default()
                print("[THUMBNAIL] ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ ë¯¸ì§€ì› ê°€ëŠ¥)")

            # í…ìŠ¤íŠ¸ ì¤„ ë¶„ë¦¬
            text_lines = thumbnail_text.replace('\\n', '\n').split('\n')

            # ìƒ‰ìƒ ì„¤ì •
            normal_color = (255, 255, 255)  # í°ìƒ‰
            highlight_color = (255, 215, 0)  # ë…¸ë€ìƒ‰ (ê³¨ë“œ)
            outline_color = (0, 0, 0)  # ê²€ì • ì™¸ê³½ì„ 

            # í…ìŠ¤íŠ¸ ìœ„ì¹˜ (ì™¼ìª½ ì •ë ¬, ìƒë‹¨ 10%)
            x_margin = int(width * 0.05)
            y_start = int(height * 0.08)
            line_height = int(font_size * 1.3)

            for i, line_text in enumerate(text_lines):
                y = y_start + (i * line_height)
                color = highlight_color if i == highlight_line else normal_color

                # ì™¸ê³½ì„  ê·¸ë¦¬ê¸° (ê²€ì •)
                for dx in [-3, -2, -1, 0, 1, 2, 3]:
                    for dy in [-3, -2, -1, 0, 1, 2, 3]:
                        draw.text((x_margin + dx, y + dy), line_text, font=font, fill=outline_color)

                # ë©”ì¸ í…ìŠ¤íŠ¸
                draw.text((x_margin, y), line_text, font=font, fill=color)

            # ì €ì¥
            img.save(img_path)
            print(f"[THUMBNAIL] í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì™„ë£Œ: {image_url}")

        except Exception as overlay_error:
            print(f"[THUMBNAIL] í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì‹¤íŒ¨ (ë¬´ì‹œ): {overlay_error}")

        print(f"[THUMBNAIL] ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ: {image_url}")

        return jsonify({
            "ok": True,
            "thumbnailUrl": image_url,
            "thumbnailText": thumbnail_text,
            "textLines": thumbnail_text.replace('\\n', '\n').split('\n'),
            "highlightLine": highlight_line,
            "imagePrompt": image_prompt
        })

    except Exception as e:
        print(f"[THUMBNAIL][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


# YouTube OAuth ì¸ì¦ ìƒíƒœ ì €ì¥ (DB ê¸°ë°˜ - Render í™˜ê²½ì—ì„œ ì•ˆì •ì )
OAUTH_STATE_FILE = 'data/oauth_state.json'  # í´ë°±ìš©

def save_oauth_state(state_data):
    """OAuth ìƒíƒœë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ (íŒŒì¼ í´ë°±)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        state_json = json.dumps(state_data, ensure_ascii=False)

        if USE_POSTGRES:
            # PostgreSQL: UPSERT
            cursor.execute('''
                INSERT INTO youtube_tokens (user_id, scopes, updated_at)
                VALUES ('oauth_state', %s, CURRENT_TIMESTAMP)
                ON CONFLICT (user_id) DO UPDATE SET
                    scopes = EXCLUDED.scopes,
                    updated_at = CURRENT_TIMESTAMP
            ''', (state_json,))
        else:
            # SQLite: INSERT OR REPLACE
            cursor.execute('''
                INSERT OR REPLACE INTO youtube_tokens (user_id, scopes, updated_at)
                VALUES ('oauth_state', ?, datetime('now'))
            ''', (state_json,))

        conn.commit()
        conn.close()
        print(f"[OAUTH-STATE] DB ì €ì¥ ì™„ë£Œ: {list(state_data.keys())}")
    except Exception as e:
        print(f"[OAUTH-STATE] DB ì €ì¥ ì‹¤íŒ¨, íŒŒì¼ë¡œ í´ë°±: {e}")
        # íŒŒì¼ í´ë°±
        try:
            os.makedirs('data', exist_ok=True)
            with open(OAUTH_STATE_FILE, 'w', encoding='utf-8') as f:
                json.dump(state_data, f, ensure_ascii=False)
            print(f"[OAUTH-STATE] íŒŒì¼ ì €ì¥ ì™„ë£Œ")
        except Exception as file_error:
            print(f"[OAUTH-STATE] íŒŒì¼ ì €ì¥ë„ ì‹¤íŒ¨: {file_error}")

def load_oauth_state():
    """OAuth ìƒíƒœë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ ë¡œë“œ (íŒŒì¼ í´ë°±)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute("SELECT scopes FROM youtube_tokens WHERE user_id = 'oauth_state'")
        else:
            cursor.execute("SELECT scopes FROM youtube_tokens WHERE user_id = 'oauth_state'")

        row = cursor.fetchone()
        conn.close()

        if row:
            state_json = row[0] if not USE_POSTGRES else row['scopes']
            if state_json:
                state_data = json.loads(state_json)
                print(f"[OAUTH-STATE] DB ë¡œë“œ ì™„ë£Œ: {list(state_data.keys())}")
                return state_data
    except Exception as e:
        print(f"[OAUTH-STATE] DB ë¡œë“œ ì‹¤íŒ¨, íŒŒì¼ë¡œ í´ë°±: {e}")

    # íŒŒì¼ í´ë°±
    try:
        if os.path.exists(OAUTH_STATE_FILE):
            with open(OAUTH_STATE_FILE, 'r', encoding='utf-8') as f:
                state_data = json.load(f)
            print(f"[OAUTH-STATE] íŒŒì¼ ë¡œë“œ ì™„ë£Œ: {list(state_data.keys())}")
            return state_data
    except Exception as e:
        print(f"[OAUTH-STATE] íŒŒì¼ ë¡œë“œë„ ì‹¤íŒ¨: {e}")
    return {}

@app.route('/api/drama/youtube-auth', methods=['GET', 'POST'])
def youtube_auth():
    """YouTube OAuth ì¸ì¦ ì‹œì‘"""
    try:
        from google_auth_oauthlib.flow import Flow
        from google.oauth2.credentials import Credentials
        import json as json_module

        # GET ë˜ëŠ” POST ëª¨ë‘ ì§€ì›
        if request.method == 'GET':
            force_project = request.args.get('project', '')
            target_channel_id = request.args.get('channel_id', '')  # íŠ¹ì • ì±„ë„ ID ì§€ì •
        else:
            data = request.get_json() or {}
            force_project = data.get('forceProject', '')
            target_channel_id = data.get('channelId', '')  # íŠ¹ì • ì±„ë„ ID ì§€ì •

        # ê°•ì œ í”„ë¡œì íŠ¸ ì§€ì • ì‹œ í•´ë‹¹ í”„ë¡œì íŠ¸ ì‚¬ìš©
        if force_project in ['_2', 'backup']:
            client_id = os.getenv('YOUTUBE_CLIENT_ID_2')
            client_secret = os.getenv('YOUTUBE_CLIENT_SECRET_2')
            project_suffix = '_2'
            print(f"[YOUTUBE-AUTH] ë°±ì—… í”„ë¡œì íŠ¸(_2) ê°•ì œ ì¸ì¦ ìš”ì²­")
        elif force_project == 'default':
            client_id = os.getenv('YOUTUBE_CLIENT_ID') or os.getenv('GOOGLE_CLIENT_ID')
            client_secret = os.getenv('YOUTUBE_CLIENT_SECRET') or os.getenv('GOOGLE_CLIENT_SECRET')
            project_suffix = ''
            print(f"[YOUTUBE-AUTH] ê¸°ë³¸ í”„ë¡œì íŠ¸ ê°•ì œ ì¸ì¦ ìš”ì²­")
        else:
            # í™˜ê²½ ë³€ìˆ˜ì—ì„œ OAuth í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ _2 í”„ë¡œì íŠ¸ë¡œ ì „í™˜
            client_id, client_secret, project_suffix = get_youtube_credentials()

        # Render í™˜ê²½ì—ì„œëŠ” ë°˜ë“œì‹œ HTTPS URL ì‚¬ìš©
        redirect_uri = os.getenv('YOUTUBE_REDIRECT_URI')
        if not redirect_uri:
            # ìš”ì²­ URLì—ì„œ ìë™ ì¶”ì¶œ
            redirect_uri = request.url_root.rstrip('/') + '/api/drama/youtube-callback'
            # HTTPë¥¼ HTTPSë¡œ ë³€í™˜ (RenderëŠ” HTTPS ì‚¬ìš©)
            if redirect_uri.startswith('http://') and 'onrender.com' in redirect_uri:
                redirect_uri = redirect_uri.replace('http://', 'https://')

        print(f"[YOUTUBE-AUTH] Redirect URI: {redirect_uri}")
        print(f"[YOUTUBE-AUTH] ì‚¬ìš© í”„ë¡œì íŠ¸: {'ê¸°ë³¸' if not project_suffix else project_suffix}")

        if not client_id or not client_secret:
            return jsonify({
                "success": False,
                "error": "YouTube API ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. YOUTUBE_CLIENT_ID/GOOGLE_CLIENT_IDì™€ YOUTUBE_CLIENT_SECRET/GOOGLE_CLIENT_SECRET í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
            })

        # ì´ë¯¸ ì¸ì¦ëœ í† í°ì´ ìˆëŠ”ì§€ í™•ì¸ (ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ) - í•´ë‹¹ í”„ë¡œì íŠ¸ì˜ í† í°ë§Œ í™•ì¸
        token_data = load_youtube_token_from_db(project_suffix=project_suffix)
        if token_data and token_data.get('refresh_token'):
            try:
                from google.auth.transport.requests import Request
                credentials = Credentials.from_authorized_user_info(token_data)
                if credentials:
                    # í† í°ì´ ë§Œë£Œë˜ì—ˆìœ¼ë©´ ê°±ì‹  ì‹œë„
                    if credentials.expired and credentials.refresh_token:
                        try:
                            credentials.refresh(Request())
                            # ê°±ì‹ ëœ í† í° ì €ì¥
                            token_data['token'] = credentials.token
                            save_youtube_token_to_db(token_data)
                            print(f"[YOUTUBE-AUTH] í† í° ê°±ì‹  ì„±ê³µ")
                        except Exception as refresh_error:
                            print(f"[YOUTUBE-AUTH] í† í° ê°±ì‹  ì‹¤íŒ¨: {refresh_error}")
                            # ê°±ì‹  ì‹¤íŒ¨ ì‹œ ìƒˆë¡œìš´ ì¸ì¦ í•„ìš”
                            pass

                    # ìœ íš¨í•œ í† í°ì´ ìˆìœ¼ë©´ ì„±ê³µ ë°˜í™˜
                    if credentials.valid or (credentials.refresh_token and not credentials.expired):
                        return jsonify({"success": True, "message": "ì´ë¯¸ ì¸ì¦ë˜ì–´ ìˆìŠµë‹ˆë‹¤."})
            except Exception as e:
                print(f"[YOUTUBE-AUTH] ê¸°ì¡´ í† í° ê²€ì¦ ì‹¤íŒ¨: {e}")

        # OAuth í”Œë¡œìš° ìƒì„±
        client_config = {
            "web": {
                "client_id": client_id,
                "client_secret": client_secret,
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "redirect_uris": [redirect_uri]
            }
        }

        flow = Flow.from_client_config(
            client_config,
            scopes=[
                'https://www.googleapis.com/auth/youtube.upload',
                'https://www.googleapis.com/auth/youtube.readonly',
                'https://www.googleapis.com/auth/youtube.force-ssl',  # ëŒ“ê¸€ ì‘ì„±ìš©
                'https://www.googleapis.com/auth/yt-analytics.readonly'  # CTR/ì¡°íšŒìˆ˜ Analytics
            ],
            redirect_uri=redirect_uri
        )

        # prompt='consent'ëŠ” ì´ë¯¸ ê¶Œí•œ ë¶€ì—¬í•œ ì‚¬ìš©ìë„ refresh_tokenì„ ë°›ê¸° ìœ„í•´ í•„ìš”
        # access_type='offline'ê³¼ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•¨
        auth_url, state = flow.authorization_url(
            access_type='offline',
            include_granted_scopes='true',
            prompt='consent'  # ë°˜ë“œì‹œ í•„ìš”! ì—†ìœ¼ë©´ refresh_token ì•ˆ ì¤Œ
        )

        # ìƒíƒœë¥¼ íŒŒì¼ì— ì €ì¥ (ë©€í‹° ì›Œì»¤ ëŒ€ì‘)
        save_oauth_state({
            'state': state,
            'redirect_uri': redirect_uri,
            'client_id': client_id,
            'client_secret': client_secret,
            'project_suffix': project_suffix,  # í”„ë¡œì íŠ¸ êµ¬ë¶„ (_2 ë“±)
            'target_channel_id': target_channel_id  # íŠ¹ì • ì±„ë„ ID (ìˆìœ¼ë©´ í•´ë‹¹ ì±„ë„ë¡œ ì €ì¥)
        })

        if target_channel_id:
            print(f"[YOUTUBE-AUTH] ëŒ€ìƒ ì±„ë„ ì§€ì •ë¨: {target_channel_id}")

        # GET ìš”ì²­ì´ë©´ ë°”ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸, POSTë©´ JSON ì‘ë‹µ
        if request.method == 'GET':
            return redirect(auth_url)

        return jsonify({
            "success": False,
            "auth_url": auth_url,
            "message": "ì¸ì¦ URLë¡œ ì´ë™í•˜ì—¬ ê¶Œí•œì„ ìŠ¹ì¸í•´ì£¼ì„¸ìš”."
        })

    except ImportError:
        return jsonify({
            "success": False,
            "error": "Google ì¸ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-auth-oauthlib google-api-python-clientë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
        })
    except Exception as e:
        print(f"[YOUTUBE-AUTH][ERROR] {str(e)}")
        return jsonify({"success": False, "error": str(e)})


@app.route('/api/drama/youtube-callback')
def youtube_callback():
    """YouTube OAuth ì½œë°± ì²˜ë¦¬"""
    try:
        code = request.args.get('code')
        state = request.args.get('state')
        error = request.args.get('error')
        error_description = request.args.get('error_description', '')

        print(f"[YOUTUBE-CALLBACK] ì½œë°± ìˆ˜ì‹  - code: {bool(code)}, state: {state[:20] if state else 'None'}...")
        print(f"[YOUTUBE-CALLBACK] Error: {error}, Description: {error_description}")

        if error:
            # ì‚¬ìš©ì ì¹œí™”ì ì¸ ì—ëŸ¬ í˜ì´ì§€ ë°˜í™˜
            return f"""
            <!DOCTYPE html>
            <html>
            <head><title>YouTube ì—°ê²° ì˜¤ë¥˜</title>
            <style>body{{font-family:Arial;padding:50px;text-align:center}}.error{{background:#ffebee;padding:20px;border-radius:8px;margin:20px auto;max-width:500px;color:#c62828}}.back-btn{{margin-top:20px;padding:10px 20px;background:#1a73e8;color:white;border:none;border-radius:4px;cursor:pointer;text-decoration:none;display:inline-block}}</style>
            </head>
            <body>
                <h1>âš ï¸ YouTube ì—°ê²° ì˜¤ë¥˜</h1>
                <div class="error">
                    <p><strong>ì˜¤ë¥˜:</strong> {error}</p>
                    <p>{error_description}</p>
                </div>
                <a href="/image" class="back-btn">â† Image Labìœ¼ë¡œ ëŒì•„ê°€ê¸°</a>
            </body>
            </html>
            """, 400

        if not code:
            return "ì¸ì¦ ì½”ë“œê°€ ì—†ìŠµë‹ˆë‹¤.", 400

        # ì €ì¥ëœ ìƒíƒœ ë¡œë“œ
        oauth_state = load_oauth_state()
        print(f"[YOUTUBE-CALLBACK] ì €ì¥ëœ OAuth ìƒíƒœ: {list(oauth_state.keys()) if oauth_state else 'None'}")
        if not oauth_state:
            return """
            <!DOCTYPE html>
            <html>
            <head><title>YouTube ì—°ê²° ì˜¤ë¥˜</title>
            <style>body{font-family:Arial;padding:50px;text-align:center}.error{background:#ffebee;padding:20px;border-radius:8px;margin:20px auto;max-width:500px}.back-btn{margin-top:20px;padding:10px 20px;background:#1a73e8;color:white;border:none;border-radius:4px;cursor:pointer;text-decoration:none;display:inline-block}</style>
            </head>
            <body>
                <h1>âš ï¸ ì¸ì¦ ì„¸ì…˜ ë§Œë£Œ</h1>
                <div class="error">
                    <p>ì¸ì¦ ì„¸ì…˜ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤.</p>
                    <p>ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.</p>
                </div>
                <a href="/image" class="back-btn">â† ë‹¤ì‹œ ì‹œë„</a>
            </body>
            </html>
            """, 400

        # â˜… Scope ê²€ì¦ ë¬¸ì œ í•´ê²°: requestsë¡œ ì§ì ‘ í† í° êµí™˜
        # Google OAuthê°€ ë°˜í™˜í•˜ëŠ” scope ìˆœì„œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ Flow.fetch_tokenì—ì„œ ì—ëŸ¬ ë°œìƒ
        # ìˆ˜ë™ìœ¼ë¡œ í† í° êµí™˜í•˜ì—¬ scope ê²€ì¦ ìš°íšŒ
        import requests as req
        token_response = req.post(
            'https://oauth2.googleapis.com/token',
            data={
                'code': code,
                'client_id': oauth_state['client_id'],
                'client_secret': oauth_state['client_secret'],
                'redirect_uri': oauth_state['redirect_uri'],
                'grant_type': 'authorization_code'
            }
        )

        if token_response.status_code != 200:
            error_data = token_response.json()
            print(f"[YOUTUBE-CALLBACK] í† í° êµí™˜ ì‹¤íŒ¨: {error_data}")
            raise Exception(f"í† í° êµí™˜ ì‹¤íŒ¨: {error_data.get('error_description', error_data.get('error', 'Unknown error'))}")

        token_json = token_response.json()
        print(f"[YOUTUBE-CALLBACK] í† í° êµí™˜ ì„±ê³µ, scopes: {token_json.get('scope', 'N/A')}")

        # í† í° ë°ì´í„° ì¤€ë¹„
        token_data = {
            'token': token_json.get('access_token'),
            'refresh_token': token_json.get('refresh_token'),
            'token_uri': 'https://oauth2.googleapis.com/token',
            'client_id': oauth_state['client_id'],
            'client_secret': oauth_state['client_secret'],
            'scopes': token_json.get('scope', '').split() if token_json.get('scope') else []
        }

        # Credentials ê°ì²´ ìƒì„± (ì±„ë„ ì •ë³´ ì¡°íšŒìš©)
        from google.oauth2.credentials import Credentials
        credentials = Credentials(
            token=token_data['token'],
            refresh_token=token_data['refresh_token'],
            token_uri=token_data['token_uri'],
            client_id=token_data['client_id'],
            client_secret=token_data['client_secret'],
            scopes=token_data['scopes']
        )

        # ì±„ë„ ì •ë³´ ì¡°íšŒ - í•´ë‹¹ ê³„ì •ì´ ê´€ë¦¬í•˜ëŠ” ëª¨ë“  ì±„ë„
        all_channels = []  # [(channel_id, channel_info), ...]
        primary_channel_id = None
        primary_channel_info = None

        try:
            from googleapiclient.discovery import build
            youtube = build('youtube', 'v3', credentials=credentials)

            # 1. managedByMe=Trueë¡œ ëª¨ë“  ê´€ë¦¬ ì±„ë„ ì¡°íšŒ
            try:
                channels_response = youtube.channels().list(
                    part='snippet',
                    managedByMe=True,
                    maxResults=50
                ).execute()
                items = channels_response.get('items', [])
                print(f"[YOUTUBE-CALLBACK] managedByMeë¡œ {len(items)}ê°œ ì±„ë„ ë°œê²¬")
            except Exception as managed_err:
                print(f"[YOUTUBE-CALLBACK] managedByMe ì‹¤íŒ¨: {managed_err}, mine=Trueë¡œ ì¬ì‹œë„")
                # managedByMeê°€ ì‹¤íŒ¨í•˜ë©´ mine=Trueë¡œ fallback
                channels_response = youtube.channels().list(
                    part='snippet',
                    mine=True
                ).execute()
                items = channels_response.get('items', [])

            for channel in items:
                ch_id = channel['id']
                ch_info = {
                    'title': channel['snippet']['title'],
                    'thumbnail': channel['snippet']['thumbnails'].get('default', {}).get('url', '')
                }
                all_channels.append((ch_id, ch_info))
                print(f"[YOUTUBE-CALLBACK] ì±„ë„ ë°œê²¬: {ch_id} - {ch_info['title']}")

                # ì²« ë²ˆì§¸ ì±„ë„ì„ primaryë¡œ ì„¤ì •
                if primary_channel_id is None:
                    primary_channel_id = ch_id
                    primary_channel_info = ch_info

        except Exception as channel_error:
            print(f"[YOUTUBE-CALLBACK] ì±„ë„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {channel_error}")

        # OAuth stateì—ì„œ í”„ë¡œì íŠ¸ ì ‘ë¯¸ì‚¬ í™•ì¸ (ì¸ì¦ ì‹œì‘ ì‹œ ì €ì¥ë¨)
        project_suffix = oauth_state.get('project_suffix', '')

        # ëª¨ë“  ê´€ë¦¬ ì±„ë„ì— ëŒ€í•´ í† í° ì €ì¥
        if all_channels:
            for ch_id, ch_info in all_channels:
                save_youtube_token_to_db(token_data, channel_id=ch_id, channel_info=ch_info, project_suffix=project_suffix)
                print(f"[YOUTUBE-CALLBACK] í† í° ì €ì¥: {ch_id}{project_suffix} - {ch_info['title']}")
            print(f"[YOUTUBE-CALLBACK] ì´ {len(all_channels)}ê°œ ì±„ë„ì— í† í° ì €ì¥ ì™„ë£Œ (project: {'ê¸°ë³¸' if not project_suffix else project_suffix})")

            # _2 í”„ë¡œì íŠ¸ì¼ ê²½ìš° default_2ë„ ì €ì¥ (fallbackìš©)
            if project_suffix == '_2':
                save_youtube_token_to_db(token_data, channel_id='default', channel_info={'title': 'default_2 (fallback)'}, project_suffix=project_suffix)
                print(f"[YOUTUBE-CALLBACK] default_2 fallback í† í°ë„ ì €ì¥ ì™„ë£Œ")
        else:
            # ì±„ë„ ì •ë³´ ì—†ìœ¼ë©´ defaultë¡œ ì €ì¥
            save_youtube_token_to_db(token_data, channel_id='default', channel_info=None, project_suffix=project_suffix)
            print(f"[YOUTUBE-CALLBACK] ì±„ë„ ì •ë³´ ì—†ìŒ, defaultë¡œ í† í° ì €ì¥ (project: {'ê¸°ë³¸' if not project_suffix else project_suffix})")

        print(f"[YOUTUBE-CALLBACK] ì¸ì¦ ì™„ë£Œ, /image í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
        # Image Lab í˜ì´ì§€ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸ (ì¸ì¦ ì™„ë£Œ)
        return redirect('/image?youtube_auth=success')

    except Exception as e:
        print(f"[YOUTUBE-CALLBACK][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return f"""
        <!DOCTYPE html>
        <html>
        <head><title>YouTube ì—°ê²° ì˜¤ë¥˜</title>
        <style>body{{font-family:Arial;padding:50px;text-align:center}}.error{{background:#ffebee;padding:20px;border-radius:8px;margin:20px auto;max-width:500px;color:#c62828}}.back-btn{{margin-top:20px;padding:10px 20px;background:#1a73e8;color:white;border:none;border-radius:4px;cursor:pointer;text-decoration:none;display:inline-block}}</style>
        </head>
        <body>
            <h1>âš ï¸ YouTube ì—°ê²° ì˜¤ë¥˜</h1>
            <div class="error">
                <p>ì¸ì¦ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤.</p>
                <p style="font-size:12px;color:#666;">{str(e)[:200]}</p>
            </div>
            <a href="/image" class="back-btn">â† ë‹¤ì‹œ ì‹œë„</a>
        </body>
        </html>
        """, 500


@app.route('/api/drama/youtube-auth-status')
def youtube_auth_status():
    """YouTube ì¸ì¦ ìƒíƒœ í™•ì¸"""
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í† í° ë¡œë“œ
        token_data = load_youtube_token_from_db()

        if token_data:
            # refresh_tokenì´ ìˆìœ¼ë©´ ì¸ì¦ëœ ê²ƒìœ¼ë¡œ ê°„ì£¼ (ìë™ ê°±ì‹  ê°€ëŠ¥)
            if token_data.get('refresh_token'):
                print(f"[YOUTUBE-AUTH-STATUS] ì¸ì¦ë¨ (refresh_token ì¡´ì¬)")
                return jsonify({"authenticated": True})
            # tokenë§Œ ìˆì–´ë„ ì¼ë‹¨ ì¸ì¦ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
            elif token_data.get('token'):
                print(f"[YOUTUBE-AUTH-STATUS] ì¸ì¦ë¨ (tokenë§Œ ì¡´ì¬, refresh_token ì—†ìŒ)")
                return jsonify({"authenticated": True, "warning": "refresh_token ì—†ìŒ"})

        print(f"[YOUTUBE-AUTH-STATUS] ì¸ì¦ ì•ˆë¨ (í† í° ì—†ìŒ)")
        return jsonify({"authenticated": False})

    except Exception as e:
        print(f"[YOUTUBE-AUTH-STATUS] ì˜¤ë¥˜: {e}")
        return jsonify({"authenticated": False, "error": str(e)})


@app.route('/api/drama/youtube-projects-status')
def youtube_projects_status():
    """
    ë‘ YouTube í”„ë¡œì íŠ¸(ê¸°ë³¸/_2)ì˜ ì¸ì¦ ìƒíƒœ í™•ì¸
    í• ë‹¹ëŸ‰ failover ê¸°ëŠ¥ìš©
    """
    try:
        # ê¸°ë³¸ í”„ë¡œì íŠ¸ í™•ì¸
        default_token = load_youtube_token_from_db('default', '')
        default_has_token = bool(default_token and default_token.get('refresh_token'))

        # _2 í”„ë¡œì íŠ¸ í™•ì¸
        backup_token = load_youtube_token_from_db('default', '_2')
        backup_has_token = bool(backup_token and backup_token.get('refresh_token'))

        # í˜„ì¬ ì‚¬ìš© ì¤‘ì¸ í”„ë¡œì íŠ¸
        _, _, current_suffix = get_youtube_credentials()
        current_project = 'ê¸°ë³¸' if not current_suffix else current_suffix

        # _2 í™˜ê²½ë³€ìˆ˜ ì„¤ì • ì—¬ë¶€
        has_backup_credentials = bool(os.getenv('YOUTUBE_CLIENT_ID_2'))

        return jsonify({
            "ok": True,
            "defaultProject": {
                "authenticated": default_has_token,
                "name": "ê¸°ë³¸"
            },
            "backupProject": {
                "authenticated": backup_has_token,
                "name": "_2",
                "configured": has_backup_credentials
            },
            "currentProject": current_project,
            "quotaExceeded": _youtube_quota_exceeded,
            "bothAuthenticated": default_has_token and backup_has_token,
            "message": "ë‘ í”„ë¡œì íŠ¸ ëª¨ë‘ ì¸ì¦ë¨ - ìë™ failover ê°€ëŠ¥" if (default_has_token and backup_has_token) else
                       "ë°±ì—… í”„ë¡œì íŠ¸ ì¸ì¦ í•„ìš”" if (default_has_token and not backup_has_token and has_backup_credentials) else
                       "ê¸°ë³¸ í”„ë¡œì íŠ¸ ì¸ì¦ í•„ìš”" if not default_has_token else
                       "ë°±ì—… í”„ë¡œì íŠ¸ ë¯¸ì„¤ì • (YOUTUBE_CLIENT_ID_2 í™˜ê²½ë³€ìˆ˜ í•„ìš”)"
        })
    except Exception as e:
        print(f"[YOUTUBE-PROJECTS-STATUS] ì˜¤ë¥˜: {e}")
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/youtube/reset-quota', methods=['GET', 'POST'])
def api_reset_youtube_quota():
    """YouTube í• ë‹¹ëŸ‰ ì´ˆê³¼ í”Œë˜ê·¸ ìˆ˜ë™ ë¦¬ì…‹"""
    global _youtube_quota_exceeded
    reset_youtube_quota_exceeded()
    return jsonify({
        "ok": True,
        "message": "YouTube í• ë‹¹ëŸ‰ ì´ˆê³¼ í”Œë˜ê·¸ê°€ ë¦¬ì…‹ë˜ì—ˆìŠµë‹ˆë‹¤.",
        "quotaExceeded": _youtube_quota_exceeded
    })


@app.route('/api/youtube/tokens-debug')
def api_youtube_tokens_debug():
    """YouTube í† í° ëª©ë¡ ë””ë²„ê·¸ìš© ì¡°íšŒ (user_idë§Œ í‘œì‹œ)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute('SELECT user_id, channel_name, updated_at FROM youtube_tokens ORDER BY updated_at DESC')
        else:
            cursor.execute('SELECT user_id, channel_name, updated_at FROM youtube_tokens ORDER BY updated_at DESC')

        rows = cursor.fetchall()
        conn.close()

        tokens = []
        for row in rows:
            if USE_POSTGRES:
                user_id = row['user_id']
                channel_name = row['channel_name']
                updated_at = str(row['updated_at']) if row['updated_at'] else None
            else:
                user_id, channel_name, updated_at = row

            is_backup = '_2' in (user_id or '')
            tokens.append({
                "user_id": user_id,
                "channel_name": channel_name or "(ì´ë¦„ì—†ìŒ)",
                "updated_at": updated_at,
                "is_backup_project": is_backup
            })

        # _2 í”„ë¡œì íŠ¸ í† í° ê°œìˆ˜
        backup_count = len([t for t in tokens if t['is_backup_project']])

        return jsonify({
            "ok": True,
            "total_count": len(tokens),
            "backup_project_count": backup_count,
            "tokens": tokens
        })
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500

@app.route('/api/drama/youtube-channels')
def youtube_channels():
    """YouTube ì±„ë„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ì €ì¥ëœ ëª¨ë“  ì±„ë„ ë°˜í™˜)"""
    try:
        from google.oauth2.credentials import Credentials
        from google.auth.transport.requests import Request
        from googleapiclient.discovery import build

        # ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ ëª¨ë“  ì±„ë„ ê°€ì ¸ì˜¤ê¸°
        saved_channels = load_all_youtube_channels_from_db()

        # ì €ì¥ëœ ì±„ë„ì´ ìˆìœ¼ë©´ ê° ì±„ë„ì˜ í† í° ìœ íš¨ì„± ê²€ì‚¬
        valid_channels = []
        for ch in saved_channels:
            channel_id = ch['id']
            token_data = load_youtube_token_from_db(channel_id)
            if token_data:
                try:
                    credentials = Credentials.from_authorized_user_info(token_data)
                    # í† í° ê°±ì‹  í•„ìš”ì‹œ
                    if credentials.expired and credentials.refresh_token:
                        credentials.refresh(Request())
                        token_data['token'] = credentials.token
                        save_youtube_token_to_db(token_data, channel_id=channel_id, channel_info={
                            'title': ch['title'],
                            'thumbnail': ch['thumbnail']
                        })
                    valid_channels.append(ch)
                except Exception as token_error:
                    print(f"[YOUTUBE-CHANNELS] ì±„ë„ {channel_id} í† í° ë§Œë£Œ/ë¬´íš¨: {token_error}")
                    # ë§Œë£Œëœ ì±„ë„ë„ ëª©ë¡ì—ëŠ” í‘œì‹œ (ì¬ì¸ì¦ ìœ ë„)
                    ch['expired'] = True
                    valid_channels.append(ch)

        if valid_channels:
            return jsonify({
                "success": True,
                "channels": valid_channels
            })

        # ì €ì¥ëœ ì±„ë„ì´ ì—†ìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ ì‹œë„ (ë ˆê±°ì‹œ í˜¸í™˜)
        token_data = load_youtube_token_from_db()
        if not token_data:
            return jsonify({
                "success": False,
                "error": "YouTube ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤.",
                "channels": []
            })

        credentials = Credentials.from_authorized_user_info(token_data)

        # í† í° ê°±ì‹  í•„ìš”ì‹œ
        if credentials.expired and credentials.refresh_token:
            credentials.refresh(Request())
            token_data['token'] = credentials.token
            save_youtube_token_to_db(token_data)

        # YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
        youtube = build('youtube', 'v3', credentials=credentials)

        # ë‚´ ì±„ë„ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        channels_response = youtube.channels().list(
            part='snippet,contentDetails',
            mine=True
        ).execute()

        channels = []
        for channel in channels_response.get('items', []):
            channels.append({
                'id': channel['id'],
                'title': channel['snippet']['title'],
                'description': channel['snippet']['description'],
                'thumbnail': channel['snippet']['thumbnails'].get('default', {}).get('url', '')
            })

        return jsonify({
            "success": True,
            "channels": channels
        })

    except Exception as e:
        import traceback
        error_detail = traceback.format_exc()
        print(f"[YOUTUBE-CHANNELS][ERROR] {str(e)}")
        print(f"[YOUTUBE-CHANNELS][ERROR] Traceback: {error_detail}")

        # ë” êµ¬ì²´ì ì¸ ì—ëŸ¬ ë©”ì‹œì§€
        if "invalid_grant" in str(e).lower():
            return jsonify({
                "success": False,
                "error": "YouTube ì¸ì¦ì´ ë§Œë£Œë˜ì—ˆìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì¸ì¦í•´ì£¼ì„¸ìš”.",
                "need_reauth": True,
                "channels": []
            })
        elif "credentials" in str(e).lower():
            return jsonify({
                "success": False,
                "error": "YouTube ì¸ì¦ ì •ë³´ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤. ë‹¤ì‹œ ì¸ì¦í•´ì£¼ì„¸ìš”.",
                "need_reauth": True,
                "channels": []
            })
        else:
            return jsonify({
                "success": False,
                "error": f"ì±„ë„ ëª©ë¡ì„ ê°€ì ¸ì˜¤ëŠ” ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {str(e)}",
                "channels": []
            })


@app.route('/api/youtube/channel/<channel_id>', methods=['DELETE'])
def delete_youtube_channel(channel_id):
    """YouTube ì±„ë„ í† í° ì‚­ì œ"""
    try:
        print(f"[YOUTUBE-DELETE] ì±„ë„ ì‚­ì œ ìš”ì²­: {channel_id}")

        deleted = delete_youtube_channel_from_db(channel_id)

        if deleted:
            return jsonify({
                "ok": True,
                "message": f"ì±„ë„ {channel_id} ì‚­ì œë¨"
            })
        else:
            return jsonify({
                "ok": False,
                "error": "ì‚­ì œí•  ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
            }), 404

    except Exception as e:
        print(f"[YOUTUBE-DELETE] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": str(e)
        }), 500


@app.route('/api/drama/upload-youtube', methods=['POST'])
def upload_youtube():
    """YouTubeì— ë¹„ë””ì˜¤ ì—…ë¡œë“œ"""
    try:
        from google.oauth2.credentials import Credentials
        from google.auth.transport.requests import Request
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        data = request.get_json()
        video_data = data.get('video_data')
        title = data.get('title', 'AI ë“œë¼ë§ˆ')
        description = data.get('description', '')
        tags = data.get('tags', [])
        category_id = data.get('category_id', '22')  # 22 = People & Blogs
        privacy_status = data.get('privacy_status') or 'private'  # ë¹ˆ ë¬¸ìì—´ë„ ê¸°ë³¸ê°’ ì²˜ë¦¬
        publish_at = data.get('publish_at')  # ISO 8601 í˜•ì‹ì˜ ì˜ˆì•½ ê³µê°œ ì‹œê°„
        channel_id = data.get('channel_id')  # ì„ íƒëœ ì±„ë„ ID

        if not video_data:
            return jsonify({"success": False, "error": "ë¹„ë””ì˜¤ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤."})

        print(f"[YOUTUBE-UPLOAD] ì„ íƒëœ ì±„ë„ ID: {channel_id or 'default'}")

        # ì„ íƒëœ ì±„ë„ì˜ í† í° ë¡œë“œ (ì—†ìœ¼ë©´ default)
        token_data = load_youtube_token_from_db(channel_id) if channel_id else load_youtube_token_from_db()
        if not token_data:
            return jsonify({"success": False, "error": "YouTube ì¸ì¦ì´ í•„ìš”í•©ë‹ˆë‹¤."})

        credentials = Credentials.from_authorized_user_info(token_data)

        # í† í° ê°±ì‹ 
        if credentials.expired and credentials.refresh_token:
            credentials.refresh(Request())
            # ê°±ì‹ ëœ í† í° ì €ì¥ (ë°ì´í„°ë² ì´ìŠ¤ì—)
            token_data['token'] = credentials.token
            save_youtube_token_to_db(token_data, channel_id=channel_id)

        # ë¹„ë””ì˜¤ íŒŒì¼ ì„ì‹œ ì €ì¥
        with tempfile.TemporaryDirectory() as temp_dir:
            video_path = os.path.join(temp_dir, 'upload_video.mp4')

            # Base64 ë””ì½”ë”©
            video_bytes = base64.b64decode(video_data)
            with open(video_path, 'wb') as f:
                f.write(video_bytes)

            print(f"[YOUTUBE-UPLOAD] ë¹„ë””ì˜¤ íŒŒì¼ ì¤€ë¹„ ì™„ë£Œ: {len(video_bytes)} bytes")

            # YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            youtube = build('youtube', 'v3', credentials=credentials)

            # ë¹„ë””ì˜¤ ë©”íƒ€ë°ì´í„°
            status_data = {
                'privacyStatus': privacy_status,
                'selfDeclaredMadeForKids': False
            }

            # ì˜ˆì•½ ì—…ë¡œë“œ ì„¤ì • (publishAtì´ ìˆìœ¼ë©´ ì˜ˆì•½ ê³µê°œ)
            if publish_at:
                status_data['publishAt'] = publish_at
                # ì˜ˆì•½ ì—…ë¡œë“œ ì‹œ privacyStatusëŠ” ë°˜ë“œì‹œ privateì´ì–´ì•¼ í•¨
                status_data['privacyStatus'] = 'private'
                print(f"[YOUTUBE-UPLOAD] ì˜ˆì•½ ì—…ë¡œë“œ ì„¤ì •: {publish_at}")

            body = {
                'snippet': {
                    'title': title,
                    'description': description,
                    'tags': tags,
                    'categoryId': category_id
                },
                'status': status_data
            }

            # ì—…ë¡œë“œ ì‹¤í–‰
            media = MediaFileUpload(
                video_path,
                mimetype='video/mp4',
                resumable=True,
                chunksize=1024*1024  # 1MB chunks
            )

            insert_request = youtube.videos().insert(
                part='snippet,status',
                body=body,
                media_body=media
            )

            response = None
            while response is None:
                status, response = insert_request.next_chunk()
                if status:
                    print(f"[YOUTUBE-UPLOAD] ì—…ë¡œë“œ ì§„í–‰ë¥ : {int(status.progress() * 100)}%")

            video_id = response['id']
            video_url = f"https://www.youtube.com/watch?v={video_id}"

            if publish_at:
                print(f"[YOUTUBE-UPLOAD] ì˜ˆì•½ ì—…ë¡œë“œ ì™„ë£Œ! Video ID: {video_id}, ê³µê°œ ì˜ˆì •: {publish_at}")
                message = f"YouTube ì˜ˆì•½ ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤! ({publish_at}ì— ê³µê°œ ì˜ˆì •)"
            else:
                print(f"[YOUTUBE-UPLOAD] ì—…ë¡œë“œ ì™„ë£Œ! Video ID: {video_id}")
                message = "YouTube ì—…ë¡œë“œê°€ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!"

            return jsonify({
                "success": True,
                "video_id": video_id,
                "video_url": video_url,
                "publish_at": publish_at,
                "message": message
            })

    except ImportError:
        return jsonify({
            "success": False,
            "error": "Google API ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. pip install google-auth-oauthlib google-api-python-clientë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”."
        })
    except Exception as e:
        print(f"[YOUTUBE-UPLOAD][ERROR] {str(e)}")
        return jsonify({"success": False, "error": str(e)})


# ===== ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ API (ë³„ë„) =====
@app.route('/api/drama/thumbnail-overlay', methods=['POST'])
def api_thumbnail_overlay():
    """ì´ë¯¸ì§€ì— í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´í•˜ì—¬ ì¸ë„¤ì¼ ìƒì„±"""
    try:
        from PIL import Image, ImageDraw, ImageFont
        from io import BytesIO
        import requests as req
        import base64
        import urllib.request
        import os as os_module

        data = request.get_json()
        if not data:
            return jsonify({"ok": False, "error": "No data received"}), 400

        # ì…ë ¥ íŒŒë¼ë¯¸í„°
        image_url = data.get("imageUrl", "")  # base64 data URL ë˜ëŠ” HTTP URL
        text_lines = data.get("textLines", [])  # ["1ì¤„", "2ì¤„", "3ì¤„", "4ì¤„"]
        highlight_lines = data.get("highlightLines", [2])  # ê°•ì¡°í•  ì¤„ ì¸ë±ìŠ¤ (0ë¶€í„° ì‹œì‘)
        text_color = data.get("textColor", "#FFFFFF")  # ê¸°ë³¸ í…ìŠ¤íŠ¸ ìƒ‰ìƒ
        highlight_color = data.get("highlightColor", "#FFD700")  # ê°•ì¡° í…ìŠ¤íŠ¸ ìƒ‰ìƒ (ë…¸ë€ìƒ‰)
        outline_color = data.get("outlineColor", "#000000")  # ì™¸ê³½ì„  ìƒ‰ìƒ
        outline_width = data.get("outlineWidth", 4)  # ì™¸ê³½ì„  ë‘ê»˜
        font_size = data.get("fontSize", 60)  # í°íŠ¸ í¬ê¸°
        position = data.get("position", "left")  # í…ìŠ¤íŠ¸ ìœ„ì¹˜: left, center, right

        # ì¤„ë³„ ìŠ¤íƒ€ì¼ ì§€ì› (ìƒˆ ê¸°ëŠ¥)
        # lineStyles: [{"color": "#FFD700", "fontSize": 80}, {"color": "#FFFFFF", "fontSize": 60}]
        line_styles = data.get("lineStyles", [])  # ì¤„ë³„ ìƒ‰ìƒ/í¬ê¸° ê°œë³„ ì§€ì •

        print(f"[THUMBNAIL] ì¸ë„¤ì¼ ìƒì„± ì‹œì‘ - í…ìŠ¤íŠ¸ {len(text_lines)}ì¤„")

        if not image_url:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ URLì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        if not text_lines:
            return jsonify({"ok": False, "error": "í…ìŠ¤íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # base_dir ë¨¼ì € ì •ì˜ (ë¡œì»¬ ê²½ë¡œ ì²˜ë¦¬ìš©)
        base_dir = os_module.path.dirname(os_module.path.abspath(__file__))

        # ì´ë¯¸ì§€ ë¡œë“œ
        if image_url.startswith("data:"):
            # Base64 data URL
            header, encoded = image_url.split(",", 1)
            image_data = base64.b64decode(encoded)
            img = Image.open(BytesIO(image_data))
        elif image_url.startswith("/static/"):
            # ë¡œì»¬ ìƒëŒ€ ê²½ë¡œ (ì„œë²„ ë‚´ íŒŒì¼)
            local_path = os_module.path.join(base_dir, image_url.lstrip("/"))
            print(f"[THUMBNAIL] ë¡œì»¬ íŒŒì¼ ë¡œë“œ: {local_path}")
            img = Image.open(local_path)
        elif image_url.startswith("http"):
            # HTTP URL
            response = req.get(image_url, timeout=30)
            img = Image.open(BytesIO(response.content))
        else:
            # ê¸°íƒ€ ë¡œì»¬ ê²½ë¡œ
            img = Image.open(image_url)

        # RGBAë¡œ ë³€í™˜ (íˆ¬ëª…ë„ ì§€ì›)
        if img.mode != 'RGBA':
            img = img.convert('RGBA')

        # ì´ë¯¸ì§€ í¬ê¸° (ìœ íŠœë¸Œ ì¸ë„¤ì¼: 1280x720 ê¶Œì¥)
        width, height = img.size
        print(f"[THUMBNAIL] ì´ë¯¸ì§€ í¬ê¸°: {width}x{height}")

        # í°íŠ¸ ì„¤ì •: lang/ko.pyì—ì„œ ê´€ë¦¬
        font = None
        base_dir = os_module.path.dirname(os_module.path.abspath(__file__))
        font_paths = [os_module.path.join(base_dir, "fonts", f) for f in lang_ko.FONTS['priority']]
        font_paths.extend(lang_ko.FONTS['system_paths'])

        for font_path in font_paths:
            if os_module.path.exists(font_path):
                try:
                    font = ImageFont.truetype(font_path, font_size)
                    print(f"[THUMBNAIL] í°íŠ¸ ë¡œë“œ: {font_path}")
                    break
                except Exception:
                    continue

        if font is None:
            # ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ ì§€ì› ì•ˆ ë  ìˆ˜ ìˆìŒ)
            font = ImageFont.load_default()
            print(f"[THUMBNAIL] ê¸°ë³¸ í°íŠ¸ ì‚¬ìš© (í•œê¸€ ë¯¸ì§€ì› ê°€ëŠ¥)")

        # ë“œë¡œì‰ ê°ì²´ ìƒì„±
        draw = ImageDraw.Draw(img)

        # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚°
        line_height = font_size + 20  # ì¤„ ê°„ê²©
        total_text_height = len(text_lines) * line_height

        # Y ì‹œì‘ ìœ„ì¹˜ (ìƒë‹¨ ì—¬ë°± ê³ ë ¤)
        y_start = int(height * 0.1)  # ìƒë‹¨ 10%ë¶€í„° ì‹œì‘

        # X ìœ„ì¹˜
        x_margin = int(width * 0.05)  # ì¢Œìš° ì—¬ë°± 5%

        # ì¤„ë³„ í°íŠ¸ ìºì‹œ (ì„œë¡œ ë‹¤ë¥¸ í¬ê¸° ì§€ì›)
        font_cache = {font_size: font}

        def get_font_for_size(size):
            """ì£¼ì–´ì§„ í¬ê¸°ì˜ í°íŠ¸ ë°˜í™˜ (ìºì‹±)"""
            if size in font_cache:
                return font_cache[size]
            # ìƒˆ í¬ê¸° í°íŠ¸ ë¡œë“œ
            for font_path in font_paths:
                if os_module.path.exists(font_path):
                    try:
                        new_font = ImageFont.truetype(font_path, size)
                        font_cache[size] = new_font
                        return new_font
                    except Exception:
                        continue
            return font  # ê¸°ë³¸ í°íŠ¸ ë°˜í™˜

        y_current = y_start
        for i, line in enumerate(text_lines):
            # ì¤„ë³„ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
            line_style = line_styles[i] if i < len(line_styles) else {}
            line_font_size = line_style.get("fontSize", font_size)
            line_color = line_style.get("color", None)

            # ì´ ì¤„ì˜ í°íŠ¸ ê°€ì ¸ì˜¤ê¸°
            current_font = get_font_for_size(line_font_size)
            current_line_height = line_font_size + 20

            # í…ìŠ¤íŠ¸ í¬ê¸° ì¸¡ì •
            bbox = draw.textbbox((0, 0), line, font=current_font)
            text_width = bbox[2] - bbox[0]

            # X ìœ„ì¹˜ ê²°ì •
            if position == "center":
                x = (width - text_width) // 2
            elif position == "right":
                x = width - text_width - x_margin
            else:  # left
                x = x_margin

            # ìƒ‰ìƒ ê²°ì • (ìš°ì„ ìˆœìœ„: lineStyles > highlightLines > textColor)
            if line_color:
                fill_color = line_color
            elif i in highlight_lines:
                fill_color = highlight_color
            else:
                fill_color = text_color

            # ì™¸ê³½ì„  ê·¸ë¦¬ê¸° (8ë°©í–¥)
            for dx in range(-outline_width, outline_width + 1):
                for dy in range(-outline_width, outline_width + 1):
                    if dx != 0 or dy != 0:
                        draw.text((x + dx, y_current + dy), line, font=current_font, fill=outline_color)

            # ë©”ì¸ í…ìŠ¤íŠ¸ ê·¸ë¦¬ê¸°
            draw.text((x, y_current), line, font=current_font, fill=fill_color)

            # ë‹¤ìŒ ì¤„ Y ìœ„ì¹˜
            y_current += current_line_height

        # ê²°ê³¼ ì´ë¯¸ì§€ë¥¼ base64ë¡œ ì¸ì½”ë”©
        output_buffer = BytesIO()
        img_rgb = img.convert('RGB')  # JPEGëŠ” RGB í•„ìš”
        img_rgb.save(output_buffer, format='JPEG', quality=95)
        output_buffer.seek(0)
        result_base64 = base64.b64encode(output_buffer.read()).decode('utf-8')
        result_url = f"data:image/jpeg;base64,{result_base64}"

        print(f"[THUMBNAIL] ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ")

        return jsonify({
            "ok": True,
            "imageUrl": result_url,  # í´ë¼ì´ì–¸íŠ¸ í˜¸í™˜ì„±ì„ ìœ„í•´ imageUrl ì‚¬ìš©
            "thumbnailUrl": result_url,  # ë ˆê±°ì‹œ í˜¸í™˜
            "width": width,
            "height": height
        })

    except Exception as e:
        print(f"[THUMBNAIL][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200


# ===== ì¹´í…Œê³ ë¦¬ë³„ ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ ì¡°íšŒ API =====
@app.route('/api/drama/benchmarks', methods=['GET'])
def api_get_benchmarks():
    """ì¹´í…Œê³ ë¦¬ë³„ ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ ëª©ë¡ ì¡°íšŒ"""
    try:
        video_category = request.args.get('videoCategory', '')
        limit = int(request.args.get('limit', 20))
        offset = int(request.args.get('offset', 0))

        conn = get_db_connection()
        cursor = conn.cursor()

        if video_category:
            if USE_POSTGRES:
                cursor.execute('''
                    SELECT id, script_text, upload_date, view_count, category, video_category,
                           analysis_result, created_at
                    FROM benchmark_analyses
                    WHERE video_category = %s
                    ORDER BY view_count DESC, created_at DESC
                    LIMIT %s OFFSET %s
                ''', (video_category, limit, offset))
            else:
                cursor.execute('''
                    SELECT id, script_text, upload_date, view_count, category, video_category,
                           analysis_result, created_at
                    FROM benchmark_analyses
                    WHERE video_category = ?
                    ORDER BY view_count DESC, created_at DESC
                    LIMIT ? OFFSET ?
                ''', (video_category, limit, offset))
        else:
            if USE_POSTGRES:
                cursor.execute('''
                    SELECT id, script_text, upload_date, view_count, category, video_category,
                           analysis_result, created_at
                    FROM benchmark_analyses
                    ORDER BY view_count DESC, created_at DESC
                    LIMIT %s OFFSET %s
                ''', (limit, offset))
            else:
                cursor.execute('''
                    SELECT id, script_text, upload_date, view_count, category, video_category,
                           analysis_result, created_at
                    FROM benchmark_analyses
                    ORDER BY view_count DESC, created_at DESC
                    LIMIT ? OFFSET ?
                ''', (limit, offset))

        rows = cursor.fetchall()

        # ì¹´í…Œê³ ë¦¬ë³„ ê°œìˆ˜ ì¡°íšŒ
        if USE_POSTGRES:
            cursor.execute('''
                SELECT video_category, COUNT(*) as cnt
                FROM benchmark_analyses
                GROUP BY video_category
            ''')
        else:
            cursor.execute('''
                SELECT video_category, COUNT(*) as cnt
                FROM benchmark_analyses
                GROUP BY video_category
            ''')
        category_counts = {row[0] or 'ë¯¸ë¶„ë¥˜': row[1] for row in cursor.fetchall()}

        conn.close()

        benchmarks = []
        for row in rows:
            benchmarks.append({
                'id': row[0],
                'scriptPreview': row[1][:200] + '...' if len(row[1]) > 200 else row[1],
                'uploadDate': row[2],
                'viewCount': row[3],
                'category': row[4],
                'videoCategory': row[5] or 'ë¯¸ë¶„ë¥˜',
                'analysisPreview': row[6][:300] + '...' if row[6] and len(row[6]) > 300 else row[6],
                'createdAt': str(row[7]) if row[7] else ''
            })

        return jsonify({
            'ok': True,
            'benchmarks': benchmarks,
            'categoryCounts': category_counts,
            'total': sum(category_counts.values())
        })

    except Exception as e:
        print(f"[BENCHMARKS][ERROR] {str(e)}")
        return jsonify({'ok': False, 'error': str(e)}), 200


@app.route('/api/drama/benchmark/<int:benchmark_id>', methods=['GET'])
def api_get_benchmark_detail(benchmark_id):
    """ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ ìƒì„¸ ì¡°íšŒ"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute('SELECT * FROM benchmark_analyses WHERE id = %s', (benchmark_id,))
        else:
            cursor.execute('SELECT * FROM benchmark_analyses WHERE id = ?', (benchmark_id,))

        row = cursor.fetchone()
        conn.close()

        if not row:
            return jsonify({'ok': False, 'error': 'ë²¤ì¹˜ë§ˆí‚¹ ëŒ€ë³¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'}), 404

        return jsonify({
            'ok': True,
            'benchmark': {
                'id': row[0],
                'scriptText': row[1],
                'uploadDate': row[3],
                'viewCount': row[4],
                'category': row[5],
                'videoCategory': row[6] if len(row) > 6 else 'ë¯¸ë¶„ë¥˜',
                'analysisResult': row[7] if len(row) > 7 else row[6],
                'storyStructure': row[8] if len(row) > 8 else '',
                'characterElements': row[9] if len(row) > 9 else '',
                'dialogueStyle': row[10] if len(row) > 10 else '',
                'successFactors': row[11] if len(row) > 11 else ''
            }
        })

    except Exception as e:
        print(f"[BENCHMARK-DETAIL][ERROR] {str(e)}")
        return jsonify({'ok': False, 'error': str(e)}), 200


# ===== í•œêµ­ì–´ â†’ ì¤‘êµ­ì–´ ë²ˆì—­ API =====
@app.route('/api/translate/ko-to-zh', methods=['POST'])
def api_translate_ko_to_zh():
    """í•œêµ­ì–´ë¥¼ ì¤‘êµ­ì–´(ê°„ì²´)ë¡œ ë²ˆì—­

    ìƒ¤ì˜¤í™ìˆ˜ ê²€ìƒ‰ì„ ìœ„í•œ ë²ˆì—­ API
    """
    try:
        data = request.get_json()
        text = data.get('text', '').strip()

        if not text:
            return jsonify({'ok': False, 'error': 'ë²ˆì—­í•  í…ìŠ¤íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤.'}), 400

        print(f"[TRANSLATE] í•œêµ­ì–´ â†’ ì¤‘êµ­ì–´: {text}")

        from openai import OpenAI
        client = OpenAI()

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {
                    "role": "system",
                    "content": "ä½ æ˜¯ä¸€ä¸ªç¿»è¯‘ä¸“å®¶ã€‚å°†éŸ©è¯­ç¿»è¯‘æˆç®€ä½“ä¸­æ–‡ã€‚åªè¾“å‡ºç¿»è¯‘ç»“æœï¼Œä¸è¦è§£é‡Šã€‚å¦‚æœæ˜¯äº§å“åç§°ï¼Œç¿»è¯‘æˆä¸­å›½æ¶ˆè´¹è€…å¸¸ç”¨çš„æœç´¢è¯ã€‚"
                },
                {
                    "role": "user",
                    "content": f"ç¿»è¯‘: {text}"
                }
            ],
            temperature=0.3,
            max_tokens=100
        )

        translated = response.choices[0].message.content.strip()
        print(f"[TRANSLATE] ë²ˆì—­ ê²°ê³¼: {translated}")

        return jsonify({
            'ok': True,
            'original': text,
            'translated': translated
        })

    except Exception as e:
        print(f"[TRANSLATE][ERROR] {str(e)}")
        return jsonify({'ok': False, 'error': str(e)}), 500


# ===== ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ ìƒí’ˆ ëŒ€ë³¸ ìƒì„± API =====
@app.route('/api/drama/generate-coupang-script', methods=['POST'])
def api_generate_coupang_script():
    """ìƒí’ˆ ì •ë³´ë¡œ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ ì‡¼ì¸  ëŒ€ë³¸ ìƒì„±

    Input:
    {
        "productName": "ìƒ¤ì˜¤ë¯¸ ë¬´ì„  ì²­ì†Œê¸° V12",
        "productPrice": "89,000ì›",
        "productFeatures": ["ê°•ë ¥í•œ í¡ì…ë ¥", "ê¸´ ë°°í„°ë¦¬"]
    }

    Output:
    {
        "ok": true,
        "script": "ìƒì„±ëœ ëŒ€ë³¸..."
    }
    """
    try:
        data = request.get_json()
        product_name = data.get('productName', '').strip()
        product_price = data.get('productPrice', '')
        product_features = data.get('productFeatures', [])

        if not product_name:
            return jsonify({'ok': False, 'error': 'ìƒí’ˆëª…ì´ ë¹„ì–´ìˆìŠµë‹ˆë‹¤.'}), 400

        print(f"[COUPANG-SCRIPT] ëŒ€ë³¸ ìƒì„± ì‹œì‘ - ìƒí’ˆ: {product_name}")

        # OpenAI APIë¡œ ëŒ€ë³¸ ìƒì„±
        from openai import OpenAI
        client = OpenAI()

        system_prompt = """ë‹¹ì‹ ì€ ì¿ íŒ¡íŒŒíŠ¸ë„ˆìŠ¤ ì œíœ´ ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤.
ìƒí’ˆ ì •ë³´ë¥¼ ë°›ì•„ 60ì´ˆ ì´í•˜ì˜ ì„¸ë¡œí˜• ì‡¼ì¸  ëŒ€ë³¸ì„ ì‘ì„±í•©ë‹ˆë‹¤.

## ëŒ€ë³¸ ì‘ì„± ê·œì¹™
1. **ì²« 3ì´ˆ í›…**: ê°€ê²©/íš¨ê³¼/ë†€ëŒìœ¼ë¡œ ì‹œì‘ ("ì´ê²Œ ë§Œì›ëŒ€?", "ì¨ë³´ê³  ë†€ëìŠµë‹ˆë‹¤")
2. **ë³¸ë¬¸ (40ì´ˆ)**: í•µì‹¬ ì¥ì  1-2ê°œë§Œ ê°„ê²°í•˜ê²Œ ì„¤ëª…
3. **CTA (ë§ˆì§€ë§‰)**: "ë§í¬ëŠ” í”„ë¡œí•„ì— ìˆì–´ìš”" ë˜ëŠ” "ì¿ íŒ¡ì—ì„œ [ìƒí’ˆëª…] ê²€ìƒ‰í•˜ì„¸ìš”"

## ëŒ€ë³¸ í˜•ì‹
- ë‚˜ë ˆì´ì…˜ í˜•ì‹ìœ¼ë¡œ ì‘ì„± (1ì¸ì¹­ ì‹œì )
- ì´ 150ì ì´ë‚´
- ì§§ì€ ë¬¸ì¥, ì„íŒ©íŠ¸ ìˆê²Œ
- ìƒí’ˆëª… ì–¸ê¸‰ í•„ìˆ˜

## ì˜ˆì‹œ ëŒ€ë³¸
"ì´ê²Œ 8ë§Œì›ëŒ€ë¼ê³ ìš”?
ìƒ¤ì˜¤ë¯¸ ë¬´ì„  ì²­ì†Œê¸° ì¨ë´¤ëŠ”ë°, ì§„ì§œ ë†€ëìŠµë‹ˆë‹¤.
í¡ì…ë ¥? ìœ ì„  ëª»ì§€ì•Šì•„ìš”.
ë°°í„°ë¦¬? 40ë¶„ ë„˜ê²Œ ê°€ë”ë¼ê³ ìš”.
ë§í¬ëŠ” í”„ë¡œí•„ì— ìˆì–´ìš”."
"""

        features_text = ', '.join(product_features) if product_features else 'ë¯¸ì…ë ¥'
        user_prompt = f"""ë‹¤ìŒ ìƒí’ˆì˜ 60ì´ˆ ì‡¼ì¸  ëŒ€ë³¸ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:

ìƒí’ˆëª…: {product_name}
ê°€ê²©: {product_price if product_price else 'ë¯¸ì…ë ¥'}
í•µì‹¬ ì¥ì : {features_text}

ëŒ€ë³¸ë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš” (ì„¤ëª… ì—†ì´)."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.7,
            max_tokens=500
        )

        script = response.choices[0].message.content.strip()
        print(f"[COUPANG-SCRIPT] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ - ê¸¸ì´: {len(script)}ì")

        return jsonify({
            'ok': True,
            'script': script,
            'productName': product_name
        })

    except Exception as e:
        print(f"[COUPANG-SCRIPT][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({'ok': False, 'error': str(e)}), 500


# ===== Step5: YouTube API =====

@app.route('/api/youtube/auth-status', methods=['GET'])
def api_youtube_auth_status_test():
    """
    YouTube ì¸ì¦ ìƒíƒœ í™•ì¸.
    ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥ëœ OAuth í† í°ì„ í™•ì¸í•©ë‹ˆë‹¤.
    """
    try:
        # ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ í† í° ë¡œë“œ
        token_data = load_youtube_token_from_db()

        if not token_data or not token_data.get('refresh_token'):
            print("[YOUTUBE-AUTH-STATUS] í† í° ì—†ìŒ - ì¸ì¦ í•„ìš”")
            return jsonify({
                "ok": True,
                "authenticated": False,
                "connected": False,
                "mode": "setup",
                "channelName": None,
                "channelId": None,
                "message": "YouTube ê³„ì •ì„ ì—°ê²°í•´ì£¼ì„¸ìš”."
            })

        # í† í° ìœ íš¨ì„± ê²€ì‚¬ ë° ì±„ë„ ì •ë³´ ì¡°íšŒ
        try:
            from google.oauth2.credentials import Credentials
            from google.auth.transport.requests import Request
            from googleapiclient.discovery import build

            creds = Credentials.from_authorized_user_info(token_data)

            # í† í° ë§Œë£Œ ì‹œ ê°±ì‹ 
            if creds.expired and creds.refresh_token:
                creds.refresh(Request())
                # ê°±ì‹ ëœ í† í° ì €ì¥
                updated_token = {
                    'token': creds.token,
                    'refresh_token': creds.refresh_token,
                    'token_uri': creds.token_uri,
                    'client_id': creds.client_id,
                    'client_secret': creds.client_secret,
                    'scopes': list(creds.scopes) if creds.scopes else []
                }
                save_youtube_token_to_db(updated_token)
                print("[YOUTUBE-AUTH-STATUS] í† í° ê°±ì‹  ì™„ë£Œ")

            # YouTube APIë¡œ ì±„ë„ ì •ë³´ ì¡°íšŒ
            youtube = build('youtube', 'v3', credentials=creds)
            channel_response = youtube.channels().list(part="snippet", mine=True).execute()

            items = channel_response.get("items", [])
            if items:
                channel = items[0]
                channel_name = channel.get("snippet", {}).get("title", "ì±„ë„")
                channel_id = channel.get("id")

                print(f"[YOUTUBE-AUTH-STATUS] ì—°ê²°ë¨: {channel_name}")
                return jsonify({
                    "ok": True,
                    "authenticated": True,
                    "connected": True,
                    "mode": "live",
                    "channelName": channel_name,
                    "channelId": channel_id,
                    "message": "YouTube ì—°ê²°ë¨"
                })
            else:
                print("[YOUTUBE-AUTH-STATUS] ì±„ë„ ì—†ìŒ")
                return jsonify({
                    "ok": True,
                    "authenticated": True,
                    "connected": False,
                    "mode": "live",
                    "channelName": None,
                    "channelId": None,
                    "message": "ì—°ê²°ëœ ì±„ë„ì´ ì—†ìŠµë‹ˆë‹¤."
                })

        except Exception as api_error:
            print(f"[YOUTUBE-AUTH-STATUS] API ì˜¤ë¥˜: {api_error}")
            # í† í°ì€ ìˆì§€ë§Œ API í˜¸ì¶œ ì‹¤íŒ¨ - ì¼ì‹œì  ì˜¤ë¥˜ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ì¸ì¦ ìƒíƒœëŠ” ìœ ì§€
            # refresh_tokenì´ ìˆìœ¼ë©´ ë‚˜ì¤‘ì— ê°±ì‹  ê°€ëŠ¥í•˜ë¯€ë¡œ authenticated: True ìœ ì§€
            return jsonify({
                "ok": True,
                "authenticated": True,  # í† í°ì´ ìˆìœ¼ë©´ ì¸ì¦ëœ ê²ƒìœ¼ë¡œ ì²˜ë¦¬
                "connected": True,
                "mode": "live",
                "channelName": "YouTube ì±„ë„",  # ì„ì‹œ ì´ë¦„ (API í˜¸ì¶œ ì‹¤íŒ¨ë¡œ ì¡°íšŒ ë¶ˆê°€)
                "channelId": None,
                "message": f"ì—°ê²°ë¨ (ì±„ë„ ì •ë³´ ì¡°íšŒ ì¤‘ ì˜¤ë¥˜: {str(api_error)[:50]})"
            })

    except Exception as e:
        print(f"[YOUTUBE-AUTH-STATUS] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": True,
            "authenticated": False,
            "connected": False,
            "mode": "test",
            "channelName": None,
            "channelId": None,
            "message": f"ì¸ì¦ í™•ì¸ ì˜¤ë¥˜: {str(e)}"
        })


@app.route('/api/openrouter/credits', methods=['GET'])
def api_openrouter_credits():
    """
    OpenRouter í¬ë ˆë”§ ì”ì•¡ ì¡°íšŒ
    """
    try:
        import requests as req

        openrouter_api_key = os.getenv("OPENROUTER_API_KEY", "")
        if not openrouter_api_key:
            return jsonify({
                "ok": False,
                "error": "OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
            })

        # OpenRouter APIë¡œ í¬ë ˆë”§ ì¡°íšŒ
        response = req.get(
            "https://openrouter.ai/api/v1/auth/key",
            headers={
                "Authorization": f"Bearer {openrouter_api_key}"
            },
            timeout=10
        )

        if response.status_code == 200:
            data = response.json()
            # data.data.limit (ì´ í¬ë ˆë”§), data.data.usage (ì‚¬ìš©ëŸ‰)
            credit_data = data.get("data", {})
            limit = credit_data.get("limit", 0)  # ì´ í¬ë ˆë”§
            usage = credit_data.get("usage", 0)  # ì‚¬ìš©ëŸ‰
            balance = limit - usage  # ì”ì•¡

            return jsonify({
                "ok": True,
                "balance": round(balance, 2),
                "limit": round(limit, 2),
                "usage": round(usage, 2),
                "formatted": f"${balance:.2f}"
            })
        else:
            return jsonify({
                "ok": False,
                "error": f"OpenRouter API ì˜¤ë¥˜: {response.status_code}"
            })

    except Exception as e:
        print(f"[OPENROUTER-CREDITS] ì˜¤ë¥˜: {e}")
        return jsonify({
            "ok": False,
            "error": str(e)
        })


@app.route('/api/youtube/auth', methods=['GET'])
def api_youtube_auth_page():
    """
    YouTube OAuth ì¸ì¦ ì‹œì‘ (GET ë°©ì‹).
    Google OAuth URLë¡œ ì§ì ‘ ë¦¬ë‹¤ì´ë ‰íŠ¸í•©ë‹ˆë‹¤.
    """
    try:
        from google_auth_oauthlib.flow import Flow
        from google.oauth2.credentials import Credentials

        # í™˜ê²½ ë³€ìˆ˜ì—ì„œ OAuth í´ë¼ì´ì–¸íŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ ìë™ìœ¼ë¡œ _2 í”„ë¡œì íŠ¸ë¡œ ì „í™˜
        client_id, client_secret, project_suffix = get_youtube_credentials()
        print(f"[YOUTUBE-AUTH-GET] ì‚¬ìš© í”„ë¡œì íŠ¸: {'ê¸°ë³¸' if not project_suffix else project_suffix}")

        # Redirect URI ì„¤ì • - ê¸°ì¡´ ì½œë°± ì—”ë“œí¬ì¸íŠ¸ ì‚¬ìš©
        redirect_uri = os.getenv('YOUTUBE_REDIRECT_URI')
        if not redirect_uri:
            redirect_uri = request.url_root.rstrip('/') + '/api/drama/youtube-callback'
            if redirect_uri.startswith('http://') and 'onrender.com' in redirect_uri:
                redirect_uri = redirect_uri.replace('http://', 'https://')

        print(f"[YOUTUBE-AUTH-GET] Redirect URI: {redirect_uri}")
        print(f"[YOUTUBE-AUTH-GET] Client ID: {client_id[:20] if client_id else 'None'}...")

        if not client_id or not client_secret:
            return """
            <!DOCTYPE html>
            <html>
            <head><title>YouTube ì—°ê²°</title>
            <style>body{font-family:Arial;padding:50px;text-align:center}.error{background:#ffebee;padding:20px;border-radius:8px;margin:20px auto;max-width:500px;color:#c62828}.back-btn{margin-top:20px;padding:10px 20px;background:#1a73e8;color:white;border:none;border-radius:4px;cursor:pointer;text-decoration:none;display:inline-block}</style>
            </head>
            <body>
                <h1>âš ï¸ YouTube ì—°ê²° ì˜¤ë¥˜</h1>
                <div class="error">
                    <p>YouTube API ì¸ì¦ ì •ë³´ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.</p>
                    <p>Render í™˜ê²½ ë³€ìˆ˜ì— <code>GOOGLE_CLIENT_ID</code>ì™€ <code>GOOGLE_CLIENT_SECRET</code>ì„ ì„¤ì •í•´ì£¼ì„¸ìš”.</p>
                </div>
                <a href="/image" class="back-btn">â† Image Labìœ¼ë¡œ ëŒì•„ê°€ê¸°</a>
            </body>
            </html>
            """

        # force íŒŒë¼ë¯¸í„° í™•ì¸ (ë‹¤ë¥¸ ê³„ì • ì—°ê²° ì‹œ ì‚¬ìš©)
        force_new_auth = request.args.get('force', '0') == '1'
        # account_id íŒŒë¼ë¯¸í„° (ì´ë©”ì¼ ë˜ëŠ” ì‹ë³„ì)
        account_id = request.args.get('account_id', '').strip()
        # project íŒŒë¼ë¯¸í„° (_2 í”„ë¡œì íŠ¸ ìˆ˜ë™ ì„ íƒ)
        manual_project = request.args.get('project', '').strip()
        if manual_project == '_2':
            # _2 í”„ë¡œì íŠ¸ë¡œ ê°•ì œ ì „í™˜
            client_id = os.getenv('YOUTUBE_CLIENT_ID_2') or os.getenv('GOOGLE_CLIENT_ID_2')
            client_secret = os.getenv('YOUTUBE_CLIENT_SECRET_2') or os.getenv('GOOGLE_CLIENT_SECRET_2')
            project_suffix = '_2'
            print(f"[YOUTUBE-AUTH-GET] project=_2 ìˆ˜ë™ ì„ íƒ - _2 í”„ë¡œì íŠ¸ë¡œ ì¸ì¦")

        if force_new_auth:
            print("[YOUTUBE-AUTH-GET] force=1 - ìƒˆ ê³„ì • ì¸ì¦ ê°•ì œ ì§„í–‰")
        if account_id:
            print(f"[YOUTUBE-AUTH-GET] account_id: {account_id}")

        # ì´ë¯¸ ì¸ì¦ëœ í† í° í™•ì¸ (refresh_tokenì´ ìˆìœ¼ë©´ ì¬ì¸ì¦ ë¶ˆí•„ìš”)
        # force=1ì´ë©´ ê¸°ì¡´ í† í° ë¬´ì‹œí•˜ê³  ìƒˆ ì¸ì¦ ì§„í–‰
        token_data = load_youtube_token_from_db() if not force_new_auth else None
        if token_data and token_data.get('refresh_token'):
            try:
                from google.auth.transport.requests import Request
                credentials = Credentials.from_authorized_user_info(token_data)

                # refresh_tokenì´ ìˆìœ¼ë©´ í•­ìƒ ê°±ì‹  ê°€ëŠ¥ - ë°”ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸
                if credentials.refresh_token:
                    # ë§Œë£Œëœ ê²½ìš° ê°±ì‹  ì‹œë„
                    if credentials.expired:
                        try:
                            credentials.refresh(Request())
                            # ê°±ì‹ ëœ í† í° ì €ì¥
                            updated_token = {
                                'token': credentials.token,
                                'refresh_token': credentials.refresh_token,
                                'token_uri': credentials.token_uri,
                                'client_id': credentials.client_id,
                                'client_secret': credentials.client_secret,
                                'scopes': list(credentials.scopes) if credentials.scopes else []
                            }
                            save_youtube_token_to_db(updated_token)
                            print("[YOUTUBE-AUTH-GET] í† í° ê°±ì‹  ì™„ë£Œ")
                        except Exception as refresh_err:
                            print(f"[YOUTUBE-AUTH-GET] í† í° ê°±ì‹  ì‹¤íŒ¨ (ì¬ì¸ì¦ í•„ìš”): {refresh_err}")
                            # ê°±ì‹  ì‹¤íŒ¨ ì‹œ ì¬ì¸ì¦ í•„ìš” - ì•„ë˜ OAuth í”Œë¡œìš°ë¡œ ì§„í–‰
                            token_data = None

                    if token_data:  # ê°±ì‹  ì„±ê³µ ë˜ëŠ” ì•„ì§ ìœ íš¨í•œ ê²½ìš°
                        print("[YOUTUBE-AUTH-GET] ê¸°ì¡´ í† í° ìœ íš¨ - ë°”ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
                        return redirect('/image?youtube_auth=success')
            except Exception as e:
                print(f"[YOUTUBE-AUTH-GET] ê¸°ì¡´ í† í° ê²€ì¦ ì‹¤íŒ¨ (ì¬ì¸ì¦ ì§„í–‰): {e}")

        # OAuth í”Œë¡œìš° ìƒì„±
        client_config = {
            "web": {
                "client_id": client_id,
                "client_secret": client_secret,
                "auth_uri": "https://accounts.google.com/o/oauth2/auth",
                "token_uri": "https://oauth2.googleapis.com/token",
                "redirect_uris": [redirect_uri]
            }
        }

        flow = Flow.from_client_config(
            client_config,
            scopes=[
                'https://www.googleapis.com/auth/youtube.upload',
                'https://www.googleapis.com/auth/youtube.readonly',
                'https://www.googleapis.com/auth/youtube.force-ssl',  # ëŒ“ê¸€ ì‘ì„±ìš©
                'https://www.googleapis.com/auth/yt-analytics.readonly'  # CTR/ì¡°íšŒìˆ˜ Analytics
            ],
            redirect_uri=redirect_uri
        )

        # force=1ì´ë©´ ê³„ì • ì„ íƒ í™”ë©´ í‘œì‹œ, ì•„ë‹ˆë©´ ë™ì˜ í™”ë©´ë§Œ
        oauth_prompt = 'select_account consent' if force_new_auth else 'consent'

        auth_url, state = flow.authorization_url(
            access_type='offline',
            include_granted_scopes='true',
            prompt=oauth_prompt  # select_account: ê³„ì • ì„ íƒ, consent: ë™ì˜ í™”ë©´ (refresh_token í™•ë³´)
        )

        # ìƒíƒœ ì €ì¥ (account_id, project_suffix í¬í•¨)
        save_oauth_state({
            'state': state,
            'redirect_uri': redirect_uri,
            'client_id': client_id,
            'client_secret': client_secret,
            'account_id': account_id,  # ì´ë©”ì¼ ë˜ëŠ” ì‹ë³„ì
            'project_suffix': project_suffix  # _2 í”„ë¡œì íŠ¸ êµ¬ë¶„
        })

        print(f"[YOUTUBE-AUTH-GET] Google OAuth URLë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸")
        print(f"[YOUTUBE-AUTH-GET] Auth URL: {auth_url[:100]}...")
        print(f"[YOUTUBE-AUTH-GET] State: {state}")
        return redirect(auth_url)

    except ImportError as e:
        print(f"[YOUTUBE-AUTH-GET] Import ì˜¤ë¥˜: {e}")
        return f"""
        <!DOCTYPE html>
        <html>
        <head><title>YouTube ì—°ê²°</title>
        <style>body{{font-family:Arial;padding:50px;text-align:center}}.error{{background:#ffebee;padding:20px;border-radius:8px;margin:20px auto;max-width:500px}}</style>
        </head>
        <body>
            <h1>âš ï¸ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì˜¤ë¥˜</h1>
            <div class="error"><p>Google ì¸ì¦ ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.</p><p>{str(e)}</p></div>
            <a href="/image">â† Image Labìœ¼ë¡œ ëŒì•„ê°€ê¸°</a>
        </body>
        </html>
        """
    except Exception as e:
        print(f"[YOUTUBE-AUTH-GET] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return f"""
        <!DOCTYPE html>
        <html>
        <head><title>YouTube ì—°ê²°</title>
        <style>body{{font-family:Arial;padding:50px;text-align:center}}.error{{background:#ffebee;padding:20px;border-radius:8px;margin:20px auto;max-width:500px}}</style>
        </head>
        <body>
            <h1>âš ï¸ ì—°ê²° ì˜¤ë¥˜</h1>
            <div class="error"><p>{str(e)}</p></div>
            <a href="/image">â† Image Labìœ¼ë¡œ ëŒì•„ê°€ê¸°</a>
        </body>
        </html>
        """


@app.route('/api/youtube/upload', methods=['POST'])
def youtube_upload():
    """
    YouTube ì—…ë¡œë“œ API.
    OAuthê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ ì‹¤ì œ ì—…ë¡œë“œ, ì•„ë‹ˆë©´ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ë™ì‘
    """
    try:
        data = request.get_json() or {}

        video_path = data.get('videoPath', '')
        title = data.get('title', 'ì œëª© ì—†ìŒ')
        description = data.get('description', '')
        tags = data.get('tags', [])
        category_id = data.get('categoryId', '22')  # People & Blogs
        privacy_status = data.get('privacyStatus') or 'private'  # ë¹ˆ ë¬¸ìì—´ë„ ê¸°ë³¸ê°’ ì²˜ë¦¬
        thumbnail_path = data.get('thumbnailPath')
        publish_at = data.get('publish_at')  # ISO 8601 ì˜ˆì•½ ê³µê°œ ì‹œê°„
        channel_id = data.get('channelId')  # ì„ íƒëœ ì±„ë„ ID
        playlist_id = data.get('playlistId')  # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID (ì„ íƒ)
        project_suffix_param = data.get('projectSuffix', None)  # íŒŒì´í”„ë¼ì¸ì—ì„œ ì „ë‹¬ëœ í”„ë¡œì íŠ¸ ì ‘ë¯¸ì‚¬

        print(f"[YOUTUBE-UPLOAD] ì—…ë¡œë“œ ìš”ì²­ ìˆ˜ì‹ ")
        print(f"  - ì˜ìƒ: {video_path}")
        print(f"  - ì œëª©: {title}")
        print(f"  - ê³µê°œ ì„¤ì •: {privacy_status}")
        print(f"  - ì˜ˆì•½ ì‹œê°„: {publish_at}")
        print(f"  - ì±„ë„ ID: {channel_id}")
        print(f"  - í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID: {playlist_id}")
        print(f"  - ì¸ë„¤ì¼: {thumbnail_path}")
        print(f"  - í”„ë¡œì íŠ¸: {project_suffix_param or '(ìë™ ì„ íƒ)'}")

        # ì˜ìƒ íŒŒì¼ ê²½ë¡œ ì²˜ë¦¬
        if video_path and not video_path.startswith('http'):
            # ì ˆëŒ€ ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©, ìƒëŒ€ ê²½ë¡œë©´ í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê¸°ì¤€ìœ¼ë¡œ ë³€í™˜
            if os.path.isabs(video_path) and os.path.exists(video_path):
                full_path = video_path
            else:
                full_path = os.path.join(os.path.dirname(__file__), video_path.lstrip('/'))

            if not os.path.exists(full_path):
                print(f"[YOUTUBE-UPLOAD][WARN] ì˜ìƒ íŒŒì¼ ì—†ìŒ: {full_path}")
                return jsonify({
                    "ok": False,
                    "error": f"ì˜ìƒ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {video_path}"
                }), 200

            # ì˜ìƒ íŒŒì¼ ìœ íš¨ì„± ê²€ì‚¬ (ê°•í™”ëœ ê²€ì¦)
            try:
                import subprocess
                import json as json_module

                # 1ë‹¨ê³„: ffprobeë¡œ ë©”íƒ€ë°ì´í„° í™•ì¸ (ì½”ë± ì •ë³´ í¬í•¨)
                probe_result = subprocess.run([
                    'ffprobe', '-v', 'error',
                    '-show_entries', 'format=duration,size:stream=codec_type,codec_name,width,height',
                    '-of', 'json', full_path
                ], capture_output=True, text=True, timeout=30)

                if probe_result.returncode != 0:
                    print(f"[YOUTUBE-UPLOAD][ERROR] ì†ìƒëœ ì˜ìƒ íŒŒì¼: {full_path}")
                    print(f"[YOUTUBE-UPLOAD][ERROR] ffprobe stderr: {probe_result.stderr[:500]}")
                    return jsonify({
                        "ok": False,
                        "error": f"ì†ìƒëœ ì˜ìƒ íŒŒì¼ì…ë‹ˆë‹¤. FFmpeg ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    }), 200

                probe_data = json_module.loads(probe_result.stdout)
                video_duration = float(probe_data.get('format', {}).get('duration', 0))
                video_size = int(probe_data.get('format', {}).get('size', 0))

                # ìŠ¤íŠ¸ë¦¼ í™•ì¸ (ë¹„ë””ì˜¤/ì˜¤ë””ì˜¤ ìˆëŠ”ì§€ + ì½”ë± ì •ë³´)
                streams = probe_data.get('streams', [])
                video_stream = next((s for s in streams if s.get('codec_type') == 'video'), None)
                audio_stream = next((s for s in streams if s.get('codec_type') == 'audio'), None)
                has_video = video_stream is not None
                has_audio = audio_stream is not None

                video_codec = video_stream.get('codec_name', 'unknown') if video_stream else 'none'
                audio_codec = audio_stream.get('codec_name', 'unknown') if audio_stream else 'none'
                video_width = video_stream.get('width', 0) if video_stream else 0
                video_height = video_stream.get('height', 0) if video_stream else 0

                print(f"[YOUTUBE-UPLOAD] ì˜ìƒ ê²€ì¦: duration={video_duration:.1f}s, size={video_size/1024/1024:.1f}MB")
                print(f"[YOUTUBE-UPLOAD] ì˜ìƒ ê²€ì¦: video={has_video} ({video_codec}, {video_width}x{video_height}), audio={has_audio} ({audio_codec})")

                # íŒŒì¼ í¬ê¸° ìµœì†Œê°’ ê²€ì‚¬ (100KB ë¯¸ë§Œì€ ì†ìƒ ê°€ëŠ¥ì„±)
                if video_size < 100 * 1024:
                    print(f"[YOUTUBE-UPLOAD][ERROR] íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŒ: {video_size/1024:.1f}KB")
                    return jsonify({
                        "ok": False,
                        "error": f"ì˜ìƒ íŒŒì¼ í¬ê¸°ê°€ ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤ ({video_size/1024:.1f}KB). ì¸ì½”ë”©ì´ ì‹¤íŒ¨í–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    }), 200

                if video_duration < 1:
                    print(f"[YOUTUBE-UPLOAD][ERROR] ì˜ìƒ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŒ: {video_duration}ì´ˆ")
                    return jsonify({
                        "ok": False,
                        "error": f"ì˜ìƒ ê¸¸ì´ê°€ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ ({video_duration:.1f}ì´ˆ). ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    }), 200

                if not has_video:
                    print(f"[YOUTUBE-UPLOAD][ERROR] ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—†ìŒ")
                    return jsonify({
                        "ok": False,
                        "error": "ì˜ìƒì— ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ì—†ìŠµë‹ˆë‹¤. ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    }), 200

                if not has_audio:
                    print(f"[YOUTUBE-UPLOAD][ERROR] ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ ì—†ìŒ")
                    return jsonify({
                        "ok": False,
                        "error": "ì˜ìƒì— ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ì´ ì—†ìŠµë‹ˆë‹¤. YouTube ì—…ë¡œë“œì—ëŠ” ì˜¤ë””ì˜¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                    }), 200

                # í•´ìƒë„ ê²€ì‚¬ (ë„ˆë¬´ ì‘ê±°ë‚˜ 0ì´ë©´ ë¬¸ì œ)
                if video_width < 100 or video_height < 100:
                    print(f"[YOUTUBE-UPLOAD][ERROR] ë¹„ì •ìƒ í•´ìƒë„: {video_width}x{video_height}")
                    return jsonify({
                        "ok": False,
                        "error": f"ì˜ìƒ í•´ìƒë„ê°€ ë¹„ì •ìƒì…ë‹ˆë‹¤ ({video_width}x{video_height}). ì¸ì½”ë”© ì˜¤ë¥˜ê°€ ë°œìƒí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    }), 200

                # 2ë‹¨ê³„: ì‹¤ì œ í”„ë ˆì„ ë””ì½”ë”© í…ŒìŠ¤íŠ¸ (ffmpegë¡œ ì²« 1ì´ˆ ì½ê¸°)
                print(f"[YOUTUBE-UPLOAD] í”„ë ˆì„ ë””ì½”ë”© í…ŒìŠ¤íŠ¸ ì‹œì‘...")
                decode_result = subprocess.run([
                    'ffmpeg', '-v', 'error',
                    '-i', full_path,
                    '-t', '1',  # ì²« 1ì´ˆë§Œ
                    '-f', 'null', '-'  # ì¶œë ¥ ì—†ì´ ë””ì½”ë”©ë§Œ
                ], capture_output=True, text=True, timeout=60)

                if decode_result.returncode != 0:
                    print(f"[YOUTUBE-UPLOAD][ERROR] í”„ë ˆì„ ë””ì½”ë”© ì‹¤íŒ¨")
                    print(f"[YOUTUBE-UPLOAD][ERROR] ffmpeg stderr: {decode_result.stderr[:500]}")
                    return jsonify({
                        "ok": False,
                        "error": f"ì˜ìƒ í”„ë ˆì„ ë””ì½”ë”©ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                    }), 200

                print(f"[YOUTUBE-UPLOAD] ì˜ìƒ ê²€ì¦ í†µê³¼!")

            except subprocess.TimeoutExpired:
                print(f"[YOUTUBE-UPLOAD][ERROR] ì˜ìƒ ê²€ì¦ íƒ€ì„ì•„ì›ƒ")
                return jsonify({
                    "ok": False,
                    "error": "ì˜ìƒ íŒŒì¼ ê²€ì¦ íƒ€ì„ì•„ì›ƒ. íŒŒì¼ì´ ì†ìƒë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤."
                }), 200
            except Exception as e:
                print(f"[YOUTUBE-UPLOAD][ERROR] ì˜ìƒ ê²€ì¦ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                return jsonify({
                    "ok": False,
                    "error": f"ì˜ìƒ íŒŒì¼ ê²€ì¦ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
                }), 200
        else:
            full_path = video_path

        # ì¸ë„¤ì¼ ê²½ë¡œ ì²˜ë¦¬
        full_thumbnail_path = None
        if thumbnail_path:
            if thumbnail_path.startswith('http'):
                full_thumbnail_path = thumbnail_path
            elif os.path.isabs(thumbnail_path) and os.path.exists(thumbnail_path):
                # ì ˆëŒ€ ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                full_thumbnail_path = thumbnail_path
            else:
                # ìƒëŒ€ ê²½ë¡œë¥¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ì•ì— /ê°€ ìˆìœ¼ë©´ ì œê±°)
                full_thumbnail_path = os.path.join(os.path.dirname(__file__), thumbnail_path.lstrip('/'))

        # ì‹¤ì œ ì—…ë¡œë“œ ì‹œë„ (DB í† í° ì§ì ‘ ì‚¬ìš©)
        # í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ _2 í”„ë¡œì íŠ¸ë¡œ ìë™ ì¬ì‹œë„
        from google.oauth2.credentials import Credentials
        from google.auth.transport.requests import Request
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        # í”„ë¡œì íŠ¸ ì ‘ë¯¸ì‚¬ ê²°ì •: íŒŒì´í”„ë¼ì¸ì—ì„œ ì „ë‹¬ëœ ê°’ ìš°ì„ , ì—†ìœ¼ë©´ ìë™ ì„ íƒ
        if project_suffix_param is not None:
            # íŒŒì´í”„ë¼ì¸ì—ì„œ ë¯¸ë¦¬ ì²´í¬í•œ í”„ë¡œì íŠ¸ ì‚¬ìš© (í• ë‹¹ëŸ‰ ì²´í¬ ê²°ê³¼)
            initial_project_suffix = project_suffix_param
            print(f"[YOUTUBE-UPLOAD] ì‚¬ìš© í”„ë¡œì íŠ¸ (íŒŒì´í”„ë¼ì¸ ì§€ì •): {'ê¸°ë³¸' if not initial_project_suffix else initial_project_suffix}")
        else:
            # ì§ì ‘ í˜¸ì¶œ ì‹œ ìë™ ì„ íƒ (í• ë‹¹ëŸ‰ ì´ˆê³¼ í”Œë˜ê·¸ ê¸°ë°˜)
            _, _, initial_project_suffix = get_youtube_credentials()
            print(f"[YOUTUBE-UPLOAD] ì‚¬ìš© í”„ë¡œì íŠ¸ (ìë™ ì„ íƒ): {'ê¸°ë³¸' if not initial_project_suffix else initial_project_suffix}")

        # ì‹œë„í•  í”„ë¡œì íŠ¸ ëª©ë¡ ìƒì„± (ê¸°ë³¸ â†’ _2)
        projects_to_try = [initial_project_suffix]
        if initial_project_suffix != "_2" and os.getenv('YOUTUBE_CLIENT_ID_2'):
            projects_to_try.append("_2")  # _2 í”„ë¡œì íŠ¸ê°€ ìˆìœ¼ë©´ ë°±ì—…ìœ¼ë¡œ ì¶”ê°€

        last_error = None
        for attempt_idx, project_suffix in enumerate(projects_to_try):
            if attempt_idx > 0:
                print(f"\n[YOUTUBE-UPLOAD] === í• ë‹¹ëŸ‰ ì´ˆê³¼ë¡œ {project_suffix} í”„ë¡œì íŠ¸ë¡œ ì¬ì‹œë„ ({attempt_idx + 1}/{len(projects_to_try)}) ===")

            try:
                # DBì—ì„œ í† í° ë¡œë“œ (ì„ íƒëœ ì±„ë„ì˜ í† í° ìš°ì„ , í”„ë¡œì íŠ¸ ì ‘ë¯¸ì‚¬ ì ìš©)
                token_data = load_youtube_token_from_db(channel_id, project_suffix) if channel_id else load_youtube_token_from_db('default', project_suffix)

                # âš ï¸ ì±„ë„ë³„ í† í°ì´ ì—†ì„ ë•Œ defaultë¡œ fallback í•˜ì§€ ì•ŠìŒ!
                # default í† í°ì€ ë‹¤ë¥¸ ì±„ë„ì¼ ìˆ˜ ìˆì–´ì„œ ì˜ëª»ëœ ì±„ë„ì— ì—…ë¡œë“œë˜ëŠ” ë²„ê·¸ ë°œìƒ
                # ì±„ë„ë³„ í† í°ì´ ì—†ìœ¼ë©´ í•´ë‹¹ ì±„ë„ ì¸ì¦ì´ í•„ìš”í•¨ì„ ì•Œë¦¼

                if not token_data or not token_data.get('refresh_token'):
                    print(f"[YOUTUBE-UPLOAD] ì—ëŸ¬ - DBì— í† í° ì—†ìŒ (channel_id: {channel_id}, project: {project_suffix or 'ê¸°ë³¸'})")
                    # í† í°ì´ ì—†ìœ¼ë©´ ë‹¤ìŒ í”„ë¡œì íŠ¸ ì‹œë„
                    if attempt_idx < len(projects_to_try) - 1:
                        print(f"[YOUTUBE-UPLOAD] ë‹¤ìŒ í”„ë¡œì íŠ¸({projects_to_try[attempt_idx + 1]})ë¡œ ì‹œë„...")
                        continue
                    return jsonify({
                        "ok": False,
                        "error": f"YouTube í† í°ì´ ì—†ìŠµë‹ˆë‹¤. í•´ë‹¹ ì±„ë„({channel_id})ë¡œ OAuth ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤. (project: {project_suffix or 'ê¸°ë³¸'})",
                        "needsAuth": True,
                        "channelId": channel_id
                    }), 200

                # Credentials ê°ì²´ ìƒì„± (í”„ë¡œì íŠ¸ì— ë§ëŠ” client_id/secret ì‚¬ìš©)
                if project_suffix == "_2":
                    fallback_client_id = os.getenv('YOUTUBE_CLIENT_ID_2')
                    fallback_client_secret = os.getenv('YOUTUBE_CLIENT_SECRET_2')
                else:
                    fallback_client_id = os.getenv('YOUTUBE_CLIENT_ID')
                    fallback_client_secret = os.getenv('YOUTUBE_CLIENT_SECRET')

                creds = Credentials(
                    token=token_data.get('token'),
                    refresh_token=token_data.get('refresh_token'),
                    token_uri=token_data.get('token_uri', 'https://oauth2.googleapis.com/token'),
                    client_id=token_data.get('client_id') or fallback_client_id,
                    client_secret=token_data.get('client_secret') or fallback_client_secret,
                    scopes=token_data.get('scopes', [
                        'https://www.googleapis.com/auth/youtube.upload',
                        'https://www.googleapis.com/auth/youtube.force-ssl'  # ëŒ“ê¸€ ì‘ì„±ìš©
                    ])
                )

                # í† í° ë§Œë£Œ ì‹œ ê°±ì‹ 
                if creds.expired and creds.refresh_token:
                    print(f"[YOUTUBE-UPLOAD] í† í° ê°±ì‹  ì¤‘... (í”„ë¡œì íŠ¸: {project_suffix or 'ê¸°ë³¸'})")
                    creds.refresh(Request())
                    # ê°±ì‹ ëœ í† í° ì €ì¥ (í”„ë¡œì íŠ¸ ì ‘ë¯¸ì‚¬ í¬í•¨)
                    updated_token = {
                        'token': creds.token,
                        'refresh_token': creds.refresh_token,
                        'token_uri': creds.token_uri,
                        'client_id': creds.client_id,
                        'client_secret': creds.client_secret,
                        'scopes': list(creds.scopes) if creds.scopes else []
                    }
                    save_youtube_token_to_db(updated_token, channel_id=channel_id, project_suffix=project_suffix)

                # YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
                youtube = build('youtube', 'v3', credentials=creds)

                # ì—…ë¡œë“œ ì‹¤í–‰
                print(f"[YOUTUBE-UPLOAD] ì‹¤ì œ ì—…ë¡œë“œ ì‹œì‘ - íŒŒì¼: {full_path}")

                body = {
                    'snippet': {
                        'title': title,
                        'description': description,
                        'tags': tags if tags else [],
                        'categoryId': category_id
                    },
                    'status': {
                        'privacyStatus': privacy_status,
                        'selfDeclaredMadeForKids': False
                    }
                }

                # ì˜ˆì•½ ê³µê°œ ì„¤ì • (publish_atì´ ìˆìœ¼ë©´ ì ìš©)
                if publish_at:
                    body['status']['publishAt'] = publish_at
                    body['status']['privacyStatus'] = 'private'  # ì˜ˆì•½ ì‹œ ë°˜ë“œì‹œ ë¹„ê³µê°œ
                    print(f"[YOUTUBE-UPLOAD] ì˜ˆì•½ ê³µê°œ ì„¤ì •: {publish_at}")

                media = MediaFileUpload(
                    full_path,
                    mimetype='video/mp4',
                    resumable=True,
                    chunksize=1024*1024  # 1MB chunks
                )

                request_obj = youtube.videos().insert(
                    part='snippet,status',
                    body=body,
                    media_body=media
                )

                response = None
                while response is None:
                    status, response = request_obj.next_chunk()
                    if status:
                        print(f"[YOUTUBE-UPLOAD] ì§„í–‰ë¥ : {int(status.progress() * 100)}%")

                video_id = response.get('id')
                video_url = f"https://www.youtube.com/watch?v={video_id}"

                print(f"[YOUTUBE-UPLOAD] ì—…ë¡œë“œ ì™„ë£Œ, ì˜ìƒ ìƒíƒœ í™•ì¸ ì¤‘...")

                # ì—…ë¡œë“œ í›„ ì˜ìƒ ìƒíƒœ í™•ì¸ (YouTubeê°€ ì˜ìƒì„ ê±°ë¶€í–ˆëŠ”ì§€)
                try:
                    video_check = youtube.videos().list(
                        part='status,processingDetails',
                        id=video_id
                    ).execute()

                    if video_check.get('items'):
                        item = video_check['items'][0]
                        upload_status = item.get('status', {}).get('uploadStatus', 'unknown')
                        rejection_reason = item.get('status', {}).get('rejectionReason', '')
                        failure_reason = item.get('status', {}).get('failureReason', '')
                        processing_status = item.get('processingDetails', {}).get('processingStatus', 'unknown')

                        print(f"[YOUTUBE-UPLOAD] ìƒíƒœ: uploadStatus={upload_status}, processingStatus={processing_status}")

                        if rejection_reason:
                            print(f"[YOUTUBE-UPLOAD][ERROR] ê±°ë¶€ë¨: {rejection_reason}")
                            return jsonify({
                                "ok": False,
                                "error": f"YouTubeê°€ ì˜ìƒì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤: {rejection_reason}"
                            }), 200

                        if failure_reason:
                            print(f"[YOUTUBE-UPLOAD][ERROR] ì‹¤íŒ¨: {failure_reason}")
                            return jsonify({
                                "ok": False,
                                "error": f"YouTube ì²˜ë¦¬ ì‹¤íŒ¨: {failure_reason}"
                            }), 200

                        if upload_status == 'rejected':
                            print(f"[YOUTUBE-UPLOAD][ERROR] ì˜ìƒì´ ê±°ë¶€ë¨")
                            return jsonify({
                                "ok": False,
                                "error": "YouTubeê°€ ì˜ìƒì„ ê±°ë¶€í–ˆìŠµë‹ˆë‹¤. ì˜ìƒ í˜•ì‹ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                            }), 200

                        if upload_status == 'failed':
                            print(f"[YOUTUBE-UPLOAD][ERROR] ì—…ë¡œë“œ ì‹¤íŒ¨ ìƒíƒœ")
                            return jsonify({
                                "ok": False,
                                "error": "YouTube ì—…ë¡œë“œê°€ ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ì˜ìƒ íŒŒì¼ì„ í™•ì¸í•´ì£¼ì„¸ìš”."
                            }), 200
                    else:
                        print(f"[YOUTUBE-UPLOAD][ERROR] ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨ - items ì—†ìŒ (video_id: {video_id})")
                        print(f"[YOUTUBE-UPLOAD][ERROR] YouTubeê°€ ì—…ë¡œë“œ ì§í›„ ì˜ìƒì„ ì‚­ì œí–ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
                        return jsonify({
                            "ok": False,
                            "error": f"YouTube ì—…ë¡œë“œ í›„ ì˜ìƒ í™•ì¸ ì‹¤íŒ¨. ì˜ìƒì´ ì •ì±… ìœ„ë°˜ìœ¼ë¡œ ì¦‰ì‹œ ì‚­ì œë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. (video_id: {video_id})"
                        }), 200
                except Exception as check_error:
                    print(f"[YOUTUBE-UPLOAD][ERROR] ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {check_error}")
                    import traceback
                    traceback.print_exc()
                    return jsonify({
                        "ok": False,
                        "error": f"YouTube ì—…ë¡œë“œ í›„ ìƒíƒœ í™•ì¸ ì‹¤íŒ¨: {str(check_error)}"
                    }), 200

                print(f"[YOUTUBE-UPLOAD] ì—…ë¡œë“œ ì„±ê³µ: {video_url}")

                # ì¸ë„¤ì¼ ì—…ë¡œë“œ (ì¸ë„¤ì¼ ê²½ë¡œê°€ ìˆëŠ” ê²½ìš°)
                thumbnail_uploaded = False
                if thumbnail_path:
                    try:
                        # ì¸ë„¤ì¼ ì „ì²´ ê²½ë¡œ ì²˜ë¦¬
                        # 1. ì ˆëŒ€ ê²½ë¡œë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                        if os.path.isabs(thumbnail_path) and os.path.exists(thumbnail_path):
                            thumb_full_path = thumbnail_path
                        # 2. ìƒëŒ€ ê²½ë¡œì¸ ê²½ìš° ì²˜ë¦¬
                        elif thumbnail_path.startswith('/'):
                            thumb_full_path = thumbnail_path[1:]  # ì•ì˜ / ì œê±°
                        else:
                            thumb_full_path = thumbnail_path

                        # /output/ â†’ outputs/ ê²½ë¡œ ë³€í™˜ (AI ì¸ë„¤ì¼ìš©)
                        if thumb_full_path.startswith('output/'):
                            thumb_full_path = 'outputs/' + thumb_full_path[7:]  # output/ ì œê±° í›„ outputs/ ì¶”ê°€

                        print(f"[YOUTUBE-UPLOAD] ì¸ë„¤ì¼ ê²½ë¡œ: {thumbnail_path} â†’ {thumb_full_path}")

                        # íŒŒì¼ ì¡´ì¬ í™•ì¸
                        if os.path.exists(thumb_full_path):
                            print(f"[YOUTUBE-UPLOAD] ì¸ë„¤ì¼ ì—…ë¡œë“œ ì‹œì‘: {thumb_full_path}")

                            # ì¸ë„¤ì¼ MIME íƒ€ì… ê²°ì •
                            thumb_ext = os.path.splitext(thumb_full_path)[1].lower()
                            thumb_mime = {
                                '.jpg': 'image/jpeg',
                                '.jpeg': 'image/jpeg',
                                '.png': 'image/png',
                                '.gif': 'image/gif'
                            }.get(thumb_ext, 'image/jpeg')

                            thumb_media = MediaFileUpload(
                                thumb_full_path,
                                mimetype=thumb_mime,
                                resumable=True
                            )

                            thumb_request = youtube.thumbnails().set(
                                videoId=video_id,
                                media_body=thumb_media
                            )
                            thumb_response = thumb_request.execute()
                            thumbnail_uploaded = True
                            print(f"[YOUTUBE-UPLOAD] ì¸ë„¤ì¼ ì—…ë¡œë“œ ì„±ê³µ!")
                        else:
                            print(f"[YOUTUBE-UPLOAD] ì¸ë„¤ì¼ íŒŒì¼ ì—†ìŒ: {thumb_full_path}")
                    except Exception as thumb_error:
                        print(f"[YOUTUBE-UPLOAD] ì¸ë„¤ì¼ ì—…ë¡œë“œ ì‹¤íŒ¨: {thumb_error}")
                        import traceback
                        traceback.print_exc()

                # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì˜ìƒ ì¶”ê°€ (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDê°€ ìˆëŠ” ê²½ìš°)
                playlist_added = False
                if playlist_id:
                    try:
                        print(f"[YOUTUBE-UPLOAD] í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì— ì˜ìƒ ì¶”ê°€ ì‹œì‘: {playlist_id}")
                        playlist_request = youtube.playlistItems().insert(
                            part="snippet",
                            body={
                                "snippet": {
                                    "playlistId": playlist_id,
                                    "resourceId": {
                                        "kind": "youtube#video",
                                        "videoId": video_id
                                    }
                                }
                            }
                        )
                        playlist_response = playlist_request.execute()
                        playlist_added = True
                        print(f"[YOUTUBE-UPLOAD] í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì„±ê³µ! playlistItemId: {playlist_response.get('id')}")
                    except Exception as playlist_error:
                        print(f"[YOUTUBE-UPLOAD] í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨: {playlist_error}")
                        import traceback
                        traceback.print_exc()
                        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì‹¤íŒ¨í•´ë„ ì—…ë¡œë“œëŠ” ì„±ê³µí•œ ê²ƒìœ¼ë¡œ ì²˜ë¦¬

                # ì²« ëŒ“ê¸€ ì‘ì„± (first_commentê°€ ìˆëŠ” ê²½ìš°)
                first_comment = data.get('firstComment', '')
                comment_posted = False
                comment_id = ''
                if first_comment:
                    import time
                    max_retries = 3
                    retry_delays = [5, 10, 15]  # 5ì´ˆ, 10ì´ˆ, 15ì´ˆ í›„ ì¬ì‹œë„

                    for attempt in range(max_retries):
                        try:
                            if attempt > 0:
                                print(f"[YOUTUBE-UPLOAD] ì²« ëŒ“ê¸€ ì¬ì‹œë„ {attempt + 1}/{max_retries} ({retry_delays[attempt]}ì´ˆ ëŒ€ê¸° í›„)...")
                                time.sleep(retry_delays[attempt])
                            else:
                                # ì²« ì‹œë„ ì „ 5ì´ˆ ëŒ€ê¸° (ì˜ìƒ ì²˜ë¦¬ ì‹œê°„ í™•ë³´)
                                print(f"[YOUTUBE-UPLOAD] ì²« ëŒ“ê¸€ ì‘ì„± ëŒ€ê¸° ì¤‘ (5ì´ˆ)...")
                                time.sleep(5)

                            print(f"[YOUTUBE-UPLOAD] ì²« ëŒ“ê¸€ ì‘ì„± ì‹œë„ {attempt + 1}: {first_comment[:50]}...")
                            comment_request = youtube.commentThreads().insert(
                                part="snippet",
                                body={
                                    "snippet": {
                                        "videoId": video_id,
                                        "topLevelComment": {
                                            "snippet": {
                                                "textOriginal": first_comment
                                            }
                                        }
                                    }
                                }
                            )
                            comment_response = comment_request.execute()
                            comment_posted = True
                            comment_id = comment_response.get('id', '')
                            print(f"[YOUTUBE-UPLOAD] ì²« ëŒ“ê¸€ ì‘ì„± ì„±ê³µ! commentId: {comment_id}")
                            break  # ì„±ê³µí•˜ë©´ ë£¨í”„ ì¢…ë£Œ

                        except Exception as comment_error:
                            error_str = str(comment_error)
                            print(f"[YOUTUBE-UPLOAD] ì²« ëŒ“ê¸€ ì‘ì„± ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {error_str}")

                            # ìƒì„¸ ì—ëŸ¬ ë¶„ì„
                            if 'commentsDisabled' in error_str:
                                print(f"[YOUTUBE-UPLOAD] ì›ì¸: ì˜ìƒ ëŒ“ê¸€ì´ ë¹„í™œì„±í™”ë¨")
                                break  # ì¬ì‹œë„ ë¶ˆí•„ìš”
                            elif 'forbidden' in error_str.lower() or '403' in error_str:
                                print(f"[YOUTUBE-UPLOAD] ì›ì¸: ê¶Œí•œ ë¶€ì¡± (youtube.force-ssl scope í™•ì¸ í•„ìš”)")
                                break  # ì¬ì‹œë„ ë¶ˆí•„ìš”
                            elif 'quotaExceeded' in error_str:
                                print(f"[YOUTUBE-UPLOAD] ì›ì¸: API í• ë‹¹ëŸ‰ ì´ˆê³¼")
                                break  # ì¬ì‹œë„ ë¶ˆí•„ìš”
                            elif 'videoNotFound' in error_str or 'notFound' in error_str.lower():
                                print(f"[YOUTUBE-UPLOAD] ì›ì¸: ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŒ (video_id: {video_id})")
                                # ë§ˆì§€ë§‰ ì‹œë„ê°€ ì•„ë‹ˆë©´ ì¬ì‹œë„
                                if attempt < max_retries - 1:
                                    continue
                            else:
                                # ì•Œ ìˆ˜ ì—†ëŠ” ì—ëŸ¬ëŠ” ì¬ì‹œë„
                                if attempt < max_retries - 1:
                                    continue

                            import traceback
                            traceback.print_exc()

                    if not comment_posted:
                        print(f"[YOUTUBE-UPLOAD] ì²« ëŒ“ê¸€ ì‘ì„± ìµœì¢… ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì†Œì§„)")

                # ë©”ì‹œì§€ ìƒì„±
                upload_message = "YouTube ì—…ë¡œë“œ ì™„ë£Œ!"
                if thumbnail_uploaded:
                    upload_message += " (ì¸ë„¤ì¼ í¬í•¨)"
                if playlist_added:
                    upload_message += " (í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ë¨)"
                if comment_posted:
                    upload_message += " (ì²« ëŒ“ê¸€ ê²Œì‹œë¨)"

                return jsonify({
                    "ok": True,
                    "mode": "live",
                    "videoId": video_id,
                    "videoUrl": video_url,
                    "status": "uploaded",
                    "thumbnailUploaded": thumbnail_uploaded,
                    "playlistAdded": playlist_added,
                    "playlistId": playlist_id if playlist_added else None,
                    "commentPosted": comment_posted,
                    "message": upload_message,
                    "metadata": {
                        "title": title,
                        "privacyStatus": privacy_status
                    }
                })

            except ImportError as e:
                print(f"[YOUTUBE-UPLOAD] ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ: {e}")
                return jsonify({
                    "ok": False,
                    "error": f"í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì—†ìŒ: {str(e)}",
                    "needsAuth": False
                }), 200
            except Exception as upload_error:
                error_str = str(upload_error).lower()
                print(f"[YOUTUBE-UPLOAD] ì—…ë¡œë“œ ì˜¤ë¥˜ (í”„ë¡œì íŠ¸: {project_suffix or 'ê¸°ë³¸'}): {upload_error}")
                import traceback
                traceback.print_exc()

                # í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€ ë° _2 í”„ë¡œì íŠ¸ë¡œ ìë™ ì¬ì‹œë„
                if 'quota' in error_str or 'quotaexceeded' in error_str:
                    print(f"[YOUTUBE-UPLOAD] í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€! (í”„ë¡œì íŠ¸: {project_suffix or 'ê¸°ë³¸'})")
                    set_youtube_quota_exceeded()  # í”Œë˜ê·¸ ì €ì¥
                    last_error = upload_error

                    # ë‹¤ìŒ í”„ë¡œì íŠ¸ê°€ ìˆìœ¼ë©´ ì¬ì‹œë„
                    if attempt_idx < len(projects_to_try) - 1:
                        print(f"[YOUTUBE-UPLOAD] â†’ _2 í”„ë¡œì íŠ¸ë¡œ ìë™ ì¬ì‹œë„í•©ë‹ˆë‹¤...")
                        continue  # ë‹¤ìŒ í”„ë¡œì íŠ¸ë¡œ ì¬ì‹œë„
                    else:
                        # ëª¨ë“  í”„ë¡œì íŠ¸ ì†Œì§„
                        print(f"[YOUTUBE-UPLOAD] ëª¨ë“  í”„ë¡œì íŠ¸({projects_to_try})ì—ì„œ í• ë‹¹ëŸ‰ ì´ˆê³¼!")
                        return jsonify({
                            "ok": False,
                            "error": f"YouTube API í• ë‹¹ëŸ‰ ì´ˆê³¼. ëª¨ë“  í”„ë¡œì íŠ¸({', '.join(p or 'ê¸°ë³¸' for p in projects_to_try)})ì—ì„œ í• ë‹¹ëŸ‰ì´ ì´ˆê³¼ë˜ì—ˆìŠµë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.",
                            "quotaExceeded": True,
                            "needsAuth": False
                        }), 200

                # í• ë‹¹ëŸ‰ ì´ˆê³¼ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì˜¤ë¥˜
                return jsonify({
                    "ok": False,
                    "error": f"ì—…ë¡œë“œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(upload_error)}",
                    "needsAuth": False
                }), 200

        # for ë£¨í”„ê°€ break ì—†ì´ ëë‚¨ - ì •ìƒì ìœ¼ë¡œëŠ” ë„ë‹¬ ë¶ˆê°€
        print(f"[YOUTUBE-UPLOAD][WARN] ì˜ˆìƒì¹˜ ëª»í•œ ì½”ë“œ ê²½ë¡œ - ëª¨ë“  ì‹œë„ ì™„ë£Œ")
        if last_error:
            return jsonify({
                "ok": False,
                "error": f"ì—…ë¡œë“œ ì‹¤íŒ¨: {str(last_error)}",
                "needsAuth": False
            }), 200
        return jsonify({
            "ok": False,
            "error": "ì˜ˆìƒì¹˜ ëª»í•œ ì½”ë“œ ê²½ë¡œì…ë‹ˆë‹¤. ì„œë²„ ë¡œê·¸ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
            "metadata": {
                "title": title,
                "privacyStatus": privacy_status
            }
        })

    except Exception as e:
        print(f"[YOUTUBE-UPLOAD][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200


@app.route('/api/drama/generate-thumbnails', methods=['POST'])
def generate_thumbnails():
    """
    ì¸ë„¤ì¼ 3ì¢… ìƒì„± API.
    Step4ì—ì„œ ìƒì„±ëœ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì¸ë„¤ì¼ í›„ë³´ ìƒì„±
    """
    try:
        data = request.get_json() or {}

        base_image_url = data.get('baseImageUrl')
        title = data.get('title', '')
        channel_type = data.get('channelType', 'nostalgia')
        styles = data.get('styles', ['warm', 'dramatic', 'nostalgic'])

        print(f"[DRAMA-THUMBNAIL] ì¸ë„¤ì¼ ìƒì„± ìš”ì²­ - ìŠ¤íƒ€ì¼: {styles}")

        # outputs í´ë”ì—ì„œ ê¸°ì¡´ ì¸ë„¤ì¼ í™•ì¸
        outputs_dir = os.path.join(os.path.dirname(__file__), 'outputs')
        thumbnail_file = os.path.join(outputs_dir, 'thumbnail_output.json')

        if os.path.exists(thumbnail_file):
            with open(thumbnail_file, 'r', encoding='utf-8') as f:
                thumb_data = json.load(f)

            candidates = thumb_data.get('candidates', [])
            if candidates:
                print(f"[DRAMA-THUMBNAIL] ê¸°ì¡´ ì¸ë„¤ì¼ {len(candidates)}ê°œ ë°œê²¬")

                thumbnails = []
                for idx, candidate in enumerate(candidates):
                    thumb_url = candidate.get('url') or candidate.get('image_url')
                    if thumb_url:
                        thumbnails.append({
                            "url": thumb_url,
                            "style": styles[idx] if idx < len(styles) else "default",
                            "path": candidate.get('path')
                        })

                if thumbnails:
                    return jsonify({
                        "ok": True,
                        "thumbnails": thumbnails,
                        "source": "cached"
                    })

        # ê¸°ì¡´ ì¸ë„¤ì¼ì´ ì—†ìœ¼ë©´ Step2 ì´ë¯¸ì§€ë¥¼ ì¸ë„¤ì¼ë¡œ ì‚¬ìš©
        if base_image_url:
            thumbnails = [
                {"url": base_image_url, "style": "warm", "path": None},
                {"url": base_image_url, "style": "dramatic", "path": None},
                {"url": base_image_url, "style": "nostalgic", "path": None}
            ]

            return jsonify({
                "ok": True,
                "thumbnails": thumbnails,
                "source": "base_image",
                "message": "ê¸°ë³¸ ì´ë¯¸ì§€ë¥¼ ì¸ë„¤ì¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ì „ìš© ì¸ë„¤ì¼ ìƒì„±ì€ ì¶”í›„ ì§€ì› ì˜ˆì •ì…ë‹ˆë‹¤."
            })

        # ì´ë¯¸ì§€ë„ ì—†ìœ¼ë©´ í”Œë ˆì´ìŠ¤í™€ë”
        return jsonify({
            "ok": True,
            "thumbnails": [
                {"url": "/static/images/placeholder-thumbnail.png", "style": "warm", "path": None},
                {"url": "/static/images/placeholder-thumbnail.png", "style": "dramatic", "path": None},
                {"url": "/static/images/placeholder-thumbnail.png", "style": "nostalgic", "path": None}
            ],
            "source": "placeholder",
            "message": "ì¸ë„¤ì¼ ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤. Step2ì—ì„œ ì´ë¯¸ì§€ë¥¼ ë¨¼ì € ìƒì„±í•´ì£¼ì„¸ìš”."
        })

    except Exception as e:
        print(f"[DRAMA-THUMBNAIL][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 200

# ===== Image Lab API =====
def load_prompt_guides():
    """í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ íŒŒì¼ë“¤ ë¡œë“œ"""
    guides = {}

    # ì „ë¬¸ê°€ í”„ë¡¬í”„íŠ¸ ê°€ì´ë“œ
    try:
        with open('guides/prompt-expert-guide.json', 'r', encoding='utf-8') as f:
            guides['expert'] = json.load(f)
    except:
        guides['expert'] = None

    # í•œêµ­ì¸ ì‹œë‹ˆì–´ ì´ë¯¸ì§€ ê°€ì´ë“œ
    try:
        with open('guides/korean-senior-image-prompts.json', 'r', encoding='utf-8') as f:
            guides['korean_senior'] = json.load(f)
    except:
        guides['korean_senior'] = None

    return guides


# ===== ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ë¡œë“œ í•¨ìˆ˜ =====
def _load_benchmark_style_prompt(style_name, category=''):
    """ì €ì¥ëœ ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤íƒ€ì¼ì„ ë¡œë“œí•˜ì—¬ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜

    Args:
        style_name: ìŠ¤íƒ€ì¼ ì´ë¦„ ë˜ëŠ” íŒŒì¼ëª…
        category: ì¹´í…Œê³ ë¦¬ (history/news/mystery)

    Returns:
        str: GPTì—ê²Œ ì „ë‹¬í•  ìŠ¤í† ë¦¬í…”ë§ ê°€ì´ë“œ í”„ë¡¬í”„íŠ¸
    """
    import json

    styles_dir = os.path.join(os.path.dirname(__file__), 'benchmark_styles')
    if not os.path.exists(styles_dir):
        print(f"[BENCHMARK] ìŠ¤íƒ€ì¼ í´ë” ì—†ìŒ: {styles_dir}")
        return ""

    # ìŠ¤íƒ€ì¼ íŒŒì¼ ì°¾ê¸°
    style_file = None
    for filename in os.listdir(styles_dir):
        if filename.endswith('.json'):
            # ì •í™•íˆ ì¼ì¹˜í•˜ê±°ë‚˜ ìŠ¤íƒ€ì¼ ì´ë¦„ í¬í•¨
            if style_name in filename or filename == f"{category}_{style_name.replace(' ', '_')}.json":
                style_file = os.path.join(styles_dir, filename)
                break

    if not style_file:
        print(f"[BENCHMARK] ìŠ¤íƒ€ì¼ íŒŒì¼ ì—†ìŒ: {style_name}")
        return ""

    try:
        with open(style_file, 'r', encoding='utf-8') as f:
            style_data = json.load(f)

        analysis = style_data.get('analysis', {})
        if not analysis:
            return ""

        # ë¶„ì„ ê²°ê³¼ë¥¼ í”„ë¡¬í”„íŠ¸ë¡œ ë³€í™˜
        prompt_parts = ["\n\nâ˜…â˜…â˜… ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ (ë°˜ë“œì‹œ ì ìš©) â˜…â˜…â˜…"]

        if analysis.get('opening_hook'):
            prompt_parts.append(f"[ì˜¤í”„ë‹ í›…] {analysis['opening_hook']}")

        if analysis.get('narrative_structure'):
            prompt_parts.append(f"[ì„œì‚¬ êµ¬ì¡°] {analysis['narrative_structure']}")

        if analysis.get('pacing'):
            prompt_parts.append(f"[í˜ì´ì‹±] {analysis['pacing']}")

        if analysis.get('narration_tone'):
            prompt_parts.append(f"[ë‚˜ë ˆì´ì…˜ í†¤] {analysis['narration_tone']}")

        if analysis.get('scene_transitions'):
            prompt_parts.append(f"[ì”¬ ì „í™˜] {analysis['scene_transitions']}")

        if analysis.get('tension_building'):
            prompt_parts.append(f"[ê¸´ì¥ê° êµ¬ì¶•] {analysis['tension_building']}")

        if analysis.get('ending_style'):
            prompt_parts.append(f"[ì—”ë”© ìŠ¤íƒ€ì¼] {analysis['ending_style']}")

        if analysis.get('key_techniques'):
            techniques = analysis['key_techniques']
            if isinstance(techniques, list):
                prompt_parts.append(f"[í•µì‹¬ ê¸°ë²•] {', '.join(techniques)}")

        if analysis.get('example_phrases'):
            phrases = analysis['example_phrases']
            if isinstance(phrases, list):
                prompt_parts.append(f"[ì°¸ê³  í‘œí˜„] {' / '.join(phrases[:3])}")

        if analysis.get('applicable_tips'):
            tips = analysis['applicable_tips']
            if isinstance(tips, list):
                prompt_parts.append(f"[ì ìš© íŒ] {', '.join(tips)}")

        style_prompt = "\n".join(prompt_parts)
        print(f"[BENCHMARK] ìŠ¤íƒ€ì¼ ë¡œë“œ ì„±ê³µ: {style_name}")
        print(f"[BENCHMARK] ì ìš© í•­ëª©: {list(analysis.keys())}")

        return style_prompt

    except Exception as e:
        print(f"[BENCHMARK] ìŠ¤íƒ€ì¼ ë¡œë“œ ì˜¤ë¥˜: {e}")
        return ""


# ===== SEO í‚¤ì›Œë“œ ë¶„ì„ í•¨ìˆ˜ =====
def _analyze_seo_keywords(script, lang='ko'):
    """ëŒ€ë³¸ì—ì„œ í‚¤ì›Œë“œë¥¼ ì¶”ì¶œí•˜ê³  YouTube SEO ë°ì´í„° ë¶„ì„

    Args:
        script: ëŒ€ë³¸ í…ìŠ¤íŠ¸
        lang: ì–¸ì–´ ì½”ë“œ (ko/en/ja)

    Returns:
        {
            "keywords": ["í‚¤ì›Œë“œ1", "í‚¤ì›Œë“œ2"],
            "youtube_trends": [{"title": "ìƒìœ„ ì˜ìƒ ì œëª©", "views": 10000, "tags": [...]}],
            "recommended_keywords": ["ì¶”ì²œ í‚¤ì›Œë“œ"],
            "title_patterns": ["íŒ¨í„´1", "íŒ¨í„´2"],
            "seo_prompt": "GPTì—ê²Œ ì „ë‹¬í•  SEO ê°€ì´ë“œ"
        }
    """
    import requests
    import re

    api_key = os.environ.get('YOUTUBE_API_KEY', '')
    if not api_key:
        print("[SEO] YouTube API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
        return None

    try:
        # 1. ëŒ€ë³¸ì—ì„œ í•µì‹¬ í‚¤ì›Œë“œ ì¶”ì¶œ (ê°„ë‹¨í•œ ë°©ì‹)
        # ê¸´ ë‹¨ì–´, ìì£¼ ë“±ì¥í•˜ëŠ” ë‹¨ì–´ ì¶”ì¶œ
        script_preview = script[:1500]

        # ìˆ«ì+ë‹¨ìœ„ íŒ¨í„´ (2025ë…„, 3ê°€ì§€, 100ë§Œì› ë“±)
        number_patterns = re.findall(r'\d+[\s]?(?:ë…„|ì›”|ì¼|ê°€ì§€|ê°œ|ë§Œì›|ì–µ|ì¡°|%|ìœ„)', script_preview)

        # ì£¼ìš” ëª…ì‚¬ ì¶”ì¶œ (í•œêµ­ì–´ ê¸°ì¤€)
        if lang == 'ko':
            # 2ê¸€ì ì´ìƒ ë‹¨ì–´ ì¤‘ ìì£¼ ë“±ì¥í•˜ëŠ” ê²ƒ
            words = re.findall(r'[ê°€-í£]{2,6}', script_preview)
        elif lang == 'ja':
            words = re.findall(r'[\u3040-\u309F\u30A0-\u30FF\u4E00-\u9FFF]{2,6}', script_preview)
        else:
            words = re.findall(r'\b[a-zA-Z]{4,}\b', script_preview.lower())

        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        from collections import Counter
        word_freq = Counter(words)

        # ë¶ˆìš©ì–´ ì œê±° (ì–¸ì–´ë³„)
        stopwords_ko = {'ìˆìŠµë‹ˆë‹¤', 'í–ˆìŠµë‹ˆë‹¤', 'í•©ë‹ˆë‹¤', 'ë©ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤', 'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ë˜ì„œ',
                        'ë•Œë¬¸ì—', 'ì´ê²ƒì€', 'ì €ê²ƒì€', 'ì—¬ëŸ¬ë¶„', 'ìš°ë¦¬ëŠ”', 'ê·¸ë“¤ì€', 'ì´ë ‡ê²Œ', 'ì €ë ‡ê²Œ',
                        'ìˆëŠ”ë°', 'ì—†ëŠ”ë°', 'í•œë‹¤ëŠ”', 'ëœë‹¤ëŠ”', 'ìˆë‹¤ê³ ', 'ì—†ë‹¤ê³ ', 'ê·¸ê²ƒì€', 'ì´ê²ƒì´'}
        stopwords_ja = {'ã¦ã„ã¾ã™', 'ã¾ã—ãŸ', 'ã§ã™', 'ã¾ã™', 'ã§ã‚ã‚‹', 'ã¨ã„ã†', 'ã“ã¨', 'ã‚‚ã®',
                        'ãã‚Œã¯', 'ã“ã‚Œã¯', 'ã‚ã‚Šã¾ã™', 'ãªã‚Šã¾ã™', 'ã«ã¤ã„ã¦', 'ãŸã‚ã«', 'ã¨ã—ã¦',
                        'ã—ã‹ã—', 'ãã—ã¦', 'ã¾ãŸ', 'ãŸã ', 'ã¤ã¾ã‚Š', 'ãªãœãªã‚‰', 'ã ã‹ã‚‰'}
        stopwords_en = {'this', 'that', 'these', 'those', 'with', 'from', 'have', 'been',
                        'were', 'will', 'would', 'could', 'should', 'about', 'which', 'their',
                        'there', 'what', 'when', 'where', 'they', 'them', 'then', 'than',
                        'more', 'some', 'into', 'other', 'also', 'just', 'only', 'very'}

        # ì–¸ì–´ë³„ ë¶ˆìš©ì–´ ì„ íƒ
        if lang == 'ko':
            stopwords = stopwords_ko
        elif lang == 'ja':
            stopwords = stopwords_ja
        else:
            stopwords = stopwords_en

        # ìƒìœ„ í‚¤ì›Œë“œ ì¶”ì¶œ
        top_keywords = [word for word, count in word_freq.most_common(20)
                       if word not in stopwords and count >= 2][:5]

        if not top_keywords:
            print("[SEO] í‚¤ì›Œë“œ ì¶”ì¶œ ì‹¤íŒ¨")
            return None

        # ê²€ìƒ‰ ì¿¼ë¦¬ ìƒì„± (ìƒìœ„ 2-3ê°œ í‚¤ì›Œë“œ ì¡°í•©)
        search_query = ' '.join(top_keywords[:3])
        print(f"[SEO] ì¶”ì¶œëœ í‚¤ì›Œë“œ: {top_keywords}")
        print(f"[SEO] ê²€ìƒ‰ ì¿¼ë¦¬: {search_query}")

        # 2. YouTube Search APIë¡œ ìƒìœ„ ì˜ìƒ ê²€ìƒ‰ (í• ë‹¹ëŸ‰ ì´ˆê³¼ ì‹œ _2 API Keyë¡œ ì¬ì‹œë„)
        api_keys_to_try = [api_key]
        api_key_2 = os.environ.get('YOUTUBE_API_KEY_2', '')
        if api_key_2:
            api_keys_to_try.append(api_key_2)

        search_data = None
        used_api_key = None

        for key_idx, current_api_key in enumerate(api_keys_to_try):
            key_label = 'ê¸°ë³¸' if key_idx == 0 else '_2'
            print(f"[SEO] YouTube ê²€ìƒ‰ ì‹œë„ ({key_label} API Key)")

            search_resp = requests.get(
                "https://www.googleapis.com/youtube/v3/search",
                params={
                    "part": "snippet",
                    "q": search_query,
                    "type": "video",
                    "maxResults": 10,
                    "order": "relevance",
                    "relevanceLanguage": lang,
                    "key": current_api_key
                },
                timeout=10
            )

            if search_resp.status_code == 200:
                search_data = search_resp.json()
                used_api_key = current_api_key
                print(f"[SEO] YouTube ê²€ìƒ‰ ì„±ê³µ ({key_label} API Key)")
                break
            else:
                print(f"[SEO] YouTube ê²€ìƒ‰ ì‹¤íŒ¨ ({key_label}): {search_resp.status_code}")
                # 403/429 ì—ëŸ¬ëŠ” í• ë‹¹ëŸ‰ ì´ˆê³¼ - ë‹¤ìŒ í‚¤ë¡œ ì‹œë„
                if search_resp.status_code in [403, 429]:
                    if key_idx == 0:
                        print(f"[SEO] {key_label} API Key í• ë‹¹ëŸ‰ ì´ˆê³¼ - _2ë¡œ ì¬ì‹œë„")
                        _save_quota_flag()  # í”Œë˜ê·¸ ì €ì¥
                        continue
                    else:
                        # ë‘ ë²ˆì§¸ í‚¤ë„ ì‹¤íŒ¨
                        print("[SEO][WARNING] ëª¨ë“  API Key í• ë‹¹ëŸ‰ ì´ˆê³¼!")
                        return {"quota_exceeded": True, "error": "YouTube API í• ë‹¹ëŸ‰ ì´ˆê³¼ (ëª¨ë“  í‚¤)"}
                return None

        if not search_data:
            return None
        video_ids = [item["id"]["videoId"] for item in search_data.get("items", [])
                    if "videoId" in item.get("id", {})]

        if not video_ids:
            print("[SEO] ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ")
            return None

        # 3. ì˜ìƒ ìƒì„¸ ì •ë³´ ì¡°íšŒ (ì œëª©, íƒœê·¸, ì¡°íšŒìˆ˜) - ê²€ìƒ‰ ì„±ê³µí•œ API Key ì‚¬ìš©
        videos_resp = requests.get(
            "https://www.googleapis.com/youtube/v3/videos",
            params={
                "part": "snippet,statistics",
                "id": ",".join(video_ids),
                "key": used_api_key or api_key
            },
            timeout=10
        )

        if videos_resp.status_code != 200:
            print(f"[SEO] ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {videos_resp.status_code}")
            return None

        # 4. ë°ì´í„° ë¶„ì„
        youtube_trends = []
        all_tags = []
        title_words = []

        for video in videos_resp.json().get("items", []):
            snippet = video.get("snippet", {})
            stats = video.get("statistics", {})

            title = snippet.get("title", "")
            tags = snippet.get("tags", [])
            view_count = int(stats.get("viewCount", 0))

            youtube_trends.append({
                "title": title,
                "views": view_count,
                "tags": tags[:10] if tags else []
            })

            all_tags.extend(tags[:10] if tags else [])
            title_words.extend(re.findall(r'[ê°€-í£]{2,}|[a-zA-Z]{3,}|\d+', title))

        # 5. íŒ¨í„´ ë¶„ì„
        tag_freq = Counter(all_tags)
        recommended_tags = [tag for tag, _ in tag_freq.most_common(15)]

        title_word_freq = Counter(title_words)
        common_title_words = [word for word, count in title_word_freq.most_common(10) if count >= 2]

        # ì œëª© íŒ¨í„´ ë¶„ì„
        title_patterns = []
        for trend in youtube_trends[:5]:
            title = trend["title"]
            # ìˆ«ì í¬í•¨ ì—¬ë¶€
            has_number = bool(re.search(r'\d+', title))
            # êµ¬ë¶„ì ì‚¬ìš© (|, -, :)
            has_separator = bool(re.search(r'[|:\-]', title))
            # ê¸¸ì´
            length = len(title)

            if has_number and has_separator:
                title_patterns.append("ìˆ«ì + êµ¬ë¶„ì (ì˜ˆ: 3ê°€ì§€ ë°©ë²• | ì™„ë²½ ì •ë¦¬)")
            elif has_number:
                title_patterns.append("ìˆ«ì ê°•ì¡° (ì˜ˆ: 2025ë…„ ë°˜ë“œì‹œ ì•Œì•„ì•¼ í• )")
            elif has_separator:
                title_patterns.append("êµ¬ë¶„ì ì‚¬ìš© (ì˜ˆ: í•µì‹¬ ì •ë¦¬ | ì „ë¬¸ê°€ ë¶„ì„)")

        title_patterns = list(set(title_patterns))[:3]

        # 6. GPTìš© SEO í”„ë¡¬í”„íŠ¸ ìƒì„±
        seo_prompt = f"""
## ğŸ” SEO í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ (YouTube ì‹¤ì‹œê°„ ë°ì´í„°)

### ì¶”ì¶œëœ í•µì‹¬ í‚¤ì›Œë“œ
{', '.join(top_keywords)}

### YouTube ìƒìœ„ ì˜ìƒ ì œëª© (ì°¸ê³ ìš©)
{chr(10).join([f"- {t['title']} (ì¡°íšŒìˆ˜: {t['views']:,})" for t in youtube_trends[:5]])}

### ì¶”ì²œ íƒœê·¸ (ìƒìœ„ ì˜ìƒë“¤ì´ ì‚¬ìš©í•˜ëŠ” íƒœê·¸)
{', '.join(recommended_tags[:10])}

### ì œëª© íŒ¨í„´ ë¶„ì„
{chr(10).join([f"- {p}" for p in title_patterns]) if title_patterns else "- ìˆ«ì + í•µì‹¬ í‚¤ì›Œë“œ ì¡°í•© ì¶”ì²œ"}

### SEO ìµœì í™” ì§€ì¹¨
1. **ìœ„ í‚¤ì›Œë“œ ì¤‘ 2-3ê°œë¥¼ ì œëª©ì— ìì—°ìŠ¤ëŸ½ê²Œ í¬í•¨**
2. **ìƒìœ„ ì˜ìƒ ì œëª© íŒ¨í„´ ì°¸ê³ í•˜ë˜, ì°¨ë³„í™”ëœ í‘œí˜„ ì‚¬ìš©**
3. **ì¶”ì²œ íƒœê·¸ë¥¼ tags í•„ë“œì— í¬í•¨**
4. **ì„¤ëª…ë€ ì²« 2ì¤„ì— í•µì‹¬ í‚¤ì›Œë“œ í¬í•¨**
"""

        print(f"[SEO] ë¶„ì„ ì™„ë£Œ: {len(youtube_trends)}ê°œ ì˜ìƒ, {len(recommended_tags)}ê°œ íƒœê·¸")

        return {
            "keywords": top_keywords,
            "youtube_trends": youtube_trends,
            "recommended_keywords": recommended_tags,
            "title_patterns": title_patterns,
            "common_title_words": common_title_words,
            "seo_prompt": seo_prompt
        }

    except Exception as e:
        print(f"[SEO] ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None


@app.route('/api/image/analyze-script', methods=['POST'])
def api_image_analyze_script():
    """ì´ë¯¸ì§€ ì œì‘ìš© ëŒ€ë³¸ ë¶„ì„ - ì”¬ ë¶„ë¦¬ + ì¸ë„¤ì¼/ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±"""
    try:
        from openai import OpenAI
        import httpx
        # GPT-5.1 ì‘ë‹µ ëŒ€ê¸° ì‹œê°„ ì„¤ì • - ëª¨ë“  íƒ€ì„ì•„ì›ƒ ëª…ì‹œì  ì„¤ì •
        client = OpenAI(timeout=httpx.Timeout(
            timeout=900.0,  # ì „ì²´ íƒ€ì„ì•„ì›ƒ 15ë¶„
            connect=60.0,   # ì—°ê²° íƒ€ì„ì•„ì›ƒ 1ë¶„
            read=900.0,     # ì½ê¸° íƒ€ì„ì•„ì›ƒ 15ë¶„
            write=60.0      # ì“°ê¸° íƒ€ì„ì•„ì›ƒ 1ë¶„
        ))

        data = request.get_json()
        script = data.get('script', '')
        content_type = data.get('content_type', 'drama')
        image_style = data.get('image_style', 'realistic')
        image_count = data.get('image_count', 4)  # ê¸°ë³¸ 4ê°œ
        audience = data.get('audience', 'senior')  # ì‹œë‹ˆì–´/ì¼ë°˜ íƒ€ê²Ÿ
        category = data.get('category', '').strip()  # ì¹´í…Œê³ ë¦¬ (ë‰´ìŠ¤ ë“±)
        output_language = data.get('output_language', 'ko')  # ì¶œë ¥ ì–¸ì–´ (ko/en/ja/auto)
        channel_style = data.get('channel_style', '')  # [TUBELENS] ì±„ë„ë³„ ìŠ¤íƒ€ì¼ ì •ë³´
        benchmark_style = data.get('benchmark_style', '')  # ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ì´ë¦„

        # â˜… ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ë¡œë“œ
        benchmark_prompt = ""
        if benchmark_style:
            benchmark_prompt = _load_benchmark_style_prompt(benchmark_style, category)

        # ì–¸ì–´ ì„¤ì • ë§¤í•‘
        language_config = {
            'ko': {'name': 'Korean', 'native': 'í•œêµ­ì–´', 'instruction': 'Write ALL titles, description, thumbnail text, and narration in Korean (í•œêµ­ì–´).'},
            'en': {'name': 'English', 'native': 'English', 'instruction': 'Write ALL titles, description, thumbnail text, and narration in English.'},
            'ja': {'name': 'Japanese', 'native': 'æ—¥æœ¬èª', 'instruction': 'Write ALL titles, description, thumbnail text, narration, overlays, and subtitles in Japanese using ONLY hiragana/katakana. âš ï¸ NO KANJI (æ¼¢å­—) ALLOWED! Use ã²ã‚‰ãŒãª instead of æ¼¢å­—. Example: å¹´é‡‘â†’ã­ã‚“ãã‚“, å±Šå‡ºâ†’ã¨ã©ã‘ã§, ç¢ºèªâ†’ã‹ãã«ã‚“. Numbers and symbols (%, å††, æœˆ) are allowed.'},
        }

        # ìë™ ê°ì§€ ì‹œ ìŠ¤í¬ë¦½íŠ¸ ì–¸ì–´ ë¶„ì„ (prompts ëª¨ë“ˆ ì‚¬ìš©)
        if output_language == 'auto':
            output_language = detect_language_simple(script)
            print(f"[IMAGE-ANALYZE] Auto-detected language: {output_language} (from script)")

        lang_config = language_config.get(output_language, language_config['ko'])

        # â˜… ì¹´í…Œê³ ë¦¬ ì‚¬ì „ ê°ì§€ (í† í° ìµœì í™”ë¥¼ ìœ„í•´ í•´ë‹¹ ì¹´í…Œê³ ë¦¬ í”„ë¡¬í”„íŠ¸ë§Œ ë¡œë“œ)
        pre_detected_category = detect_category_simple(script)
        print(f"[IMAGE-ANALYZE] Pre-detected category: {pre_detected_category} (keyword-based)")

        # â˜…â˜…â˜… ì¹´í…Œê³ ë¦¬ë³„ ì”¬ ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼ (prompts/category/styles.pyì—ì„œ import) â˜…â˜…â˜…
        category_style = get_category_style(pre_detected_category)
        if category_style:
            print(f"[IMAGE-ANALYZE] â˜… Using category-specific style: {category_style['name']}")

        if not script:
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # â˜… SEO í‚¤ì›Œë“œ ë¶„ì„ (YouTube ìƒìœ„ ì˜ìƒ ë¶„ì„)
        seo_data = _analyze_seo_keywords(script, output_language)
        seo_prompt = ""
        if seo_data:
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ê°ì§€ ì‹œ ì¡°ê¸° ì¤‘ë‹¨
            if seo_data.get('quota_exceeded'):
                print("[IMAGE-ANALYZE][ERROR] YouTube API í• ë‹¹ëŸ‰ ì´ˆê³¼ - íŒŒì´í”„ë¼ì¸ ì¤‘ë‹¨")
                return jsonify({
                    "ok": False,
                    "error": "YouTube API í• ë‹¹ëŸ‰ ì´ˆê³¼. íŒŒì´í”„ë¼ì¸ì„ ì¤‘ë‹¨í•©ë‹ˆë‹¤. ë‚´ì¼ ë‹¤ì‹œ ì‹œë„í•˜ì„¸ìš”.",
                    "quota_exceeded": True
                }), 200
            seo_prompt = seo_data.get('seo_prompt', '')
            print(f"[IMAGE-ANALYZE] SEO ë¶„ì„ ì™„ë£Œ: {len(seo_data.get('keywords', []))}ê°œ í‚¤ì›Œë“œ, {len(seo_data.get('recommended_keywords', []))}ê°œ ì¶”ì²œ íƒœê·¸")
        else:
            print("[IMAGE-ANALYZE] SEO ë¶„ì„ ìŠ¤í‚µ (API í‚¤ ì—†ìŒ ë˜ëŠ” ì˜¤ë¥˜)")

        # ê°€ì´ë“œ íŒŒì¼ ë¡œë“œ
        guides = load_prompt_guides()
        korean_senior = guides.get('korean_senior', {})
        expert_guide = guides.get('expert', {})

        # ì‹œëŒ€ ê°ì„± ìŠ¤íƒ€ì¼ ê°€ì´ë“œ
        era_guide = korean_senior.get('era_1970s_1980s', {}).get('visual_style', {}) if korean_senior else {}
        style_guides = {
            'realistic': 'photorealistic, high quality photography, natural lighting, sharp focus, cinematic composition',
            'animation': 'WEBTOON_STYLE'  # ì›¹íˆ° ìŠ¤íƒ€ì¼ ì²˜ë¦¬
        }

        style_desc = style_guides.get(image_style, 'photorealistic')

        # GPT-5.1ì´ ëŒ€ë³¸ ë‚´ìš©ì„ ë¶„ì„í•´ì„œ ì¹´í…Œê³ ë¦¬ë¥¼ ìë™ ê°ì§€í•˜ë„ë¡ í•¨
        # (ë” ì´ìƒ Google Sheetsì˜ category ì»¬ëŸ¼ì— ì˜ì¡´í•˜ì§€ ì•ŠìŒ)

        # ì• ë‹ˆë©”ì´ì…˜(ì›¹íˆ°) ìŠ¤íƒ€ì¼ ì „ìš© ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ - prompts ëª¨ë“ˆ ì‚¬ìš© (í† í° ìµœì í™”)
        if image_style == 'animation':
            # â˜… prompts ëª¨ë“ˆì„ ì‚¬ìš©í•œ ë™ì  í”„ë¡¬í”„íŠ¸ ìƒì„± (í† í° ìµœì í™”)
            # ì–¸ì–´ + ì¹´í…Œê³ ë¦¬ì— ë§ëŠ” ê·œì¹™ë§Œ ë¡œë“œí•˜ì—¬ í† í° ì ˆì•½
            system_prompt = build_system_prompt(
                language=output_language,
                category=pre_detected_category,
                audience=audience,
                image_count=image_count
            )
            print(f"[IMAGE-ANALYZE] Using optimized prompt for lang={output_language}, category={pre_detected_category}")

            # [TUBELENS] ì±„ë„ ìŠ¤íƒ€ì¼ ì •ë³´ê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if channel_style:
                channel_style_section = f"""

## ì±„ë„ë³„ ìŠ¤íƒ€ì¼ ê°€ì´ë“œ (TubeLens ë¶„ì„ ê²°ê³¼)
ì´ ì±„ë„ì˜ ê¸°ì¡´ ì˜ìƒ ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤. ì¼ê´€ëœ ë¸Œëœë”©ì„ ìœ„í•´ ì´ ìŠ¤íƒ€ì¼ì„ ì°¸ê³ í•˜ì„¸ìš”:

{channel_style}

**ì¤‘ìš”**: ìœ„ ë¶„ì„ëœ íŒ¨í„´ì„ ì¸ë„¤ì¼ ìƒì„± ì‹œ ë°˜ì˜í•˜ì„¸ìš”.
"""
                system_prompt += channel_style_section


        # ì½˜í…ì¸  íƒ€ì…ë³„ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë¶„ê¸° (ì‹¤ì‚¬ ìŠ¤íƒ€ì¼)
        elif content_type == 'product':
            # ìƒí’ˆ ì†Œê°œ ì½˜í…ì¸ 
            system_prompt = f"""ë‹¹ì‹ ì˜ ì—­í• ì€ ìƒí’ˆ ì†Œê°œ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ AI ì´ë¯¸ì§€ìš© í”„ë¡¬í”„íŠ¸ë¥¼ ì „ë¬¸ì ìœ¼ë¡œ ì‘ì„±í•˜ëŠ” ë¹„ì„œì…ë‹ˆë‹¤.

## í•µì‹¬ ì‘ì—…
1. ëŒ€ë³¸ì—ì„œ ì†Œê°œí•˜ëŠ” **ì œí’ˆ/ìƒí’ˆ**ì„ íŒŒì•…í•©ë‹ˆë‹¤.
2. ì œí’ˆ ì¤‘ì‹¬ì˜ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. (ì¸ë¬¼ì€ í•„ìš”í•œ ê²½ìš°ì—ë§Œ ìµœì†Œí•œìœ¼ë¡œ)

## ìƒí’ˆ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ê·œì¹™
- **ì œí’ˆì´ ì£¼ì¸ê³µ**: ì œí’ˆì„ í”„ë¡¬í”„íŠ¸ ë§¨ ì•ì— ë°°ì¹˜
- **ì œí’ˆ í´ë¡œì¦ˆì—…**: ì œí’ˆì˜ ë””í…Œì¼, ì§ˆê°, ê¸°ëŠ¥ì„ ê°•ì¡°
- **ì‚¬ìš© ì¥ë©´**: ì œí’ˆì´ ì‚¬ìš©ë˜ëŠ” í™˜ê²½/ìƒí™© (ì†ì´ë‚˜ ì¼ë¶€ ì‹ ì²´ë§Œ ë“±ì¥ ê°€ëŠ¥)
- **ì¸í¬ê·¸ë˜í”½ ìŠ¤íƒ€ì¼**: ì œí’ˆ ê¸°ëŠ¥ ì„¤ëª…ì—ëŠ” ë‹¤ì´ì–´ê·¸ë¨, ë„í‘œ ìŠ¤íƒ€ì¼
- **ê¹”ë”í•œ ë°°ê²½**: í°ìƒ‰, ê·¸ë¼ë°ì´ì…˜, ë˜ëŠ” ì œí’ˆê³¼ ì–´ìš¸ë¦¬ëŠ” ë°°ê²½

## ìƒí’ˆë³„ í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ
- ê°€ì „ì œí’ˆ: "Modern [product name], sleek design, studio lighting, white background, product photography, sharp focus, 4K detail"
- ì‹í’ˆ: "[food product] beautifully plated, appetizing presentation, natural lighting, shallow depth of field"
- ì „ìê¸°ê¸°: "Close-up of [device], highlighting key features, tech product photography, clean minimal background"
- ìƒí™œìš©í’ˆ: "[product] in use, lifestyle photography, cozy home setting, soft natural light"

## í”„ë¡¬í”„íŠ¸ ì‘ì„± ì›ì¹™
1. ì¶œë ¥ í”„ë¡¬í”„íŠ¸ëŠ” í•­ìƒ ì˜ì–´ë¡œ ì‘ì„±í•©ë‹ˆë‹¤.
2. ì œí’ˆëª…, ì œí’ˆ íŠ¹ì§•ì„ ì •í™•íˆ í¬í•¨í•©ë‹ˆë‹¤.
3. ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
   - [product] ì œí’ˆëª…ê³¼ íŠ¹ì§• - í”„ë¡¬í”„íŠ¸ ë§¨ ì•ì— ë°°ì¹˜
   - [angle] ì´¬ì˜ ê°ë„ (top-down, eye-level, 45-degree, close-up)
   - [lighting] ì¡°ëª… (studio lighting, soft box, natural light)
   - [background] ë°°ê²½ (white, gradient, lifestyle setting)
   - [style] ìŠ¤íƒ€ì¼ (product photography, commercial, lifestyle)

## ì´ë¯¸ì§€ ìŠ¤íƒ€ì¼
{style_desc}

## ì¶œë ¥ í˜•ì‹ (ë°˜ë“œì‹œ JSON)
{{
  "thumbnail": {{
    "title": "ìœ íŠœë¸Œ ì¸ë„¤ì¼ìš© í•œê¸€ ì œëª© (ì œí’ˆëª… + í•µì‹¬ ê¸°ëŠ¥/í˜œíƒ)",
    "text_lines": ["1ì¤„: ì œí’ˆëª…/ë¸Œëœë“œ", "2ì¤„: í•µì‹¬ ê¸°ëŠ¥", "3ì¤„: í˜œíƒ ê°•ì¡°", "4ì¤„: í–‰ë™ ìœ ë„"],
    "highlight_line": 2,
    "prompt": "Product hero shot - [product] with dramatic lighting, premium feel, commercial photography"
  }},
  "scenes": [
    {{
      "scene_number": 1,
      "narration": "í•œêµ­ì–´ ë‚˜ë ˆì´ì…˜ (ì›ë³¸ ëŒ€ë³¸ ê¸°ë°˜)",
      "image_prompt": "Product-focused prompt: [product details], [angle], [lighting], [background], [style]"
    }}
  ]
}}"""
        else:
            # ë“œë¼ë§ˆ/ìŠ¤í† ë¦¬ ì½˜í…ì¸  (ê¸°ë³¸ê°’) - audienceì— ë”°ë¼ ë‹¤ë¥¸ ê·œì¹™ ì ìš©
            # audienceë³„ ì¸ë„¤ì¼ ê·œì¹™ ì„¤ì •
            if audience == 'general':
                thumbnail_rules = """## ì¼ë°˜ìš© ì¸ë„¤ì¼ ë¬¸êµ¬ ê·œì¹™ (ì¤‘ìš”!)
ì¼ë°˜ íƒ€ê²Ÿ(20-40ëŒ€) ì¸ë„¤ì¼ì€ "ê¶ê¸ˆì¦/ìê·¹"ì„ ìœ ë°œí•´ì•¼ í•©ë‹ˆë‹¤.

1. **ë¬¸êµ¬ ê¸¸ì´**: 4-7ì (ì§§ê³  ê°•ë ¬í•˜ê²Œ!)
2. **ë¬¸êµ¬ ìœ í˜•**:
   - ìê·¹í˜•: "ê²°êµ­ í„°ì¡Œë‹¤", "ì´ê²Œ ì‹¤í™”?", "ì™„ì „ ë¯¸ì³¤ë‹¤"
   - ê¶ê¸ˆì¦í˜•: "ì™œ ì•„ë¬´ë„ ì•ˆì•Œë ¤ì¤¬ì§€?", "ì´ê²ƒë§Œ ì•Œë©´", "ì§„ì§œ ì´ìœ "
   - ì¶©ê²©í˜•: "ì†Œë¦„ ë‹ì•˜ë‹¤", "ì—­ëŒ€ê¸‰ ë°˜ì „", "ì¶©ê²© ì‹¤í™”"
3. **ìƒ‰ìƒ ì¡°í•©**: í°ìƒ‰+ê²€ì •, ë¹¨ê°•+ê²€ì • (ê°•í•œ ëŒ€ë¹„)
4. **êµ¬ë„**: ì¤‘ì•™ í…ìŠ¤íŠ¸ + ì–´ë‘ìš´ ë°°ê²½/ì‹¤ë£¨ì—£"""
                thumbnail_color = "#FFFFFF"
                outline_color = "#000000"
            else:
                thumbnail_rules = """## ì‹œë‹ˆì–´ìš© ì¸ë„¤ì¼ ë¬¸êµ¬ ê·œì¹™ (ì¤‘ìš”!)
ì‹œë‹ˆì–´ íƒ€ê²Ÿ(50-70ëŒ€) ì¸ë„¤ì¼ì€ "ê²½í—˜ì„ ë– ì˜¬ë¦¬ê²Œ" í•´ì•¼ í•©ë‹ˆë‹¤.

1. **ë¬¸êµ¬ ê¸¸ì´**: 8-12ì (ë…¸ì•ˆ ê³ ë ¤, ì½ê¸° ì‰½ê²Œ)
2. **ë¬¸êµ¬ ìœ í˜•**:
   - íšŒìƒí˜•: "ê·¸ë‚ ì„ ìŠì§€ ì•ŠëŠ”ë‹¤", "ì²˜ìŒì—” ëª°ëë‹¤", "ëŒì•„ë³´ë©´ ëˆˆë¬¼ì´ ë‚œë‹¤"
   - í›„íšŒ/êµí›ˆí˜•: "í•˜ëŠ” ê²Œ ì•„ë‹ˆì—ˆë‹¤", "ëŠ¦ê²Œ ì•Œì•˜ë‹¤", "ì™œ ê·¸ë¬ì„ê¹Œ"
   - ê²½í—˜ ê³µìœ í˜•: "ë‹¤ ê²ªì–´ë´¤ë‹¤", "ë‚˜ë„ ê·¸ë¬ë‹¤", "ëˆ„êµ¬ë‚˜ ê·¸ëŸ° ë‚  ìˆë‹¤"
3. **ìƒ‰ìƒ ì¡°í•©**: ë…¸ë‘+ê²€ì •ì´ ìµœê³  CTR (text_colorì— ë°˜ì˜)
4. **êµ¬ë„**: ì™¼ìª½ ìƒë‹¨ í…ìŠ¤íŠ¸ + ì˜¤ë¥¸ìª½ ì¸ë¬¼/ìƒí™©"""
                thumbnail_color = "#FFD700"
                outline_color = "#000000"

            system_prompt = f"""You are an AI assistant that analyzes scripts and generates image prompts.

## âš ï¸ LANGUAGE RULE (CRITICAL!) âš ï¸
Output Language: {lang_config['name']} ({lang_config['native']})
{lang_config['instruction']}
- YouTube titles, description â†’ {lang_config['name']}
- Thumbnail text â†’ {lang_config['name']}
- Narration â†’ {lang_config['name']}
- ONLY image_prompt â†’ Always in English (for AI image generation)

Target audience: {'General (20-40s)' if audience == 'general' else 'Senior (50-70s)'}

## âš ï¸âš ï¸âš ï¸ CRITICAL: KOREAN WEBTOON/MANHWA STYLE (MUST FOLLOW!) âš ï¸âš ï¸âš ï¸
- ABSOLUTELY NO photorealistic human faces! Use KOREAN WEBTOON/MANHWA style only!
- ABSOLUTELY NO stickman/stick figures!
- Character style: "Korean WEBTOON/manhwa style character with EXAGGERATED EXPRESSION (shocked face, wide eyes, open mouth, sweat drops), 30-50 year old Korean man or woman, clean bold outlines, vibrant flat colors"
- Background: Detailed backgrounds related to the scene context
- Style: "Korean webtoon/manhwa style illustration with comic-style expression marks"

## Core Tasks
1. Extract protagonist's age, gender, occupation, appearance from the script.
2. Generate consistent image prompts based on extracted character info (KOREAN WEBTOON STYLE).
3. Generate YouTube thumbnail text and prompts for the target audience.

## Character Prompt Rules (for image_prompt - always in English)
- âš ï¸ ALL CHARACTERS = KOREAN WEBTOON/MANHWA STYLE! No photorealistic faces, no stickman!
- Character: "Korean WEBTOON/manhwa style character with EXAGGERATED EXPRESSION, 30-50 year old Korean man or woman, clean bold outlines"
- Background: Detailed backgrounds with vibrant colors, related to the scene context
- Style: Clean bold outlines, vibrant flat colors, comic-style expression marks (sweat drops, impact lines)
- Actions/poses should be dynamic with exaggerated webtoon expressions
- Emotions shown through exaggerated facial expressions (wide eyes, open mouth, sweat drops, impact lines)

{thumbnail_rules}

## Prompt Writing Principles
1. **image_prompt is ALWAYS in English** (for AI image generation)
2. Write concise but information-dense prompts.
3. Include these elements:
   - [subject] Main subject - place at the beginning (detailed character features)
   - [environment] Background, location
   - [lighting] Lighting (soft natural light, warm golden hour, dramatic side lighting)
   - [color] Color tone (warm tones, muted colors, film color grading)
   - [camera] Shot type (wide/medium/close-up), lens (50mm/85mm), depth of field
   - [style] Style
   - [mood] Emotion/atmosphere

## Image Style
{style_desc}

## ğŸ¯ ìœ íŠœë¸Œ ì œëª© ìƒì„± ê·œì¹™
- ê¸¸ì´: **18-32ì** (ê³µë°± í¬í•¨)
- **ìˆ«ì 1ê°œ ì´ìƒ í•„ìˆ˜**
- ì‹¬ë¦¬ íŠ¸ë¦¬ê±° **2ê°œ ì´ìƒ**: í˜¸ê¸°ì‹¬ê°­, ê¸´ê¸‰ì„±, ìˆ«ì, íƒ€ê¹ƒëª…ì‹œ, ê²°ê³¼ì œì‹œ
- ë‚šì‹œì„±/ê³¼ì¥ **ê¸ˆì§€** ("ì¶©ê²©", "ì†Œë¦„" ë“± ê¸ˆì§€)
- íƒ€ê²Ÿë³„: ì‹œë‹ˆì–´=íšŒìƒí˜•/ê°ì„±ì , ì¼ë°˜=ì •ë³´í˜•/í•´ê²°í˜•
- **3ê°€ì§€ ìŠ¤íƒ€ì¼**: curiosity(í˜¸ê¸°ì‹¬), solution(í•´ê²°), authority(ê¶Œìœ„)

## ğŸ¯ ìœ íŠœë¸Œ ì„¤ëª…ë€ ìƒì„± ê·œì¹™
- **ì²« 2ì¤„**: ê²€ìƒ‰ ë…¸ì¶œ êµ¬ê°„ - í•µì‹¬ ì£¼ì œ + ì‹œì²­ì ì´ë“ + í‚¤ì›Œë“œ í¬í•¨
- **ë³¸ë¬¸**: 600-1200ì, ì‚¬ì‹¤ + í•´ì„ + ì¸ì‚¬ì´íŠ¸ ì¤‘ì‹¬
- **ì±•í„°**: ì”¬ë³„ chapter_title í™œìš©, "00:00 ì œëª©" í˜•ì‹
- **í•´ì‹œíƒœê·¸**: 3-5ê°œ (ì£¼ì œíƒœê·¸ + ì¹´í…Œê³ ë¦¬íƒœê·¸)
- **íƒœê·¸**: 5-12ê°œ (ë„“ì€/êµ¬ì²´/ë³€í˜•/ì±„ë„ í‚¤ì›Œë“œ)
- **í†¤**: ê³¼ì¥ ê¸ˆì§€, íŒ©íŠ¸ â†’ ì˜ë¯¸ â†’ ì•¡ì…˜ ìˆœì„œ

## âš ï¸ ê³ ì • ëŒ“ê¸€ (pin_comment) ìƒì„± ê·œì¹™ - í•„ìˆ˜!
- **ë°˜ë“œì‹œ ìƒì„±í•  ê²ƒ!** ì ˆëŒ€ ë¹ˆ ê°’ìœ¼ë¡œ ë‘ì§€ ë§ˆì„¸ìš”!
- **ì–¸ì–´**: ëŒ€ë³¸ê³¼ ë™ì¼í•œ ì–¸ì–´ë¡œ ì‘ì„± (í•œêµ­ì–´ ëŒ€ë³¸ â†’ í•œêµ­ì–´ ëŒ“ê¸€)
- **ê¸¸ì´**: 50-150ì
- **êµ¬ì¡°**: [í•µì‹¬ ë‚´ìš© 1-2ë¬¸ì¥] + [ì‹œì²­ì ì°¸ì—¬ ìœ ë„ ì§ˆë¬¸ 1ê°œ]
- **ì§ˆë¬¸ ì˜ˆì‹œ**:
  - "ì—¬ëŸ¬ë¶„ì€ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”?"
  - "ë¹„ìŠ·í•œ ê²½í—˜ ìˆìœ¼ì‹  ë¶„ ëŒ“ê¸€ë¡œ ê³µìœ í•´ì£¼ì„¸ìš”!"
  - "ì´ ì¤‘ì—ì„œ ê°€ì¥ ê³µê°ë˜ëŠ” ê±´ ë­”ê°€ìš”?"
  - "ë” ì•Œê³  ì‹¶ì€ ë‚´ìš© ìˆìœ¼ë©´ ëŒ“ê¸€ ë‚¨ê²¨ì£¼ì„¸ìš”!"

{seo_prompt}
{benchmark_prompt}

## Output Format (MUST be valid JSON)
{{
  "youtube": {{
    "title": "ë©”ì¸ ì œëª© (18-32ì, ìˆ«ì í¬í•¨, ì‹¬ë¦¬ íŠ¸ë¦¬ê±° 2ê°œ ì´ìƒ)",
    "title_options": [
      {{"style": "curiosity", "title": "í˜¸ê¸°ì‹¬í˜• ì œëª©"}},
      {{"style": "solution", "title": "í•´ê²°í˜• ì œëª©"}},
      {{"style": "authority", "title": "ê¶Œìœ„í˜• ì œëª©"}}
    ],
    "description": {{
      "full_text": "ìœ íŠœë¸Œ ì„¤ëª…ë€ ì „ì²´ í…ìŠ¤íŠ¸ (600-1200ì)",
      "preview_2_lines": "ê²€ìƒ‰ ê²°ê³¼ì— ë…¸ì¶œë˜ëŠ” ì²« 2ì¤„ ìš”ì•½",
      "chapters": [{{"time": "00:00", "title": "ì±•í„° ì œëª©"}}]
    }},
    "hashtags": ["#ì£¼ì œíƒœê·¸1", "#ì£¼ì œíƒœê·¸2", "#ì¹´í…Œê³ ë¦¬íƒœê·¸"],
    "tags": ["ë„“ì€ í‚¤ì›Œë“œ", "êµ¬ì²´ í‚¤ì›Œë“œ", "ë³€í˜• í‚¤ì›Œë“œ"],
    "pin_comment": "âš ï¸ í•„ìˆ˜! 50-150ì ê³ ì • ëŒ“ê¸€: [ì˜ìƒ í•µì‹¬ ë‚´ìš© 1-2ë¬¸ì¥] + [ì°¸ì—¬ ìœ ë„ ì§ˆë¬¸]. ì˜ˆ: 'ì˜¤ëŠ˜ ì˜ìƒì—ì„œ ë‹¤ë£¬ XX ì •ë§ ë†€ëì§€ ì•Šë‚˜ìš”? ì—¬ëŸ¬ë¶„ì€ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”? ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”!'"
  }},
  "thumbnail": {{
    "thumbnail_text_candidates": [
      "ì¸ë„¤ì¼ ë¬¸êµ¬ í›„ë³´ 1 (10~15ì, ìµœëŒ€ 2ì¤„, ì¤„ë°”ê¿ˆ ì‹œ \\n ì‚¬ìš©)",
      "ì¸ë„¤ì¼ ë¬¸êµ¬ í›„ë³´ 2",
      "ì¸ë„¤ì¼ ë¬¸êµ¬ í›„ë³´ 3"
    ],
    "best_combo": {{
      "chosen_title": "youtube.title_options ì¤‘ ê°€ì¥ ì í•©í•œ ì œëª©",
      "chosen_thumbnail_text": "thumbnail_text_candidates ì¤‘ ê°€ì¥ ì í•©í•œ ë¬¸êµ¬",
      "reason": "ì´ ì¡°í•©ì„ ì„ íƒí•œ ì´ìœ ë¥¼ 2~4ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…"
    }},
    "layout_suggestion": {{
      "layout_type": "top_text_bottom_image | left_text_right_image | center_text_background_image | split_before_after | collage ì¤‘ í•˜ë‚˜",
      "layout_description": "í…ìŠ¤íŠ¸ ìœ„ì¹˜, ì¸ë¬¼/ì´ë¯¸ì§€ ìœ„ì¹˜, ì‚¬ìš©í•  ì•„ì´ì½˜ ë“±ì„ 3~6ë¬¸ì¥ìœ¼ë¡œ êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…"
    }},
    "image_prompt": "ì˜ì–´ë¡œ ì‘ì„±ëœ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ (16:9, high resolution, no text, without any words or letters ì¡°ê±´ í¬í•¨)",
    "design_notes": "í°íŠ¸ êµµê¸°, ìƒ‰ìƒ ëŒ€ë¹„, ê°•ì¡° ìƒ‰, ê·¸ë¼ë°ì´ì…˜/ë¹„ë„¤íŒ… ì‚¬ìš© ë“± ë””ìì´ë„ˆì—ê²Œ ì¤„ êµ¬ì²´ì ì¸ ì§€ì¹¨ì„ 4~8ë¬¸ì¥ìœ¼ë¡œ",
    "consistency_check": {{
      "ctr_score": 7,
      "watchtime_score": 8,
      "consistency_note": "ì¸ë„¤ì¼Â·ì œëª©Â·ì˜ìƒ ë‚´ìš©ì˜ ì—°ê²°ì„±ì„ 3~6ë¬¸ì¥ìœ¼ë¡œ ì„¤ëª…"
    }},
    "ai_prompts": {{
      "A": {{"description": "ìŠ¤íƒ€ì¼ A ì„¤ëª…", "prompt": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸", "text_overlay": {{"main": "ë©”ì¸ í…ìŠ¤íŠ¸ (ìµœëŒ€ 6ì)", "sub": "ì„œë¸Œ í…ìŠ¤íŠ¸ (ìµœëŒ€ 15ì)"}}, "style": "news ë˜ëŠ” story"}},
      "B": {{"description": "ìŠ¤íƒ€ì¼ B ì„¤ëª…", "prompt": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸", "text_overlay": {{"main": "ë©”ì¸ í…ìŠ¤íŠ¸", "sub": "ì„œë¸Œ í…ìŠ¤íŠ¸"}}, "style": "news ë˜ëŠ” story"}},
      "C": {{"description": "ìŠ¤íƒ€ì¼ C ì„¤ëª…", "prompt": "ì˜ë¬¸ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸", "text_overlay": {{"main": "ë©”ì¸ í…ìŠ¤íŠ¸", "sub": "ì„œë¸Œ í…ìŠ¤íŠ¸"}}, "style": "news ë˜ëŠ” story"}}
    }}
  }},
  "scenes": [
    {{
      "scene_number": 1,
      "narration": "âš ï¸ EXACT TEXT from the script - COPY-PASTE the original sentences, DO NOT summarize!",
      "image_prompt": "English image prompt..."
    }}
  ]
}}

## âš ï¸ CRITICAL: AI THUMBNAIL PROMPTS RULES âš ï¸
The "ai_prompts" field generates 3 different YouTube thumbnails for A/B testing.

### â˜…â˜…â˜… ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ (WEBTOON/COMIC STYLE) â˜…â˜…â˜…
âš ï¸ ëª¨ë“  ì¸ë„¤ì¼ì€ ì›¹íˆ°/ë§Œí™” ì¼ëŸ¬ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ë¡œ ì œì‘!
âš ï¸ NO photorealistic, NO stickman - ì›¹íˆ° ìŠ¤íƒ€ì¼ë§Œ!

**ìºë¦­í„° êµ­ì  ê·œì¹™ (ì–¸ì–´ì— ë”°ë¼ ê²°ì •):**
- í•œêµ­ì–´ ëŒ€ë³¸ â†’ í•œêµ­ì¸ ìºë¦­í„° (Korean man/woman)
- ì¼ë³¸ì–´ ëŒ€ë³¸ â†’ ì¼ë³¸ì¸ ìºë¦­í„° (Japanese man/woman)
- ì˜ì–´ ëŒ€ë³¸ â†’ ì„œì–‘ì¸ ìºë¦­í„° (Western man/woman)

**ìºë¦­í„° ìŠ¤íƒ€ì¼:**
- ì›¹íˆ° ìŠ¤íƒ€ì¼ ìºë¦­í„° (webtoon style character)
- âš ï¸ ê·¹ë‹¨ì ìœ¼ë¡œ ê³¼ì¥ëœ í‘œì • í•„ìˆ˜! (THIS IS A THUMBNAIL - EXAGGERATE!)
- 30-40ëŒ€ ë‚¨ì„±/ì—¬ì„± (ìƒí™©ì— ë§ê²Œ, êµ­ì ì€ ìœ„ ê·œì¹™ ë”°ë¦„)
- ì„ ëª…í•œ ì™¸ê³½ì„ , ê¹”ë”í•œ ì±„ìƒ‰

**â˜…â˜…â˜… í‘œì • í•„ìˆ˜ ìš”êµ¬ì‚¬í•­ (ê°€ì¥ ì¤‘ìš”!) â˜…â˜…â˜…**
âš ï¸ ì¸ë„¤ì¼ì€ í´ë¦­ì„ ìœ ë„í•´ì•¼ í•©ë‹ˆë‹¤! ë¬´í‘œì •/ì°¨ë¶„í•œ í‘œì • ì ˆëŒ€ ê¸ˆì§€!
- ëˆˆ: í‰ì†Œì˜ 2ë°° í¬ê¸°ë¡œ ê·¹ë‹¨ì ìœ¼ë¡œ í¬ê²Œ, í°ììœ„ê°€ ë³´ì´ê²Œ
- ì…: í¬ê²Œ ë²Œë ¤ì„œ ì´ë¹¨ì´ ë³´ì´ê±°ë‚˜, ê½‰ ë‹¤ë¬¼ê³  ê¸´ì¥í•œ í‘œì •
- ëˆˆì¹: ê·¹ë‹¨ì ìœ¼ë¡œ ì¹˜ì¼œì˜¬ë¦¬ê±°ë‚˜(ë†€ëŒ) ê¹Šì´ ì°Œí‘¸ë¦¬ê¸°(ì¶©ê²©/ë¶„ë…¸)
- ì–¼êµ´: ë•€ë°©ìš¸, ëˆˆë¬¼, í™ì¡°, ê°ì •ì„  ë“± ë§Œí™”ì  íš¨ê³¼ í•„ìˆ˜
- ëª¸: ëº¨ì— ì† ëŒ€ê¸°, ë¨¸ë¦¬ ì¥ì–´ëœ¯ê¸°, ì†ê°€ë½ ê°€ë¦¬í‚¤ê¸° ë“± ê³¼ì¥ëœ í¬ì¦ˆ
- ì°¸ê³ : í•œêµ­ ì›¹íˆ° ë¦¬ì•¡ì…˜ ì¥ë©´, ğŸ˜±ğŸ˜¨ğŸ˜² ì´ëª¨ì§€ í‘œì • ìˆ˜ì¤€ìœ¼ë¡œ ê³¼ì¥!

**â›” ì ˆëŒ€ ê¸ˆì§€ (ë¬´ì¡°ê±´ í”¼í•  ê²ƒ!):**
- ì°¨ë¶„í•œ í‘œì •, ë¬´í‘œì •, ì‚´ì§ ë¯¸ì†Œ
- í‰í™”ë¡œìš´ í‘œì •, ë¯¸ë¬˜í•œ ê°ì •
- í˜„ì‹¤ì ì¸ í‘œì • ë¹„ìœ¨ (ë§Œí™”ë‹ˆê¹Œ ê³¼ì¥í•´ì•¼ í•¨!)

**ë°°ê²½ ìŠ¤íƒ€ì¼:**
- ì£¼ì œì™€ ê´€ë ¨ëœ ë°°ê²½/ì†Œí’ˆ í¬í•¨
- ì˜ˆ: ì˜·ê°€ê²Œ+íŒ¨ë”©, ìˆ˜ì¡±ê´€+ë¬¼ê³ ê¸°, ì²­êµ¬ì„œ+ëˆ ë“±
- ë§Œí™”ì  íš¨ê³¼ì„ , ì¶©ê²© ì´í™íŠ¸ (ë°©ì‚¬í˜• ì„ , ë²ˆê°œ ë“±)

**êµ¬ë„:**
- ìºë¦­í„°ê°€ í™”ë©´ ì˜¤ë¥¸ìª½ ë˜ëŠ” ì¤‘ì•™ì— ë°°ì¹˜
- ì™¼ìª½ì— í…ìŠ¤íŠ¸ ê³µê°„ í™•ë³´
- ë°°ê²½ ì†Œí’ˆì´ ìƒí™© ì„¤ëª…

### â˜…â˜…â˜… í”„ë¡¬í”„íŠ¸ ì‘ì„± ê·œì¹™ â˜…â˜…â˜…
**ë°˜ë“œì‹œ í¬í•¨í•  í‚¤ì›Œë“œ:**
- "[êµ­ì ] webtoon style illustration" (ì˜ˆ: "Korean/Japanese/Western webtoon style")
- "EXTREMELY exaggerated shocked expression" (ê·¹ë‹¨ì  ê³¼ì¥ í•„ìˆ˜!)
- "eyes wide open 2x larger than normal, mouth wide open showing teeth" (êµ¬ì²´ì  í‘œì • ë¬˜ì‚¬)
- "comic style expression marks, sweat drops, impact lines"
- "NO calm face, NO neutral expression" (ë¬´í‘œì • ê¸ˆì§€ ëª…ì‹œ!)
- "YouTube thumbnail, 16:9"

**í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ (í•œêµ­ì–´ ëŒ€ë³¸):**
- "Korean webtoon style illustration, Korean man in his 30s with EXTREMELY EXAGGERATED SHOCKED EXPRESSION - eyes 2x larger than normal with visible whites, mouth WIDE OPEN showing teeth, eyebrows raised extremely high, multiple sweat drops, hands on cheeks in disbelief, standing in front of clothing store with colorful padded jackets, comic style impact lines radiating from face, clean lines, vibrant colors, NO calm face, YouTube thumbnail 16:9"

**í”„ë¡¬í”„íŠ¸ ì˜ˆì‹œ (ì¼ë³¸ì–´ ëŒ€ë³¸):**
- "Japanese webtoon style illustration, Japanese man in his 30s with EXTREMELY EXAGGERATED SHOCKED EXPRESSION - eyes 2x larger than normal, pupils dilated, jaw dropped with mouth wide open, visible sweat drops, dramatic body language, standing in front of office building, comic style impact lines, clean lines, vibrant colors, NO neutral expression, YouTube thumbnail 16:9"

### â˜…â˜…â˜… A/B/C ìŠ¤íƒ€ì¼ ê°€ì´ë“œ â˜…â˜…â˜…
- **A**: ìºë¦­í„° ì¤‘ì‹¬ - ê·¹ë‹¨ì ìœ¼ë¡œ ê³¼ì¥ëœ í‘œì •ì˜ ìºë¦­í„° (ğŸ˜± ìˆ˜ì¤€) + ê´€ë ¨ ë°°ê²½
- **B**: ìƒí™© ì¤‘ì‹¬ - ì¶©ê²©ë°›ì€ ìºë¦­í„° + ë¬¸ì œ ìƒí™©ì„ ë³´ì—¬ì£¼ëŠ” ì†Œí’ˆ/ë°°ê²½
- **C**: ëŒ€ë¹„/ë¹„êµ - ë¶„í•  í™”ë©´ ë˜ëŠ” Before/After ëŠë‚Œ (ìºë¦­í„° í‘œì •ì€ ì—¬ì „íˆ ê³¼ì¥!)

## âš ï¸ CRITICAL: TEXT_OVERLAY RULES (ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ ê·œì¹™) âš ï¸
The "text_overlay" text MUST match the OUTPUT LANGUAGE!
âš ï¸ IMAGE GENERATION MODELS STRUGGLE WITH LONG TEXT! Keep it SHORT!

### ğŸŒ ì–¸ì–´ ê·œì¹™: OUTPUT LANGUAGE = ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ ì–¸ì–´!

**MAIN TEXT RULES (ì–¸ì–´ë³„):**
- í•œêµ­ì–´: ìµœëŒ€ 6ì | ì¼ë³¸ì–´: ìµœëŒ€ 8ì | ì˜ì–´: ìµœëŒ€ 15ì
- Use SIMPLE, COMMON words - NO typos, NO made-up words

**SUB TEXT RULES (ì–¸ì–´ë³„):**
- í•œêµ­ì–´: ìµœëŒ€ 15ì | ì¼ë³¸ì–´: ìµœëŒ€ 20ì | ì˜ì–´: ìµœëŒ€ 40ì

**GOOD EXAMPLES:**
- í•œêµ­ì–´: main: "ìš´ëª…ì˜ ì„ íƒ", sub: "ê·¸ ë‚ ì˜ ê²°ì •ì´ ëª¨ë“  ê±¸ ë°”ê¿¨ë‹¤"
- ì¼ë³¸ì–´: main: "é‹å‘½ã®ç¬é–“", sub: "ã‚ã®æ—¥ã®æ±ºæ–­ãŒå…¨ã¦ã‚’å¤‰ãˆãŸ"
- ì˜ì–´: main: "THE MOMENT", sub: "One decision changed everything"

**BAD EXAMPLES (ì ˆëŒ€ ê¸ˆì§€):**
- "ì«“ì´ ì«“ì•„ê°€ë˜" âŒ (ì˜¤íƒ€) | "ê·¸ë‚ ì„ ìŠì§€ ëª»í•´ìš” ì •ë§ë¡œ" âŒ (ë„ˆë¬´ ê¹€)

## âš ï¸ CRITICAL: NARRATION RULE âš ï¸
The "narration" field MUST contain the EXACT ORIGINAL TEXT from the script!
- DO NOT summarize or paraphrase - COPY-PASTE the exact sentences
- This helps the user know EXACTLY where to place each image in the video"""

        # Style-specific user prompt
        if image_style == 'animation':
            # Thumbnail rules by audience
            if audience == 'general':
                thumb_instruction = "Thumbnail text for General audience (4-7 chars, provocative/shocking style)"
            else:
                thumb_instruction = "Thumbnail text for Senior audience (8-12 chars, nostalgic/reflective style)"

            # â˜…â˜…â˜… ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤íƒ€ì¼ ë¶„ê¸° â˜…â˜…â˜…
            if category_style:
                # history, news, mystery ë“± íŠ¹ì • ì¹´í…Œê³ ë¦¬ìš© ìŠ¤íƒ€ì¼
                user_prompt = f"""Script:
{script}

â˜…â˜…â˜… OUTPUT LANGUAGE: {lang_config['name']} ({lang_config['native']}) â˜…â˜…â˜…
{lang_config['instruction']}
- ONLY image_prompt should be in English

Split this script into exactly {image_count} scenes and generate "{category_style['name']}" style image prompts.
Target audience: {'General (20-40s)' if audience == 'general' else 'Senior (50-70s)'}
Detected category: {pre_detected_category}

â˜…â˜…â˜… MANDATORY IMAGE STYLE: {category_style['name']} â˜…â˜…â˜…
Every scene's image_prompt MUST follow this template:
{category_style['style_prompt']}

â›” FORBIDDEN: {category_style['forbidden']}
âœ… REQUIRED: {category_style['required']}

Rules:
1. Generate exactly {image_count} scenes (no more, no less)
2. EVERY image_prompt MUST use the {category_style['name']} style template above
3. Replace [SCENE DESCRIPTION] with the actual scene content
4. {thumb_instruction}
5. âš ï¸ NARRATION = EXACT SCRIPT TEXT! Copy-paste the original sentences from the script. DO NOT summarize or paraphrase!

image_prompt MUST be in English."""
            else:
                # ê¸°ë³¸ ì›¹íˆ° ìŠ¤íƒ€ì¼
                user_prompt = f"""Script:
{script}

â˜…â˜…â˜… OUTPUT LANGUAGE: {lang_config['name']} ({lang_config['native']}) â˜…â˜…â˜…
{lang_config['instruction']}
- ONLY image_prompt should be in English

Split this script into exactly {image_count} scenes and generate "KOREAN WEBTOON/MANHWA STYLE" image prompts.
Target audience: {'General (20-40s)' if audience == 'general' else 'Senior (50-70s)'}

Core Style (MUST follow):
- Character = Korean WEBTOON/manhwa style with EXTREMELY EXAGGERATED EXPRESSIONS
- Character age = 30-50 year old Korean man or woman (match the story context)
- Style = Clean bold outlines, vibrant flat colors, comic-style expression marks
- Background = Detailed backgrounds related to the scene context

â˜…â˜…â˜… THUMBNAIL CHARACTER EXPRESSION (MOST IMPORTANT!) â˜…â˜…â˜…
This is for YouTube thumbnails - characters MUST have OVER-THE-TOP dramatic expressions!
- Eyes: 2x larger than normal, visible whites of eyes, pupils tiny or dilated
- Mouth: Wide open showing teeth OR tightly clenched with tension
- Eyebrows: Extremely raised (surprised) OR deeply furrowed (shocked)
- Face: Sweat drops, tears, emotion lines, blush marks
- Body: Hands on cheeks, pulling hair, dramatic pointing, defensive pose
- Reference: Like ğŸ˜±ğŸ˜¨ğŸ˜² emoji expressions

â›” FORBIDDEN: NO calm face, NO neutral expression, NO slight smile, NO subtle emotions!

Rules:
1. Generate exactly {image_count} scenes (no more, no less)
2. Character MUST be KOREAN WEBTOON/MANHWA style - NO photorealistic, NO stickman!
3. Character: "Korean WEBTOON/manhwa style character with EXTREMELY EXAGGERATED EXPRESSION (eyes 2x larger, mouth wide open), 30-50 year old Korean man or woman, clean bold outlines"
4. Character face MUST have: EXTREME exaggerated expression - NO calm or neutral faces allowed!
5. NO photorealistic humans, NO stickman/stick figures, NO Japanese anime style!
6. Express emotion through EXTREME facial expressions (eyes 2x size, jaw dropped, visible sweat drops, impact lines radiating from face)
7. Add these tags to every image_prompt: Korean webtoon style, manhwa illustration, EXTREMELY exaggerated shocked expression, eyes wide open, mouth open, clean bold outlines, NO photorealistic, NO stickman, NO calm face
8. {thumb_instruction}
9. âš ï¸ NARRATION = EXACT SCRIPT TEXT! Copy-paste the original sentences from the script. DO NOT summarize or paraphrase!

image_prompt MUST be in English."""
        else:
            # Thumbnail rules by audience
            if audience == 'general':
                thumbnail_instruction = "Thumbnail text for General audience (4-7 chars, provocative/curiosity/shocking style)"
            else:
                thumbnail_instruction = "Thumbnail text for Senior audience (8-12 chars, nostalgic/reflective/experience-sharing style)"

            # â˜…â˜…â˜… ì¹´í…Œê³ ë¦¬ë³„ ìŠ¤íƒ€ì¼ ë¶„ê¸° â˜…â˜…â˜…
            if category_style:
                # history, news, mystery ë“± íŠ¹ì • ì¹´í…Œê³ ë¦¬ìš© ìŠ¤íƒ€ì¼
                user_prompt = f"""Script:
{script}

â˜…â˜…â˜… OUTPUT LANGUAGE: {lang_config['name']} ({lang_config['native']}) â˜…â˜…â˜…
{lang_config['instruction']}
- ONLY image_prompt should be in English

Split this script into exactly {image_count} scenes and generate "{category_style['name']}" style image prompts.
Target audience: {'General (20-40s)' if audience == 'general' else 'Senior (50-70s)'}
Detected category: {pre_detected_category}

â˜…â˜…â˜… MANDATORY IMAGE STYLE: {category_style['name']} â˜…â˜…â˜…
Every scene's image_prompt MUST follow this template:
{category_style['style_prompt']}

â›” FORBIDDEN: {category_style['forbidden']}
âœ… REQUIRED: {category_style['required']}

Rules:
1. Generate exactly {image_count} scenes (no more, no less)
2. EVERY image_prompt MUST use the {category_style['name']} style template above
3. Replace [SCENE DESCRIPTION] with the actual scene content
4. {thumbnail_instruction}
5. image_prompt MUST be in English

âš ï¸âš ï¸âš ï¸ CRITICAL - NARRATION RULE âš ï¸âš ï¸âš ï¸
- DIVIDE the script into {image_count} equal parts
- Each scene's "narration" = COPY-PASTE that part of the ORIGINAL SCRIPT
- DO NOT summarize! DO NOT write new sentences!
- Script is {len(script)} chars â†’ each narration should be ~{len(script) // image_count} chars
- If your total narration is less than {len(script) * 0.9} chars, YOU ARE DOING IT WRONG!"""
            else:
                # ê¸°ë³¸ ìŠ¤íƒ€ì¼
                user_prompt = f"""Script:
{script}

â˜…â˜…â˜… OUTPUT LANGUAGE: {lang_config['name']} ({lang_config['native']}) â˜…â˜…â˜…
{lang_config['instruction']}
- ONLY image_prompt should be in English

Split this script into exactly {image_count} scenes and generate professional image prompts.
Target audience: {'General (20-40s)' if audience == 'general' else 'Senior (50-70s)'}

Rules:
1. Generate exactly {image_count} scenes (no more, no less)
2. {thumbnail_instruction}
3. image_prompt MUST be in English, following the prompt writing principles above.
4. âš ï¸ ALL CHARACTERS = KOREAN WEBTOON/MANHWA STYLE! No photorealistic humans, no stickman.

âš ï¸âš ï¸âš ï¸ CRITICAL - NARRATION RULE âš ï¸âš ï¸âš ï¸
- DIVIDE the script into {image_count} equal parts
- Each scene's "narration" = COPY-PASTE that part of the ORIGINAL SCRIPT
- DO NOT summarize! DO NOT write new sentences!
- Script is {len(script)} chars â†’ each narration should be ~{len(script) // image_count} chars
- If your total narration is less than {len(script) * 0.9} chars, YOU ARE DOING IT WRONG!"""

        print(f"[IMAGE-ANALYZE] GPT-4o generating prompts... (style: {image_style}, content: {content_type}, audience: {audience}, language: {output_language}, category: {pre_detected_category})")

        # GPT-4oëŠ” Chat Completions API ì‚¬ìš©
        # max_tokens=16384: ê¸´ ëŒ€ë³¸(20ë¶„+)ì˜ ì „ì²´ narrationì„ í¬í•¨í•˜ê¸° ìœ„í•´ í•„ìš”
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt + "\n\nIMPORTANT: Respond ONLY with valid JSON. No other text, just pure JSON output."}
            ],
            temperature=0.7,
            max_tokens=16384,
            response_format={"type": "json_object"}
        )

        # ì‘ë‹µ ì™„ë£Œ ì²´í¬ (truncation ê°ì§€)
        finish_reason = response.choices[0].finish_reason
        usage = getattr(response, 'usage', None)
        print(f"[IMAGE-ANALYZE] GPT-4o ì‘ë‹µ ì™„ë£Œ - finish_reason: {finish_reason}")
        if usage:
            print(f"[IMAGE-ANALYZE] í† í° ì‚¬ìš©ëŸ‰ - input: {usage.prompt_tokens}, output: {usage.completion_tokens}")
        if finish_reason == 'length':
            print(f"[IMAGE-ANALYZE] âš ï¸ ê²½ê³ : ì‘ë‹µì´ max_tokensì— ì˜í•´ ì˜ë ¸ìŠµë‹ˆë‹¤! ì¶œë ¥ í† í° ë¶€ì¡±")

        # Chat Completions API ê²°ê³¼ ì¶”ì¶œ
        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°)
        if result_text.startswith("```"):
            result_text = result_text.split("```")[1]
            if result_text.startswith("json"):
                result_text = result_text[4:]
        result_text = result_text.strip()

        # Trailing comma ì œê±° (LLMì´ ìì£¼ ì‹¤ìˆ˜í•˜ëŠ” íŒ¨í„´)
        import re
        # ,] â†’ ]
        result_text = re.sub(r',\s*\]', ']', result_text)
        # ,} â†’ }
        result_text = re.sub(r',\s*\}', '}', result_text)

        result = json.loads(result_text)

        # video_effects ì¶”ì¶œ ë° ë¡œê¹…
        video_effects = result.get("video_effects", {})
        detected_category = result.get("detected_category", "story")

        print(f"[IMAGE-ANALYZE] detected_category: {detected_category}")

        # ì”¬ ì •ë³´ ë¡œê¹… (ì˜ìƒ ê¸¸ì´ ë””ë²„ê¹…ìš©)
        scenes_data = result.get("scenes", [])
        total_narration_len = sum(len(s.get('narration', '')) for s in scenes_data)
        print(f"[IMAGE-ANALYZE] â˜… ì”¬ ê°œìˆ˜: {len(scenes_data)}ê°œ, ì´ ë‚˜ë ˆì´ì…˜ ê¸¸ì´: {total_narration_len}ì")
        for i, scene in enumerate(scenes_data[:3]):  # ì²˜ìŒ 3ê°œ ì”¬ë§Œ ë¡œê¹…
            narr_preview = scene.get('narration', '')[:50]
            print(f"[IMAGE-ANALYZE]   ì”¬ {i+1}: narration {len(scene.get('narration', ''))}ì - '{narr_preview}...'")

        print(f"[IMAGE-ANALYZE] video_effects keys: {list(video_effects.keys())}")
        if video_effects:
            print(f"[IMAGE-ANALYZE] bgm_mood: {video_effects.get('bgm_mood', '(ì—†ìŒ)')}")
            print(f"[IMAGE-ANALYZE] sound_effects: {len(video_effects.get('sound_effects', []))}ê°œ")
            print(f"[IMAGE-ANALYZE] scene_bgm_changes: {len(video_effects.get('scene_bgm_changes', []))}ê°œ")

        # ìœ íŠœë¸Œ ë©”íƒ€ë°ì´í„° ë¡œê¹…
        youtube_meta = result.get("youtube", {})
        desc = youtube_meta.get("description", {})
        if isinstance(desc, dict):
            print(f"[IMAGE-ANALYZE] description.full_text ê¸¸ì´: {len(desc.get('full_text', ''))}ì")
            print(f"[IMAGE-ANALYZE] description.chapters: {len(desc.get('chapters', []))}ê°œ")
        print(f"[IMAGE-ANALYZE] hashtags: {youtube_meta.get('hashtags', [])}")
        print(f"[IMAGE-ANALYZE] tags: {len(youtube_meta.get('tags', []))}ê°œ")
        print(f"[IMAGE-ANALYZE] pin_comment: {'ìˆìŒ' if youtube_meta.get('pin_comment') else 'ì—†ìŒ'}")

        return jsonify({
            "ok": True,
            "youtube": result.get("youtube", {}),
            "thumbnail": result.get("thumbnail", {}),
            "scenes": result.get("scenes", []),
            "video_effects": video_effects,
            "detected_category": detected_category,
            "settings": {
                "content_type": content_type,
                "image_style": image_style,
                "image_count": image_count,
                "audience": audience
            }
        })

    except Exception as e:
        print(f"[IMAGE-ANALYZE][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/image/download-zip', methods=['POST'])
def api_image_download_zip():
    """ì´ë¯¸ì§€ë“¤ì„ ZIPìœ¼ë¡œ ë¬¶ì–´ ë‹¤ìš´ë¡œë“œ"""
    try:
        import zipfile
        import io
        import urllib.request

        data = request.get_json()
        images = data.get('images', [])

        if not images:
            return jsonify({"ok": False, "error": "ë‹¤ìš´ë¡œë“œí•  ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"}), 400

        # ZIP íŒŒì¼ ìƒì„±
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for img in images:
                try:
                    name = img.get('name', 'image.png')
                    url = img.get('url', '')

                    if url.startswith('http'):
                        # ì™¸ë¶€ URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                        req = urllib.request.Request(url, headers={'User-Agent': 'Mozilla/5.0'})
                        with urllib.request.urlopen(req, timeout=30) as response:
                            img_data = response.read()
                            zip_file.writestr(name, img_data)
                    elif url.startswith('/'):
                        # ë¡œì»¬ íŒŒì¼
                        local_path = url.lstrip('/')
                        if os.path.exists(local_path):
                            with open(local_path, 'rb') as f:
                                zip_file.writestr(name, f.read())
                except Exception as e:
                    print(f"[IMAGE-ZIP] Failed to add {img.get('name')}: {e}")
                    continue

        zip_buffer.seek(0)

        return send_file(
            zip_buffer,
            mimetype='application/zip',
            as_attachment=True,
            download_name='images.zip'
        )

    except Exception as e:
        print(f"[IMAGE-ZIP][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/image/generate-assets-zip', methods=['POST'])
def api_image_generate_assets_zip():
    """CapCutìš© ì—ì…‹ ZIP ìƒì„± (ì´ë¯¸ì§€ + TTS ì˜¤ë””ì˜¤ + SRT ìë§‰) - ë¬¸ì¥ë³„ ì •í™•í•œ ì‹±í¬"""
    try:
        import zipfile
        import io
        import urllib.request
        import requests
        import base64
        import uuid
        import subprocess
        import gc  # ë©”ëª¨ë¦¬ ì •ë¦¬ìš©
        from datetime import datetime

        def detect_language(text):
            """í…ìŠ¤íŠ¸ì˜ ì£¼ìš” ì–¸ì–´ ê°ì§€ (í•œêµ­ì–´/ì˜ì–´/ì¼ë³¸ì–´)

            ì¼ë³¸ì–´ ë‰´ìŠ¤/ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ë³¸ì€ í•œì(æ¼¢å­—) ë¹„ìœ¨ì´ ë†’ê³  íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ ì ìŒ.
            ë”°ë¼ì„œ í•œê¸€ì´ ì—†ê³  íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ 1ê°œ ì´ìƒ ìˆìœ¼ë©´ ì¼ë³¸ì–´ë¡œ íŒë‹¨.
            """
            if not text:
                return 'en'
            korean_chars = len(re.findall(r'[ê°€-í£]', text))
            japanese_chars = len(re.findall(r'[\u3040-\u309F\u30A0-\u30FF]', text))
            # í•œêµ­ì–´ ìš°ì„  ê°ì§€ (í•œê¸€ì´ ìˆìœ¼ë©´ í•œêµ­ì–´)
            if korean_chars > 0:
                return 'ko'
            # ì¼ë³¸ì–´ ê°ì§€: íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ 1ê°œ ì´ìƒ ìˆìœ¼ë©´ ì¼ë³¸ì–´
            elif japanese_chars > 0:
                return 'ja'
            return 'en'

        def get_voice_for_language(lang, base_voice):
            """ì–¸ì–´ì— ë§ëŠ” TTS ìŒì„± ë°˜í™˜ (lang/*.pyì—ì„œ ê´€ë¦¬)"""
            # Chirp 3 HD ìŒì„±ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if is_chirp3_voice(base_voice):
                return base_voice
            # Gemini TTS ìŒì„±ì´ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
            if is_gemini_voice(base_voice):
                return base_voice

            is_female = 'Neural2-A' in base_voice or 'Neural2-B' in base_voice or 'Wavenet-A' in base_voice
            voice_map = {
                'ko': {'female': lang_ko.TTS['voices']['female'], 'male': lang_ko.TTS['voices']['male']},
                'ja': {'female': lang_ja.TTS['voices']['female'], 'male': lang_ja.TTS['voices']['male']},
                'en': {'female': lang_en.TTS['voices']['female'], 'male': lang_en.TTS['voices']['male']},
            }
            gender = 'female' if is_female else 'male'
            return voice_map.get(lang, voice_map['en'])[gender]

        def get_language_code(lang):
            """ì–¸ì–´ ì½”ë“œ ë°˜í™˜ (lang/*.pyì—ì„œ ê´€ë¦¬)"""
            return {'ko': lang_ko.TTS['language_code'], 'ja': lang_ja.TTS['language_code'], 'en': lang_en.TTS['language_code']}.get(lang, lang_en.TTS['language_code'])

        def split_sentences_with_gpt(text, lang='ko'):
            """GPT-5.1ì„ ì‚¬ìš©í•´ ìì—°ìŠ¤ëŸ¬ìš´ ìë§‰ ë‹¨ìœ„ë¡œ ë¶„ë¦¬"""
            try:
                openai_api_key = os.getenv("OPENAI_API_KEY")
                if not openai_api_key:
                    print("[SUBTITLE-SPLIT] OpenAI API í‚¤ ì—†ìŒ, í´ë°± ì‚¬ìš©")
                    return split_korean_semantic_fallback(text)

                from openai import OpenAI
                client = OpenAI(api_key=openai_api_key)

                prompt = f"""ë‹¤ìŒ ë‚˜ë ˆì´ì…˜ì„ TTS ìë§‰ìš©ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ë¶„ë¦¬í•´ì£¼ì„¸ìš”.

ê·œì¹™:
1. í•œ ì¤„ì€ 10~20ì ì‚¬ì´ë¡œ (ì˜ë¯¸ê°€ ëŠê¸°ì§€ ì•Šìœ¼ë©´ 15ìë„ OK)
2. ë§ì˜ íë¦„ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŠì–´ì§€ëŠ” ê³³ì—ì„œ ë¶„ë¦¬ (ì¡°ì‚¬ ë’¤, ì‰¼í‘œ ë’¤ ë“±)
3. ì ˆëŒ€ë¡œ ë‹¨ì–´ ì¤‘ê°„ì—ì„œ ëŠì§€ ë§ˆì„¸ìš”
4. ë¬¸ì¥ì´ ì§„í–‰ ì¤‘ì¸ë° ê°•ì œë¡œ 20ìì—ì„œ ìë¥´ì§€ ë§ˆì„¸ìš”
5. ì˜ë¯¸ ë‹¨ìœ„ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ëŠìœ¼ì„¸ìš”

ì˜ˆì‹œ:
ì…ë ¥: "ì˜¤ëŠ˜ì€ ê·¸ ì‹œì ˆ ìš°ë¦¬ ë™ë„¤ ì‘ì€ êµ¬ë©ê°€ê²Œ ì´ì•¼ê¸°ë¥¼ ë‚˜ëˆ ë³´ë ¤ê³  í•©ë‹ˆë‹¤."
ì¶œë ¥:
ì˜¤ëŠ˜ì€ ê·¸ ì‹œì ˆ
ìš°ë¦¬ ë™ë„¤
ì‘ì€ êµ¬ë©ê°€ê²Œ ì´ì•¼ê¸°ë¥¼
ë‚˜ëˆ ë³´ë ¤ê³  í•©ë‹ˆë‹¤.

ë‚˜ë ˆì´ì…˜:
{text}

ë¶„ë¦¬ëœ ìë§‰ (í•œ ì¤„ì— í•˜ë‚˜ì”©, ë‹¤ë¥¸ ì„¤ëª… ì—†ì´):"""

                response = client.responses.create(
                    model="gpt-5.1",
                    input=[
                        {
                            "role": "user",
                            "content": [{"type": "input_text", "text": prompt}]
                        }
                    ],
                    temperature=0.3
                )

                # ì‘ë‹µ ì¶”ì¶œ
                result_text = ""
                if getattr(response, "output_text", None):
                    result_text = response.output_text.strip()
                else:
                    for item in getattr(response, "output", []) or []:
                        for content in getattr(item, "content", []) or []:
                            if getattr(content, "type", "") == "text":
                                result_text += getattr(content, "text", "")

                # ì¤„ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
                lines = [line.strip() for line in result_text.strip().split('\n') if line.strip()]

                if lines:
                    print(f"[SUBTITLE-SPLIT] GPT-5.1 ë¶„ë¦¬ ì™„ë£Œ: {len(lines)}ì¤„")
                    return lines
                else:
                    print("[SUBTITLE-SPLIT] GPT ì‘ë‹µ ë¹„ì–´ìˆìŒ, í´ë°± ì‚¬ìš©")
                    return split_korean_semantic_fallback(text)

            except Exception as e:
                print(f"[SUBTITLE-SPLIT] GPT ì˜¤ë¥˜: {e}, í´ë°± ì‚¬ìš©")
                return split_korean_semantic_fallback(text)

        def split_sentences(text, lang='en'):
            """í…ìŠ¤íŠ¸ë¥¼ ìë§‰ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ - ì–¸ì–´ë³„ ì²­í‚¹ ì ìš©"""
            # í•œêµ­ì–´: ì˜ë¯¸ ê¸°ë°˜ ì²­í‚¹ ì‚¬ìš© (lang/ko.py ì„¤ì • ì°¸ì¡°)
            if lang == 'ko' and lang_ko.SUBTITLE.get('chunking', {}).get('enabled', False):
                max_chars = lang_ko.SUBTITLE['chunking'].get('max_chars', 20)
                return split_korean_semantic_fallback(text, max_chars)

            # ì†Œìˆ˜ì (7.5)ì€ ë¬¸ì¥ ëì´ ì•„ë‹ˆë¯€ë¡œ ì„ì‹œë¡œ ì¹˜í™˜
            # ìˆ«ì.ìˆ«ì íŒ¨í„´ì„ ì„ì‹œ ë§ˆì»¤ë¡œ êµì²´
            decimal_pattern = r'(\d)\.(\d)'
            text_safe = re.sub(decimal_pattern, r'\1<DECIMAL>\2', text.strip())

            # ë¬¸ì¥ ë¶€í˜¸(. ! ?)ë¡œ ë¶„ë¦¬
            sentences = re.split(r'(?<=[.!?ã€‚])\s*', text_safe)

            # ì„ì‹œ ë§ˆì»¤ë¥¼ ë‹¤ì‹œ ì†Œìˆ˜ì ìœ¼ë¡œ ë³µì›
            sentences = [s.replace('<DECIMAL>', '.').strip() for s in sentences if s.strip()]
            return sentences

        def split_korean_semantic_fallback(text, max_chars=20):
            """GPT ì‹¤íŒ¨ ì‹œ í´ë°±: í•œêµ­ì–´ ì˜ë¯¸ ê¸°ì¤€ ë¶„ë¦¬"""
            # â˜… ì†Œìˆ˜ì  ë³´í˜¸: ìˆ«ì.ìˆ«ì íŒ¨í„´ì„ ì„ì‹œ ë§ˆì»¤ë¡œ ì¹˜í™˜ (2.6% â†’ 2<DECIMAL>6%)
            decimal_pattern = r'(\d)\.(\d)'
            text_safe = re.sub(decimal_pattern, r'\1<DECIMAL>\2', text.strip())

            # ë¨¼ì € ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„ë¦¬
            sentences = re.split(r'(?<=[.!?])\s*', text_safe)
            sentences = [s.strip() for s in sentences if s.strip()]

            # â˜… ì†Œìˆ˜ì  ë³µì›
            sentences = [s.replace('<DECIMAL>', '.') for s in sentences]

            result = []
            for sentence in sentences:
                if len(sentence) <= max_chars:
                    result.append(sentence)
                else:
                    # ì˜ë¯¸ ë‹¨ìœ„ë¡œ ë¶„ë¦¬ (ì¡°ì‚¬, ì ‘ì†ì‚¬, ì‰¼í‘œ ë“±)
                    chunks = split_by_meaning_fallback(sentence, max_chars)
                    result.extend(chunks)

            # â˜… í›„ì²˜ë¦¬: ì§§ì€ ìë§‰ í•©ì¹˜ê¸° (10ê¸€ì ë¯¸ë§Œì€ ì´ì „/ë‹¤ìŒê³¼ í•©ì¹¨)
            MIN_SUBTITLE_LEN = 10  # ìµœì†Œ ìë§‰ ê¸¸ì´
            result = merge_short_subtitles(result, MIN_SUBTITLE_LEN, max_chars)

            return result

        def merge_short_subtitles(chunks, min_len=10, max_len=35):
            """ì§§ì€ ìë§‰ì„ ì´ì „/ë‹¤ìŒê³¼ í•©ì¹˜ê¸°

            - 10ê¸€ì ë¯¸ë§Œ ìë§‰ì€ ì¸ì ‘ ìë§‰ê³¼ í•©ì¹¨
            - í•©ì³ë„ max_lenì„ ì´ˆê³¼í•˜ë©´ ë‘ ì¤„ë¡œ í‘œì‹œ (ì¤„ë°”ê¿ˆ)
            """
            if not chunks or len(chunks) <= 1:
                return chunks

            merged = []
            i = 0

            while i < len(chunks):
                current = chunks[i]

                # í˜„ì¬ê°€ ì¶©ë¶„íˆ ê¸¸ë©´ ê·¸ëƒ¥ ì¶”ê°€
                if len(current) >= min_len:
                    merged.append(current)
                    i += 1
                    continue

                # ì§§ì€ ìë§‰: ë‹¤ìŒê³¼ í•©ì¹˜ê¸° ì‹œë„
                if i + 1 < len(chunks):
                    next_chunk = chunks[i + 1]
                    combined = current + " " + next_chunk

                    if len(combined) <= max_len:
                        # í•œ ì¤„ë¡œ í•©ì¹¨
                        merged.append(combined)
                        i += 2  # ë‹¤ìŒ ì²­í¬ë„ ê±´ë„ˆëœ€
                    else:
                        # ë‘ ì¤„ë¡œ í•©ì¹¨ (ì¤„ë°”ê¿ˆ ì‚¬ìš©)
                        merged.append(current + "\\N" + next_chunk)
                        i += 2
                # ë§ˆì§€ë§‰ ì§§ì€ ìë§‰: ì´ì „ê³¼ í•©ì¹˜ê¸°
                elif merged:
                    prev = merged.pop()
                    combined = prev + " " + current

                    if len(combined) <= max_len:
                        merged.append(combined)
                    else:
                        # ë‘ ì¤„ë¡œ í•©ì¹¨
                        merged.append(prev + "\\N" + current)
                    i += 1
                else:
                    # ì²« ë²ˆì§¸ì´ë©´ì„œ ì§§ì€ ê²½ìš° ê·¸ëƒ¥ ì¶”ê°€
                    merged.append(current)
                    i += 1

            return merged

        def split_by_meaning_fallback(text, max_chars=35, lang='ko'):
            """GPT ì‹¤íŒ¨ ì‹œ í´ë°±: ì˜ë¯¸ ë‹¨ìœ„ë¡œ í…ìŠ¤íŠ¸ ë¶„ë¦¬

            ë¶„ë¦¬ ìš°ì„ ìˆœìœ„ (í•œêµ­ì–´):
            1. ì‰¼í‘œ (,)
            2. ì ‘ì†ì‚¬/ì—°ê²°ì–´ë¯¸ (í•˜ì§€ë§Œ, ê·¸ë˜ì„œ, ê·¸ë¦¬ê³ , ~í•´ì„œ, ~í•˜ê³ )
            3. ì¡°ì‚¬ (ì€/ëŠ”/ì´/ê°€ ë“±) - ìµœì†Œ 15ê¸€ì ì´ìƒì¼ ë•Œë§Œ
            4. ê³µë°±
            5. ê°•ì œ ë¶„ë¦¬
            """
            chunks = []
            remaining = text.strip()
            min_chunk_len = 15  # ìµœì†Œ ì²­í¬ ê¸¸ì´ (ì´ë³´ë‹¤ ì§§ìœ¼ë©´ ë¶„ë¦¬ ì•ˆ í•¨)

            while remaining:
                if len(remaining) <= max_chars:
                    chunks.append(remaining)
                    break

                # ìµœëŒ€ ê¸¸ì´ ë‚´ì—ì„œ ë¶„ë¦¬ì  ì°¾ê¸°
                search_range = remaining[:max_chars + 5]  # ì•½ê°„ ì—¬ìœ 
                best_split = None

                # 1. ì‰¼í‘œì—ì„œ ë¶„ë¦¬ (ê°€ì¥ ìì—°ìŠ¤ëŸ¬ìš´ ë¶„ë¦¬ì )
                if lang == 'ja':
                    comma_pos = max(search_range.rfind(','), search_range.rfind('ã€'))
                else:
                    comma_pos = search_range.rfind(',')
                if comma_pos >= min_chunk_len:
                    best_split = comma_pos + 1

                # 2. ì ‘ì†ì‚¬/ì—°ê²°ì–´ë¯¸ì—ì„œ ë¶„ë¦¬ (ì‰¼í‘œ ì—†ìœ¼ë©´)
                if best_split is None:
                    if lang == 'ja':
                        connective_patterns = [
                            r'(.{10,}?(?:ã‘ã©|ã®ã§|ã®ã«|ã¦ã‚‚|ãŸã‚‰|ãªã‚‰|ã‹ã‚‰|ã¾ã§))',
                        ]
                    else:
                        # í•œêµ­ì–´: ì ‘ì†ì‚¬/ì—°ê²°ì–´ë¯¸ ë’¤ì—ì„œ ë¶„ë¦¬ (ë” ìì—°ìŠ¤ëŸ¬ìš´ ëŠê¹€ì )
                        connective_patterns = [
                            r'(.{12,}?(?:í•˜ì§€ë§Œ|ê·¸ëŸ¬ë‚˜|ê·¸ë˜ì„œ|ê·¸ë¦¬ê³ |ë”°ë¼ì„œ|ê·¸ëŸ°ë°|ê·¸ëŸ¬ë©´|í•˜ì—¬|í•´ì„œ|í–ˆê³ |í–ˆì§€ë§Œ|í•˜ê³ |ë˜ì–´|ë˜ê³ |ì¸ë°|ì§€ë§Œ))\s',
                        ]
                    for pattern in connective_patterns:
                        match = re.search(pattern, search_range)
                        if match and len(match.group(1)) <= max_chars:
                            best_split = match.end(1)
                            break

                # 3. ì¡°ì‚¬ì—ì„œ ë¶„ë¦¬ (ìµœì†Œ 15ê¸€ì ì´ìƒì¼ ë•Œë§Œ - ëœ ê³µê²©ì )
                if best_split is None:
                    if lang == 'ja':
                        particle_patterns = [
                            r'(.{15,}?(?:ã¯|ãŒ|ã‚’|ã«|ã§|ã¨|ã®|ã¸|ã‚ˆã‚Š))',
                        ]
                    else:
                        # í•œêµ­ì–´: ì¡°ì‚¬ + ê³µë°±ì—ì„œ ë¶„ë¦¬ (ìµœì†Œ 15ê¸€ì í™•ë³´)
                        particle_patterns = [
                            r'(.{15,}?(?:ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ì—ì„œ|ì—ê²Œ|ìœ¼ë¡œ|ë¡œ|ì™€|ê³¼))\s',
                        ]
                    for pattern in particle_patterns:
                        match = re.search(pattern, search_range)
                        if match and len(match.group(1)) <= max_chars:
                            best_split = match.end(1)
                            break

                # 4. ê³µë°±ì—ì„œ ë¶„ë¦¬ (ì¼ë³¸ì–´ëŠ” ìŠ¤í‚µ)
                # â˜… ì˜ì¡´ëª…ì‚¬(ìˆ˜, ê²ƒ, ì¤„, ë°, ë•Œ, ê³³, ë¿ ë“±) ì•ì—ì„œëŠ” ë¶„ë¦¬ ì•ˆ í•¨
                if best_split is None and lang != 'ja':
                    search_text = search_range[:max_chars]
                    # ì˜ì¡´ëª…ì‚¬ íŒ¨í„´: ê³µë°± + ì˜ì¡´ëª…ì‚¬ + (ê³µë°± ë˜ëŠ” ì¡°ì‚¬)
                    dependent_nouns = ['ìˆ˜', 'ê²ƒ', 'ì¤„', 'ë°', 'ë•Œ', 'ê³³', 'ë¿', 'ë§Œí¼', 'ëŒ€ë¡œ', 'ë°”', 'ë¦¬', 'ê²Œ', 'ì§€', 'ë“¯', 'ì±„', 'ê¹€', 'í„°', 'ë²•', 'ì…ˆ']

                    # ë’¤ì—ì„œë¶€í„° ê³µë°± ì°¾ê¸°
                    space_pos = search_text.rfind(' ')
                    while space_pos >= min_chunk_len:
                        # ê³µë°± ë‹¤ìŒ ë‹¨ì–´ í™•ì¸
                        after_space = search_text[space_pos+1:space_pos+4]  # ìµœëŒ€ 3ê¸€ì
                        first_word = after_space.split()[0] if after_space.split() else ''

                        # ì˜ì¡´ëª…ì‚¬ë¡œ ì‹œì‘í•˜ë©´ ë” ì•ì˜ ê³µë°±ìœ¼ë¡œ ì´ë™
                        if first_word and any(first_word.startswith(dn) for dn in dependent_nouns):
                            space_pos = search_text[:space_pos].rfind(' ')
                        else:
                            break

                    if space_pos >= min_chunk_len:
                        best_split = space_pos

                # 5. ê°•ì œ ë¶„ë¦¬ (ìœ„ì—ì„œ ì°¾ì§€ ëª»í•¨)
                if best_split is None:
                    best_split = max_chars

                chunks.append(remaining[:best_split].strip())
                remaining = remaining[best_split:].strip()

            return chunks

        def get_mp3_duration(audio_bytes):
            """MP3 ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì • (ì´ˆ)"""
            # ì„ì‹œ íŒŒì¼ì— ì €ì¥ í›„ ffprobeë¡œ ì¸¡ì •
            try:
                with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp:
                    tmp.write(audio_bytes)
                    tmp_path = tmp.name

                cmd = [
                    "ffprobe", "-v", "error",
                    "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1",
                    tmp_path
                ]
                result = subprocess.run(cmd, capture_output=True, text=True, timeout=10)
                os.unlink(tmp_path)

                if result.returncode == 0 and result.stdout.strip():
                    return float(result.stdout.strip())
            except Exception as e:
                print(f"[ASSETS-ZIP] ffprobe failed: {e}")

            # í´ë°±: MP3 128kbps ê¸°ì¤€ ì¶”ì • (16KB/ì´ˆ)
            return len(audio_bytes) / 16000

        def convert_numbers_to_korean(text):
            """ìˆ«ìë¥¼ í•œê¸€ë¡œ ë³€í™˜ (TTS ìì—°ìŠ¤ëŸ¬ìš´ ì½ê¸°ìš©)

            - ê³ ìœ ì–´ ë‹¨ìœ„ (ë²ˆ, ê°œ, ëª…, ì‚´, ì‹œ, ë§ˆë¦¬, ì”, ë³‘, ê¶Œ, ëŒ€, ì±„, ì¥, ë²Œ, ì¼¤ë ˆ, ê·¸ë£¨, ì†¡ì´):
              15ë²ˆ â†’ ì—´ë‹¤ì„¯ë²ˆ, 3ê°œ â†’ ì„¸ê°œ
            - í•œìì–´ ë‹¨ìœ„ (ì›, ì¸µ, ë…„, ì›”, ì¼, ë¶„, ì´ˆ, ë„, í˜¸, íšŒ, ë°°, km, m, kg, g):
              200ì› â†’ ì´ë°±ì›, 15ì¸µ â†’ ì‹­ì˜¤ì¸µ
            """
            import re

            # â˜… ì „ì²˜ë¦¬: ì‰¼í‘œê°€ í¬í•¨ëœ ìˆ«ì ì²˜ë¦¬ (1,350 â†’ 1350)
            # ìˆ«ì+ì‰¼í‘œ+ìˆ«ì íŒ¨í„´ì—ì„œ ì‰¼í‘œ ì œê±° (ì²œ ë‹¨ìœ„ êµ¬ë¶„ì)
            text = re.sub(r'(\d),(\d{3})', r'\1\2', text)
            # ì—°ì†ëœ ì‰¼í‘œ íŒ¨í„´ë„ ì²˜ë¦¬ (1,234,567 â†’ 1234567)
            while re.search(r'(\d),(\d{3})', text):
                text = re.sub(r'(\d),(\d{3})', r'\1\2', text)

            # ê³ ìœ ì–´ ìˆ«ì (1~99)
            native_units = ['ë²ˆ', 'ê°œ', 'ëª…', 'ì‚´', 'ì‹œ', 'ë§ˆë¦¬', 'ì”', 'ë³‘', 'ê¶Œ', 'ëŒ€', 'ì±„', 'ì¥', 'ë²Œ', 'ì¼¤ë ˆ', 'ê·¸ë£¨', 'ì†¡ì´', 'êµ°ë°', 'ê°€ì§€', 'ì¤„', 'ìŒ']
            native_ones = ['', 'í•œ', 'ë‘', 'ì„¸', 'ë„¤', 'ë‹¤ì„¯', 'ì—¬ì„¯', 'ì¼ê³±', 'ì—¬ëŸ', 'ì•„í™‰']
            native_tens = ['', 'ì—´', 'ìŠ¤ë¬¼', 'ì„œë¥¸', 'ë§ˆí”', 'ì‰°', 'ì˜ˆìˆœ', 'ì¼í”', 'ì—¬ë“ ', 'ì•„í”']

            def num_to_native(n):
                """ìˆ«ìë¥¼ ê³ ìœ ì–´ë¡œ ë³€í™˜ (1~99)"""
                if n <= 0 or n >= 100:
                    return str(n)
                tens = n // 10
                ones = n % 10
                return native_tens[tens] + native_ones[ones]

            # í•œìì–´ ìˆ«ì
            sino_digits = ['', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']

            def num_to_sino(n):
                """ìˆ«ìë¥¼ í•œìì–´ë¡œ ë³€í™˜"""
                if n == 0:
                    return 'ì˜'
                if n < 0:
                    return 'ë§ˆì´ë„ˆìŠ¤ ' + num_to_sino(-n)

                result = ''

                # ì–µ ë‹¨ìœ„
                if n >= 100000000:
                    result += num_to_sino(n // 100000000) + 'ì–µ'
                    n %= 100000000

                # ë§Œ ë‹¨ìœ„
                if n >= 10000:
                    man = n // 10000
                    if man == 1:
                        result += 'ë§Œ'
                    else:
                        result += num_to_sino(man) + 'ë§Œ'
                    n %= 10000

                # ì²œ ë‹¨ìœ„
                if n >= 1000:
                    cheon = n // 1000
                    if cheon == 1:
                        result += 'ì²œ'
                    else:
                        result += sino_digits[cheon] + 'ì²œ'
                    n %= 1000

                # ë°± ë‹¨ìœ„
                if n >= 100:
                    baek = n // 100
                    if baek == 1:
                        result += 'ë°±'
                    else:
                        result += sino_digits[baek] + 'ë°±'
                    n %= 100

                # ì‹­ ë‹¨ìœ„
                if n >= 10:
                    sip = n // 10
                    if sip == 1:
                        result += 'ì‹­'
                    else:
                        result += sino_digits[sip] + 'ì‹­'
                    n %= 10

                # ì¼ ë‹¨ìœ„
                if n > 0:
                    result += sino_digits[n]

                return result

            # â˜… ì„±ê²½ êµ¬ì ˆ íŒ¨í„´ (Xì¥ Yì ˆ) - í•œìì–´ë¡œ ì½ì–´ì•¼ í•¨ (ê³ ìœ ì–´ ì²˜ë¦¬ ì „ì—!)
            # ì˜ˆ: "4ì¥ 3ì ˆ" â†’ "ì‚¬ì¥ ì‚¼ì ˆ", "5ì¥ 18ì ˆ" â†’ "ì˜¤ì¥ ì‹­íŒ”ì ˆ"
            # ì¥(ç« , ì±•í„°)ì€ í•œìì–´ ë‹¨ìœ„ì´ë¯€ë¡œ í•œìì–´ ìˆ˜ì‚¬ ì‚¬ìš©
            def replace_bible_verse(match):
                chapter = num_to_sino(int(match.group(1)))
                verse = num_to_sino(int(match.group(2)))
                return f"{chapter}ì¥ {verse}ì ˆ"
            text = re.sub(r'(\d+)ì¥\s*(\d+)ì ˆ', replace_bible_verse, text)

            # Xì¥ë§Œ ë‹¨ë…ìœ¼ë¡œ ì‚¬ìš©ëœ ê²½ìš°ë„ í•œìì–´ë¡œ (ë¬¸ë§¥ìƒ ì±•í„°ë¥¼ ì˜ë¯¸í•  ë•Œ)
            # "ì œ1ì¥", "1ì¥ì—ì„œ" ë“±ì˜ íŒ¨í„´
            def replace_chapter_context(match):
                prefix = match.group(1) or ''
                chapter = num_to_sino(int(match.group(2)))
                suffix = match.group(3)
                return f"{prefix}{chapter}ì¥{suffix}"
            # ì œXì¥, Xì¥ì—ì„œ, Xì¥ì„, Xì¥ì˜, Xì¥ì€, Xì¥ì´, Xì¥ê³¼, Xì¥ë¶€í„°, Xì¥ê¹Œì§€ ë“±
            text = re.sub(r'(ì œ)?(\d+)ì¥(ì—ì„œ|ì„|ì˜|ì€|ì´|ê³¼|ë¶€í„°|ê¹Œì§€|ìœ¼ë¡œ|ì—|ë„)', replace_chapter_context, text)

            # â˜… "ê°œ"ë¡œ ì‹œì‘í•˜ëŠ” í•œìì–´ ë‹¨ìœ„ (ê³ ìœ ì–´ ì²˜ë¦¬ ì „ì— ë¨¼ì €!)
            # "11ê°œì›”" â†’ "ì‹­ì¼ê°œì›”" (O), "ì—´í•œê°œì›”" (X)
            # "5ê°œêµ­" â†’ "ì˜¤ê°œêµ­" (O), "ë‹¤ì„¯ê°œêµ­" (X)
            sino_ge_units = ['ê°œì›”', 'ê°œêµ­', 'ê°œì‚¬', 'ê°œë…„', 'ê°œì†Œ', 'ê°œí•­', 'ê°œêµ']
            for unit in sino_ge_units:
                pattern = r'(\d+)' + re.escape(unit)
                def replace_sino_ge(match, u=unit):
                    num = int(match.group(1))
                    return num_to_sino(num) + u
                text = re.sub(pattern, replace_sino_ge, text)

            # ê³ ìœ ì–´ ë‹¨ìœ„ íŒ¨í„´ (ìˆ«ì + ê³ ìœ ì–´ë‹¨ìœ„)
            for unit in native_units:
                pattern = r'(\d+)' + re.escape(unit)
                def replace_native(match, u=unit):
                    num = int(match.group(1))
                    if 1 <= num <= 99:
                        return num_to_native(num) + u
                    else:
                        return num_to_sino(num) + u
                text = re.sub(pattern, replace_native, text)

            # â˜…â˜…â˜… ì†Œìˆ˜ì  íŒ¨í„´ì„ ì •ìˆ˜+ë‹¨ìœ„ íŒ¨í„´ë³´ë‹¤ ë¨¼ì € ì²˜ë¦¬ (2024-12-20 ìˆ˜ì •) â˜…â˜…â˜…
            # 0.75% â†’ "ì˜ì ì¹ ì˜¤í¼ì„¼íŠ¸" (O), "ì˜ì ì¹ ì‹­ì˜¤í¼ì„¼íŠ¸" (X)
            # ì†Œìˆ˜ì  ë’¤ì˜ ìˆ«ìëŠ” ê°œë³„ ìë¦¿ìˆ˜ë¡œ ì½ì–´ì•¼ í•¨

            # ì†Œìˆ˜ì  ìˆ«ì (7.5 â†’ ì¹ ì ì˜¤, 3.14 â†’ ì‚¼ì ì¼ì‚¬)
            def convert_decimal(match):
                integer_part = match.group(1)
                decimal_part = match.group(2)
                unit = match.group(3) if match.lastindex >= 3 else ''

                # ì •ìˆ˜ ë¶€ë¶„ ë³€í™˜
                result = num_to_sino(int(integer_part)) + 'ì '

                # ì†Œìˆ˜ì  ì´í•˜ ê° ìë¦¿ìˆ˜ ë³€í™˜ (0.75 â†’ ì˜ì ì¹ ì˜¤)
                decimal_digits = ['ì˜', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
                for digit in decimal_part:
                    result += decimal_digits[int(digit)]

                # % â†’ í¼ì„¼íŠ¸ë¡œ ë³€í™˜
                if unit == '%':
                    unit = 'í¼ì„¼íŠ¸'

                return result + unit

            # ì†Œìˆ˜ì  + ë‹¨ìœ„ íŒ¨í„´ (7.5ì¼, 3.5kg, 0.75% ë“±) - ì •ìˆ˜+ë‹¨ìœ„ë³´ë‹¤ ë¨¼ì €!
            text = re.sub(r'(\d+)\.(\d+)(ì¼|ì‹œê°„|ë¶„|ì´ˆ|km|m|kg|g|cm|mm|%|í¼ì„¼íŠ¸|ë°°|ë„|ë¦¬í„°|L|ml)', convert_decimal, text)

            # ë‹¨ìœ„ ì—†ëŠ” ì†Œìˆ˜ì  (ê·¸ëƒ¥ 7.5 ë“±)
            text = re.sub(r'(\d+)\.(\d+)(?![ê°€-í£a-zA-Z%])', lambda m: convert_decimal(m), text)

            # í•œìì–´ ë‹¨ìœ„ íŒ¨í„´ (ìˆ«ì + í•œìì–´ë‹¨ìœ„) - ì†Œìˆ˜ì  ì²˜ë¦¬ í›„ ë‚¨ì€ ì •ìˆ˜+ë‹¨ìœ„
            # â˜… ë³µí•© ë‹¨ìœ„(ì¡°ì›, ì–µì› ë“±)ê°€ ë‹¨ìˆœ ë‹¨ìœ„(ì›)ë³´ë‹¤ ë¨¼ì € ì™€ì•¼ í•¨
            sino_units = [
                # í° ë‹¨ìœ„ ë³µí•©ì–´ (ë¨¼ì € ì²˜ë¦¬)
                'ì¡°ì›', 'ì–µì›', 'ë§Œì›', 'ì²œì›', 'ë°±ì›',
                'ì¡°ë‹¬ëŸ¬', 'ì–µë‹¬ëŸ¬', 'ë§Œë‹¬ëŸ¬',
                'ì¡°ì—”', 'ì–µì—”', 'ë§Œì—”',
                # í° ë‹¨ìœ„ ë‹¨ë…
                'ì¡°', 'ì–µ', 'ë§Œ',
                # ì¼ë°˜ ë‹¨ìœ„
                'ì›', 'ì¸µ', 'ë…„', 'ì›”', 'ì¼', 'ë¶„', 'ì´ˆ', 'ë„', 'í˜¸', 'íšŒ', 'ë°°', 'ìœ„', 'ë“±', 'ì ',
                'í¼ì„¼íŠ¸', '%', 'km', 'm', 'kg', 'g', 'cm', 'mm', 'ì›ì§œë¦¬', 'ë‹¬ëŸ¬', 'ì—”', 'ìœ ë¡œ',
                # ì£¼ì‹/ì§€ìˆ˜ ë‹¨ìœ„
                'ì„ ', 'í¬ì¸íŠ¸', 'p', 'pt',
                # â˜… ì¶”ê°€ ë‹¨ìœ„ (2025-12-23)
                'ì„¸ê¸°', 'ì°¨', 'í•­', 'ê¸°', 'ë°˜', 'íŒ', 'ë¶€', 'í¸', 'ê³¡', 'ë§‰', 'ì ˆ', 'ê´€',
                'ì¡°', 'ì¥', 'ê¶Œ', 'ìª½', 'ë©´', 'í˜ì´ì§€', 'í™”', 'íšŒì°¨', 'ë¼ìš´ë“œ', 'ì„¸íŠ¸',
                'ë²ˆì§€', 'ë™', 'í˜¸ì‹¤', 'êµ¬', 'ë¡œ', 'ê¸¸',  # ì£¼ì†Œ
                'êµì‹œ', 'í•™ë…„', 'í•™ê¸°',  # í•™êµ
                'ëŒ€', 'ì„¸ëŒ€',  # ì„¸ëŒ€
                'ìŠ¹', 'íŒ¨', 'ë¬´',  # ìŠ¤í¬ì¸ 
            ]
            for unit in sino_units:
                pattern = r'(\d+)' + re.escape(unit)
                def replace_sino(match, u=unit):
                    num = int(match.group(1))
                    converted = num_to_sino(num)
                    # % â†’ í¼ì„¼íŠ¸ë¡œ ì½ê¸°
                    if u == '%':
                        u = 'í¼ì„¼íŠ¸'
                    return converted + u
                text = re.sub(pattern, replace_sino, text)

            # ê³±í•˜ê¸°/ë‚˜ëˆ„ê¸° í‘œí˜„
            text = re.sub(r'(\d+)\s*[xXÃ—]\s*(\d+)', lambda m: num_to_sino(int(m.group(1))) + ' ê³±í•˜ê¸° ' + num_to_sino(int(m.group(2))), text)
            text = re.sub(r'(\d+)\s*[/Ã·]\s*(\d+)', lambda m: num_to_sino(int(m.group(1))) + ' ë‚˜ëˆ„ê¸° ' + num_to_sino(int(m.group(2))), text)

            # â˜… ë²”ìœ„ í‘œí˜„ (ë¬¼ê²°í‘œ ~) (2025-12-22 ì¶”ê°€)
            # 7~8 â†’ "ì¹ ì—ì„œíŒ”", 10~20% â†’ "ì‹­ì—ì„œì´ì‹­í¼ì„¼íŠ¸"
            # ë¬¼ê²°í‘œë¥¼ "ì—ì„œ"ë¡œ ë³€í™˜í•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ ë²”ìœ„ ì½ê¸°
            def replace_range(match):
                num1 = num_to_sino(int(match.group(1)))
                num2 = num_to_sino(int(match.group(2)))
                unit = match.group(3) if match.lastindex >= 3 and match.group(3) else ''
                # % â†’ í¼ì„¼íŠ¸
                if unit == '%':
                    unit = 'í¼ì„¼íŠ¸'
                return f"{num1}ì—ì„œ{num2}{unit}"
            # ìˆ«ì~ìˆ«ì + ì„ íƒì  ë‹¨ìœ„ (%, ê°œ, ëª…, ì› ë“±)
            text = re.sub(r'(\d+)~(\d+)(%|í¼ì„¼íŠ¸|ê°œ|ëª…|ì›|ë§Œì›|ì–µì›|ì¡°ì›|kg|g|cm|m|km|ì¼|ì‹œê°„|ë¶„|ì´ˆ)?', replace_range, text)
            # ë‚¨ì€ ~ ë¬¸ì ì œê±° (TTSê°€ "ë¬¼ê²°í‘œ"ë¡œ ì½ëŠ” ê²ƒ ë°©ì§€)
            text = text.replace('~', ' ')

            # â˜…â˜…â˜… ì¶”ê°€ íŒ¨í„´ë“¤ (2025-12-23) â˜…â˜…â˜…

            # â˜… ì‹œê°„ íŒ¨í„´ (3:30 â†’ ì„¸ì‹œ ì‚¼ì‹­ë¶„) - ìŠ¤ì½”ì–´ë³´ë‹¤ ë¨¼ì € ì²˜ë¦¬!
            # ì‹œê°„ì€ ê³ ìœ ì–´ë¡œ ì½ìŒ (í•œì‹œ, ë‘ì‹œ, ì„¸ì‹œ...)
            def replace_time(match):
                hour = int(match.group(1))
                minute = int(match.group(2))
                # ì‹œê°„ ë²”ìœ„ ì²´í¬ (0~23ì‹œ, 0~59ë¶„)
                if hour > 23 or minute > 59:
                    return match.group(0)  # ì‹œê°„ì´ ì•„ë‹˜
                # ì‹œê°„ì€ 1~12ëŠ” ê³ ìœ ì–´, 0/13~23ëŠ” í•œìì–´
                if 1 <= hour <= 12:
                    hour_str = num_to_native(hour) + 'ì‹œ'
                else:
                    hour_str = num_to_sino(hour) + 'ì‹œ'
                # ë¶„ì€ í•œìì–´
                if minute == 0:
                    return hour_str
                elif minute == 30:
                    return hour_str + ' ë°˜'
                else:
                    return hour_str + ' ' + num_to_sino(minute) + 'ë¶„'
            # HH:MM íŒ¨í„´ (00:00 ~ 23:59) - ë¶„ì´ 00~59 ë²”ìœ„ì¸ ê²½ìš°ë§Œ
            text = re.sub(r'\b([0-2]?[0-9]):([0-5][0-9])\b', replace_time, text)

            # â˜… ìŠ¤ì½”ì–´/ë¹„ìœ¨ (3:2 â†’ ì‚¼ ëŒ€ ì´) - ì‹œê°„ ì²˜ë¦¬ í›„ ë‚¨ì€ ì½œë¡  íŒ¨í„´
            def replace_score(match):
                num1 = num_to_sino(int(match.group(1)))
                num2 = num_to_sino(int(match.group(2)))
                return f"{num1} ëŒ€ {num2}"
            text = re.sub(r'(\d+)\s*:\s*(\d+)(?!\d)', replace_score, text)

            # â˜… ì „í™”ë²ˆí˜¸ (010-1234-5678 â†’ ê³µì¼ê³µ ì¼ì´ì‚¼ì‚¬ ì˜¤ìœ¡ì¹ íŒ”)
            def replace_phone(match):
                digits = re.sub(r'[^\d]', '', match.group(0))
                digit_names = ['ê³µ', 'ì¼', 'ì´', 'ì‚¼', 'ì‚¬', 'ì˜¤', 'ìœ¡', 'ì¹ ', 'íŒ”', 'êµ¬']
                result = ' '.join(digit_names[int(d)] for d in digits)
                return result
            # ì „í™”ë²ˆí˜¸ íŒ¨í„´: 010-1234-5678, 02-123-4567
            text = re.sub(r'\b(0\d{1,2})[- ](\d{3,4})[- ](\d{4})\b', replace_phone, text)

            # â˜… ISO ë‚ ì§œ (2025-12-23 â†’ ì´ì²œì´ì‹­ì˜¤ë…„ ì‹­ì´ì›” ì´ì‹­ì‚¼ì¼)
            def replace_iso_date(match):
                year = num_to_sino(int(match.group(1)))
                month = num_to_sino(int(match.group(2)))
                day = num_to_sino(int(match.group(3)))
                return f"{year}ë…„ {month}ì›” {day}ì¼"
            text = re.sub(r'\b(\d{4})-(\d{1,2})-(\d{1,2})\b', replace_iso_date, text)

            # â˜… ê´„í˜¸ ìˆ«ì ((1), (2) â†’ ì¼, ì´)
            def replace_paren_num(match):
                num = num_to_sino(int(match.group(1)))
                return f"({num})"
            text = re.sub(r'\((\d+)\)', replace_paren_num, text)

            # â˜… ì›ë¬¸ì (â‘ â‘¡â‘¢... â†’ ì¼, ì´, ì‚¼...)
            circled_nums = {'â‘ ': 'ì¼', 'â‘¡': 'ì´', 'â‘¢': 'ì‚¼', 'â‘£': 'ì‚¬', 'â‘¤': 'ì˜¤',
                           'â‘¥': 'ìœ¡', 'â‘¦': 'ì¹ ', 'â‘§': 'íŒ”', 'â‘¨': 'êµ¬', 'â‘©': 'ì‹­',
                           'â‘ª': 'ì‹­ì¼', 'â‘«': 'ì‹­ì´', 'â‘¬': 'ì‹­ì‚¼', 'â‘­': 'ì‹­ì‚¬', 'â‘®': 'ì‹­ì˜¤',
                           'â‘¯': 'ì‹­ìœ¡', 'â‘°': 'ì‹­ì¹ ', 'â‘±': 'ì‹­íŒ”', 'â‘²': 'ì‹­êµ¬', 'â‘³': 'ì´ì‹­'}
            for symbol, reading in circled_nums.items():
                text = text.replace(symbol, reading)

            # â˜… ë¡œë§ˆ ìˆ«ì (â… , â…¡, â…¢... â†’ ì¼, ì´, ì‚¼...)
            roman_nums = {'â… ': 'ì¼', 'â…¡': 'ì´', 'â…¢': 'ì‚¼', 'â…£': 'ì‚¬', 'â…¤': 'ì˜¤',
                         'â…¥': 'ìœ¡', 'â…¦': 'ì¹ ', 'â…§': 'íŒ”', 'â…¨': 'êµ¬', 'â…©': 'ì‹­',
                         'â…ª': 'ì‹­ì¼', 'â…«': 'ì‹­ì´',
                         'â…°': 'ì¼', 'â…±': 'ì´', 'â…²': 'ì‚¼', 'â…³': 'ì‚¬', 'â…´': 'ì˜¤',
                         'â…µ': 'ìœ¡', 'â…¶': 'ì¹ ', 'â…·': 'íŒ”', 'â…¸': 'êµ¬', 'â…¹': 'ì‹­'}
            for symbol, reading in roman_nums.items():
                text = text.replace(symbol, reading)

            # â˜… ë‹¨ìœ„ ì—†ëŠ” í° ìˆ«ì (ë§ˆì§€ë§‰ì— ì²˜ë¦¬ - ë‹¤ë¥¸ íŒ¨í„´ì— ì•ˆ ê±¸ë¦° ìˆ«ì)
            def replace_standalone_number(match):
                # ì•ë’¤ì— í•œê¸€/ì˜ë¬¸ì´ ì—†ëŠ” ìˆœìˆ˜ ìˆ«ìë§Œ
                num = int(match.group(1))
                if num >= 100:  # 100 ì´ìƒë§Œ ë³€í™˜ (ì‘ì€ ìˆ«ìëŠ” ê·¸ëŒ€ë¡œ)
                    return num_to_sino(num)
                return match.group(0)
            # ë‹¨ì–´ ê²½ê³„ì˜ ìˆ«ì (ì•ë’¤ë¡œ í•œê¸€/ì˜ë¬¸ ì—†ìŒ)
            text = re.sub(r'(?<![ê°€-í£a-zA-Z])(\d{3,})(?![ê°€-í£a-zA-Z%])', replace_standalone_number, text)

            return text

        def generate_tts_for_sentence(text, voice_name, language_code, api_key):
            """ë‹¨ì¼ ë¬¸ì¥ì— ëŒ€í•œ TTS ìƒì„± (Chirp 3 HD, Gemini TTS, Google Cloud TTS ì§€ì›)"""

            # ===== TTS ì „ì²˜ë¦¬ =====
            # 0-1) ì˜ë¬¸ ì¸ëª… ê´„í˜¸ ì œê±° (ìë§‰ì—ëŠ” ë‚¨ê³ , TTSì—ì„œëŠ” ì½ì§€ ì•ŠìŒ)
            text = preprocess_tts_text(text)

            # 0-1b) í™•ì¥ ì „ì²˜ë¦¬: ì˜ë¬¸ ì•½ì–´, íŠ¹ìˆ˜ê¸°í˜¸, ì´ëª¨ì§€, URL ë“± (2025-12-23)
            text = preprocess_tts_extended(text)

            # 0-2) ì¤„ë°”ê¿ˆ ì œê±° (ëª¨ë“  í˜•íƒœ: \n, \\n, \N, \\N)
            text = text.replace('\\N', ' ').replace('\\n', ' ')  # ì´ìŠ¤ì¼€ì´í”„ëœ í˜•íƒœ ë¨¼ì €
            text = text.replace('\n', ' ')                        # ì‹¤ì œ ì¤„ë°”ê¿ˆ ë¬¸ì
            text = re.sub(r'[/\\][nN]', ' ', text)               # ìŠ¬ë˜ì‹œ í˜•íƒœê¹Œì§€

            # 0-3) ë¬¸ì¥ë¶€í˜¸ ì •ë¦¬ (TTSê°€ "ì ", "ë¬¼ìŒí‘œ"ë¡œ ì½ëŠ” ê²ƒ ë°©ì§€)
            # ì—°ì†ëœ ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ â†’ ë‹¨ì¼ ê³µë°± (íœ´ì§€ íš¨ê³¼)
            text = re.sub(r'[.]{2,}', ' ', text)   # ... â†’ ê³µë°±
            text = re.sub(r'[?]{2,}', ' ', text)   # ??? â†’ ê³µë°±
            text = re.sub(r'[!]{2,}', ' ', text)   # !!! â†’ ê³µë°±
            # ë¬¸ì¥ ë ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ â†’ ê³µë°±ìœ¼ë¡œ ëŒ€ì²´ (TTSëŠ” ë¬¸ì¥ ëì—ì„œ ìì—°ìŠ¤ëŸ½ê²Œ íœ´ì§€)
            text = re.sub(r'[.?!]+\s*$', '', text)  # ë¬¸ì¥ ë ë¶€í˜¸ ì œê±°
            text = re.sub(r'[.?!]+\s+', ' ', text)  # ë¬¸ì¥ ì¤‘ê°„ ë¶€í˜¸ â†’ ê³µë°±
            # ë‹¨ë… ë¶€í˜¸ ì œê±°
            text = re.sub(r'\s+[.?!]+\s+', ' ', text)

            # 0-4) ì‰¼í‘œ ì²˜ë¦¬
            # ë¨¼ì € ìˆ«ì ë‚´ ì‰¼í‘œ ì œê±° (103,600 â†’ 103600) - ì²œë‹¨ìœ„ êµ¬ë¶„ì
            text = re.sub(r'(\d),(\d{3})', r'\1\2', text)
            while re.search(r'(\d),(\d{3})', text):  # ì—°ì† ì‰¼í‘œ ì²˜ë¦¬ (1,234,567)
                text = re.sub(r'(\d),(\d{3})', r'\1\2', text)
            # ë‚˜ë¨¸ì§€ ì‰¼í‘œ â†’ ê³µë°± (íœ´ì§€ íš¨ê³¼)
            text = text.replace(',', ' ')

            # ì—°ì† ê³µë°± ì •ë¦¬
            text = re.sub(r'\s+', ' ', text).strip()

            # ===== Chirp 3 HD ì²˜ë¦¬ (ìµœê³  í’ˆì§ˆ + ë¹ ë¥¸ ì†ë„) =====
            if is_chirp3_voice(voice_name):
                chirp3_config = parse_chirp3_voice(voice_name, language_code)
                print(f"[TTS-CHIRP3] ì‚¬ìš©: {chirp3_config['voice']}", flush=True)

                # í•œêµ­ì–´ ìˆ«ì ë³€í™˜
                if language_code.startswith('ko'):
                    text = convert_numbers_to_korean(text)

                # SSML íƒœê·¸ ì œê±°
                clean_text = re.sub(r'<[^>]+>', '', text).strip()
                if not clean_text:
                    clean_text = text

                result = generate_chirp3_tts(
                    text=clean_text,
                    voice_name=chirp3_config['voice'],
                    language_code=language_code
                )

                if result.get("ok"):
                    return result['audio_data']
                else:
                    # â˜… í´ë°± ì œê±°: Chirp3 ì‹¤íŒ¨ ì‹œ ì˜ìƒ ìƒì„± ì¤‘ë‹¨ (ë¸Œëœë“œ ìŒì„± ë³´í˜¸)
                    print(f"[TTS-CHIRP3] âŒ ì‹¤íŒ¨: {result.get('error')} - í´ë°± ì—†ì´ ì¤‘ë‹¨")
                    return None  # í´ë°±í•˜ì§€ ì•Šê³  ì‹¤íŒ¨ ë°˜í™˜

            # ===== Gemini TTS ì²˜ë¦¬ =====
            if is_gemini_voice(voice_name):
                gemini_config = parse_gemini_voice(voice_name)
                print(f"[TTS-GEMINI] ì‚¬ìš©: {gemini_config['voice']} ({gemini_config['model']})")

                # í•œêµ­ì–´ ìˆ«ì ë³€í™˜
                if language_code.startswith('ko'):
                    text = convert_numbers_to_korean(text)

                # SSML íƒœê·¸ ì œê±° (GeminiëŠ” SSML ë¯¸ì§€ì›)
                clean_text = text
                # ëª¨ë“  XML/SSML íƒœê·¸ ì œê±°
                clean_text = re.sub(r'<[^>]+>', '', clean_text)
                clean_text = clean_text.strip()

                # íƒœê·¸ ì œê±° í›„ í…ìŠ¤íŠ¸ê°€ ë¹„ë©´ ì›ë³¸ ì‚¬ìš©
                if not clean_text:
                    print(f"[TTS-GEMINI] SSML íƒœê·¸ ì œê±° í›„ ë¹ˆ í…ìŠ¤íŠ¸, ì›ë³¸ ì‚¬ìš©: {text[:50]}...")
                    clean_text = re.sub(r'<[^>]+>', '', text).strip() or text

                result = generate_gemini_tts(
                    text=clean_text.strip(),
                    voice_name=gemini_config['voice'],
                    model=gemini_config['model']
                )

                if result.get("ok"):
                    # WAVë¥¼ MP3ë¡œ ë³€í™˜
                    mp3_data = convert_gemini_wav_to_mp3(result['audio_data'])
                    if mp3_data:
                        return mp3_data
                    else:
                        # MP3 ë³€í™˜ ì‹¤íŒ¨ ì‹œ WAV ë°˜í™˜
                        return result['audio_data']
                else:
                    # â˜… í´ë°± ì œê±°: Gemini ì‹¤íŒ¨ ì‹œ ì˜ìƒ ìƒì„± ì¤‘ë‹¨ (ë¸Œëœë“œ ìŒì„± ë³´í˜¸)
                    print(f"[TTS-GEMINI] âŒ ì‹¤íŒ¨: {result.get('error')} - í´ë°± ì—†ì´ ì¤‘ë‹¨")
                    return None  # í´ë°±í•˜ì§€ ì•Šê³  ì‹¤íŒ¨ ë°˜í™˜

            # ===== Google Cloud TTS ì²˜ë¦¬ =====
            # SSML íƒœê·¸ ê°ì§€
            ssml_tags = ['<speak>', '<prosody', '<emphasis', '<break']
            is_ssml = any(tag in text for tag in ssml_tags)

            if is_ssml:
                # SSML ëª¨ë“œ: <speak> íƒœê·¸ê°€ ì—†ìœ¼ë©´ ì¶”ê°€
                if not text.strip().startswith('<speak>'):
                    text = f"<speak>{text}</speak>"
                # SSML ë‚´ë¶€ì˜ í…ìŠ¤íŠ¸ì—ì„œ ìˆ«ì ë³€í™˜ (íƒœê·¸ ë°”ê¹¥ë§Œ)
                if language_code.startswith('ko'):
                    # SSML íƒœê·¸ë¥¼ ë³´ì¡´í•˜ë©´ì„œ í…ìŠ¤íŠ¸ë§Œ ë³€í™˜
                    def convert_text_in_ssml(ssml_text):
                        import re
                        # íƒœê·¸ë¥¼ í”Œë ˆì´ìŠ¤í™€ë”ë¡œ ëŒ€ì²´
                        tag_pattern = r'(<[^>]+>)'
                        parts = re.split(tag_pattern, ssml_text)
                        converted_parts = []
                        for part in parts:
                            if part.startswith('<'):
                                converted_parts.append(part)  # íƒœê·¸ëŠ” ê·¸ëŒ€ë¡œ
                            else:
                                converted_parts.append(convert_numbers_to_korean(part))  # í…ìŠ¤íŠ¸ë§Œ ë³€í™˜
                        return ''.join(converted_parts)
                    text = convert_text_in_ssml(text)
                print(f"[TTS-SSML] ê°ì • í‘œí˜„ TTS: {text[:80]}...")
                tts_url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={api_key}"
                payload = {
                    "input": {"ssml": text},  # SSML ì…ë ¥
                    "voice": {"languageCode": language_code, "name": voice_name},
                    "audioConfig": {"audioEncoding": "MP3"}  # SSMLì€ prosodyë¡œ ì†ë„/í”¼ì¹˜ ì œì–´
                }
            else:
                # ì¼ë°˜ í…ìŠ¤íŠ¸ ëª¨ë“œ
                if language_code.startswith('ko'):
                    text = convert_numbers_to_korean(text)
                    print(f"[TTS] ìˆ«ì ë³€í™˜ í›„: {text[:50]}...")
                tts_url = f"https://texttospeech.googleapis.com/v1/text:synthesize?key={api_key}"
                payload = {
                    "input": {"text": text},
                    "voice": {"languageCode": language_code, "name": voice_name},
                    "audioConfig": {"audioEncoding": "MP3", "speakingRate": 0.95, "pitch": 0}
                }

            response = requests.post(tts_url, json=payload, timeout=60)
            if response.status_code == 200:
                result = response.json()
                return base64.b64decode(result.get("audioContent", ""))
            else:
                print(f"[TTS] ì—ëŸ¬: {response.status_code} - {response.text[:200]}")
            return None

        data = request.get_json()
        session_id = data.get('session_id', str(uuid.uuid4())[:8])
        base_voice = data.get('voice', lang_ko.TTS['default_voice'])
        scenes = data.get('scenes', [])

        if not scenes:
            return jsonify({"ok": False, "error": "ì”¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}), 400

        # API í‚¤ ì²´í¬ (Chirp 3 HD vs Gemini TTS vs Google Cloud TTS)
        google_cloud_api_key = os.getenv("GOOGLE_CLOUD_API_KEY", "")
        google_api_key = os.getenv("GOOGLE_API_KEY", "")  # Gemini TTSìš©

        # TTS íƒ€ì… íŒë³„
        using_chirp3 = is_chirp3_voice(base_voice)
        using_gemini = is_gemini_voice(base_voice)

        if using_chirp3:
            # Chirp 3 HD: Google Cloud ì„œë¹„ìŠ¤ ê³„ì • (GOOGLE_APPLICATION_CREDENTIALS) ì‚¬ìš©
            # API í‚¤ ë¶ˆí•„ìš”, ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì‚¬ìš©
            api_key = google_cloud_api_key  # í´ë°±ìš©
            print(f"[ASSETS-ZIP] Chirp 3 HD ì‚¬ìš©: {base_voice} (100 req/min)")
        elif using_gemini:
            if not google_api_key:
                return jsonify({"ok": False, "error": "GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤ (Gemini TTSìš©)"}), 500
            api_key = google_api_key
            print(f"[ASSETS-ZIP] Gemini TTS ì‚¬ìš©: {base_voice} (10 req/min - ëŠë¦¼!)")
        else:
            if not google_cloud_api_key:
                return jsonify({"ok": False, "error": "GOOGLE_CLOUD_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 500
            api_key = google_cloud_api_key
            print(f"[ASSETS-ZIP] Google Cloud TTS ì‚¬ìš©: {base_voice}")

        print(f"[ASSETS-ZIP] Starting TTS for {len(scenes)} scenes (voice: {base_voice})")

        # â˜… ì—°ì† ì‹¤íŒ¨ ì¹´ìš´í„° ì´ˆê¸°í™” (ì´ì „ ìš”ì²­ì—ì„œ ëˆ„ì ëœ ê°’ ë¦¬ì…‹)
        consecutive_tts_fails = 0

        # ê²°ê³¼ ì €ì¥ìš©
        all_sentence_audios = []  # [(scene_idx, sent_idx, audio_bytes, duration, text), ...]
        srt_entries = []
        current_time = 0.0

        # ì”¬ë³„ ë©”íƒ€ë°ì´í„° (ì˜ìƒ ìƒì„±ìš©)
        scene_metadata = []  # [{image_url, audio_url, duration, subtitles: [{start, end, text}], language}]
        detected_lang_global = 'ko'  # ì „ì²´ ì–¸ì–´ (ë§ˆì§€ë§‰ ê°ì§€ëœ ì–¸ì–´)

        def strip_ssml_tags(text):
            """SSML íƒœê·¸ë¥¼ ì œê±°í•˜ê³  ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ"""
            import re
            # ëª¨ë“  SSML íƒœê·¸ ì œê±°
            clean_text = re.sub(r'<[^>]+>', '', text)
            # ì—°ì† ê³µë°± ì •ë¦¬
            clean_text = re.sub(r'\s+', ' ', clean_text).strip()
            return clean_text

        def is_ssml_content(text):
            """SSML íƒœê·¸ê°€ í¬í•¨ëœ í…ìŠ¤íŠ¸ì¸ì§€ í™•ì¸"""
            ssml_tags = ['<speak>', '<prosody', '<emphasis', '<break']
            return any(tag in text for tag in ssml_tags)

        # Gemini TTS Rate Limit: ë”œë ˆì´ìš© time_module
        import time as time_module

        # 1. ê° ì”¬ì˜ TTS ìƒì„± (ì”¬ ë‹¨ìœ„)
        for scene_idx, scene in enumerate(scenes):
            narration = scene.get('text', '')
            image_url = scene.get('image_url', '')
            if not narration:
                continue

            detected_lang = detect_language(narration)
            detected_lang_global = detected_lang  # ì „ì²´ ì–¸ì–´ ì—…ë°ì´íŠ¸
            voice_name = get_voice_for_language(detected_lang, base_voice)
            language_code = get_language_code(detected_lang)

            # SSML ëª¨ë“œ ë¹„í™œì„±í™” (Gemini TTSëŠ” SSML ë¯¸ì§€ì›, ì†ë„ ì €í•˜ ì›ì¸)
            has_ssml = False  # is_ssml_content(narration)

            # â˜… VRCS 2.0: subtitle_segmentsë¡œ ë¬¸ì¥ë³„ ON/OFF ì œì–´
            subtitle_segments = scene.get('subtitle_segments', [])

            # ìë§‰ìš© í…ìŠ¤íŠ¸ ë¶„í•  (â˜… í•­ìƒ SSML íƒœê·¸ ì œê±° - has_ssmlê³¼ ë¬´ê´€)
            plain_narration = strip_ssml_tags(narration)

            # â˜… í•µì‹¬ ìˆ˜ì •: í•­ìƒ ëŒ€ë³¸ ì „ì²´ë¥¼ ë¬¸ì¥ ë¶„í• í•˜ì—¬ TTS ìˆ˜í–‰
            # subtitle_segmentsëŠ” ìë§‰ í‘œì‹œ ì—¬ë¶€ë§Œ ì œì–´ (TTS ëŒ€ìƒì„ ì œí•œí•˜ë©´ ì•ˆë¨!)
            # â˜… TTS ì–µì–‘ ê°œì„ : í•œêµ­ì–´ëŠ” ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (20ì ì²­í‚¹ ëŒ€ì‹ )
            if detected_lang == 'ko':
                tts_sentences = tts_split_sentences(plain_narration)
            else:
                tts_sentences = split_sentences(plain_narration, detected_lang)
            if not tts_sentences:
                tts_sentences = [plain_narration]

            print(f"[ASSETS-ZIP] Scene {scene_idx + 1}: {len(tts_sentences)}ê°œ ë¬¸ì¥ TTS ì˜ˆì •")

            # ìë§‰ ë§¤í•‘: subtitle_segmentsê°€ ìˆìœ¼ë©´ VRCS ëª¨ë“œ, ì—†ìœ¼ë©´ ì „ì²´ ìë§‰
            vrcs_mode = bool(subtitle_segments)
            subtitle_map = {}  # {sentence_idx: subtitle_text}

            if vrcs_mode and len(subtitle_segments) == len(tts_sentences):
                # VRCS 2.0: subtitle_on=trueì¸ ë¬¸ì¥ë§Œ ìë§‰ í‘œì‹œ
                for idx, seg in enumerate(subtitle_segments):
                    if seg.get('subtitle_on') and seg.get('subtitle_text'):
                        subtitle_map[idx] = seg.get('subtitle_text', '')
                vrcs_on_count = len(subtitle_map)
                print(f"[ASSETS-ZIP] Scene {scene_idx + 1}: VRCS ëª¨ë“œ - {vrcs_on_count}/{len(tts_sentences)} ë¬¸ì¥ ìë§‰ ON")
            else:
                # ê¸°ë³¸: ëª¨ë“  ë¬¸ì¥ ìë§‰í™”
                for idx, sent in enumerate(tts_sentences):
                    subtitle_map[idx] = sent
                if vrcs_mode:
                    print(f"[ASSETS-ZIP] Scene {scene_idx + 1}: VRCS ë¬¸ì¥ìˆ˜ ë¶ˆì¼ì¹˜ ({len(subtitle_segments)} vs {len(tts_sentences)}), ì „ì²´ ìë§‰ ëª¨ë“œ")

            scene_audios = []
            scene_start_time = current_time  # ì”¬ ì‹œì‘ ì‹œê°„
            scene_subtitles = []  # ì”¬ ë‚´ ìƒëŒ€ì  ìë§‰ íƒ€ì´ë°
            scene_relative_time = 0.0

            # â˜… VRCS íƒ€ì´ë° ìƒìˆ˜
            VRCS_SUBTITLE_LEAD = 0.3  # ìë§‰ì´ TTSë³´ë‹¤ 0.3ì´ˆ ë¨¼ì € ì‹œì‘
            VRCS_SUBTITLE_TRAIL = 0.2  # ìë§‰ì´ TTSë³´ë‹¤ 0.2ì´ˆ ëŠ¦ê²Œ ëë‚¨

            if has_ssml:
                # â˜… SSML ëª¨ë“œ: ì „ì²´ ë‚˜ë ˆì´ì…˜ì„ í•˜ë‚˜ì˜ TTSë¡œ ì²˜ë¦¬ (ê°ì • í‘œí˜„ ìœ ì§€!)
                print(f"[ASSETS-ZIP] Scene {scene_idx + 1}: SSML ê°ì • í‘œí˜„ TTS (ì „ì²´ ì²˜ë¦¬)")

                # ì „ì²´ SSML ë‚˜ë ˆì´ì…˜ìœ¼ë¡œ TTS ìƒì„±
                audio_bytes = generate_tts_for_sentence(narration, voice_name, language_code, api_key)

                if audio_bytes:
                    total_duration = get_mp3_duration(audio_bytes)
                    scene_audios.append(audio_bytes)
                    all_sentence_audios.append((scene_idx, 0, audio_bytes))

                    # ë¬¸ì¥ë³„ duration ê³„ì‚° (ê¸€ì ìˆ˜ ë¹„ìœ¨)
                    if vrcs_mode:
                        sentences_for_timing = tts_sentences
                    else:
                        sentences_for_timing = tts_sentences

                    total_chars = sum(len(s) for s in sentences_for_timing)
                    if total_chars == 0:
                        total_chars = 1

                    for sent_idx, sentence in enumerate(sentences_for_timing):
                        # ê¸€ì ìˆ˜ ë¹„ìœ¨ë¡œ duration ê³„ì‚°
                        char_ratio = len(sentence) / total_chars
                        sent_duration = total_duration * char_ratio

                        # â˜… VRCS 2.0: subtitle_on=trueì¸ ë¬¸ì¥ë§Œ ìë§‰ ì¶”ê°€
                        if sent_idx in subtitle_map:
                            subtitle_text = subtitle_map[sent_idx]

                            # â˜… VRCS íƒ€ì´ë°: ìë§‰ì´ 0.3ì´ˆ ë¨¼ì € ì‹œì‘, 0.2ì´ˆ ëŠ¦ê²Œ ëë‚¨
                            sub_start = max(0, current_time - VRCS_SUBTITLE_LEAD)
                            sub_end = current_time + sent_duration + VRCS_SUBTITLE_TRAIL
                            sub_relative_start = max(0, scene_relative_time - VRCS_SUBTITLE_LEAD)
                            sub_relative_end = scene_relative_time + sent_duration + VRCS_SUBTITLE_TRAIL

                            # â˜… ìë§‰ ê²¹ì¹¨ ë°©ì§€: ì´ì „ ìë§‰ ì¢…ë£Œ ì‹œê°„ì´ í˜„ì¬ ì‹œì‘ ì‹œê°„ì„ ì´ˆê³¼í•˜ë©´ ì¡°ì •
                            if srt_entries and srt_entries[-1]['end'] > sub_start:
                                srt_entries[-1]['end'] = sub_start
                            if scene_subtitles and scene_subtitles[-1]['end'] > sub_relative_start:
                                scene_subtitles[-1]['end'] = sub_relative_start

                            srt_entries.append({
                                'index': len(srt_entries) + 1,
                                'start': sub_start,
                                'end': sub_end,
                                'text': subtitle_text
                            })
                            scene_subtitles.append({
                                'start': sub_relative_start,
                                'end': sub_relative_end,
                                'text': subtitle_text
                            })

                            if vrcs_mode:
                                print(f"  Sent {sent_idx + 1}: {sent_duration:.2f}s - ìë§‰ ON - '{subtitle_text}'")
                            else:
                                print(f"  Sent {sent_idx + 1}: {sent_duration:.2f}s - {sentence[:30]}...")
                        else:
                            # ìë§‰ OFF - TTSë§Œ ì¬ìƒ
                            if vrcs_mode:
                                print(f"  Sent {sent_idx + 1}: {sent_duration:.2f}s - ìë§‰ OFF")

                        current_time += sent_duration
                        scene_relative_time += sent_duration
                else:
                    print(f"[ASSETS-ZIP] Scene {scene_idx + 1}: SSML TTS ì‹¤íŒ¨, ë¬¸ì¥ë³„ í´ë°±")
                    has_ssml = False  # í´ë°±í•˜ì—¬ ì•„ë˜ ë¬¸ì¥ë³„ ì²˜ë¦¬ë¡œ

            if not has_ssml:
                # â˜… ë¬¸ì¥ë³„ TTS ìƒì„±
                sentences = tts_sentences
                print(f"[ASSETS-ZIP] Scene {scene_idx + 1}: {len(sentences)} sentences â†’ ë¬¸ì¥ë³„ TTS")

                for sent_idx, sentence in enumerate(sentences):
                    # Rate limit ëŒ€ì‘:
                    # - Chirp 3 HD: 100 req/min â†’ ë”œë ˆì´ ë¶ˆí•„ìš”
                    # - Gemini TTS: 10 req/min â†’ 1.5ì´ˆ ë”œë ˆì´ í•„ìš”
                    # - Google Cloud TTS: 600 req/min â†’ ë”œë ˆì´ ë¶ˆí•„ìš”
                    if using_gemini and sent_idx > 0:
                        time_module.sleep(1.5)

                    # ë¬¸ì¥ë³„ TTS ìƒì„±
                    audio_bytes = generate_tts_for_sentence(sentence, voice_name, language_code, api_key)

                    if audio_bytes:
                        duration = get_mp3_duration(audio_bytes)
                        scene_audios.append(audio_bytes)
                        all_sentence_audios.append((scene_idx, sent_idx, audio_bytes))

                        # â˜… VRCS 2.0: subtitle_on=trueì¸ ë¬¸ì¥ë§Œ ìë§‰ ì¶”ê°€
                        if sent_idx in subtitle_map:
                            subtitle_text = subtitle_map[sent_idx]

                            # â˜… VRCS íƒ€ì´ë°: ìë§‰ì´ 0.3ì´ˆ ë¨¼ì € ì‹œì‘, 0.2ì´ˆ ëŠ¦ê²Œ ëë‚¨
                            sub_start = max(0, current_time - VRCS_SUBTITLE_LEAD)
                            sub_end = current_time + duration + VRCS_SUBTITLE_TRAIL
                            sub_relative_start = max(0, scene_relative_time - VRCS_SUBTITLE_LEAD)
                            sub_relative_end = scene_relative_time + duration + VRCS_SUBTITLE_TRAIL

                            # â˜… ìë§‰ ê²¹ì¹¨ ë°©ì§€: ì´ì „ ìë§‰ ì¢…ë£Œ ì‹œê°„ì´ í˜„ì¬ ì‹œì‘ ì‹œê°„ì„ ì´ˆê³¼í•˜ë©´ ì¡°ì •
                            if srt_entries and srt_entries[-1]['end'] > sub_start:
                                srt_entries[-1]['end'] = sub_start
                            if scene_subtitles and scene_subtitles[-1]['end'] > sub_relative_start:
                                scene_subtitles[-1]['end'] = sub_relative_start

                            srt_entries.append({
                                'index': len(srt_entries) + 1,
                                'start': sub_start,
                                'end': sub_end,
                                'text': subtitle_text
                            })
                            scene_subtitles.append({
                                'start': sub_relative_start,
                                'end': sub_relative_end,
                                'text': subtitle_text
                            })

                            if vrcs_mode:
                                print(f"  Sent {sent_idx + 1}: {duration:.2f}s - ìë§‰ ON - '{subtitle_text[:30]}...'")
                            else:
                                print(f"  Sent {sent_idx + 1}: {duration:.2f}s - {sentence[:30]}...")
                        else:
                            # ìë§‰ OFF - TTSë§Œ ì¬ìƒ
                            if vrcs_mode:
                                print(f"  Sent {sent_idx + 1}: {duration:.2f}s - ìë§‰ OFF")

                        current_time += duration
                        scene_relative_time += duration
                        consecutive_tts_fails = 0  # ì„±ê³µ ì‹œ ë¦¬ì…‹
                    else:
                        consecutive_tts_fails += 1
                        print(f"[ASSETS-ZIP] Scene {scene_idx + 1} Sent {sent_idx + 1}: TTS ì‹¤íŒ¨ ({consecutive_tts_fails}íšŒ) - '{sentence[:40]}...'")
                        # â˜… ì—°ì† ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨ (5íšŒ ì—°ì† ì‹¤íŒ¨ = ì‹¬ê°í•œ ë¬¸ì œ)
                        if consecutive_tts_fails >= 5:
                            error_msg = f"TTS ì—°ì† 5íšŒ ì‹¤íŒ¨ - ì¤‘ë‹¨ (Scene {scene_idx + 1}, Sent {sent_idx + 1})"
                            print(f"[ASSETS-ZIP][ERROR] {error_msg}")
                            return jsonify({"ok": False, "error": error_msg}), 500

            # ì”¬ ë©”íƒ€ë°ì´í„° ì €ì¥
            scene_duration = current_time - scene_start_time
            scene_metadata.append({
                'scene_idx': scene_idx,
                'image_url': image_url,
                'duration': scene_duration,
                'subtitles': scene_subtitles,
                'language': detected_lang
            })

            # ì”¬ ê°„ ì§§ì€ ê°„ê²© (ë¬´ìŒ 0.3ì´ˆ ì¶”ê°€ ê°€ëŠ¥, ì—¬ê¸°ì„œëŠ” ì‹œê°„ë§Œ ì¡°ì •)
            current_time += 0.3

        # â˜… TTS ì„±ê³µ/ì‹¤íŒ¨ ìš”ì•½ ë¡œê·¸
        total_sentences = sum(len(s.get('subtitle_segments', [])) or 1 for s in scenes if s.get('text'))
        successful_tts = len(all_sentence_audios)
        print(f"[ASSETS-ZIP] Total: {successful_tts}/{total_sentences} sentences TTS ì„±ê³µ, {current_time:.1f}s")
        if successful_tts < total_sentences:
            print(f"[ASSETS-ZIP][WARNING] {total_sentences - successful_tts}ê°œ ë¬¸ì¥ TTS ì‹¤íŒ¨!")

        # 2. ZIP íŒŒì¼ ìƒì„±
        zip_buffer = io.BytesIO()
        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:

            # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ë° ì¶”ê°€
            image_count = 0
            for idx, scene in enumerate(scenes):
                image_url = scene.get('image_url', '')
                if not image_url:
                    continue

                try:
                    if image_url.startswith('http'):
                        req = urllib.request.Request(image_url, headers={'User-Agent': 'Mozilla/5.0'})
                        with urllib.request.urlopen(req, timeout=30) as response:
                            img_data = response.read()
                    elif image_url.startswith('/'):
                        local_path = image_url.lstrip('/')
                        if os.path.exists(local_path):
                            with open(local_path, 'rb') as f:
                                img_data = f.read()
                        else:
                            continue
                    else:
                        continue

                    # íŒŒì¼ëª…: 01_scene.jpg, 02_scene.jpg, ...
                    filename = f"{str(idx + 1).zfill(2)}_scene.jpg"
                    zip_file.writestr(f"images/{filename}", img_data)
                    image_count += 1

                except Exception as e:
                    print(f"[ASSETS-ZIP] Failed to add image {idx + 1}: {e}")

            # ì˜¤ë””ì˜¤ íŒŒì¼ ì¶”ê°€ (ë¬¸ì¥ë³„ + ì”¬ë³„ ë³‘í•© + ì „ì²´ ë³‘í•©)
            if all_sentence_audios:
                # 1. ë¬¸ì¥ë³„ ê°œë³„ ì˜¤ë””ì˜¤ ì €ì¥
                for scene_idx, sent_idx, audio_bytes in all_sentence_audios:
                    filename = f"{str(scene_idx + 1).zfill(2)}_{str(sent_idx + 1).zfill(2)}_sent.mp3"
                    zip_file.writestr(f"audio/sentences/{filename}", audio_bytes)

                # 2. ì”¬ë³„ ì˜¤ë””ì˜¤ ë³‘í•© (FFmpeg ì‚¬ìš©) + uploads/ ì €ì¥
                scene_audio_map = {}  # {scene_idx: [audio_bytes, ...]}
                for scene_idx, sent_idx, audio_bytes in all_sentence_audios:
                    if scene_idx not in scene_audio_map:
                        scene_audio_map[scene_idx] = []
                    scene_audio_map[scene_idx].append(audio_bytes)

                # uploads ë””ë ‰í† ë¦¬ ìƒì„±
                upload_dir = "uploads"
                os.makedirs(upload_dir, exist_ok=True)

                scene_merged_files = []
                for scene_idx in sorted(scene_audio_map.keys()):
                    audios = scene_audio_map[scene_idx]
                    try:
                        # ì„ì‹œ íŒŒì¼ë“¤ ìƒì„±
                        temp_files = []
                        for i, audio in enumerate(audios):
                            with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp:
                                tmp.write(audio)
                                temp_files.append(tmp.name)

                        # FFmpeg concatìœ¼ë¡œ ë³‘í•©
                        with tempfile.NamedTemporaryFile(suffix='.txt', delete=False, mode='w') as list_file:
                            for tf in temp_files:
                                list_file.write(f"file '{tf}'\n")
                            list_path = list_file.name

                        merged_path = tempfile.mktemp(suffix='.mp3')
                        cmd = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path, "-c", "copy", merged_path]
                        # ë©”ëª¨ë¦¬ ìµœì í™”: stdout/stderr DEVNULL (OOM ë°©ì§€)
                        merge_result = subprocess.run(
                            cmd,
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.DEVNULL,
                            timeout=60
                        )
                        del merge_result
                        gc.collect()

                        if os.path.exists(merged_path):
                            with open(merged_path, 'rb') as f:
                                merged_audio = f.read()
                            filename = f"{str(scene_idx + 1).zfill(2)}_scene.mp3"
                            zip_file.writestr(f"audio/{filename}", merged_audio)

                            # uploads/ì—ë„ ê°œë³„ ì €ì¥ (ì˜ìƒ ìƒì„±ìš©)
                            audio_filename = f"{session_id}_scene_{str(scene_idx + 1).zfill(2)}.mp3"
                            audio_path = os.path.join(upload_dir, audio_filename)
                            with open(audio_path, 'wb') as f:
                                f.write(merged_audio)

                            # scene_metadataì— audio_url ì¶”ê°€
                            for sm in scene_metadata:
                                if sm['scene_idx'] == scene_idx:
                                    sm['audio_url'] = f"/uploads/{audio_filename}"
                                    break

                            scene_merged_files.append(merged_path)
                            os.unlink(merged_path)

                        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
                        for tf in temp_files:
                            if os.path.exists(tf):
                                os.unlink(tf)
                        if os.path.exists(list_path):
                            os.unlink(list_path)

                    except Exception as e:
                        print(f"[ASSETS-ZIP] Scene {scene_idx + 1} merge failed: {e}")

                # 3. ì „ì²´ ì˜¤ë””ì˜¤ ë³‘í•©
                try:
                    all_audios = [audio for _, _, audio in all_sentence_audios]
                    temp_files = []
                    for audio in all_audios:
                        with tempfile.NamedTemporaryFile(suffix='.mp3', delete=False) as tmp:
                            tmp.write(audio)
                            temp_files.append(tmp.name)

                    with tempfile.NamedTemporaryFile(suffix='.txt', delete=False, mode='w') as list_file:
                        for tf in temp_files:
                            list_file.write(f"file '{tf}'\n")
                        list_path = list_file.name

                    full_merged_path = tempfile.mktemp(suffix='.mp3')
                    cmd = ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", list_path, "-c", "copy", full_merged_path]
                    # ë©”ëª¨ë¦¬ ìµœì í™”: stdout/stderr DEVNULL (OOM ë°©ì§€)
                    full_merge_result = subprocess.run(
                        cmd,
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.DEVNULL,
                        timeout=120
                    )
                    del full_merge_result
                    gc.collect()

                    if os.path.exists(full_merged_path):
                        with open(full_merged_path, 'rb') as f:
                            full_audio = f.read()
                        zip_file.writestr("audio/narration_full.mp3", full_audio)
                        os.unlink(full_merged_path)

                    for tf in temp_files:
                        if os.path.exists(tf):
                            os.unlink(tf)
                    if os.path.exists(list_path):
                        os.unlink(list_path)

                except Exception as e:
                    print(f"[ASSETS-ZIP] Full audio merge failed: {e}")

            # SRT ìë§‰ íŒŒì¼ ìƒì„±
            srt_content = ""
            for entry in srt_entries:
                start = format_srt_time(entry['start'])
                end = format_srt_time(entry['end'])
                srt_content += f"{entry['index']}\n{start} --> {end}\n{entry['text']}\n\n"

            zip_file.writestr("subtitles.srt", srt_content.encode('utf-8'))

            # ê°€ì´ë“œ íŒŒì¼ ì¶”ê°€
            guide_content = f"""CapCut ì—ì…‹ ê°€ì´ë“œ
==================

ğŸ“ í´ë” êµ¬ì¡°:
- images/ : ì”¬ë³„ ì´ë¯¸ì§€ ({image_count}ê°œ)
- audio/narration_full.mp3 : ì „ì²´ ë‚˜ë ˆì´ì…˜ (ì‹±í¬ìš©)
- audio/01_scene.mp3, 02_scene.mp3... : ì”¬ë³„ ì˜¤ë””ì˜¤
- audio/sentences/ : ë¬¸ì¥ë³„ ê°œë³„ ì˜¤ë””ì˜¤
- subtitles.srt : ìë§‰ íŒŒì¼ (ì •í™•í•œ ì‹±í¬!)

ğŸ¬ CapCut ì„í¬íŠ¸ ë°©ë²•:
1. audio/narration_full.mp3ë¥¼ ì˜¤ë””ì˜¤ íŠ¸ë™ì— ë“œë˜ê·¸
2. subtitles.srtë¥¼ ìë§‰ìœ¼ë¡œ ì„í¬íŠ¸ â†’ ìë™ ì‹±í¬!
3. images í´ë”ì˜ ì´ë¯¸ì§€ë“¤ì„ íƒ€ì„ë¼ì¸ì— ë°°ì¹˜

âœ¨ ìë§‰ ì‹±í¬ ì •ë³´:
- ë¬¸ì¥ë³„ TTSë¥¼ ê°œë³„ ìƒì„±í•˜ì—¬ ì •í™•í•œ íƒ€ì´ë° ì¸¡ì •
- SRT íŒŒì¼ì˜ ì‹œê°„ì´ ì‹¤ì œ ì˜¤ë””ì˜¤ì™€ ì •í™•íˆ ì¼ì¹˜í•©ë‹ˆë‹¤
- ì´ {len(srt_entries)}ê°œ ìë§‰, {current_time:.1f}ì´ˆ

ìƒì„±ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
"""
            zip_file.writestr("README.txt", guide_content.encode('utf-8'))

        # 3. ZIP íŒŒì¼ ì €ì¥
        zip_buffer.seek(0)
        zip_filename = f"capcut_assets_{session_id}.zip"
        upload_dir = "uploads"
        os.makedirs(upload_dir, exist_ok=True)
        zip_path = os.path.join(upload_dir, zip_filename)

        with open(zip_path, 'wb') as f:
            f.write(zip_buffer.read())

        # ì˜¤ë””ì˜¤ ì´ ê¸¸ì´ ê³„ì‚°
        total_duration = current_time
        minutes = int(total_duration // 60)
        seconds = int(total_duration % 60)
        duration_str = f"{minutes}ë¶„ {seconds}ì´ˆ"

        print(f"[ASSETS-ZIP] ZIP created: {zip_path}, images: {image_count}, duration: {duration_str}")

        return jsonify({
            "ok": True,
            "zip_url": f"/uploads/{zip_filename}",
            "image_count": image_count,
            "audio_duration": duration_str,
            "scene_metadata": scene_metadata,  # ì˜ìƒ ìƒì„±ìš© ë©”íƒ€ë°ì´í„°
            "detected_language": detected_lang_global  # ê°ì§€ëœ ì–¸ì–´
        })

    except Exception as e:
        print(f"[ASSETS-ZIP][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


def format_srt_time(seconds):
    """ì´ˆë¥¼ SRT ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (00:00:00,000)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    millis = int((seconds - int(seconds)) * 1000)
    return f"{hours:02d}:{minutes:02d}:{secs:02d},{millis:03d}"


# ===== Image Lab ì˜ìƒ ìƒì„± API (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬) =====

# ì˜ìƒ ìƒì„± ì‘ì—… ìƒíƒœ ì €ì¥ (PostgreSQL ë˜ëŠ” íŒŒì¼ ê¸°ë°˜)
# PostgreSQL: ì„œë²„ ì¬ì‹œì‘ì—ë„ ì‘ì—… ìƒíƒœ ìœ ì§€ë¨
# íŒŒì¼: ë¡œì»¬ ê°œë°œìš© í´ë°±
VIDEO_JOBS_DIR = "uploads/video_jobs"
os.makedirs(VIDEO_JOBS_DIR, exist_ok=True)

def _save_job_status(job_id, status_data):
    """ì‘ì—… ìƒíƒœë¥¼ DB ë˜ëŠ” íŒŒì¼ë¡œ ì €ì¥"""
    if USE_POSTGRES:
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute('''
                INSERT INTO video_jobs (job_id, status, progress, message, video_url, error, session_id, updated_at)
                VALUES (%s, %s, %s, %s, %s, %s, %s, CURRENT_TIMESTAMP)
                ON CONFLICT (job_id) DO UPDATE SET
                    status = EXCLUDED.status,
                    progress = EXCLUDED.progress,
                    message = EXCLUDED.message,
                    video_url = EXCLUDED.video_url,
                    error = EXCLUDED.error,
                    session_id = EXCLUDED.session_id,
                    updated_at = CURRENT_TIMESTAMP
            ''', (
                job_id,
                status_data.get('status', 'pending'),
                status_data.get('progress', 0),
                status_data.get('message', ''),
                status_data.get('video_url', ''),
                status_data.get('error', ''),
                status_data.get('session_id', '')
            ))
            conn.commit()
            cursor.close()
            conn.close()
            print(f"[VIDEO-JOB-DB] Saved job {job_id} to PostgreSQL")
        except Exception as e:
            print(f"[VIDEO-JOB-DB] Error saving to PostgreSQL: {e}, falling back to file")
            # í´ë°±: íŒŒì¼ ì €ì¥
            job_file = os.path.join(VIDEO_JOBS_DIR, f"{job_id}.json")
            with open(job_file, 'w', encoding='utf-8') as f:
                json.dump(status_data, f, ensure_ascii=False)
    else:
        job_file = os.path.join(VIDEO_JOBS_DIR, f"{job_id}.json")
        with open(job_file, 'w', encoding='utf-8') as f:
            json.dump(status_data, f, ensure_ascii=False)

def _load_job_status(job_id):
    """ì‘ì—… ìƒíƒœë¥¼ DB ë˜ëŠ” íŒŒì¼ì—ì„œ ë¡œë“œ"""
    if USE_POSTGRES:
        try:
            conn = get_db_connection()
            cursor = conn.cursor()
            cursor.execute('''
                SELECT job_id, status, progress, message, video_url, error, session_id
                FROM video_jobs WHERE job_id = %s
            ''', (job_id,))
            row = cursor.fetchone()
            cursor.close()
            conn.close()

            if row:
                result = {
                    'job_id': row['job_id'],
                    'status': row['status'],
                    'progress': row['progress'],
                    'message': row['message'],
                    'video_url': row['video_url'],
                    'error': row['error'],
                    'session_id': row['session_id']
                }
                # ë””ë²„ê·¸ ë¡œê¹… (ë„ˆë¬´ ë¹ˆë²ˆí•œ í˜¸ì¶œ ë°©ì§€ë¥¼ ìœ„í•´ progressê°€ ë³€í•  ë•Œë§Œ)
                print(f"[VIDEO-JOB-DB] Load job {job_id}: status={result['status']}, progress={result['progress']}")
                return result
            print(f"[VIDEO-JOB-DB] Job {job_id} not found in PostgreSQL")
            return None
        except Exception as e:
            print(f"[VIDEO-JOB-DB] Error loading from PostgreSQL: {e}, falling back to file")
            # í´ë°±: íŒŒì¼ì—ì„œ ë¡œë“œ
            job_file = os.path.join(VIDEO_JOBS_DIR, f"{job_id}.json")
            if os.path.exists(job_file):
                with open(job_file, 'r', encoding='utf-8') as f:
                    return json.load(f)
            return None
    else:
        job_file = os.path.join(VIDEO_JOBS_DIR, f"{job_id}.json")
        if os.path.exists(job_file):
            with open(job_file, 'r', encoding='utf-8') as f:
                return json.load(f)
        return None

def _update_job_status(job_id, **kwargs):
    """ì‘ì—… ìƒíƒœ ë¶€ë¶„ ì—…ë°ì´íŠ¸"""
    if USE_POSTGRES:
        try:
            conn = get_db_connection()
            cursor = conn.cursor()

            # ë™ì  UPDATE ì¿¼ë¦¬ ìƒì„±
            update_fields = []
            values = []
            for key, value in kwargs.items():
                if key in ['status', 'progress', 'message', 'video_url', 'error', 'session_id']:
                    update_fields.append(f"{key} = %s")
                    values.append(value)

            if update_fields:
                update_fields.append("updated_at = CURRENT_TIMESTAMP")
                values.append(job_id)
                query = f"UPDATE video_jobs SET {', '.join(update_fields)} WHERE job_id = %s"
                cursor.execute(query, values)
                rows_affected = cursor.rowcount
                conn.commit()

                # ë””ë²„ê·¸ ë¡œê¹…: ì—…ë°ì´íŠ¸ ì„±ê³µ ì—¬ë¶€ í™•ì¸
                if rows_affected == 0:
                    print(f"[VIDEO-JOB-DB] WARNING: No rows updated for job {job_id} - job may not exist in DB")
                else:
                    progress = kwargs.get('progress', '-')
                    status = kwargs.get('status', '-')
                    print(f"[VIDEO-JOB-DB] Updated job {job_id}: progress={progress}, status={status}")

            cursor.close()
            conn.close()
        except Exception as e:
            print(f"[VIDEO-JOB-DB] Error updating PostgreSQL: {e}, falling back to file")
            # í´ë°±: íŒŒì¼ ì—…ë°ì´íŠ¸
            status = _load_job_status(job_id)
            if status:
                status.update(kwargs)
                job_file = os.path.join(VIDEO_JOBS_DIR, f"{job_id}.json")
                with open(job_file, 'w', encoding='utf-8') as f:
                    json.dump(status, f, ensure_ascii=False)
    else:
        status = _load_job_status(job_id)
        if status:
            status.update(kwargs)
            job_file = os.path.join(VIDEO_JOBS_DIR, f"{job_id}.json")
            with open(job_file, 'w', encoding='utf-8') as f:
                json.dump(status, f, ensure_ascii=False)

def _get_subtitle_style(lang):
    """ì–¸ì–´ë³„ ìë§‰ ìŠ¤íƒ€ì¼ ë°˜í™˜ (ASS í˜•ì‹) - ë°˜íˆ¬ëª… ê²€ì •ë°•ìŠ¤ + í°ìƒ‰ í…ìŠ¤íŠ¸

    ê¹”ë”í•œ ìŠ¤íƒ€ì¼: ë°˜íˆ¬ëª… ê²€ì • ë°°ê²½ ë°•ìŠ¤ ìœ„ì— í°ìƒ‰ í…ìŠ¤íŠ¸
    """
    # ê¹”ë”í•œ ìŠ¤íƒ€ì¼: í°ìƒ‰ í…ìŠ¤íŠ¸ + ë°˜íˆ¬ëª… ê²€ì • ë°•ìŠ¤
    # BorderStyle=4: ì™¸ê³½ì„  + ë°°ê²½ ë°•ìŠ¤
    # PrimaryColour=&HFFFFFF: í°ìƒ‰ í…ìŠ¤íŠ¸ (BGR ìˆœì„œ)
    # BackColour=&H80000000: ë°˜íˆ¬ëª… ê²€ì • ë°•ìŠ¤ (80=ì•½ 50% íˆ¬ëª…ë„)
    # OutlineColour=&H00000000: ê²€ì • ì™¸ê³½ì„ 
    # Outline=1: ì–‡ì€ ì™¸ê³½ì„ 
    if lang == 'ko':
        font_name = lang_ko.FONTS['default_name']
        return (
            f"FontName={font_name},FontSize=48,PrimaryColour=&HFFFFFF,"
            "OutlineColour=&H00000000,BackColour=&H80000000,"
            "BorderStyle=4,Outline=1,Shadow=0,MarginV=50,Bold=1"
        )
    elif lang == 'ja':
        font_name = lang_ja.FONTS['default_name']
        font_size = lang_ja.SUBTITLE['style']['font_size']
        return (
            f"FontName={font_name},FontSize={font_size},PrimaryColour=&HFFFFFF,"
            "OutlineColour=&H00000000,BackColour=&H80000000,"
            "BorderStyle=4,Outline=1,Shadow=0,MarginV=40,Bold=1"
        )
    elif lang == 'en':
        font_name = lang_en.FONTS['default_name']
        font_size = lang_en.SUBTITLE['style']['font_size']
        return (
            f"FontName={font_name},FontSize={font_size},PrimaryColour=&HFFFFFF,"
            "OutlineColour=&H00000000,BackColour=&H80000000,"
            "BorderStyle=4,Outline=1,Shadow=0,MarginV=40,Bold=1"
        )
    else:
        font_name = lang_en.FONTS['default_name']
        return (
            f"FontName={font_name},FontSize=22,PrimaryColour=&HFFFFFF,"
            "OutlineColour=&H00000000,BackColour=&H80000000,"
            "BorderStyle=4,Outline=1,Shadow=0,MarginV=40,Bold=1"
        )

def _hex_to_ass_color(hex_color):
    """HEX ìƒ‰ìƒì„ ASS í¬ë§·ìœ¼ë¡œ ë³€í™˜ (#RRGGBB -> &HBBGGRR&)"""
    if not hex_color or not hex_color.startswith('#'):
        return "&HFFFFFF&"  # ê¸°ë³¸ í°ìƒ‰
    hex_color = hex_color.lstrip('#')
    if len(hex_color) == 6:
        r, g, b = hex_color[0:2], hex_color[2:4], hex_color[4:6]
        return f"&H{b}{g}{r}&"
    return "&HFFFFFF&"  # ê¸°ë³¸ í°ìƒ‰


def _apply_subtitle_highlights(text, highlights):
    """ìë§‰ í…ìŠ¤íŠ¸ì— í‚¤ì›Œë“œ ìƒ‰ìƒ ê°•ì¡° ì ìš© (ë°•ìŠ¤ ë°°ê²½ í¬í•¨)

    Args:
        text: ì›ë³¸ ìë§‰ í…ìŠ¤íŠ¸
        highlights: [{"keyword": "ë‹¨ì–´", "color": "#FF0000"}, ...]

    Returns:
        ìƒ‰ìƒ íƒœê·¸ê°€ ì ìš©ëœ í…ìŠ¤íŠ¸ (ASS override tags)
    """
    if not highlights:
        return text

    result = text
    for h in highlights:
        keyword = h.get('keyword', '')
        color = h.get('color', '#FFFF00')
        if keyword and keyword in result:
            ass_color = _hex_to_ass_color(color)
            # ASS ìë§‰ ìƒ‰ìƒ ê°•ì¡° (ì›ë˜ ìŠ¤íƒ€ì¼ - ìƒ‰ìƒë§Œ ë³€ê²½)
            # - \c{ìƒ‰ìƒ}: í…ìŠ¤íŠ¸ ìƒ‰ìƒì„ ê°•ì¡°ìƒ‰ìœ¼ë¡œ ë³€ê²½
            # - ê°•ì¡° í›„ ì›ë˜ í°ìƒ‰ìœ¼ë¡œ ë³µì›
            colored_keyword = f"{{\\c{ass_color}}}{keyword}{{\\c&HFFFFFF&}}"
            result = result.replace(keyword, colored_keyword)

    return result


def _format_ass_time(seconds):
    """ì´ˆë¥¼ ASS ì‹œê°„ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (H:MM:SS.cc)"""
    hours = int(seconds // 3600)
    minutes = int((seconds % 3600) // 60)
    secs = int(seconds % 60)
    centisecs = int((seconds % 1) * 100)
    return f"{hours}:{minutes:02d}:{secs:02d}.{centisecs:02d}"


def _generate_ass_subtitles(subtitles, highlights, output_path, lang='ko'):
    """ASS í˜•ì‹ ìë§‰ íŒŒì¼ ìƒì„± (ìƒ‰ìƒ ê°•ì¡° ì§€ì›)

    Args:
        subtitles: [{"start": 0.0, "end": 3.0, "text": "ìë§‰"}, ...]
        highlights: [{"keyword": "ë‹¨ì–´", "color": "#FF0000"}, ...]
        output_path: ASS íŒŒì¼ ì¶œë ¥ ê²½ë¡œ
        lang: ì–¸ì–´ ì½”ë“œ

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    try:
        # ì–¸ì–´ë³„ í°íŠ¸ ì„¤ì • (í° ìë§‰ - 50ëŒ€+ ì‹œì²­ì ê°€ë…ì„±)
        # í•œêµ­ì–´ í°íŠ¸: lang/ko.pyì—ì„œ ê´€ë¦¬
        if lang == 'ko':
            font_name = lang_ko.FONTS['default_name']
            font_size = 48  # 24 â†’ 48 (2ë°° í¬ê¸°)
            max_chars_per_line = 100  # â˜… ì²­í‚¹ ë°©ì‹: ì¤„ë°”ê¿ˆ ë¹„í™œì„±í™” (í•œ ë¬¸ì¥ = í•œ ìë§‰)
        elif lang == 'ja':
            # ì¼ë³¸ì–´: lang/ja.pyì—ì„œ ê´€ë¦¬
            font_name = lang_ja.FONTS['default_name']
            font_size = lang_ja.SUBTITLE['style']['font_size_burn']
            max_chars_per_line = lang_ja.SUBTITLE['max_chars_per_line']
        elif lang == 'en':
            # ì˜ì–´: lang/en.pyì—ì„œ ê´€ë¦¬
            font_name = lang_en.FONTS['default_name']
            font_size = lang_en.SUBTITLE['style']['font_size_burn']
            max_chars_per_line = lang_en.SUBTITLE['max_chars_per_line']
        else:
            # ê¸°íƒ€ ì–¸ì–´ - ì˜ì–´ ì„¤ì •ìœ¼ë¡œ fallback
            font_name = lang_en.FONTS['default_name']
            font_size = lang_en.SUBTITLE['style']['font_size_burn']
            max_chars_per_line = lang_en.SUBTITLE['max_chars_per_line']

        # ê¸´ í…ìŠ¤íŠ¸ ìë™ ì¤„ë°”ê¿ˆ í•¨ìˆ˜
        def wrap_text(text, max_chars):
            """ê¸´ í…ìŠ¤íŠ¸ë¥¼ max_chars ê¸°ì¤€ìœ¼ë¡œ ì¤„ë°”ê¿ˆ"""
            if len(text) <= max_chars:
                return text

            # ì´ë¯¸ ì¤„ë°”ê¿ˆì´ ìˆìœ¼ë©´ ê° ì¤„ì— ëŒ€í•´ ì¬ê·€ ì²˜ë¦¬
            if '\n' in text:
                return '\n'.join(wrap_text(line, max_chars) for line in text.split('\n'))
            if '\\N' in text:
                return '\\N'.join(wrap_text(line, max_chars) for line in text.split('\\N'))

            # ì–¸ì–´ì— ë”°ë¥¸ ë¶„ë¦¬ ê¸°ì¤€
            # ì¼ë³¸ì–´/í•œêµ­ì–´: êµ¬ë‘ì , í•œêµ­ì–´: ë„ì–´ì“°ê¸°ë„ í¬í•¨
            punctuation = 'ã€ã€‚ï¼Œï¼!?ï¼ï¼Ÿ ã€€'  # ì¼ë³¸ì–´ êµ¬ë‘ì  + ê³µë°±

            # ìì—°ìŠ¤ëŸ¬ìš´ ì¤„ë°”ê¿ˆ ìœ„ì¹˜ ì°¾ê¸° (êµ¬ë‘ì /ê³µë°±ì—ì„œ ë¶„ë¦¬)
            words = []
            current = ""
            for char in text:
                current += char
                if char in punctuation:
                    words.append(current)
                    current = ""
            if current:
                words.append(current)

            # ë‹¨ì–´ ë‹¨ìœ„ë¡œ ì¤„ë°”ê¿ˆ
            lines = []
            current_line = ""
            for word in words:
                # ë‹¨ì–´ ìì²´ê°€ max_charsë³´ë‹¤ ê¸´ ê²½ìš° ê°•ì œ ë¶„í• 
                if len(word) > max_chars:
                    # í˜„ì¬ ì¤„ ì €ì¥
                    if current_line:
                        lines.append(current_line.strip())
                        current_line = ""
                    # ê¸´ ë‹¨ì–´ ê°•ì œ ë¶„í• 
                    while len(word) > max_chars:
                        lines.append(word[:max_chars])
                        word = word[max_chars:]
                    if word:
                        current_line = word
                elif len(current_line) + len(word) <= max_chars:
                    current_line += word
                else:
                    if current_line:
                        lines.append(current_line.strip())
                    current_line = word
            if current_line:
                lines.append(current_line.strip())

            # ë¹ˆ ì¤„ ì œê±°
            lines = [l for l in lines if l]

            # ë§ˆì§€ë§‰ ì¤„ì´ ë„ˆë¬´ ì§§ìœ¼ë©´ (8ì ë¯¸ë§Œ) ì´ì „ ì¤„ê³¼ í•©ì¹˜ê¸°
            # ì˜ˆ: "í•´ë“œë¦¬ê² ìŠµë‹ˆë‹¤." (8ì) ê°™ì€ ì§§ì€ ë ë¶€ë¶„ ë°©ì§€
            min_last_line_chars = 8
            if len(lines) >= 2 and len(lines[-1]) < min_last_line_chars:
                # ì´ì „ ì¤„ê³¼ í•©ì³¤ì„ ë•Œ max_charsë¥¼ ì•½ê°„ ì´ˆê³¼í•´ë„ í—ˆìš© (ê°€ë…ì„± ìš°ì„ )
                combined = lines[-2] + ' ' + lines[-1]
                if len(combined) <= max_chars + 6:  # ìµœëŒ€ 32ìê¹Œì§€ í—ˆìš©
                    lines[-2] = combined
                    lines.pop()

            result = '\n'.join(lines)
            return result

        # ASS í—¤ë” (ë°˜íˆ¬ëª… ë°•ìŠ¤ + ìë™ ì¤„ë°”ê¿ˆ)
        # BorderStyle=4: ì™¸ê³½ì„  + ë°°ê²½ ë°•ìŠ¤
        # BackColour=&H80000000: ë°˜íˆ¬ëª… ê²€ì • ë°°ê²½ (80 = ì•½ 50% íˆ¬ëª…)
        # PrimaryColour=&HFFFFFF: í°ìƒ‰ í…ìŠ¤íŠ¸ (BGR ìˆœì„œ)
        # OutlineColour=&H00000000: ê²€ì • ì™¸ê³½ì„ 
        # Outline=1: ì–‡ì€ ì™¸ê³½ì„ 
        # Shadow=0: ê·¸ë¦¼ì ì œê±°
        # MarginL/R=100: ì¢Œìš° ì—¬ë°±ìœ¼ë¡œ ìë™ ì¤„ë°”ê¿ˆ ì˜ì—­ ì œí•œ
        # MarginV=40: í•˜ë‹¨ ì—¬ë°±
        # WrapStyle=0: ìŠ¤ë§ˆíŠ¸ ì¤„ë°”ê¿ˆ (ê¸´ í…ìŠ¤íŠ¸ ìë™ 2ì¤„)
        ass_header = f"""[Script Info]
ScriptType: v4.00+
PlayResX: 1280
PlayResY: 720
WrapStyle: 0

[V4+ Styles]
Format: Name, Fontname, Fontsize, PrimaryColour, SecondaryColour, OutlineColour, BackColour, Bold, Italic, Underline, StrikeOut, ScaleX, ScaleY, Spacing, Angle, BorderStyle, Outline, Shadow, Alignment, MarginL, MarginR, MarginV, Encoding
Style: Default,{font_name},{font_size},&HFFFFFF,&H000000FF,&H00000000,&H80000000,1,0,0,0,100,100,0,0,4,1,0,2,100,100,40,1

[Events]
Format: Layer, Start, End, Style, Name, MarginL, MarginR, MarginV, Effect, Text
"""

        # ì´ë²¤íŠ¸ ìƒì„±
        events = []
        for sub in subtitles:
            start = _format_ass_time(sub['start'])
            end = _format_ass_time(sub['end'])
            text = sub.get('text', '')

            # ê¸´ í…ìŠ¤íŠ¸ ìë™ ì¤„ë°”ê¿ˆ ì ìš©
            original_text = text
            text = wrap_text(text, max_chars_per_line)
            if text != original_text:
                print(f"[ASS] ìë§‰ ì¤„ë°”ê¿ˆ ì ìš© (lang={lang}): '{original_text[:30]}...' â†’ {text.count(chr(10)) + 1}ì¤„")

            # ìƒ‰ìƒ ê°•ì¡° ì ìš©
            if highlights:
                text = _apply_subtitle_highlights(text, highlights)

            # ASSì—ì„œëŠ” \Nì´ ì¤„ë°”ê¿ˆ
            text = text.replace('\n', '\\N')

            events.append(f"Dialogue: 0,{start},{end},Default,,0,0,0,,{text}")

        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(ass_header)
            f.write('\n'.join(events))

        print(f"[ASS] ìë§‰ ìƒì„± ì™„ë£Œ: {len(subtitles)}ê°œ ìë§‰, {len(highlights)}ê°œ ê°•ì¡° í‚¤ì›Œë“œ")
        return True

    except Exception as e:
        print(f"[ASS] ìë§‰ ìƒì„± ì˜¤ë¥˜: {e}")
        return False


def _generate_screen_overlay_filter(screen_overlays, scenes, fonts_dir, subtitles=None, lang='ko'):
    """í™”ë©´ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ìš© FFmpeg drawtext í•„í„° ìƒì„± (ë‚˜ë ˆì´ì…˜ ì‹±í¬)

    Args:
        screen_overlays: [{"scene": 3, "text": "ëŒ€ë°•!", "duration": 3, "style": "impact"}, ...]
        scenes: ì”¬ ëª©ë¡ (duration ê³„ì‚°ìš©)
        fonts_dir: í°íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        subtitles: ìë§‰ ë°ì´í„° [{"start": 0.0, "end": 2.5, "text": "..."}, ...] (ë‚˜ë ˆì´ì…˜ ì‹±í¬ìš©)
        lang: ì–¸ì–´ ì½”ë“œ (ko, ja, en)

    Returns:
        FFmpeg drawtext í•„í„° ë¬¸ìì—´ ë˜ëŠ” None
    """
    if not screen_overlays:
        return None

    # ì”¬ë³„ ì‹œì‘ ì‹œê°„ ê³„ì‚° (fallbackìš©)
    scene_start_times = {}
    current_time = 0
    for idx, scene in enumerate(scenes):
        scene_start_times[idx + 1] = current_time  # 1-based index
        current_time += scene.get('duration', 0)

    filters = []
    # ì–¸ì–´ë³„ í°íŠ¸ ì„ íƒ (font= íŒŒë¼ë¯¸í„°ë¡œ fontconfig í´ë°± í™œì„±í™”)
    if lang == 'ja':
        font_name = lang_ja.FONTS['default_name']
    elif lang == 'en':
        font_name = lang_en.FONTS['default_name']
    else:
        font_name = lang_ko.FONTS['default_name']
    font_escaped = font_name.replace(':', '\\:')

    for overlay in screen_overlays:
        scene_num = overlay.get('scene', 1)
        text = overlay.get('text', '')
        duration = overlay.get('duration', 5)  # ê¸°ë³¸ 5ì´ˆë¡œ ì¦ê°€ (ê¸°ì¡´ 3ì´ˆ)
        style = overlay.get('style', 'impact')

        if not text:
            continue

        # ========== ë‚˜ë ˆì´ì…˜ ì‹±í¬: ìë§‰ì—ì„œ í•´ë‹¹ í…ìŠ¤íŠ¸ê°€ ë‚˜ì˜¤ëŠ” ì‹œê°„ ì°¾ê¸° ==========
        start_time = None
        if subtitles:
            # ì˜¤ë²„ë ˆì´ í…ìŠ¤íŠ¸ê°€ í¬í•¨ëœ ìë§‰ ì°¾ê¸°
            text_lower = text.lower().replace(' ', '')
            for sub in subtitles:
                sub_text = sub.get('text', '').lower().replace(' ', '')
                if text_lower in sub_text:
                    start_time = sub.get('start', 0)
                    print(f"[OVERLAY] ë‚˜ë ˆì´ì…˜ ì‹±í¬ ì„±ê³µ: '{text}' â†’ {start_time:.1f}s (ìë§‰: '{sub.get('text', '')[:30]}...')")
                    break

        # ìë§‰ì—ì„œ ëª» ì°¾ìœ¼ë©´ ì”¬ ì‹œì‘ ì‹œê°„ ì‚¬ìš© (fallback)
        if start_time is None:
            if scene_num in scene_start_times:
                start_time = scene_start_times[scene_num]
                print(f"[OVERLAY] ë‚˜ë ˆì´ì…˜ ì‹±í¬ ì‹¤íŒ¨, ì”¬ ì‹œì‘ ì‹œê°„ ì‚¬ìš©: '{text}' â†’ scene {scene_num} = {start_time:.1f}s")
            else:
                print(f"[OVERLAY] ìŠ¤í‚µ: text='{text}', scene={scene_num} ì—†ìŒ")
                continue

        end_time = start_time + duration

        # ========== ìŠ¤íƒ€ì¼ë³„ ì„¤ì • (ë°•ìŠ¤ ë°°ê²½ ì¶”ê°€) ==========
        # 3ë²ˆ ì´ë¯¸ì§€ì²˜ëŸ¼ í…ìŠ¤íŠ¸ì— ë°•ìŠ¤ ë°°ê²½ ì ìš©
        if style == 'impact':
            # ë¹¨ê°„ ë°•ìŠ¤ + í°ìƒ‰ í…ìŠ¤íŠ¸ (ê°€ì¥ ê°•ë ¬)
            fontcolor = "white"
            fontsize = 100
            borderw = 3
            bordercolor = "black"
            box_enabled = True
            boxcolor = "red@0.9"  # ë¹¨ê°„ ë°•ìŠ¤ 90% ë¶ˆíˆ¬ëª…
            boxborderw = 15  # ë°•ìŠ¤ íŒ¨ë”©
        elif style == 'dramatic':
            # ë…¸ë€ ë°•ìŠ¤ + ê²€ì€ í…ìŠ¤íŠ¸
            fontcolor = "black"
            fontsize = 90
            borderw = 0
            bordercolor = "black"
            box_enabled = True
            boxcolor = "yellow@0.9"  # ë…¸ë€ ë°•ìŠ¤
            boxborderw = 12
        elif style == 'emotional':
            # ì²­ë¡ ë°•ìŠ¤ + í°ìƒ‰ í…ìŠ¤íŠ¸
            fontcolor = "white"
            fontsize = 80
            borderw = 2
            bordercolor = "black"
            box_enabled = True
            boxcolor = "#00CCCC@0.85"  # ì²­ë¡ ë°•ìŠ¤
            boxborderw = 10
        else:
            # ê¸°ë³¸: ê²€ì€ ë°•ìŠ¤ + í°ìƒ‰ í…ìŠ¤íŠ¸
            fontcolor = "white"
            fontsize = 90
            borderw = 2
            bordercolor = "black"
            box_enabled = True
            boxcolor = "black@0.8"
            boxborderw = 12

        # FFmpeg drawtext í…ìŠ¤íŠ¸ ì´ìŠ¤ì¼€ì´í”„
        text_escaped = text.replace('\\', '\\\\').replace("'", "\\'").replace(':', '\\:').replace('=', '\\=')

        print(f"[OVERLAY] ì¶”ê°€: text='{text}', style={style}, time={start_time:.1f}-{end_time:.1f}s (duration={duration}s)")

        # drawtext í•„í„° ìƒì„± (í™”ë©´ ì¤‘ì•™, ë°•ìŠ¤ ë°°ê²½ ì¶”ê°€)
        # font= íŒŒë¼ë¯¸í„° ì‚¬ìš©ìœ¼ë¡œ fontconfig í´ë°± í™œì„±í™” (ì¼ë³¸ì–´ ë¬¸ì ê¹¨ì§ ë°©ì§€)
        drawtext = (
            f"drawtext=text='{text_escaped}':"
            f"font='{font_escaped}':"
            f"fontsize={fontsize}:"
            f"fontcolor={fontcolor}:"
            f"bordercolor={bordercolor}:"
            f"borderw={borderw}:"
            f"box=1:"
            f"boxcolor={boxcolor}:"
            f"boxborderw={boxborderw}:"
            f"x=(w-text_w)/2:"
            f"y=(h-text_h)/2:"
            f"enable='between(t,{start_time},{end_time})'"
        )
        filters.append(drawtext)

    if filters:
        return ",".join(filters)
    return None


def _generate_lower_thirds_filter(lower_thirds, scenes, fonts_dir, lang='ko'):
    """ë¡œì›Œì„œë“œ(í•˜ë‹¨ ìë§‰) ì˜¤ë²„ë ˆì´ìš© FFmpeg drawtext í•„í„° ìƒì„±

    Args:
        lower_thirds: [{"scene": 2, "text": "ì¶œì²˜: OOì¼ë³´", "position": "bottom-left"}, ...]
        scenes: ì”¬ ëª©ë¡ (duration ê³„ì‚°ìš©)
        fonts_dir: í°íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        lang: ì–¸ì–´ ì½”ë“œ (ko, ja, en)

    Returns:
        FFmpeg drawtext í•„í„° ë¬¸ìì—´ ë˜ëŠ” None
    """
    if not lower_thirds:
        return None

    # ì”¬ë³„ ì‹œì‘ ì‹œê°„ ê³„ì‚°
    scene_start_times = {}
    scene_durations = {}
    current_time = 0
    for idx, scene in enumerate(scenes):
        scene_start_times[idx + 1] = current_time  # 1-based index
        scene_durations[idx + 1] = scene.get('duration', 0)
        current_time += scene.get('duration', 0)

    filters = []
    # ì–¸ì–´ë³„ í°íŠ¸ ì„ íƒ (font= íŒŒë¼ë¯¸í„°ë¡œ fontconfig í´ë°± í™œì„±í™”)
    if lang == 'ja':
        font_name = lang_ja.FONTS['default_name']
    elif lang == 'en':
        font_name = lang_en.FONTS['default_name']
    else:
        font_name = lang_ko.FONTS['default_name']
    font_escaped = font_name.replace(':', '\\:')

    for lt in lower_thirds:
        scene_num = lt.get('scene', 1)
        text = lt.get('text', '')
        position = lt.get('position', 'bottom-left')

        if not text or scene_num not in scene_start_times:
            continue

        start_time = scene_start_times[scene_num]
        # ë¡œì›Œì„œë“œëŠ” ì”¬ ì „ì²´ ë™ì•ˆ í‘œì‹œ (í˜ì´ë“œì¸/ì•„ì›ƒ)
        scene_duration = scene_durations.get(scene_num, 5)
        end_time = start_time + scene_duration

        # ìœ„ì¹˜ë³„ ì¢Œí‘œ ì„¤ì •
        # ìë§‰ê³¼ ê²¹ì¹˜ì§€ ì•Šë„ë¡ ì¶©ë¶„íˆ ìœ„ë¡œ (í•˜ë‹¨ì—ì„œ 180px)
        if position == 'bottom-left':
            x_pos = "30"
            y_pos = "h-th-180"  # í•˜ë‹¨ì—ì„œ 180px ìœ„ (ìë§‰ ìœ„)
        elif position == 'bottom-right':
            x_pos = "w-tw-30"
            y_pos = "h-th-180"
        elif position == 'bottom-center':
            x_pos = "(w-tw)/2"
            y_pos = "h-th-180"
        else:  # default: bottom-left
            x_pos = "30"
            y_pos = "h-th-180"

        # ë°˜íˆ¬ëª… ë°°ê²½ ë°•ìŠ¤ + í…ìŠ¤íŠ¸ (ë‰´ìŠ¤ ìŠ¤íƒ€ì¼)
        # ë°°ê²½ ë°•ìŠ¤ í•„í„° (drawbox)
        box_filter = (
            f"drawbox=x={x_pos}-10:y={y_pos}-10:"
            f"w=tw+20:h=th+20:"
            f"color=black@0.7:t=fill:"
            f"enable='between(t,{start_time},{end_time})'"
        )

        # í…ìŠ¤íŠ¸ í•„í„° (font= íŒŒë¼ë¯¸í„°ë¡œ fontconfig í´ë°± í™œì„±í™”)
        text_escaped = text.replace("'", "'\\''").replace(":", "\\:")
        text_filter = (
            f"drawtext=text='{text_escaped}':"
            f"font='{font_escaped}':"
            f"fontsize=28:"
            f"fontcolor=white:"
            f"x={x_pos}:"
            f"y={y_pos}:"
            f"enable='between(t,{start_time},{end_time})'"
        )

        # drawboxëŠ” text_wë¥¼ ëª¨ë¥´ë¯€ë¡œ ëŒ€ëµì ì¸ í¬ê¸° ì‚¬ìš©
        # ë” ì •í™•í•œ ë°©ë²•: í…ìŠ¤íŠ¸ë§Œ í‘œì‹œ (ë°°ê²½ ì—†ì´)
        # ë˜ëŠ” box=1:boxcolor=black@0.7:boxborderw=10 ì‚¬ìš©
        text_with_bg = (
            f"drawtext=text='{text_escaped}':"
            f"font='{font_escaped}':"
            f"fontsize=28:"
            f"fontcolor=white:"
            f"box=1:"
            f"boxcolor=black@0.7:"
            f"boxborderw=10:"
            f"x={x_pos}:"
            f"y={y_pos}:"
            f"enable='between(t,{start_time},{end_time})'"
        )

        filters.append(text_with_bg)

    if filters:
        return ",".join(filters)
    return None


def _generate_news_ticker_filter(news_ticker, total_duration, fonts_dir, lang='ko'):
    """ë‰´ìŠ¤ í‹°ì»¤(ìŠ¤í¬ë¡¤ í—¤ë“œë¼ì¸) í•„í„° ìƒì„±

    Args:
        news_ticker: {"enabled": true, "headlines": ["ì†ë³´: ...", "ì´ìŠˆ: ..."]}
        total_duration: ì „ì²´ ì˜ìƒ ê¸¸ì´ (ì´ˆ)
        fonts_dir: í°íŠ¸ ë””ë ‰í† ë¦¬ ê²½ë¡œ
        lang: ì–¸ì–´ ì½”ë“œ (ko, ja, en)

    Returns:
        FFmpeg drawtext í•„í„° ë¬¸ìì—´ ë˜ëŠ” None
    """
    if not news_ticker or not news_ticker.get('enabled'):
        return None

    headlines = news_ticker.get('headlines', [])
    if not headlines:
        return None

    # í—¤ë“œë¼ì¸ì„ í•˜ë‚˜ì˜ ê¸´ í…ìŠ¤íŠ¸ë¡œ ì—°ê²° (êµ¬ë¶„ì: â—)
    ticker_text = "   â—   ".join(headlines) + "   â—   " + headlines[0]  # ë°˜ë³µì„ ìœ„í•´ ì²« ë²ˆì§¸ ì¶”ê°€
    ticker_text = ticker_text.replace("'", "'\\''").replace(":", "\\:")

    # ì–¸ì–´ë³„ í°íŠ¸ ì„ íƒ (font= íŒŒë¼ë¯¸í„°ë¡œ fontconfig í´ë°± í™œì„±í™”)
    if lang == 'ja':
        font_name = lang_ja.FONTS['default_name']
    elif lang == 'en':
        font_name = lang_en.FONTS['default_name']
    else:
        font_name = lang_ko.FONTS['default_name']
    font_escaped = font_name.replace(':', '\\:')

    # ìŠ¤í¬ë¡¤ ì†ë„: ì „ì²´ ì˜ìƒ ë™ì•ˆ í…ìŠ¤íŠ¸ê°€ 2-3ë²ˆ ì •ë„ ì§€ë‚˜ê°€ë„ë¡
    # x = w - (mod(t * speed, tw + w))
    # speed = (tw + w) / (total_duration / scroll_cycles)
    scroll_speed = 100  # ì´ˆë‹¹ 100í”½ì…€ ì´ë™

    # ë‰´ìŠ¤ í‹°ì»¤ ìŠ¤íƒ€ì¼: í•˜ë‹¨ì— ì–´ë‘ìš´ ë¹¨ê°„ ë°°ê²½(ë°˜íˆ¬ëª…) + í° í…ìŠ¤íŠ¸
    # ì°¸ê³ : drawboxì—ì„œ w=wëŠ” ìˆœí™˜ ì°¸ì¡° ì—ëŸ¬ ë°œìƒ, iw(ì…ë ¥ ë„ˆë¹„) ì‚¬ìš©
    # font= íŒŒë¼ë¯¸í„° ì‚¬ìš©ìœ¼ë¡œ fontconfig í´ë°± í™œì„±í™” (ì¼ë³¸ì–´ ë¬¸ì ê¹¨ì§ ë°©ì§€)
    ticker_filter = (
        f"drawbox=x=0:y=ih-40:w=iw:h=40:color=0x8B0000@0.7:t=fill,"
        f"drawtext=text='{ticker_text}':"
        f"font='{font_escaped}':"
        f"fontsize=24:"
        f"fontcolor=white:"
        f"x=w-mod(t*{scroll_speed}\\,tw+w):"
        f"y=h-35"
    )

    return ticker_filter


# BGM ë¶„ìœ„ê¸° ë³„ì¹­ ë§¤í•‘ (íŒŒì¼ì´ ì—†ì„ ê²½ìš° ëŒ€ì²´ ë¶„ìœ„ê¸°ë¡œ í´ë°±)
# í˜„ì¬ ì‚¬ìš© ê°€ëŠ¥í•œ BGM: calm, cinematic, comedic, dramatic, epic, hopeful, horror, mysterious, nostalgic, sad, tense, upbeat
BGM_MOOD_ALIAS = {
    # ë‰´ìŠ¤/ë‹¤íë©˜í„°ë¦¬/ê¸°ì—… ê³„ì—´ â†’ calm ë˜ëŠ” cinematic
    "documentary": "cinematic",
    "news": "calm",
    "informative": "calm",
    "corporate": "calm",
    "trailer": "cinematic",

    # ê°ì • ê³„ì—´ â†’ sad, hopeful, nostalgic
    "melancholy": "sad",
    "melancholic": "sad",
    "sentimental": "sad",
    "touching": "sad",
    "emotional": "sad",
    "inspiring": "hopeful",
    "uplifting": "hopeful",
    "motivational": "hopeful",
    "triumphant": "epic",
    "romantic": "nostalgic",

    # ê¸´ì¥/ì„œìŠ¤íœìŠ¤ ê³„ì—´ â†’ tense, mysterious, horror
    "suspense": "tense",
    "suspenseful": "tense",
    "thriller": "tense",
    "chase": "tense",
    "dark": "mysterious",
    "ethereal": "mysterious",

    # ë°ì€/ê¸ì •/ì—ë„ˆì§€ ê³„ì—´ â†’ upbeat, comedic
    "cheerful": "upbeat",
    "happy": "upbeat",
    "bright": "upbeat",
    "energetic": "upbeat",
    "whimsical": "comedic",

    # ì°¨ë¶„í•œ/í‰í™” ê³„ì—´ â†’ calm
    "peaceful": "calm",
    "relaxing": "calm",
    "ambient": "calm",
    "jazz": "calm",
    "classical": "calm",
    "acoustic": "calm",
    "piano": "calm",
    "electronic": "upbeat",

    # ì•¡ì…˜/ëª¨í—˜ ê³„ì—´ â†’ epic, dramatic
    "action": "epic",
    "adventure": "epic",
    "battle": "epic",
    "heroic": "epic",
}


def _get_bgm_file(mood, bgm_dir=None):
    """ë¶„ìœ„ê¸°ì— ë§ëŠ” BGM íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œë©´ ëœë¤)

    Args:
        mood: ì§€ì› ë¶„ìœ„ê¸° (12ì¢…) - calm, cinematic, comedic, dramatic, epic,
              hopeful, horror, mysterious, nostalgic, sad, tense, upbeat
              (íŒŒì¼ì´ ì—†ìœ¼ë©´ BGM_MOOD_ALIASì— ë”°ë¼ ëŒ€ì²´ ë¶„ìœ„ê¸°ë¡œ í´ë°±)
        bgm_dir: BGM íŒŒì¼ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)

    Returns:
        BGM íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    import glob
    import random

    # ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
    if bgm_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")

    print(f"[BGM] ê²€ìƒ‰ ì‹œì‘: mood='{mood}', dir='{bgm_dir}'")

    if not mood:
        print(f"[BGM] moodê°€ ë¹„ì–´ìˆìŒ")
        return None

    if not os.path.exists(bgm_dir):
        print(f"[BGM] ë””ë ‰í† ë¦¬ ì—†ìŒ: {bgm_dir}")
        print(f"[BGM] âš ï¸ BGM íŒŒì¼ì„ {bgm_dir}ì— ì—…ë¡œë“œí•˜ì„¸ìš”. ì˜ˆ: {mood}.mp3, {mood}_01.mp3")
        return None

    # íŒŒì¼ëª… íŒ¨í„´: mood.mp3, mood_01.mp3, mood (1).mp3 ë“±
    patterns = [
        os.path.join(bgm_dir, f"{mood}.mp3"),
        os.path.join(bgm_dir, f"{mood}_*.mp3"),
        os.path.join(bgm_dir, f"{mood} *.mp3"),  # ê³µë°± í¬í•¨
        os.path.join(bgm_dir, f"{mood}*.mp3"),
    ]

    matching_files = []
    for pattern in patterns:
        found = glob.glob(pattern)
        matching_files.extend(found)

    # ì¤‘ë³µ ì œê±°
    matching_files = list(set(matching_files))

    # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ì¶œë ¥ (ë””ë²„ê·¸ìš©)
    all_files = glob.glob(os.path.join(bgm_dir, "*.mp3"))
    print(f"[BGM] ë””ë ‰í† ë¦¬ ë‚´ ì „ì²´ íŒŒì¼: {[os.path.basename(f) for f in all_files]}")

    if not matching_files:
        # ë³„ì¹­ ë§¤í•‘ìœ¼ë¡œ í´ë°± ì‹œë„
        alias_mood = BGM_MOOD_ALIAS.get(mood)
        if alias_mood:
            print(f"[BGM] '{mood}' íŒŒì¼ ì—†ìŒ â†’ '{alias_mood}'ë¡œ í´ë°± ì‹œë„")
            alias_patterns = [
                os.path.join(bgm_dir, f"{alias_mood}.mp3"),
                os.path.join(bgm_dir, f"{alias_mood}_*.mp3"),
                os.path.join(bgm_dir, f"{alias_mood} *.mp3"),
                os.path.join(bgm_dir, f"{alias_mood}*.mp3"),
            ]
            for pattern in alias_patterns:
                matching_files.extend(glob.glob(pattern))
            matching_files = list(set(matching_files))

        if not matching_files:
            print(f"[BGM] '{mood}' ë¶„ìœ„ê¸° BGM íŒŒì¼ ì—†ìŒ")
            print(f"[BGM] âš ï¸ {bgm_dir}/{mood}.mp3 ë˜ëŠ” {mood}_01.mp3 í˜•ì‹ìœ¼ë¡œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
            return None

    # ëœë¤ ì„ íƒ
    selected = random.choice(matching_files)
    print(f"[BGM] ì„ íƒëœ BGM: {selected} (í›„ë³´ {len(matching_files)}ê°œ ì¤‘)")
    return selected


def _mix_bgm_with_video(video_path, bgm_path, output_path, bgm_volume=0.10):
    """ë¹„ë””ì˜¤ì— BGM ë¯¹ì‹± (ë‚˜ë ˆì´ì…˜ ìœ ì§€, BGMì€ ì‘ê²Œ)

    Args:
        video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
        bgm_path: BGM ì˜¤ë””ì˜¤ ê²½ë¡œ
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        bgm_volume: BGM ë³¼ë¥¨ (0.0~1.0, ê¸°ë³¸ 0.10 = 10%)

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    try:
        # ë¹„ë””ì˜¤ ê¸¸ì´ í™•ì¸
        probe_cmd = ["ffprobe", "-v", "error", "-show_entries", "format=duration",
                     "-of", "default=noprint_wrappers=1:nokey=1", video_path]
        result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
        video_duration = float(result.stdout.strip())

        print(f"[BGM] ë¹„ë””ì˜¤ ê¸¸ì´: {video_duration:.1f}ì´ˆ", flush=True)

        # FFmpeg ëª…ë ¹: BGM ë£¨í”„ + ë³¼ë¥¨ ì¡°ì ˆ + ë¯¹ì‹± + í˜ì´ë“œì•„ì›ƒ
        # -stream_loop -1: BGM ë¬´í•œ ë£¨í”„
        # volume: BGM ë³¼ë¥¨ ë‚®ì¶¤
        # amix: ì˜¤ë””ì˜¤ ë¯¹ì‹±
        # afade: ë§ˆì§€ë§‰ 3ì´ˆ í˜ì´ë“œì•„ì›ƒ

        fade_start = max(0, video_duration - 3)  # ë§ˆì§€ë§‰ 3ì´ˆ

        ffmpeg_cmd = [
            "ffmpeg", "-y",
            "-i", video_path,                          # ì›ë³¸ ë¹„ë””ì˜¤ (ì˜¤ë””ì˜¤ í¬í•¨)
            "-stream_loop", "-1", "-i", bgm_path,      # BGM ë£¨í”„
            "-filter_complex",
            f"[1:a]volume={bgm_volume},afade=t=in:st=0:d=2,afade=t=out:st={fade_start}:d=3[bgm];"  # BGM ë³¼ë¥¨+í˜ì´ë“œ
            f"[0:a][bgm]amix=inputs=2:duration=first:dropout_transition=2:normalize=0[aout]",  # ë¯¹ì‹± (normalize=0: TTS ë³¼ë¥¨ ìœ ì§€)
            "-map", "0:v",                             # ë¹„ë””ì˜¤ ìŠ¤íŠ¸ë¦¼
            "-map", "[aout]",                          # ë¯¹ì‹±ëœ ì˜¤ë””ì˜¤
            "-c:v", "copy",                            # ë¹„ë””ì˜¤ ì¬ì¸ì½”ë”© ì•ˆí•¨
            "-c:a", "aac", "-b:a", "128k",            # ì˜¤ë””ì˜¤ ì¸ì½”ë”©
            "-shortest",                               # ë¹„ë””ì˜¤ ê¸¸ì´ì— ë§ì¶¤
            output_path
        ]

        print(f"[BGM] ë¯¹ì‹± ì‹œì‘...", flush=True)
        result = subprocess.run(ffmpeg_cmd, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE, timeout=600)

        if result.returncode == 0:
            print(f"[BGM] ë¯¹ì‹± ì™„ë£Œ: {output_path}", flush=True)
            return True
        else:
            stderr = result.stderr.decode('utf-8', errors='ignore')[:300]
            print(f"[BGM] ë¯¹ì‹± ì‹¤íŒ¨: {stderr}", flush=True)
            return False

    except Exception as e:
        print(f"[BGM] ë¯¹ì‹± ì˜¤ë¥˜: {e}", flush=True)
        return False


def _mix_scene_bgm_with_video(video_path, scenes, video_effects, output_path, bgm_volume=0.10):
    """ë¹„ë””ì˜¤ì— ì”¬ë³„ BGM ë¯¹ì‹± (ê°ì • íë¦„ì— ë”°ë¼ BGM ì „í™˜)

    Args:
        video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
        scenes: ì”¬ ëª©ë¡ (duration ì •ë³´ í¬í•¨)
        video_effects: video_effects ê°ì²´ (bgm_mood, scene_bgm_changes í¬í•¨)
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        bgm_volume: BGM ë³¼ë¥¨ (0.0~1.0, ê¸°ë³¸ 0.10 = 10%)

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    import tempfile
    import shutil

    try:
        base_mood = video_effects.get('bgm_mood', '')
        scene_bgm_changes = video_effects.get('scene_bgm_changes', [])

        if not base_mood:
            print(f"[BGM-SCENE] ê¸°ë³¸ BGM ë¶„ìœ„ê¸°ê°€ ì—†ìŒ")
            return False

        # ì”¬ë³„ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
        scene_times = []
        current_time = 0
        for idx, scene in enumerate(scenes):
            duration = scene.get('duration', 0)
            scene_times.append({
                'scene': idx + 1,
                'start': current_time,
                'end': current_time + duration,
                'duration': duration
            })
            current_time += duration

        total_duration = current_time
        print(f"[BGM-SCENE] ì „ì²´ ê¸¸ì´: {total_duration:.1f}ì´ˆ, ì”¬ ìˆ˜: {len(scenes)}")

        # scene_bgm_changesê°€ ì—†ê±°ë‚˜ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        if not scene_bgm_changes:
            print(f"[BGM-SCENE] ì”¬ë³„ BGM ë³€ê²½ ì—†ìŒ, ê¸°ì¡´ ë°©ì‹ ì‚¬ìš©")
            bgm_file = _get_bgm_file(base_mood)
            if bgm_file:
                return _mix_bgm_with_video(video_path, bgm_file, output_path, bgm_volume)
            return False

        # BGM êµ¬ê°„ ê³„ì‚° (ê° êµ¬ê°„ì˜ moodì™€ ì‹œê°„)
        bgm_segments = []
        changes_dict = {c['scene']: c['mood'] for c in scene_bgm_changes}

        current_mood = base_mood
        segment_start = 0

        for st in scene_times:
            scene_num = st['scene']
            if scene_num in changes_dict:
                # ì´ì „ êµ¬ê°„ ì €ì¥
                if st['start'] > segment_start:
                    bgm_segments.append({
                        'mood': current_mood,
                        'start': segment_start,
                        'end': st['start'],
                        'duration': st['start'] - segment_start
                    })
                # ìƒˆ moodë¡œ ì „í™˜
                current_mood = changes_dict[scene_num]
                segment_start = st['start']

        # ë§ˆì§€ë§‰ êµ¬ê°„ ì¶”ê°€
        if total_duration > segment_start:
            bgm_segments.append({
                'mood': current_mood,
                'start': segment_start,
                'end': total_duration,
                'duration': total_duration - segment_start
            })

        print(f"[BGM-SCENE] BGM êµ¬ê°„: {len(bgm_segments)}ê°œ")
        for seg in bgm_segments:
            print(f"  - {seg['mood']}: {seg['start']:.1f}s ~ {seg['end']:.1f}s ({seg['duration']:.1f}s)")

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp()

        try:
            # ê° êµ¬ê°„ë³„ BGM ì„¸ê·¸ë¨¼íŠ¸ ì¤€ë¹„
            input_files = [video_path]
            filter_parts = []

            for i, seg in enumerate(bgm_segments):
                bgm_file = _get_bgm_file(seg['mood'])
                if not bgm_file:
                    print(f"[BGM-SCENE] '{seg['mood']}' BGM íŒŒì¼ ì—†ìŒ, ê±´ë„ˆëœ€")
                    continue

                input_files.append(bgm_file)
                input_idx = len(input_files) - 1

                # ê° BGM êµ¬ê°„ì— ë³¼ë¥¨, ë”œë ˆì´, íŠ¸ë¦¼, í˜ì´ë“œ ì ìš©
                delay_ms = int(seg['start'] * 1000)
                duration = seg['duration']

                # í˜ì´ë“œ ì¸/ì•„ì›ƒ: êµ¬ê°„ ì‹œì‘/ëì— 1ì´ˆì”©
                fade_in_duration = min(1.0, duration * 0.2)
                fade_out_start = max(0, duration - 1.0)
                fade_out_duration = min(1.0, duration * 0.2)

                filter_parts.append(
                    f"[{input_idx}:a]atrim=0:{duration},asetpts=PTS-STARTPTS,"
                    f"volume={bgm_volume},"
                    f"afade=t=in:st=0:d={fade_in_duration},"
                    f"afade=t=out:st={fade_out_start}:d={fade_out_duration},"
                    f"adelay={delay_ms}|{delay_ms}[bgm{i}]"
                )

            if not filter_parts:
                print(f"[BGM-SCENE] ì‚¬ìš© ê°€ëŠ¥í•œ BGM ì—†ìŒ")
                shutil.rmtree(temp_dir, ignore_errors=True)
                return False

            # ëª¨ë“  BGM ìŠ¤íŠ¸ë¦¼ ë¯¹ì‹±
            bgm_labels = "".join([f"[bgm{i}]" for i in range(len(filter_parts))])
            filter_parts.append(
                f"{bgm_labels}amix=inputs={len(filter_parts)}:duration=longest:dropout_transition=2:normalize=0[bgm_mixed]"
            )

            # ì›ë³¸ ì˜¤ë””ì˜¤ì™€ ë¯¹ì‹±ëœ BGM í•©ì¹˜ê¸°
            filter_parts.append(
                f"[0:a][bgm_mixed]amix=inputs=2:duration=first:dropout_transition=2:normalize=0[aout]"
            )

            filter_complex = ";".join(filter_parts)

            # FFmpeg ëª…ë ¹ êµ¬ì„±
            input_args = []
            for f in input_files:
                if f == input_files[0]:
                    input_args.extend(["-i", f])
                else:
                    input_args.extend(["-stream_loop", "-1", "-i", f])

            ffmpeg_cmd = [
                "ffmpeg", "-y",
                *input_args,
                "-filter_complex", filter_complex,
                "-map", "0:v",
                "-map", "[aout]",
                "-c:v", "copy",
                "-c:a", "aac", "-b:a", "128k",
                "-shortest",
                output_path
            ]

            print(f"[BGM-SCENE] ì”¬ë³„ BGM ë¯¹ì‹± ì‹œì‘...")
            result = subprocess.run(ffmpeg_cmd, stdout=subprocess.DEVNULL,
                                   stderr=subprocess.PIPE, timeout=900)

            if result.returncode == 0:
                print(f"[BGM-SCENE] ë¯¹ì‹± ì™„ë£Œ: {output_path}")
                return True
            else:
                stderr = result.stderr.decode('utf-8', errors='ignore')[-500:]
                print(f"[BGM-SCENE] ë¯¹ì‹± ì‹¤íŒ¨: {stderr}")
                # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
                print(f"[BGM-SCENE] ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±...")
                bgm_file = _get_bgm_file(base_mood)
                if bgm_file:
                    return _mix_bgm_with_video(video_path, bgm_file, output_path, bgm_volume)
                return False

        finally:
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        print(f"[BGM-SCENE] ë¯¹ì‹± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        # ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ í´ë°±
        try:
            base_mood = video_effects.get('bgm_mood', '')
            if base_mood:
                bgm_file = _get_bgm_file(base_mood)
                if bgm_file:
                    return _mix_bgm_with_video(video_path, bgm_file, output_path, bgm_volume)
        except:
            pass
        return False


def _get_sfx_file(sfx_type, sfx_dir=None):
    """íš¨ê³¼ìŒ íƒ€ì…ì— ë§ëŠ” íŒŒì¼ ì„ íƒ (ì—¬ëŸ¬ ê°œë©´ ëœë¤)

    Args:
        sfx_type: impact, whoosh, ding, tension, emotional, success
        sfx_dir: íš¨ê³¼ìŒ íŒŒì¼ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)

    Returns:
        íš¨ê³¼ìŒ íŒŒì¼ ê²½ë¡œ ë˜ëŠ” None
    """
    import glob
    import random

    # ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
    if sfx_dir is None:
        script_dir = os.path.dirname(os.path.abspath(__file__))
        sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")

    print(f"[SFX] ê²€ìƒ‰ ì‹œì‘: type='{sfx_type}', dir='{sfx_dir}'")

    if not sfx_type:
        print(f"[SFX] sfx_typeì´ ë¹„ì–´ìˆìŒ")
        return None

    if not os.path.exists(sfx_dir):
        print(f"[SFX] ë””ë ‰í† ë¦¬ ì—†ìŒ: {sfx_dir}")
        print(f"[SFX] âš ï¸ íš¨ê³¼ìŒ íŒŒì¼ì„ {sfx_dir}ì— ì—…ë¡œë“œí•˜ì„¸ìš”. ì˜ˆ: {sfx_type}.mp3")
        return None

    patterns = [
        os.path.join(sfx_dir, f"{sfx_type}.mp3"),
        os.path.join(sfx_dir, f"{sfx_type}_*.mp3"),
        os.path.join(sfx_dir, f"{sfx_type}*.mp3"),
    ]

    matching_files = []
    for pattern in patterns:
        matching_files.extend(glob.glob(pattern))

    matching_files = list(set(matching_files))

    # ë””ë ‰í† ë¦¬ ë‚´ ëª¨ë“  íŒŒì¼ ì¶œë ¥ (ë””ë²„ê·¸ìš©)
    all_files = glob.glob(os.path.join(sfx_dir, "*.mp3"))
    print(f"[SFX] ë””ë ‰í† ë¦¬ ë‚´ ì „ì²´ íŒŒì¼: {[os.path.basename(f) for f in all_files]}")

    if not matching_files:
        print(f"[SFX] '{sfx_type}' íš¨ê³¼ìŒ íŒŒì¼ ì—†ìŒ")
        print(f"[SFX] âš ï¸ {sfx_dir}/{sfx_type}.mp3 í˜•ì‹ìœ¼ë¡œ íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”")
        return None

    selected = random.choice(matching_files)
    print(f"[SFX] ì„ íƒëœ íš¨ê³¼ìŒ: {selected}")
    return selected


def _trim_sfx(input_path, output_path, max_duration=2.5, fade_out=0.5):
    """íš¨ê³¼ìŒì„ ì§€ì • ê¸¸ì´ë¡œ ìë¥´ê³  í˜ì´ë“œì•„ì›ƒ ì ìš©

    Args:
        input_path: ì›ë³¸ íš¨ê³¼ìŒ ê²½ë¡œ
        output_path: ì¶œë ¥ ê²½ë¡œ
        max_duration: ìµœëŒ€ ê¸¸ì´ (ì´ˆ)
        fade_out: í˜ì´ë“œì•„ì›ƒ ê¸¸ì´ (ì´ˆ)

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    try:
        fade_start = max(0, max_duration - fade_out)
        ffmpeg_cmd = [
            "ffmpeg", "-y",
            "-i", input_path,
            "-t", str(max_duration),
            "-af", f"afade=t=out:st={fade_start}:d={fade_out}",
            "-c:a", "libmp3lame", "-q:a", "2",
            output_path
        ]
        result = subprocess.run(ffmpeg_cmd, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE, timeout=30)
        return result.returncode == 0
    except Exception as e:
        print(f"[SFX] íŠ¸ë¦¼ ì˜¤ë¥˜: {e}")
        return False


def _mix_sfx_into_video(video_path, sound_effects, scenes, output_path, sfx_dir=None):
    """ë¹„ë””ì˜¤ì— íš¨ê³¼ìŒ ë¯¹ì‹±

    Args:
        video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
        sound_effects: [{"scene": 1, "type": "impact"}, ...]
        scenes: ì”¬ ëª©ë¡ (íƒ€ì´ë° ê³„ì‚°ìš©)
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ
        sfx_dir: íš¨ê³¼ìŒ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    if not sound_effects:
        return False

    try:
        import tempfile

        # ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
        if sfx_dir is None:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            sfx_dir = os.path.join(script_dir, "static", "audio", "sfx")

        print(f"[SFX] íš¨ê³¼ìŒ ë””ë ‰í† ë¦¬: {sfx_dir}")
        print(f"[SFX] ë””ë ‰í† ë¦¬ ì¡´ì¬ ì—¬ë¶€: {os.path.exists(sfx_dir)}")
        if os.path.exists(sfx_dir):
            import glob
            all_sfx = glob.glob(os.path.join(sfx_dir, "*.mp3"))
            print(f"[SFX] ë””ë ‰í† ë¦¬ ë‚´ ì „ì²´ íŒŒì¼: {[os.path.basename(f) for f in all_sfx]}")

        # ì”¬ë³„ ì‹œì‘ ì‹œê°„ ê³„ì‚°
        scene_start_times = {}
        current_time = 0
        for idx, scene in enumerate(scenes):
            scene_start_times[idx + 1] = current_time
            current_time += scene.get('duration', 0)

        # íš¨ê³¼ìŒ íŒŒì¼ ì¤€ë¹„ ë° íƒ€ì´ë° ê³„ì‚°
        sfx_inputs = []
        adelay_filters = []

        temp_dir = tempfile.mkdtemp()

        # ìˆœì°¨ì  ì¸ë±ìŠ¤ ì‚¬ìš© (continueë¡œ ê±´ë„ˆë›´ í•­ëª©ê³¼ ê´€ê³„ì—†ì´ ì—°ì† ì¸ë±ìŠ¤ ë³´ì¥)
        sfx_idx = 0
        for sfx in sound_effects:
            scene_num = sfx.get('scene', 1)
            sfx_type = sfx.get('type', '')

            if scene_num not in scene_start_times:
                continue

            # íš¨ê³¼ìŒ íŒŒì¼ ì°¾ê¸° (None ì „ë‹¬ ì‹œ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©)
            sfx_file = _get_sfx_file(sfx_type)
            if not sfx_file:
                continue

            # íš¨ê³¼ìŒ íŠ¸ë¦¼ (2.5ì´ˆë¡œ ìë¥´ê¸°)
            trimmed_path = os.path.join(temp_dir, f"sfx_{sfx_idx}.mp3")
            if not _trim_sfx(sfx_file, trimmed_path, max_duration=2.5, fade_out=0.5):
                continue

            # ë”œë ˆì´ ê³„ì‚° (ì”¬ ì‹œì‘ + 0.5ì´ˆ)
            delay_ms = int((scene_start_times[scene_num] + 0.5) * 1000)

            sfx_inputs.append(trimmed_path)
            # FFmpeg ì…ë ¥ ì¸ë±ìŠ¤: [0]=ë¹„ë””ì˜¤, [1]=ì²«ë²ˆì§¸ SFX, [2]=ë‘ë²ˆì§¸ SFX...
            # sfx_idxëŠ” 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ ì…ë ¥ ì¸ë±ìŠ¤ëŠ” sfx_idx+1
            adelay_filters.append(f"[{sfx_idx+1}:a]adelay={delay_ms}|{delay_ms},volume=0.8[sfx{sfx_idx}]")
            sfx_idx += 1

        if not sfx_inputs:
            print(f"[SFX] ì‚¬ìš© ê°€ëŠ¥í•œ íš¨ê³¼ìŒ ì—†ìŒ")
            return False

        # FFmpeg ëª…ë ¹ êµ¬ì„±
        input_args = ["-i", video_path]
        for sfx_path in sfx_inputs:
            input_args.extend(["-i", sfx_path])

        # í•„í„° êµ¬ì„±: ëª¨ë“  íš¨ê³¼ìŒ + ì›ë³¸ ì˜¤ë””ì˜¤ ë¯¹ì‹±
        filter_parts = adelay_filters.copy()

        # amixë¡œ ëª¨ë“  ì˜¤ë””ì˜¤ í•©ì¹˜ê¸°
        sfx_labels = "".join([f"[sfx{i}]" for i in range(len(sfx_inputs))])
        mix_inputs = len(sfx_inputs) + 1  # íš¨ê³¼ìŒ ê°œìˆ˜ + ì›ë³¸ ì˜¤ë””ì˜¤
        filter_parts.append(f"[0:a]{sfx_labels}amix=inputs={mix_inputs}:duration=first:dropout_transition=2:normalize=0[aout]")

        filter_complex = ";".join(filter_parts)

        ffmpeg_cmd = [
            "ffmpeg", "-y",
            *input_args,
            "-filter_complex", filter_complex,
            "-map", "0:v",
            "-map", "[aout]",
            "-c:v", "copy",
            "-c:a", "aac", "-b:a", "128k",
            output_path
        ]

        print(f"[SFX] íš¨ê³¼ìŒ {len(sfx_inputs)}ê°œ ë¯¹ì‹± ì¤‘...")
        result = subprocess.run(ffmpeg_cmd, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE, timeout=600)

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        import shutil
        shutil.rmtree(temp_dir, ignore_errors=True)

        if result.returncode == 0:
            print(f"[SFX] íš¨ê³¼ìŒ ë¯¹ì‹± ì™„ë£Œ")
            return True
        else:
            stderr = result.stderr.decode('utf-8', errors='ignore')[:300]
            print(f"[SFX] ë¯¹ì‹± ì‹¤íŒ¨: {stderr}")
            return False

    except Exception as e:
        print(f"[SFX] ë¯¹ì‹± ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def _generate_outro_video(output_path, duration=5, fonts_dir=None):
    """ê³µìš© ì•„ì›ƒíŠ¸ë¡œ ì˜ìƒ ìƒì„± (êµ¬ë…/ì¢‹ì•„ìš” ìš”ì²­)

    Args:
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        duration: ì•„ì›ƒíŠ¸ë¡œ ê¸¸ì´ (ì´ˆ)
        fonts_dir: í°íŠ¸ ë””ë ‰í† ë¦¬ (ì—†ìœ¼ë©´ ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    try:
        # ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€ ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
        if fonts_dir is None:
            script_dir = os.path.dirname(os.path.abspath(__file__))
            fonts_dir = os.path.join(script_dir, "fonts")

        print(f"[OUTRO] í°íŠ¸ ë””ë ‰í† ë¦¬: {fonts_dir}")
        print(f"[OUTRO] ë””ë ‰í† ë¦¬ ì¡´ì¬: {os.path.exists(fonts_dir)}")

        # í°íŠ¸ ì„¤ì •: lang/ko.pyì—ì„œ ê´€ë¦¬
        font_path = None
        for font_file in lang_ko.FONTS['priority']:
            candidate = os.path.join(fonts_dir, font_file)
            if os.path.exists(candidate):
                font_path = candidate
                break
        if not font_path:
            # ì‹œìŠ¤í…œ í°íŠ¸ ì‹œë„
            for sys_path in lang_ko.FONTS['system_paths']:
                if os.path.exists(sys_path):
                    font_path = sys_path
                    break
        if not font_path:
            print(f"[OUTRO] í°íŠ¸ íŒŒì¼ ì—†ìŒ: {fonts_dir}")
            return False

        print(f"[OUTRO] ì‚¬ìš© í°íŠ¸: {font_path}")
        font_escaped = font_path.replace('\\', '/').replace(':', '\\:')

        # ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ + í…ìŠ¤íŠ¸ ì•„ì›ƒíŠ¸ë¡œ
        # ë©”ì¸ ì˜ìƒê³¼ ë™ì¼í•œ 1280x720 í•´ìƒë„ ì‚¬ìš© (concat í˜¸í™˜ì„±)
        # ì´ëª¨ì§€ ì œê±° (FFmpeg drawtext í˜¸í™˜ì„± ë¬¸ì œ)
        ffmpeg_cmd = [
            "ffmpeg", "-y",
            "-f", "lavfi",
            "-i", f"color=c=0x1a1a2e:s=1280x720:d={duration}",
            "-f", "lavfi",
            "-i", f"anullsrc=r=44100:cl=stereo:d={duration}",
            "-vf", (
                f"drawtext=text='ì‹œì²­í•´ ì£¼ì…”ì„œ ê°ì‚¬í•©ë‹ˆë‹¤':"
                f"fontfile='{font_escaped}':fontsize=48:fontcolor=white:"
                f"x=(w-text_w)/2:y=(h-text_h)/2-70,"
                f"drawtext=text='ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒë“œë ¤ìš”':"
                f"fontfile='{font_escaped}':fontsize=38:fontcolor=yellow:"
                f"x=(w-text_w)/2:y=(h-text_h)/2+15,"
                f"drawtext=text='ì•Œë¦¼ ì„¤ì •ë„ ìŠì§€ ë§ˆì„¸ìš”':"
                f"fontfile='{font_escaped}':fontsize=30:fontcolor=#aaaaaa:"
                f"x=(w-text_w)/2:y=(h-text_h)/2+80,"
                f"fade=t=in:st=0:d=0.5,fade=t=out:st={duration-0.5}:d=0.5"
            ),
            # ë©”ì¸ ì˜ìƒê³¼ ë™ì¼í•œ ì¸ì½”ë”© ì„¤ì • (concat demuxer í˜¸í™˜)
            "-c:v", "libx264", "-preset", "fast", "-profile:v", "high", "-level", "4.0",
            "-pix_fmt", "yuv420p", "-r", "24",  # 24fps (ë©”ì¸ ì˜ìƒê³¼ ë™ì¼)
            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
            "-movflags", "+faststart",
            "-t", str(duration),
            output_path
        ]

        result = subprocess.run(ffmpeg_cmd, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE, timeout=60)

        if result.returncode == 0:
            print(f"[OUTRO] ì•„ì›ƒíŠ¸ë¡œ ìƒì„± ì™„ë£Œ (1280x720, 24fps): {output_path}")
            return True
        else:
            stderr = result.stderr.decode('utf-8', errors='ignore')[:300]
            print(f"[OUTRO] ìƒì„± ì‹¤íŒ¨: {stderr}")
            return False

    except Exception as e:
        print(f"[OUTRO] ì˜¤ë¥˜: {e}")
        return False


def _append_outro_to_video(video_path, outro_path, output_path):
    """ë¹„ë””ì˜¤ì— ì•„ì›ƒíŠ¸ë¡œ ì—°ê²° (concat demuxer ì‚¬ìš© - ì¬ì¸ì½”ë”© ì—†ì´ ë¹ ë¦„)

    Args:
        video_path: ì›ë³¸ ë¹„ë””ì˜¤ ê²½ë¡œ
        outro_path: ì•„ì›ƒíŠ¸ë¡œ ë¹„ë””ì˜¤ ê²½ë¡œ
        output_path: ì¶œë ¥ ë¹„ë””ì˜¤ ê²½ë¡œ

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    try:
        # concat demuxer ë°©ì‹ ì‚¬ìš© (ì¬ì¸ì½”ë”© ì—†ì´ ìŠ¤íŠ¸ë¦¼ ë³µì‚¬ - ë§¤ìš° ë¹ ë¦„)
        # ë‹¨, ë‘ íŒŒì¼ì˜ ì½”ë±/í•´ìƒë„/í”„ë ˆì„ë ˆì´íŠ¸ê°€ ë™ì¼í•´ì•¼ í•¨
        work_dir = os.path.dirname(output_path)
        concat_list_path = os.path.join(work_dir, "concat_list.txt")

        # concat ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        with open(concat_list_path, 'w', encoding='utf-8') as f:
            f.write(f"file '{os.path.abspath(video_path)}'\n")
            f.write(f"file '{os.path.abspath(outro_path)}'\n")

        ffmpeg_cmd = [
            "ffmpeg", "-y",
            "-f", "concat",
            "-safe", "0",
            "-i", concat_list_path,
            "-c", "copy",  # ìŠ¤íŠ¸ë¦¼ ë³µì‚¬ (ì¬ì¸ì½”ë”© ì—†ìŒ)
            "-movflags", "+faststart",
            output_path
        ]

        # concat demuxer + copyëŠ” ë§¤ìš° ë¹ ë¦„ (60ì´ˆë©´ ì¶©ë¶„)
        result = subprocess.run(ffmpeg_cmd, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE, timeout=60)

        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if os.path.exists(concat_list_path):
            os.remove(concat_list_path)

        if result.returncode == 0:
            print(f"[OUTRO] ì•„ì›ƒíŠ¸ë¡œ ì—°ê²° ì™„ë£Œ (concat demuxer): {output_path}")
            return True
        else:
            stderr = result.stderr.decode('utf-8', errors='ignore')[-500:]
            print(f"[OUTRO] concat demuxer ì‹¤íŒ¨: {stderr}")

            # Fallback: concat filter ì‚¬ìš© (ì¬ì¸ì½”ë”© í•„ìš”í•˜ì§€ë§Œ í˜¸í™˜ì„± ë†’ìŒ)
            print(f"[OUTRO] Fallback: concat filter ì‚¬ìš©...")
            ffmpeg_cmd_fallback = [
                "ffmpeg", "-y",
                "-i", video_path,
                "-i", outro_path,
                "-filter_complex",
                "[0:v][0:a][1:v][1:a]concat=n=2:v=1:a=1[outv][outa]",
                "-map", "[outv]", "-map", "[outa]",
                "-c:v", "libx264", "-preset", "ultrafast",  # ë” ë¹ ë¥¸ í”„ë¦¬ì…‹
                "-c:a", "aac", "-b:a", "128k",
                "-movflags", "+faststart",
                output_path
            ]

            result_fallback = subprocess.run(ffmpeg_cmd_fallback, stdout=subprocess.DEVNULL,
                                            stderr=subprocess.PIPE, timeout=1200)  # 20ë¶„ íƒ€ì„ì•„ì›ƒ

            if result_fallback.returncode == 0:
                print(f"[OUTRO] ì•„ì›ƒíŠ¸ë¡œ ì—°ê²° ì™„ë£Œ (concat filter fallback): {output_path}")
                return True
            else:
                stderr_fb = result_fallback.stderr.decode('utf-8', errors='ignore')[-300:]
                print(f"[OUTRO] concat filterë„ ì‹¤íŒ¨: {stderr_fb}")
                return False

    except Exception as e:
        print(f"[OUTRO] ì—°ê²° ì˜¤ë¥˜: {e}")
        return False


def _analyze_shorts_content_gpt(highlight_narrations, title, detected_category, audience="general", duration_target=45):
    """GPT-5.1ë¡œ ì‡¼ì¸  ì „ìš© ì½˜í…ì¸  ë¶„ì„ ë° beats êµ¬ì¡° ìƒì„±

    Args:
        highlight_narrations: í•˜ì´ë¼ì´íŠ¸ ì”¬ë“¤ì˜ ë‚˜ë ˆì´ì…˜ ëª©ë¡
        title: ì›ë³¸ ì˜ìƒ ì œëª©
        detected_category: news ë˜ëŠ” story
        audience: general ë˜ëŠ” senior
        duration_target: ëª©í‘œ ê¸¸ì´ (ì´ˆ)

    Returns:
        dict: beats êµ¬ì¡°, meta, design_guide ë“±
    """
    try:
        from openai import OpenAI
        client = OpenAI()

        # ë‚˜ë ˆì´ì…˜ì—ì„œ í•µì‹¬ í¬ì¸íŠ¸ ì¶”ì¶œ
        combined_narration = "\n".join(highlight_narrations)
        main_points = highlight_narrations[:3] if len(highlight_narrations) >= 3 else highlight_narrations

        # short_type ê²°ì •
        short_type = "í•´ì„¤" if detected_category == "news" else "ì‚¬ë¡€ì†Œê°œ"

        # audience_needs ì„¤ì •
        if audience == "senior":
            audience_desc = "50-70ëŒ€ ì‹œë‹ˆì–´"
            audience_needs = ["ì§§ì€ ì‹œê°„ì— í•µì‹¬ë§Œ ì•Œê³  ì‹¶ë‹¤", "ë³µì¡í•œ ì„¤ëª… ì—†ì´ ìš”ì ë§Œ"]
        else:
            audience_desc = "20-40ëŒ€ ì§ì¥ì¸"
            audience_needs = ["ì¶œí‡´ê·¼ 1ë¶„ ì•ˆì— í•µì‹¬ë§Œ", "ì§€ê¸ˆ ë‹¹ì¥ ë­˜ í•´ì•¼ í•˜ëŠ”ì§€"]

        system_prompt = f'''ë„ˆëŠ” "ìœ íŠœë¸Œ ì‡¼ì¸  ì „ë‹´ PD + í¸ì§‘ ë””ë ‰í„° + ê°ë³¸ê°€"ë‹¤.
ë‰´ìŠ¤Â·ì‹œì‚¬Â·ê²½ì œÂ·ì •ë³´ ì½˜í…ì¸ ë¥¼ ì‡¼ì¸  í¬ë§·(60ì´ˆ ì´í•˜)ìœ¼ë¡œ ìµœì í™”í•˜ëŠ” ì „ë¬¸ê°€ë‹¤.

ëª©í‘œ:
1) 1.5ì´ˆ ì•ˆì— ìŠ¤í¬ë¡¤ì„ ë©ˆì¶”ëŠ” ê°•ë ¥í•œ í›…
2) ì™„ì£¼ìœ¨ 80-90% ëª©í‘œì˜ êµ¬ì¡° ì„¤ê³„
3) í¸ì§‘ìê°€ ê·¸ëŒ€ë¡œ ë”°ë¼ ë§Œë“¤ ìˆ˜ ìˆëŠ” ì”¬ ë‹¨ìœ„ ì„¤ê³„ì„œ(JSON)

## í¬ë§· ê·œê²©
- ë°©í–¥: ì„¸ë¡œ 9:16 (1080x1920)
- ê¸¸ì´: 35-60ì´ˆ (ì •ë³´/í•´ì„¤í˜•)
- ì²« 1.5-3ì´ˆ ì•ˆì— ìŠ¤í¬ë¡¤ ë©ˆì¶”ëŠ” í›… í•„ìˆ˜

## ì…ë ¥ê°’
- short_topic: "{title}"
- short_type: "{short_type}"
- main_audience: "{audience_desc}"
- audience_needs: {audience_needs}
- main_point_1: "{main_points[0] if len(main_points) > 0 else ''}"
- main_point_2: "{main_points[1] if len(main_points) > 1 else ''}"
- main_point_3: "{main_points[2] if len(main_points) > 2 else ''}"
- duration_target_sec: {duration_target}
- hook_angle_preference: "ìˆ«ì, ì†”ë£¨ì…˜"

## beats ì„¤ê³„ ê·œì¹™
- 1.0-3.0ì´ˆ ë‹¨ìœ„ì˜ beatë¥¼ ì—°ì† ì„¤ê³„
- ê¸°ë³¸ êµ¬ì¡°:
  - Beat 1: hook (0-2ì´ˆ) - 12-18ì, 3ì´ˆ ì´ë‚´ ë‚­ë…
  - Beat 2: ìƒí™©/ë¬¸ì œ ì œê¸° (2-6ì´ˆ)
  - Beat 3-4: í•µì‹¬ í¬ì¸íŠ¸ 1,2 (6-18ì´ˆ)
  - Beat 5-6: í•µì‹¬ í¬ì¸íŠ¸ 3 + ë°˜ì „/ê²½ê³  (18-35ì´ˆ)
  - Beat 7: ìš”ì•½ + CTA or loop (ë§ˆì§€ë§‰ 3-5ì´ˆ)

## ê° beat í•„ìˆ˜ í¬í•¨
- voiceover: TTSìš© ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´
- on_screen_text: í•µì‹¬ 1-2ì¤„ (16ì ë‚´ì™¸)
- visual_type: A-roll_talking_head / B-roll / infographic / text_only
- visual_direction: í™”ë©´ êµ¬ì„± ì„¤ëª…
- broll_idea_or_prompt: AI ì´ë¯¸ì§€ ìƒì„±ìš© ì˜ì–´ í”„ë¡¬í”„íŠ¸
- caption_style: {{ use_captions, emphasis_words, position }}
- sound_direction: {{ bgm_mood, sfx, pause_hint }}

## ì¶œë ¥ í˜•ì‹ (JSON ONLY)
JSON ì™¸ë¶€ì— ì–´ë–¤ í…ìŠ¤íŠ¸ë„ ì“°ì§€ ë§ ê²ƒ.'''

        user_prompt = f'''ì›ë³¸ ì˜ìƒì˜ í•˜ì´ë¼ì´íŠ¸ ë‚˜ë ˆì´ì…˜:
{combined_narration}

ìœ„ ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ {duration_target}ì´ˆ ì‡¼ì¸ ë¥¼ ì„¤ê³„í•´ì¤˜.
í›…ì€ "ìˆ«ì + ìœ„í—˜/ê¸°íšŒ + íƒ€ê¹ƒ"ì„ ì¡°í•©í•´ì„œ ê°•ë ¥í•˜ê²Œ ë§Œë“¤ì–´.

JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´. ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´ ìˆœìˆ˜ JSONë§Œ.'''

        print(f"[SHORTS-GPT] ì‡¼ì¸  ì½˜í…ì¸  ë¶„ì„ ì‹œì‘...")

        response = client.responses.create(
            model="gpt-5.1",
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": system_prompt}]},
                {"role": "user", "content": [{"type": "input_text", "text": user_prompt}]}
            ],
            temperature=0.7
        )

        # ê²°ê³¼ ì¶”ì¶œ
        if getattr(response, "output_text", None):
            result_text = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content in getattr(item, "content", []) or []:
                    if getattr(content, "type", "") == "text":
                        text_chunks.append(getattr(content, "text", ""))
            result_text = "\n".join(text_chunks).strip()

        # JSON íŒŒì‹±
        print(f"[SHORTS-GPT] GPT ì‘ë‹µ ê¸¸ì´: {len(result_text)}ì")
        print(f"[SHORTS-GPT] GPT ì‘ë‹µ (ì²˜ìŒ 500ì): {result_text[:500]}")

        if result_text.startswith("```"):
            result_text = result_text.split("```")[1]
            if result_text.startswith("json"):
                result_text = result_text[4:]
        result_text = result_text.strip()

        import re
        result_text = re.sub(r',\s*\]', ']', result_text)
        result_text = re.sub(r',\s*\}', '}', result_text)

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as je:
            print(f"[SHORTS-GPT] JSON íŒŒì‹± ì‹¤íŒ¨: {je}")
            print(f"[SHORTS-GPT] íŒŒì‹± ì‹œë„í•œ í…ìŠ¤íŠ¸: {result_text[:1000]}")
            return None

        # beats ìœ„ì¹˜: result.beats ë˜ëŠ” result.structure.beats
        beats = result.get("beats", []) or result.get("structure", {}).get("beats", [])
        print(f"[SHORTS-GPT] ë¶„ì„ ì™„ë£Œ: {len(beats)}ê°œ beats ìƒì„±")
        if len(beats) == 0:
            print(f"[SHORTS-GPT] ê²½ê³ : beats ì—†ìŒ. result keys: {list(result.keys())}")
            if "beats" in result:
                print(f"[SHORTS-GPT] beats íƒ€ì…: {type(result['beats'])}")

        return result

    except Exception as e:
        print(f"[SHORTS-GPT] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return None


def _generate_shorts_video_v2(shorts_analysis, voice_name, output_path, base_url="http://localhost:5000", scene_images=None, fixed_title=None):
    """ì‡¼ì¸  ì „ìš© ì˜ìƒ ìƒì„± (ìƒˆ TTS + ë©”ì¸ ì˜ìƒ ì´ë¯¸ì§€ í¬ë¡­ + í•œêµ­ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸)

    Args:
        shorts_analysis: GPT-5.1 ì‡¼ì¸  ë¶„ì„ ê²°ê³¼ (beats í¬í•¨)
        voice_name: TTS ìŒì„± ì´ë¦„
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        base_url: API ì„œë²„ URL
        scene_images: ë©”ì¸ ì˜ìƒì˜ ì”¬ ì´ë¯¸ì§€ URL ë¦¬ìŠ¤íŠ¸ (16:9 â†’ 9:16 í¬ë¡­ìš©)
        fixed_title: ì „ì²´ ì˜ìƒì— ê³ ì • í‘œì‹œí•  íƒ€ì´í‹€ (ì˜ìƒ ì œëª©)

    Returns:
        dict: {ok, shorts_path, duration, cost}
    """
    import requests as req
    import tempfile
    import shutil

    print(f"[SHORTS-V2] ì‡¼ì¸  ì˜ìƒ ìƒì„± ì‹œì‘ (ë©”ì¸ ì´ë¯¸ì§€ í¬ë¡­ + í•œêµ­ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼)")

    try:
        # beats ìœ„ì¹˜: result.beats ë˜ëŠ” result.structure.beats
        beats = shorts_analysis.get("beats", []) or shorts_analysis.get("structure", {}).get("beats", [])
        if not beats:
            return {"ok": False, "error": "beats ë°ì´í„° ì—†ìŒ"}

        print(f"[SHORTS-V2] {len(beats)}ê°œ beats ì²˜ë¦¬ ì‹œì‘")

        temp_dir = tempfile.mkdtemp()
        total_cost = 0.0
        beat_data = []  # [{audio_path, image_path, duration, subtitles, on_screen_text}]

        try:
            # ========== 1. ê° beatë³„ TTS + ì´ë¯¸ì§€ ìƒì„± ==========
            for idx, beat in enumerate(beats):
                beat_id = beat.get("id", idx + 1)
                voiceover = beat.get("voiceover", "")
                on_screen_text = beat.get("on_screen_text", "")
                visual_direction = beat.get("visual_direction", "")
                broll_prompt = beat.get("broll_idea_or_prompt", "")
                caption_style = beat.get("caption_style", {})

                print(f"[SHORTS-V2] Beat {beat_id}: {voiceover[:30]}...")

                # 1-1. TTS ìƒì„±
                audio_path = os.path.join(temp_dir, f"beat_{beat_id:02d}_audio.mp3")
                try:
                    tts_resp = req.post(f"{base_url}/api/shorts/generate-tts", json={
                        "text": voiceover,
                        "voice": voice_name,
                        "speed": 1.2
                    }, timeout=60)

                    if tts_resp.status_code == 200:
                        tts_data = tts_resp.json()
                        if tts_data.get("ok"):
                            # ì˜¤ë””ì˜¤ URLì—ì„œ ë‹¤ìš´ë¡œë“œ
                            audio_url = tts_data.get("audioUrl", "")
                            if audio_url:
                                audio_resp = req.get(f"{base_url}{audio_url}", timeout=30)
                                with open(audio_path, "wb") as f:
                                    f.write(audio_resp.content)
                                total_cost += len(voiceover) * 0.000004
                                print(f"[SHORTS-V2] Beat {beat_id} TTS ì™„ë£Œ")
                except Exception as tts_err:
                    print(f"[SHORTS-V2] Beat {beat_id} TTS ì‹¤íŒ¨: {tts_err}")
                    # TTS ì‹¤íŒ¨ ì‹œ ë¬´ìŒ ìƒì„±
                    subprocess.run([
                        "ffmpeg", "-y", "-f", "lavfi",
                        "-i", f"anullsrc=r=44100:cl=mono",
                        "-t", "3", audio_path
                    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

                # ì˜¤ë””ì˜¤ ê¸¸ì´ ì¸¡ì •
                duration = 3.0  # ê¸°ë³¸ê°’
                if os.path.exists(audio_path):
                    probe_result = subprocess.run([
                        "ffprobe", "-v", "error", "-show_entries", "format=duration",
                        "-of", "default=noprint_wrappers=1:nokey=1", audio_path
                    ], capture_output=True, text=True)
                    if probe_result.returncode == 0:
                        try:
                            duration = float(probe_result.stdout.strip())
                        except:
                            pass

                # 1-2. ì‡¼ì¸ ìš© 9:16 ì´ë¯¸ì§€ ìƒì„± (ìŠ¤í‹±ë§¨ ì¤‘ì•™ ë°°ì¹˜)
                image_path = os.path.join(temp_dir, f"beat_{beat_id:02d}_image.png")

                # ì˜µì…˜ 1: broll_promptê°€ ìˆìœ¼ë©´ ì „ìš© 9:16 ì´ë¯¸ì§€ ìƒì„± ì‹œë„
                shorts_image_generated = False
                if broll_prompt:
                    try:
                        # 9:16 ì„¸ë¡œ ì´ë¯¸ì§€ìš© í”„ë¡¬í”„íŠ¸ ê°•í™”
                        # ì¤‘ìš”: ì›¹íˆ° ìŠ¤íƒ€ì¼ ìºë¦­í„° + ë°°ê²½ (ë‹¤ë¥¸ ì‚¬ëŒ/í…ìŠ¤íŠ¸ ì—†ìŒ)
                        vertical_prompt = f"""VERTICAL 9:16 PORTRAIT composition for mobile shorts.

CRITICAL - KOREAN WEBTOON/MANHWA STYLE CHARACTER:
- CENTER a Korean webtoon/manhwa style character in the frame
- Character design: EXAGGERATED EXPRESSION (shocked face, wide eyes, open mouth, sweat drops), 30-50 year old Korean man or woman
- Clean bold outlines, vibrant flat colors, comic-style expression marks
- Position character in the CENTER-BOTTOM area (leaving top 25% for text overlay)

FORBIDDEN - DO NOT INCLUDE:
- NO photorealistic humans or photographs
- NO stickman/stick figures
- NO text, letters, words, Korean characters, or any writing in the image
- NO Japanese anime style, NO 3D render

Background style: Detailed background related to the scene, vibrant colors
Scene environment: {broll_prompt}

OUTPUT: 1080x1920 vertical Korean webtoon style illustration with centered character against scenic background."""

                        # Gemini APIë¡œ 9:16 ì´ë¯¸ì§€ ìƒì„±
                        gen_resp = req.post(f"{base_url}/api/drama/generate-image", json={
                            "prompt": vertical_prompt,
                            "width": 1080,
                            "height": 1920,
                            "model": "gemini-2.5-flash"
                        }, timeout=60)

                        if gen_resp.status_code == 200:
                            gen_data = gen_resp.json()
                            if gen_data.get("ok") and gen_data.get("imageUrl"):
                                img_url = gen_data["imageUrl"]
                                # ìƒì„±ëœ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                                if img_url.startswith("http"):
                                    img_download = req.get(img_url, timeout=30)
                                else:
                                    img_download = req.get(f"{base_url}{img_url}", timeout=30)

                                with open(image_path, "wb") as f:
                                    f.write(img_download.content)

                                if os.path.exists(image_path) and os.path.getsize(image_path) > 1000:
                                    shorts_image_generated = True
                                    total_cost += 0.02  # Gemini ì´ë¯¸ì§€ ìƒì„± ë¹„ìš©
                                    print(f"[SHORTS-V2] Beat {beat_id} ì „ìš© 9:16 ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ (ìŠ¤í‹±ë§¨ ì¤‘ì•™)")
                    except Exception as gen_err:
                        print(f"[SHORTS-V2] Beat {beat_id} ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨, í¬ë¡­ìœ¼ë¡œ fallback: {gen_err}")

                # ì˜µì…˜ 2: ì „ìš© ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨ ì‹œ ê¸°ì¡´ ì´ë¯¸ì§€ í¬ë¡­
                if not shorts_image_generated and scene_images and len(scene_images) > 0:
                    # beat_idì— í•´ë‹¹í•˜ëŠ” ì´ë¯¸ì§€ ì„ íƒ (ìˆœí™˜)
                    img_idx = (idx) % len(scene_images)
                    source_img_url = scene_images[img_idx]

                    if source_img_url:
                        try:
                            # ì›ë³¸ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                            temp_source = os.path.join(temp_dir, f"source_{beat_id:02d}.png")
                            if source_img_url.startswith("http"):
                                img_download = req.get(source_img_url, timeout=30)
                            else:
                                img_download = req.get(f"{base_url}{source_img_url}", timeout=30)

                            with open(temp_source, "wb") as f:
                                f.write(img_download.content)

                            # 16:9 â†’ 9:16 í¬ë¡­ (ì¤‘ì•™ ê¸°ì¤€, ì„¸ë¡œë¡œ í™•ëŒ€ í›„ ì¢Œìš° í¬ë¡­)
                            # scale=-1:1920 = ë†’ì´ 1920ìœ¼ë¡œ ìŠ¤ì¼€ì¼ (ë¹„ìœ¨ ìœ ì§€)
                            # crop=1080:1920 = ì¤‘ì•™ì—ì„œ 1080x1920 í¬ë¡­
                            crop_cmd = [
                                "ffmpeg", "-y", "-i", temp_source,
                                "-vf", "scale=-1:1920,crop=1080:1920",
                                "-frames:v", "1", image_path
                            ]
                            crop_result = subprocess.run(crop_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=30)

                            if crop_result.returncode == 0 and os.path.exists(image_path):
                                print(f"[SHORTS-V2] Beat {beat_id} ì´ë¯¸ì§€ í¬ë¡­ ì™„ë£Œ (ì›ë³¸: {img_idx+1}ë²ˆì§¸, ìŠ¤í‹±ë§¨ ì˜ë¦´ ìˆ˜ ìˆìŒ)")
                            else:
                                print(f"[SHORTS-V2] Beat {beat_id} í¬ë¡­ ì‹¤íŒ¨: {crop_result.stderr.decode('utf-8', errors='ignore')[-200:]}")
                        except Exception as crop_err:
                            print(f"[SHORTS-V2] Beat {beat_id} ì´ë¯¸ì§€ í¬ë¡­ ì‹¤íŒ¨: {crop_err}")

                # ì´ë¯¸ì§€ íŒŒì¼ì´ ì—†ìœ¼ë©´ fallback: ì–´ë‘ìš´ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„±
                if not os.path.exists(image_path):
                    print(f"[SHORTS-V2] Beat {beat_id} ì´ë¯¸ì§€ ì—†ìŒ, ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ ìƒì„±")
                    # ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ ì–´ë‘ìš´ ê·¸ë¼ë°ì´ì…˜ ë°°ê²½ (ìƒë‹¨ ì§„í•œ íŒŒë‘ â†’ í•˜ë‹¨ ê²€ì •)
                    subprocess.run([
                        "ffmpeg", "-y", "-f", "lavfi",
                        "-i", "gradients=s=1080x1920:c0=0x0a1628:c1=0x000000:x0=0:y0=0:x1=0:y1=1920:d=1",
                        "-frames:v", "1", image_path
                    ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

                    # gradients í•„í„°ê°€ ì—†ëŠ” FFmpeg ë²„ì „ fallback
                    if not os.path.exists(image_path):
                        subprocess.run([
                            "ffmpeg", "-y", "-f", "lavfi",
                            "-i", "color=c=0x0a1628:s=1080x1920:d=1",
                            "-frames:v", "1", image_path
                        ], stdout=subprocess.DEVNULL, stderr=subprocess.DEVNULL)

                # ìë§‰ ì •ë³´ ì €ì¥
                emphasis_words = caption_style.get("emphasis_words", [])

                beat_data.append({
                    "beat_id": beat_id,
                    "audio_path": audio_path,
                    "image_path": image_path,
                    "duration": duration,
                    "voiceover": voiceover,
                    "on_screen_text": on_screen_text,
                    "emphasis_words": emphasis_words
                })

            # ========== 2. ê° beatë¥¼ í´ë¦½ìœ¼ë¡œ í•©ì„± ==========
            print(f"[SHORTS-V2] í´ë¦½ í•©ì„± ì‹œì‘...")
            clip_paths = []

            for bd in beat_data:
                clip_path = os.path.join(temp_dir, f"clip_{bd['beat_id']:02d}.mp4")

                # ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + ìë§‰ í•©ì„± (í•œêµ­ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ + TTS ì‹±í¬)
                voiceover_raw = bd['voiceover']
                beat_duration = bd['duration']

                # í°íŠ¸ ì„¤ì •: lang/ko.pyì—ì„œ ê´€ë¦¬
                font_path = f"fonts/{lang_ko.FONTS['default']}"
                if not os.path.exists(font_path):
                    font_path = lang_ko.FONTS['system_paths'][0] if lang_ko.FONTS['system_paths'] else font_path
                font_escaped = font_path.replace("\\", "/").replace(":", "\\:")

                # ========== TTS ì‹±í¬ ìë§‰: ë¬¸ì¥/êµ¬ ë‹¨ìœ„ë¡œ ë¶„í•  ==========
                # ë§ˆì¹¨í‘œ, ì‰¼í‘œ, ë¬¼ìŒí‘œ ë“±ìœ¼ë¡œ ë¶„í• 
                import re
                # ë¬¸ì¥ êµ¬ë¶„ìë¡œ ë¶„í•  (êµ¬ë¶„ì í¬í•¨)
                sentence_pattern = r'([^.!?,ã€‚ï¼Œã€ï¼ï¼Ÿ]+[.!?,ã€‚ï¼Œã€ï¼ï¼Ÿ]?)'
                raw_segments = re.findall(sentence_pattern, voiceover_raw)
                # ë¹ˆ ë¬¸ìì—´ ì œê±° ë° ì •ë¦¬
                segments = [s.strip() for s in raw_segments if s.strip()]

                # ì„¸ê·¸ë¨¼íŠ¸ê°€ ë„ˆë¬´ ë§ìœ¼ë©´ ë³‘í•© (ìµœëŒ€ 4ê°œ)
                if len(segments) > 4:
                    merged = []
                    chunk_size = (len(segments) + 3) // 4
                    for i in range(0, len(segments), chunk_size):
                        merged.append(' '.join(segments[i:i+chunk_size]))
                    segments = merged

                # ì„¸ê·¸ë¨¼íŠ¸ê°€ ì—†ìœ¼ë©´ ì „ì²´ë¥¼ í•˜ë‚˜ë¡œ
                if not segments:
                    segments = [voiceover_raw]

                # ê° ì„¸ê·¸ë¨¼íŠ¸ì˜ ì‹œê°„ ê³„ì‚° (ê¸€ì ìˆ˜ ë¹„ìœ¨ ê¸°ë°˜)
                total_chars = sum(len(s) for s in segments)
                if total_chars == 0:
                    total_chars = 1

                segment_timings = []
                current_time = 0.0
                for seg in segments:
                    seg_duration = (len(seg) / total_chars) * beat_duration
                    segment_timings.append({
                        'text': seg,
                        'start': current_time,
                        'end': current_time + seg_duration
                    })
                    current_time += seg_duration

                # ========== í•œêµ­ ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ==========
                # ì‡¼ì¸  í•´ìƒë„: 1080x1920 (9:16)
                # 1. ê¸°ë³¸ í•„í„°: í•´ìƒë„ + í•˜ë‹¨ ë°°ê²½ ë°•ìŠ¤
                subtitle_filter = (
                    f"scale=1080:1920:force_original_aspect_ratio=decrease,pad=1080:1920:(ow-iw)/2:(oh-ih)/2:black,"
                    f"drawbox=x=0:y=ih*0.68:w=iw:h=ih*0.32:color=black@0.75:t=fill"
                )

                # 2. TTS ì‹±í¬ ìë§‰: ê° ì„¸ê·¸ë¨¼íŠ¸ë¥¼ ì‹œê°„ì— ë§ì¶° í‘œì‹œ
                for seg_idx, seg_info in enumerate(segment_timings):
                    # í…ìŠ¤íŠ¸ ì¤„ë°”ê¿ˆ ì²˜ë¦¬ (14ìë§ˆë‹¤)
                    seg_text = seg_info['text']
                    max_chars_per_line = 14
                    lines = []
                    current_line = ""
                    for char in seg_text:
                        current_line += char
                        if len(current_line) >= max_chars_per_line:
                            lines.append(current_line)
                            current_line = ""
                    if current_line:
                        lines.append(current_line)
                    wrapped_text = "\n".join(lines[:3])  # ìµœëŒ€ 3ì¤„

                    # FFmpeg ì´ìŠ¤ì¼€ì´í”„
                    text_escaped = wrapped_text.replace("\\", "\\\\").replace(":", "\\:").replace("'", "'\\''")

                    # enable í‘œí˜„ì‹ìœ¼ë¡œ ì‹œê°„ ë²”ìœ„ ì§€ì •
                    start_t = seg_info['start']
                    end_t = seg_info['end']

                    subtitle_filter += (
                        f",drawtext=text='{text_escaped}':"
                        f"fontfile='{font_escaped}':fontsize=68:fontcolor=white:"
                        f"borderw=4:bordercolor=black:"
                        f"x=(w-text_w)/2:y=h*0.73:"
                        f"line_spacing=16:"
                        f"enable='between(t,{start_t:.2f},{end_t:.2f})'"
                    )

                # 2. ìƒë‹¨ í—¤ë“œë¼ì¸: ê³ ì • íƒ€ì´í‹€ (ì˜ìƒ ì œëª©) - ë…¸ë€ìƒ‰, ì „ì²´ ì˜ìƒì— ë™ì¼í•˜ê²Œ í‘œì‹œ
                # fixed_titleì´ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ on_screen_text fallback
                headline_text = fixed_title if fixed_title else bd.get('on_screen_text', '')
                if headline_text:
                    # FFmpeg drawtext ì´ìŠ¤ì¼€ì´í”„ ìˆœì„œ: ë°±ìŠ¬ë˜ì‹œ â†’ ì½œë¡  â†’ ë”°ì˜´í‘œ
                    text_escaped = headline_text.replace("\\", "\\\\").replace(":", "\\:").replace("'", "'\\''")

                    # í…ìŠ¤íŠ¸ ê¸¸ì´ì— ë”°ë¼ í°íŠ¸ í¬ê¸° ì¡°ì ˆ (ë” êµµê³  í¬ê²Œ)
                    text_len = len(headline_text)
                    if text_len <= 8:
                        headline_fontsize = 100  # ë§¤ìš° ì§§ì€ íƒ€ì´í‹€
                    elif text_len <= 15:
                        headline_fontsize = 88   # ì§§ì€ íƒ€ì´í‹€
                    elif text_len <= 25:
                        headline_fontsize = 72   # ì¤‘ê°„ íƒ€ì´í‹€
                    else:
                        headline_fontsize = 60   # ê¸´ íƒ€ì´í‹€

                    # ê³ ì • íƒ€ì´í‹€ì€ í•­ìƒ ë…¸ë€ìƒ‰ (ì¼ê´€ì„±)
                    headline_color = "yellow"

                    subtitle_filter += (
                        # ìƒë‹¨ ë°˜íˆ¬ëª… ë°°ê²½ (ìƒë‹¨ 22% - ë” í° íƒ€ì´í‹€ ê³µê°„)
                        f",drawbox=x=0:y=0:w=iw:h=ih*0.22:color=black@0.65:t=fill,"
                        # í—¤ë“œë¼ì¸ í…ìŠ¤íŠ¸ (í°íŠ¸/í…Œë‘ë¦¬ ì¦ê°€)
                        f"drawtext=text='{text_escaped}':"
                        f"fontfile='{font_escaped}':fontsize={headline_fontsize}:fontcolor={headline_color}:"
                        f"borderw=6:bordercolor=black:"
                        f"x=(w-text_w)/2:y=h*0.10"
                    )

                cmd = [
                    "ffmpeg", "-y",
                    "-loop", "1", "-i", bd['image_path'],
                    "-i", bd['audio_path'],
                    "-vf", subtitle_filter,
                    "-c:v", "libx264", "-preset", "fast",
                    "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                    "-pix_fmt", "yuv420p",
                    "-t", str(bd['duration']),
                    "-shortest",
                    clip_path
                ]

                # íŒŒì¼ ì¡´ì¬ í™•ì¸
                if not os.path.exists(bd['image_path']):
                    print(f"[SHORTS-V2] í´ë¦½ {bd['beat_id']} ì´ë¯¸ì§€ íŒŒì¼ ì—†ìŒ: {bd['image_path']}")
                    continue
                if not os.path.exists(bd['audio_path']):
                    print(f"[SHORTS-V2] í´ë¦½ {bd['beat_id']} ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ: {bd['audio_path']}")
                    continue

                result = subprocess.run(cmd, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=120)
                if result.returncode == 0 and os.path.exists(clip_path):
                    clip_paths.append(clip_path)
                    print(f"[SHORTS-V2] í´ë¦½ {bd['beat_id']} ì™„ë£Œ ({bd['duration']:.1f}ì´ˆ)")
                else:
                    stderr = result.stderr.decode('utf-8', errors='ignore')[-500:]  # ë§ˆì§€ë§‰ 500ì (ì—ëŸ¬ ë©”ì‹œì§€ê°€ ëì— ìˆìŒ)
                    print(f"[SHORTS-V2] í´ë¦½ {bd['beat_id']} ì‹¤íŒ¨: {stderr}")

            if not clip_paths:
                return {"ok": False, "error": "í´ë¦½ ìƒì„± ì‹¤íŒ¨"}

            # ========== 3. í´ë¦½ ë³‘í•© ==========
            print(f"[SHORTS-V2] {len(clip_paths)}ê°œ í´ë¦½ ë³‘í•©...")
            concat_list = os.path.join(temp_dir, "concat.txt")
            with open(concat_list, 'w') as f:
                for clip_path in clip_paths:
                    f.write(f"file '{os.path.abspath(clip_path)}'\n")

            # ë³‘í•©
            concat_cmd = [
                "ffmpeg", "-y",
                "-f", "concat", "-safe", "0",
                "-i", concat_list,
                "-c:v", "libx264", "-preset", "fast",
                "-c:a", "aac", "-b:a", "128k",
                "-movflags", "+faststart",
                output_path
            ]

            result = subprocess.run(concat_cmd, stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=180)

            if result.returncode == 0 and os.path.exists(output_path):
                # ìµœì¢… ì˜ìƒ ê¸¸ì´ í™•ì¸
                probe_result = subprocess.run([
                    "ffprobe", "-v", "error", "-show_entries", "format=duration",
                    "-of", "default=noprint_wrappers=1:nokey=1", output_path
                ], capture_output=True, text=True)

                final_duration = 0
                if probe_result.returncode == 0:
                    try:
                        final_duration = float(probe_result.stdout.strip())
                    except:
                        pass

                print(f"[SHORTS-V2] ì‡¼ì¸  ìƒì„± ì™„ë£Œ: {output_path} ({final_duration:.1f}ì´ˆ)")

                return {
                    "ok": True,
                    "shorts_path": output_path,
                    "duration": final_duration,
                    "cost": total_cost,
                    "beats_count": len(beats)
                }
            else:
                stderr = result.stderr.decode('utf-8', errors='ignore')[:300]
                return {"ok": False, "error": f"ë³‘í•© ì‹¤íŒ¨: {stderr}"}

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        print(f"[SHORTS-V2] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}


def _generate_shorts_video(main_video_path, scenes, highlight_scenes, hook_text, output_path):
    """ë©”ì¸ ì˜ìƒì—ì„œ ì‡¼ì¸ ìš© ì„¸ë¡œ ì˜ìƒ(9:16) ìƒì„± [ë ˆê±°ì‹œ - í¬ë¡­ ë°©ì‹]

    Args:
        main_video_path: ì›ë³¸ ë©”ì¸ ì˜ìƒ ê²½ë¡œ
        scenes: ì”¬ ì •ë³´ ëª©ë¡ (duration í¬í•¨)
        highlight_scenes: í•˜ì´ë¼ì´íŠ¸ ì”¬ ë²ˆí˜¸ ëª©ë¡ [1, 2, 3]
        hook_text: ì‡¼ì¸  ì‹œì‘ í›… í…ìŠ¤íŠ¸
        output_path: ì¶œë ¥ ê²½ë¡œ

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    print(f"[SHORTS] ì‡¼ì¸  ìƒì„± ì‹œì‘")
    print(f"[SHORTS] ë©”ì¸ ì˜ìƒ: {main_video_path}, ì¡´ì¬: {os.path.exists(main_video_path)}")
    print(f"[SHORTS] ì”¬ ìˆ˜: {len(scenes) if scenes else 0}")
    print(f"[SHORTS] í•˜ì´ë¼ì´íŠ¸ ì”¬: {highlight_scenes}")
    print(f"[SHORTS] í›… í…ìŠ¤íŠ¸: {hook_text}")
    print(f"[SHORTS] ì¶œë ¥ ê²½ë¡œ: {output_path}")

    try:
        import tempfile
        import shutil

        # ì”¬ë³„ ì‹œì‘/ì¢…ë£Œ ì‹œê°„ ê³„ì‚°
        scene_times = []
        current_time = 0
        for idx, scene in enumerate(scenes):
            duration = scene.get('duration', 5)
            scene_times.append({
                'scene_num': idx + 1,
                'start': current_time,
                'end': current_time + duration,
                'duration': duration
            })
            current_time += duration

        # í•˜ì´ë¼ì´íŠ¸ ì”¬ ì¶”ì¶œ (60ì´ˆ ì´í•˜ë¡œ ì œí•œ)
        selected_clips = []
        total_duration = 0
        max_duration = 58  # 60ì´ˆ ì œí•œ (ì—¬ìœ  2ì´ˆ)

        for scene_num in highlight_scenes:
            if scene_num < 1 or scene_num > len(scene_times):
                continue
            scene_info = scene_times[scene_num - 1]
            if total_duration + scene_info['duration'] <= max_duration:
                selected_clips.append(scene_info)
                total_duration += scene_info['duration']
            else:
                # ë‚¨ì€ ì‹œê°„ë§Œí¼ë§Œ ì¶”ê°€
                remaining = max_duration - total_duration
                if remaining > 3:  # ìµœì†Œ 3ì´ˆ ì´ìƒì¼ ë•Œë§Œ ì¶”ê°€
                    selected_clips.append({
                        **scene_info,
                        'end': scene_info['start'] + remaining,
                        'duration': remaining
                    })
                    total_duration += remaining
                break

        if not selected_clips:
            print(f"[SHORTS] ì„ íƒëœ í´ë¦½ ì—†ìŒ")
            return False

        print(f"[SHORTS] {len(selected_clips)}ê°œ í´ë¦½ ì„ íƒ, ì´ {total_duration:.1f}ì´ˆ")

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp()
        concat_list = os.path.join(temp_dir, "concat.txt")

        try:
            # ê° í•˜ì´ë¼ì´íŠ¸ í´ë¦½ ì¶”ì¶œ ë° ì„¸ë¡œ ë³€í™˜
            clip_paths = []
            for i, clip in enumerate(selected_clips):
                clip_path = os.path.join(temp_dir, f"clip_{i:03d}.mp4")

                # ê°€ë¡œ(16:9) â†’ ì„¸ë¡œ(9:16) ë³€í™˜ + í´ë¦½ ì¶”ì¶œ
                # ì¤‘ì•™ í¬ë¡­ + ë¸”ëŸ¬ ë°°ê²½ ë°©ì‹
                vf_filter = (
                    # ì›ë³¸ì„ 1080x1920 ì„¸ë¡œ ë¹„ìœ¨ë¡œ í¬ë¡­ (ì¤‘ì•™)
                    "scale=1080:1920:force_original_aspect_ratio=increase,"
                    "crop=1080:1920,"
                    # ìë§‰ ìœ„ì¹˜ ì¡°ì • (í•˜ë‹¨)
                    "setsar=1"
                )

                cmd = [
                    "ffmpeg", "-y",
                    "-ss", str(clip['start']),
                    "-i", main_video_path,
                    "-t", str(clip['duration']),
                    "-vf", vf_filter,
                    "-c:v", "libx264", "-preset", "fast",
                    "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                    "-pix_fmt", "yuv420p",
                    clip_path
                ]

                result = subprocess.run(cmd, stdout=subprocess.DEVNULL,
                                       stderr=subprocess.PIPE, timeout=120)
                if result.returncode == 0 and os.path.exists(clip_path):
                    clip_paths.append(clip_path)
                    print(f"[SHORTS] í´ë¦½ {i+1}/{len(selected_clips)} ì¶”ì¶œ ì™„ë£Œ")
                else:
                    stderr = result.stderr.decode('utf-8', errors='ignore')[:200]
                    print(f"[SHORTS] í´ë¦½ {i+1} ì¶”ì¶œ ì‹¤íŒ¨: {stderr}")

            if not clip_paths:
                print(f"[SHORTS] í´ë¦½ ì¶”ì¶œ ì‹¤íŒ¨")
                return False

            # concat íŒŒì¼ ìƒì„±
            with open(concat_list, 'w') as f:
                for clip_path in clip_paths:
                    f.write(f"file '{os.path.abspath(clip_path)}'\n")

            # í´ë¦½ ë³‘í•©
            merged_path = os.path.join(temp_dir, "merged.mp4")
            concat_cmd = [
                "ffmpeg", "-y",
                "-f", "concat", "-safe", "0",
                "-i", concat_list,
                "-c", "copy",
                merged_path
            ]
            result = subprocess.run(concat_cmd, stdout=subprocess.DEVNULL,
                                   stderr=subprocess.PIPE, timeout=120)

            if result.returncode != 0:
                stderr = result.stderr.decode('utf-8', errors='ignore')[:200]
                print(f"[SHORTS] í´ë¦½ ë³‘í•© ì‹¤íŒ¨: {stderr}")
                return False

            # í›… í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì¶”ê°€ (ì²˜ìŒ 3ì´ˆ)
            # í°íŠ¸ ì„¤ì •: lang/ko.pyì—ì„œ ê´€ë¦¬
            if hook_text:
                font_path = f"fonts/{lang_ko.FONTS['default']}"
                font_escaped = font_path.replace('\\', '/').replace(':', '\\:')

                hook_filter = (
                    f"drawtext=text='{hook_text}':"
                    f"fontfile='{font_escaped}':fontsize=48:fontcolor=white:"
                    f"borderw=3:bordercolor=black:"
                    f"x=(w-text_w)/2:y=h*0.15:"
                    f"enable='lt(t,3)'"  # ì²˜ìŒ 3ì´ˆë§Œ í‘œì‹œ
                )

                final_cmd = [
                    "ffmpeg", "-y",
                    "-i", merged_path,
                    "-vf", hook_filter,
                    "-c:v", "libx264", "-preset", "fast",
                    "-c:a", "copy",
                    output_path
                ]
            else:
                final_cmd = ["cp", merged_path, output_path]

            result = subprocess.run(final_cmd, stdout=subprocess.DEVNULL,
                                   stderr=subprocess.PIPE, timeout=120)

            if result.returncode == 0 and os.path.exists(output_path):
                print(f"[SHORTS] ì‡¼ì¸  ìƒì„± ì™„ë£Œ: {output_path}")
                return True
            else:
                stderr = result.stderr.decode('utf-8', errors='ignore')[:200]
                print(f"[SHORTS] ìµœì¢… ìƒì„± ì‹¤íŒ¨: {stderr}")
                return False

        finally:
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            shutil.rmtree(temp_dir, ignore_errors=True)

    except Exception as e:
        print(f"[SHORTS] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def _apply_transitions(clip_paths, output_path, transition_style="crossfade", duration=0.5):
    """í´ë¦½ë“¤ ì‚¬ì´ì— ì „í™˜ íš¨ê³¼ ì ìš©

    Args:
        clip_paths: í´ë¦½ íŒŒì¼ ê²½ë¡œ ëª©ë¡
        output_path: ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
        transition_style: crossfade, fade_black, fade_white, none
        duration: ì „í™˜ íš¨ê³¼ ê¸¸ì´ (ì´ˆ)

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    if not clip_paths or len(clip_paths) < 2:
        # í´ë¦½ì´ 1ê°œ ì´í•˜ë©´ ì „í™˜ íš¨ê³¼ ë¶ˆí•„ìš”
        if clip_paths:
            import shutil
            shutil.copy(clip_paths[0], output_path)
            return True
        return False

    try:
        if transition_style == "none":
            # ì „í™˜ íš¨ê³¼ ì—†ì´ ë‹¨ìˆœ concat
            import tempfile
            concat_list = tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False)
            for clip_path in clip_paths:
                concat_list.write(f"file '{os.path.abspath(clip_path)}'\n")
            concat_list.close()

            cmd = [
                "ffmpeg", "-y",
                "-f", "concat", "-safe", "0",
                "-i", concat_list.name,
                "-c", "copy",
                output_path
            ]
            result = subprocess.run(cmd, stdout=subprocess.DEVNULL,
                                   stderr=subprocess.PIPE, timeout=300)
            os.unlink(concat_list.name)
            return result.returncode == 0

        # xfade í•„í„°ë¡œ ì „í™˜ íš¨ê³¼ ì ìš©
        n = len(clip_paths)

        # ì…ë ¥ íŒŒì¼ ì˜µì…˜
        input_args = []
        for clip_path in clip_paths:
            input_args.extend(["-i", clip_path])

        # xfade í•„í„° ì²´ì¸ êµ¬ì„±
        # fade ìƒ‰ìƒ ì„¤ì •
        fade_color = "black" if transition_style == "fade_black" else "white" if transition_style == "fade_white" else None

        if n == 2:
            # 2ê°œ í´ë¦½: ë‹¨ì¼ xfade
            if fade_color:
                filter_complex = f"[0:v]fade=t=out:st=0:d={duration}:color={fade_color}[v0];[1:v]fade=t=in:st=0:d={duration}:color={fade_color}[v1];[v0][v1]concat=n=2:v=1:a=0[outv];[0:a][1:a]concat=n=2:v=0:a=1[outa]"
            else:
                # crossfade
                filter_complex = f"[0:v][1:v]xfade=transition=fade:duration={duration}:offset=0[outv];[0:a][1:a]acrossfade=d={duration}[outa]"
        else:
            # 3ê°œ ì´ìƒ: ì²´ì¸ xfade (ë³µì¡, ë‹¨ìˆœí™”)
            # ê°„ë‹¨í•˜ê²Œ ê° í´ë¦½ì— fade inë§Œ ì ìš© í›„ concat
            # ì£¼ì˜: fade outì€ í´ë¦½ ê¸¸ì´ë¥¼ ëª¨ë¥´ë©´ st ê³„ì‚° ë¶ˆê°€í•˜ë¯€ë¡œ ìƒëµ
            filter_parts = []
            for i in range(n):
                if fade_color:
                    filter_parts.append(f"[{i}:v]fade=t=in:st=0:d={duration/2}:color={fade_color}[v{i}]")
                else:
                    filter_parts.append(f"[{i}:v]fade=t=in:st=0:d={duration/2}[v{i}]")

            video_concat = "".join([f"[v{i}]" for i in range(n)]) + f"concat=n={n}:v=1:a=0[outv]"
            audio_concat = "".join([f"[{i}:a]" for i in range(n)]) + f"concat=n={n}:v=0:a=1[outa]"

            filter_complex = ";".join(filter_parts) + ";" + video_concat + ";" + audio_concat

        cmd = [
            "ffmpeg", "-y",
            *input_args,
            "-filter_complex", filter_complex,
            "-map", "[outv]", "-map", "[outa]",
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "aac", "-b:a", "128k",
            output_path
        ]

        print(f"[TRANSITIONS] {transition_style} íš¨ê³¼ ì ìš© ì¤‘ ({n}ê°œ í´ë¦½)...")
        result = subprocess.run(cmd, stdout=subprocess.DEVNULL,
                               stderr=subprocess.PIPE, timeout=600)

        if result.returncode == 0:
            print(f"[TRANSITIONS] ì „í™˜ íš¨ê³¼ ì ìš© ì™„ë£Œ")
            return True
        else:
            stderr = result.stderr.decode('utf-8', errors='ignore')[:300]
            print(f"[TRANSITIONS] ì‹¤íŒ¨: {stderr}")
            # ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ concatìœ¼ë¡œ í´ë°±
            print(f"[TRANSITIONS] ë‹¨ìˆœ concatìœ¼ë¡œ í´ë°±...")
            return _apply_transitions(clip_paths, output_path, "none", 0)

    except Exception as e:
        print(f"[TRANSITIONS] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def _upload_youtube_captions(video_id, srt_path, language="ko", credentials=None):
    """YouTubeì— ìë§‰ íŒŒì¼(.srt) ì—…ë¡œë“œ

    Args:
        video_id: YouTube ë¹„ë””ì˜¤ ID
        srt_path: SRT ìë§‰ íŒŒì¼ ê²½ë¡œ
        language: ìë§‰ ì–¸ì–´ ì½”ë“œ (ko, en, ja ë“±)
        credentials: Google OAuth ìê²© ì¦ëª…

    Returns:
        ì„±ê³µ ì—¬ë¶€ (bool)
    """
    try:
        from googleapiclient.discovery import build
        from googleapiclient.http import MediaFileUpload

        if not credentials:
            print(f"[CAPTIONS] ìê²© ì¦ëª… ì—†ìŒ")
            return False

        if not os.path.exists(srt_path):
            print(f"[CAPTIONS] ìë§‰ íŒŒì¼ ì—†ìŒ: {srt_path}")
            return False

        youtube = build('youtube', 'v3', credentials=credentials)

        # ìë§‰ ì‚½ì… ìš”ì²­
        caption_body = {
            "snippet": {
                "videoId": video_id,
                "language": language,
                "name": "Korean" if language == "ko" else language.upper(),
                "isDraft": False
            }
        }

        media = MediaFileUpload(srt_path, mimetype='application/x-subrip', resumable=True)

        request = youtube.captions().insert(
            part="snippet",
            body=caption_body,
            media_body=media
        )

        response = None
        while response is None:
            status, response = request.next_chunk()
            if status:
                print(f"[CAPTIONS] ì—…ë¡œë“œ ì§„í–‰ë¥ : {int(status.progress() * 100)}%")

        print(f"[CAPTIONS] ìë§‰ ì—…ë¡œë“œ ì™„ë£Œ: {response.get('id')}")
        return True

    except Exception as e:
        print(f"[CAPTIONS] ì—…ë¡œë“œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return False


def _get_ken_burns_filter(effect_type, duration, fps=24, output_size="1280x720"):
    """Ken Burns íš¨ê³¼ìš© zoompan í•„í„° ìƒì„± - ë¶€ë“œëŸ¬ìš´ sin/cos ëª¨ì…˜

    Args:
        effect_type: zoom_in, zoom_out, pan_left, pan_right, pan_up, pan_down
        duration: í´ë¦½ ê¸¸ì´ (ì´ˆ)
        fps: í”„ë ˆì„ ë ˆì´íŠ¸
        output_size: ì¶œë ¥ í•´ìƒë„

    Returns:
        FFmpeg vf filter string (scale + zoompan + fade)
    """
    total_frames = int(duration * fps)
    w, h = map(int, output_size.split('x'))

    # ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„ì„ ìœ„í•œ ì„¤ì •
    # ì´ë¯¸ì§€ë¥¼ í¬ê²Œ ìŠ¤ì¼€ì¼í•´ì„œ íŒ¨ë‹/ì¤Œ ì‹œ ê²€ì • í…Œë‘ë¦¬ ë°©ì§€
    scale_w = int(w * 1.4)  # 40% ë” í¬ê²Œ
    scale_h = int(h * 1.4)

    fade_in = min(0.5, duration * 0.1)  # í˜ì´ë“œì¸ (ìµœëŒ€ 0.5ì´ˆ)
    fade_out = min(0.5, duration * 0.1)  # í˜ì´ë“œì•„ì›ƒ (ìµœëŒ€ 0.5ì´ˆ)
    fade_out_start = max(0, duration - fade_out)

    # ê° íš¨ê³¼ë³„ ì„¤ì • (sin/cosë¡œ ë§¤ìš° ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„)
    # on: í˜„ì¬ í”„ë ˆì„ ë²ˆí˜¸, total_frames: ì „ì²´ í”„ë ˆì„ ìˆ˜
    # â˜… ëŠë¦° ì›€ì§ì„: sin/cos ì£¼ê¸° 2ë°°, ì›€ì§ì„ ë²”ìœ„ 1/2
    if effect_type == 'zoom_in':
        # ì²œì²œíˆ ì¤Œì¸ + ì•„ì£¼ ë¯¸ì„¸í•œ íŒ¨ë‹
        zoom_expr = f"1.0+0.08*on/{total_frames}"  # 1.0 â†’ 1.08ë¡œ (ë” ì‘ì€ ì¤Œ)
        x_expr = f"(iw-{w})/2+8*sin(on/120)"  # ì¢Œìš° ì•„ì£¼ ë¯¸ì„¸ (ì£¼ê¸° 120)
        y_expr = f"(ih-{h})/2+6*cos(on/150)"  # ìƒí•˜ ì•„ì£¼ ë¯¸ì„¸ (ì£¼ê¸° 150)
    elif effect_type == 'zoom_out':
        # ì²œì²œíˆ ì¤Œì•„ì›ƒ + ì•„ì£¼ ë¯¸ì„¸í•œ íŒ¨ë‹
        zoom_expr = f"1.08-0.08*on/{total_frames}"  # 1.08 â†’ 1.0ìœ¼ë¡œ
        x_expr = f"(iw-{w})/2-8*sin(on/120)"
        y_expr = f"(ih-{h})/2-6*cos(on/150)"
    elif effect_type == 'pan_left':
        # ì˜¤ë¥¸ìª½ì—ì„œ ì™¼ìª½ìœ¼ë¡œ ì•„ì£¼ ì²œì²œíˆ íŒ¨ë‹
        zoom_expr = "1.03"  # ì¤Œ ê±°ì˜ ì—†ìŒ
        x_expr = f"(iw-{w})*0.6*(1-on/{total_frames})+5*sin(on/100)"  # ë¶€ë“œëŸ¬ìš´ íŒ¨ë‹
        y_expr = f"(ih-{h})/2+4*cos(on/140)"
    elif effect_type == 'pan_right':
        # ì™¼ìª½ì—ì„œ ì˜¤ë¥¸ìª½ìœ¼ë¡œ ì•„ì£¼ ì²œì²œíˆ íŒ¨ë‹
        zoom_expr = "1.03"
        x_expr = f"(iw-{w})*0.4+(iw-{w})*0.2*on/{total_frames}+5*sin(on/100)"
        y_expr = f"(ih-{h})/2+4*cos(on/140)"
    elif effect_type == 'pan_up':
        # ì•„ë˜ì—ì„œ ìœ„ë¡œ ì•„ì£¼ ì²œì²œíˆ íŒ¨ë‹
        zoom_expr = "1.03"
        x_expr = f"(iw-{w})/2+5*sin(on/120)"
        y_expr = f"(ih-{h})*0.6*(1-on/{total_frames})+4*cos(on/100)"
    elif effect_type == 'pan_down':
        # ìœ„ì—ì„œ ì•„ë˜ë¡œ ì•„ì£¼ ì²œì²œíˆ íŒ¨ë‹
        zoom_expr = "1.03"
        x_expr = f"(iw-{w})/2+5*sin(on/120)"
        y_expr = f"(ih-{h})*0.4+(ih-{h})*0.2*on/{total_frames}+4*cos(on/100)"
    else:
        # ê¸°ë³¸: ì¤Œì¸ + ì•„ì£¼ ë¯¸ì„¸í•œ ì›€ì§ì„
        zoom_expr = f"1.0+0.08*on/{total_frames}"
        x_expr = f"(iw-{w})/2+8*sin(on/120)"
        y_expr = f"(ih-{h})/2+6*cos(on/150)"

    # í•„í„° ì²´ì¸: scale(í¬ê²Œ) â†’ zoompan(ë¶€ë“œëŸ¬ìš´ ì›€ì§ì„) â†’ fade(í˜ì´ë“œì¸/ì•„ì›ƒ)
    vf_filter = (
        f"scale={scale_w}:{scale_h}:force_original_aspect_ratio=increase,"
        f"crop={scale_w}:{scale_h},"
        f"zoompan=z='{zoom_expr}':x='{x_expr}':y='{y_expr}':d={total_frames}:s={output_size}:fps={fps},"
        f"fade=t=in:st=0:d={fade_in},fade=t=out:st={fade_out_start}:d={fade_out}"
    )

    return vf_filter


def _create_scene_clip_worker(task):
    """
    ë‹¨ì¼ ì”¬ì˜ í´ë¦½ì„ ìƒì„±í•˜ëŠ” í—¬í¼ í•¨ìˆ˜ (ThreadPoolExecutorìš©)
    ë³‘ë ¬ ì²˜ë¦¬ ì‹œ ê° ì›Œì»¤ì—ì„œ ë…ë¦½ì ìœ¼ë¡œ ì‹¤í–‰ë¨
    """
    import subprocess
    import shutil
    import urllib.request
    import gc

    idx, scene, work_dir, total_scenes = task

    image_url = scene.get('image_url', '')
    audio_url = scene.get('audio_url', '')
    duration = scene.get('duration', 5.0)

    print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1}/{total_scenes} ì²˜ë¦¬ ì‹œì‘...")

    if not image_url:
        print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ìŠ¤í‚µ - ì´ë¯¸ì§€ URL ì—†ìŒ")
        return idx, None, duration

    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
    img_path = os.path.join(work_dir, f"scene_{idx:03d}.jpg")
    try:
        if image_url.startswith('http'):
            req = urllib.request.Request(image_url, headers={'User-Agent': 'Mozilla/5.0'})
            with urllib.request.urlopen(req, timeout=30) as response:
                with open(img_path, 'wb') as f:
                    f.write(response.read())
        elif image_url.startswith('/'):
            local_path = image_url.lstrip('/')
            if os.path.exists(local_path):
                shutil.copy(local_path, img_path)
            else:
                print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ë¡œì»¬ ì´ë¯¸ì§€ ì—†ìŒ: {local_path}")
                return idx, None, duration
        else:
            # ë¡œì»¬ ê²½ë¡œ (/ ì—†ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°, ì˜ˆ: uploads/xxx/image.png)
            if os.path.exists(image_url):
                shutil.copy(image_url, img_path)
            else:
                print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ë¡œì»¬ ì´ë¯¸ì§€ ì—†ìŒ: {image_url}")
                return idx, None, duration
    except Exception as e:
        print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
        return idx, None, duration

    if not os.path.exists(img_path):
        return idx, None, duration

    # ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
    audio_path = None
    if audio_url:
        audio_path = os.path.join(work_dir, f"audio_{idx:03d}.mp3")
        try:
            if audio_url.startswith('http'):
                req = urllib.request.Request(audio_url, headers={'User-Agent': 'Mozilla/5.0'})
                with urllib.request.urlopen(req, timeout=30) as response:
                    with open(audio_path, 'wb') as f:
                        f.write(response.read())
            elif audio_url.startswith('/'):
                local_path = audio_url.lstrip('/')
                if os.path.exists(local_path):
                    shutil.copy(local_path, audio_path)
            else:
                # ë¡œì»¬ ê²½ë¡œ (/ ì—†ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°)
                if os.path.exists(audio_url):
                    shutil.copy(audio_url, audio_path)
        except Exception as e:
            print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {e}")
            audio_path = None

    # Ken Burns íš¨ê³¼ (ì”¬ë³„ë¡œ ë‹¤ì–‘í•œ íš¨ê³¼ ìë™ ë°°ì •)
    ken_burns_effect = scene.get('ken_burns', None)
    if not ken_burns_effect:
        effects_cycle = ['zoom_in', 'pan_right', 'zoom_out', 'pan_left', 'zoom_in', 'pan_up']
        ken_burns_effect = effects_cycle[idx % len(effects_cycle)]

    ken_burns_filter = _get_ken_burns_filter(ken_burns_effect, duration)

    # ì”¬ í´ë¦½ ìƒì„±
    clip_path = os.path.join(work_dir, f"clip_{idx:03d}.mp4")
    if audio_path and os.path.exists(audio_path):
        cmd = [
            "ffmpeg", "-y",
            "-loop", "1",
            "-framerate", "24",
            "-i", img_path,
            "-i", audio_path,
            "-vf", ken_burns_filter,
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
            "-pix_fmt", "yuv420p",
            "-shortest", "-t", str(duration),
            clip_path
        ]
    else:
        cmd = [
            "ffmpeg", "-y",
            "-loop", "1",
            "-framerate", "24",
            "-i", img_path,
            "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
            "-vf", ken_burns_filter,
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
            "-pix_fmt", "yuv420p",
            "-t", str(duration), "-shortest",
            clip_path
        ]

    result = subprocess.run(
        cmd,
        stdout=subprocess.DEVNULL,
        stderr=subprocess.PIPE,
        timeout=600
    )

    if result.returncode == 0 and os.path.exists(clip_path):
        print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ì™„ë£Œ: {duration:.1f}ì´ˆ")
        del result
        gc.collect()
        return idx, clip_path, duration

    # Ken Burns ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
    stderr_msg = result.stderr.decode('utf-8', errors='ignore')[:300] if result.stderr else ''
    print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} Ken Burns ì‹¤íŒ¨, ë‹¨ìˆœ ë°©ì‹ ì¬ì‹œë„: {stderr_msg}")
    del result
    gc.collect()

    simple_filter = "scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2"
    if audio_path and os.path.exists(audio_path):
        fallback_cmd = [
            "ffmpeg", "-y",
            "-loop", "1",
            "-i", img_path,
            "-i", audio_path,
            "-vf", simple_filter,
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
            "-pix_fmt", "yuv420p",
            "-shortest", "-t", str(duration),
            clip_path
        ]
    else:
        fallback_cmd = [
            "ffmpeg", "-y",
            "-loop", "1",
            "-i", img_path,
            "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
            "-vf", simple_filter,
            "-c:v", "libx264", "-preset", "fast",
            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
            "-pix_fmt", "yuv420p",
            "-t", str(duration), "-shortest",
            clip_path
        ]

    fallback_result = subprocess.run(
        fallback_cmd,
        stdout=subprocess.DEVNULL,
        stderr=subprocess.PIPE,
        timeout=600
    )

    if fallback_result.returncode == 0 and os.path.exists(clip_path):
        print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ë‹¨ìˆœ ë°©ì‹ ì„±ê³µ: {duration:.1f}ì´ˆ")
        del fallback_result
        gc.collect()
        return idx, clip_path, duration

    print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ìµœì¢… ì‹¤íŒ¨")
    del fallback_result
    gc.collect()
    return idx, None, duration


def _generate_video_worker(job_id, session_id, scenes, detected_lang, video_effects=None):
    """ë°±ê·¸ë¼ìš´ë“œ ì˜ìƒ ìƒì„± ì›Œì»¤

    video_effects êµ¬ì¡°:
    {
        "bgm_mood": "calm/cinematic/comedic/dramatic/epic/hopeful/horror/mysterious/nostalgic/sad/tense/upbeat",
        "subtitle_highlights": [{"keyword": "ë‹¨ì–´", "color": "#FF0000"}],
        "sound_effects": [{"scene": 1, "type": "impact", "moment": "..."}],
        "lower_thirds": [{"scene": 2, "text": "ì¶œì²˜", "position": "bottom-left"}]
    }
    """
    import subprocess
    import shutil
    import urllib.request
    import gc  # ë©”ëª¨ë¦¬ ì •ë¦¬ìš©

    if video_effects is None:
        video_effects = {}

    # FFmpeg ì„¸ë§ˆí¬ì–´ íšë“ (ë‹¤ë¥¸ FFmpeg ì‘ì—…ê³¼ ë™ì‹œ ì‹¤í–‰ ë°©ì§€ - ë©”ëª¨ë¦¬ ë³´í˜¸)
    print(f"[VIDEO-WORKER] FFmpeg ì„¸ë§ˆí¬ì–´ ëŒ€ê¸° ì¤‘...")
    ffmpeg_semaphore.acquire()
    print(f"[VIDEO-WORKER] FFmpeg ì„¸ë§ˆí¬ì–´ íšë“, ì˜ìƒ ìƒì„± ì‹œì‘...")

    try:
        _update_job_status(job_id, status='processing', message='ì˜ìƒ ìƒì„± ì‹œì‘...')

        # === video_effects ë””ë²„ê·¸ ë¡œê¹… ===
        print(f"[VIDEO-WORKER] ========== VIDEO EFFECTS ì„¤ì • ==========")
        print(f"[VIDEO-WORKER] bgm_mood: {video_effects.get('bgm_mood', '(ì—†ìŒ)')}")
        print(f"[VIDEO-WORKER] subtitle_highlights: {len(video_effects.get('subtitle_highlights', []))}ê°œ")
        print(f"[VIDEO-WORKER] screen_overlays: {len(video_effects.get('screen_overlays', []))}ê°œ")
        print(f"[VIDEO-WORKER] sound_effects: {len(video_effects.get('sound_effects', []))}ê°œ")
        print(f"[VIDEO-WORKER] lower_thirds: {len(video_effects.get('lower_thirds', []))}ê°œ")
        print(f"[VIDEO-WORKER] news_ticker enabled: {video_effects.get('news_ticker', {}).get('enabled', False)}")
        print(f"[VIDEO-WORKER] shorts highlight_scenes: {video_effects.get('shorts', {}).get('highlight_scenes', [])}")
        print(f"[VIDEO-WORKER] transitions style: {video_effects.get('transitions', {}).get('style', 'none')}")
        print(f"[VIDEO-WORKER] add_outro: {video_effects.get('add_outro', True)}")
        print(f"[VIDEO-WORKER] ============================================")

        total_scenes = len(scenes)
        upload_dir = "uploads"
        os.makedirs(upload_dir, exist_ok=True)

        # ì‘ì—… ë””ë ‰í† ë¦¬ ìƒì„± (tempfile ëŒ€ì‹  ì§ì ‘ ê´€ë¦¬)
        work_dir = os.path.join(upload_dir, f"work_{job_id}")
        os.makedirs(work_dir, exist_ok=True)

        try:
            scene_videos = []
            all_subtitles = []
            current_time = 0.0

            # í™˜ê²½ë³€ìˆ˜ë¡œ ë³‘ë ¬ ì²˜ë¦¬ ì›Œì»¤ ìˆ˜ ì„¤ì • (ê¸°ë³¸ê°’: 1 = ìˆœì°¨ ì²˜ë¦¬)
            # Render Pro (4GB) í™˜ê²½ì—ì„œëŠ” 2ë¡œ ì„¤ì • ê¶Œì¥
            parallel_workers = int(os.environ.get('VIDEO_PARALLEL_WORKERS', 1))

            # 1. ê° ì”¬ë³„ ì˜ìƒ í´ë¦½ ìƒì„±
            if parallel_workers > 1:
                # ========== ë³‘ë ¬ ì²˜ë¦¬ ëª¨ë“œ ==========
                from concurrent.futures import ThreadPoolExecutor, as_completed

                print(f"[VIDEO-WORKER-PARALLEL] ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ - {total_scenes}ê°œ ì”¬, {parallel_workers}ê°œ ì›Œì»¤")
                _update_job_status(job_id, progress=5, message=f'ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ ({parallel_workers}ê°œ ì›Œì»¤)...')

                tasks = [(idx, scene, work_dir, total_scenes) for idx, scene in enumerate(scenes)]
                results = [None] * total_scenes  # ìˆœì„œ ìœ ì§€ë¥¼ ìœ„í•œ ë¦¬ìŠ¤íŠ¸

                with ThreadPoolExecutor(max_workers=parallel_workers) as executor:
                    future_to_idx = {executor.submit(_create_scene_clip_worker, task): task[0] for task in tasks}
                    completed = 0

                    for future in as_completed(future_to_idx):
                        idx = future_to_idx[future]
                        completed += 1
                        progress = int((completed / total_scenes) * 70)
                        _update_job_status(job_id, progress=progress, message=f'ì”¬ {completed}/{total_scenes} í´ë¦½ ìƒì„± ì¤‘...')

                        try:
                            result_idx, clip_path, duration = future.result()
                            results[idx] = (clip_path, duration)
                        except Exception as e:
                            print(f"[VIDEO-WORKER-PARALLEL] ì”¬ {idx+1} ì˜¤ë¥˜: {e}")
                            results[idx] = (None, scenes[idx].get('duration', 5.0))

                # ê²°ê³¼ ì •ë¦¬ (ìˆœì„œëŒ€ë¡œ) + ìë§‰ ì‹œê°„ ê³„ì‚°
                for idx, (clip_path, duration) in enumerate(results):
                    if clip_path and os.path.exists(clip_path):
                        scene_videos.append(clip_path)

                    # ìë§‰ ì‹œê°„ ì¡°ì • (ìˆœì°¨ì ìœ¼ë¡œ)
                    subtitles = scenes[idx].get('subtitles', [])
                    for sub in subtitles:
                        all_subtitles.append({
                            'start': current_time + sub.get('start', 0),
                            'end': current_time + sub.get('end', duration),
                            'text': sub.get('text', '')
                        })
                    current_time += duration

                gc.collect()
                print(f"[VIDEO-WORKER-PARALLEL] ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {len(scene_videos)}/{total_scenes}")

            else:
                # ========== ìˆœì°¨ ì²˜ë¦¬ ëª¨ë“œ (ê¸°ë³¸ê°’ - ë©”ëª¨ë¦¬ ì ˆì•½) ==========
                print(f"[VIDEO-WORKER-SEQUENTIAL] ìˆœì°¨ ì²˜ë¦¬ ì‹œì‘ - {total_scenes}ê°œ ì”¬ (ë©”ëª¨ë¦¬ ì ˆì•½ ëª¨ë“œ)")

                for idx, scene in enumerate(scenes):
                    progress = int((idx / total_scenes) * 70)
                    _update_job_status(job_id, progress=progress, message=f'ì”¬ {idx + 1}/{total_scenes} ì²˜ë¦¬ ì¤‘...')

                    image_url = scene.get('image_url', '')
                    audio_url = scene.get('audio_url', '')
                    duration = scene.get('duration', 5.0)
                    subtitles = scene.get('subtitles', [])

                    print(f"[VIDEO-WORKER-SEQUENTIAL] Scene {idx + 1}: duration={duration:.2f}s")

                    if not image_url:
                        current_time += duration
                        continue

                    # ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
                    img_path = os.path.join(work_dir, f"scene_{idx:03d}.jpg")
                    print(f"[VIDEO-WORKER-SEQUENTIAL] Scene {idx + 1} image_url: {image_url[:100]}...")
                    try:
                        if image_url.startswith('http'):
                            req = urllib.request.Request(image_url, headers={'User-Agent': 'Mozilla/5.0'})
                            with urllib.request.urlopen(req, timeout=30) as response:
                                with open(img_path, 'wb') as f:
                                    f.write(response.read())
                        elif image_url.startswith('/'):
                            local_path = image_url.lstrip('/')
                            if os.path.exists(local_path):
                                shutil.copy(local_path, img_path)
                            else:
                                print(f"[VIDEO-WORKER-SEQUENTIAL] Local image not found: {local_path}")
                                current_time += duration
                                continue
                        else:
                            # ë¡œì»¬ ê²½ë¡œ (/ ì—†ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°)
                            if os.path.exists(image_url):
                                shutil.copy(image_url, img_path)
                            else:
                                print(f"[VIDEO-WORKER-SEQUENTIAL] Local image not found: {image_url}")
                                current_time += duration
                                continue
                    except Exception as e:
                        print(f"[VIDEO-WORKER-SEQUENTIAL] Image download failed: {e}")
                        current_time += duration
                        continue

                    # ì´ë¯¸ì§€ íŒŒì¼ ê²€ì¦
                    if not os.path.exists(img_path):
                        print(f"[VIDEO-WORKER-SEQUENTIAL] Image file not created: {img_path}")
                        current_time += duration
                        continue
                    img_size = os.path.getsize(img_path)
                    print(f"[VIDEO-WORKER-SEQUENTIAL] Scene {idx + 1} image saved: {img_size} bytes")

                    # ì˜¤ë””ì˜¤ ë‹¤ìš´ë¡œë“œ
                    audio_path = None
                    if audio_url:
                        audio_path = os.path.join(work_dir, f"audio_{idx:03d}.mp3")
                        try:
                            if audio_url.startswith('http'):
                                req = urllib.request.Request(audio_url, headers={'User-Agent': 'Mozilla/5.0'})
                                with urllib.request.urlopen(req, timeout=30) as response:
                                    with open(audio_path, 'wb') as f:
                                        f.write(response.read())
                            elif audio_url.startswith('/'):
                                local_path = audio_url.lstrip('/')
                                if os.path.exists(local_path):
                                    shutil.copy(local_path, audio_path)
                            else:
                                # ë¡œì»¬ ê²½ë¡œ (/ ì—†ì´ ì‹œì‘í•˜ëŠ” ê²½ìš°)
                                if os.path.exists(audio_url):
                                    shutil.copy(audio_url, audio_path)
                        except Exception as e:
                            print(f"[VIDEO-WORKER-SEQUENTIAL] Audio download failed: {e}")
                            audio_path = None

                    # ìë§‰ ì‹œê°„ ì¡°ì •
                    for sub in subtitles:
                        all_subtitles.append({
                            'start': current_time + sub.get('start', 0),
                            'end': current_time + sub.get('end', duration),
                            'text': sub.get('text', '')
                        })
                    current_time += duration

                    # Ken Burns íš¨ê³¼ ê°€ì ¸ì˜¤ê¸° (ì”¬ë³„ë¡œ ë‹¤ë¥¸ íš¨ê³¼ ì ìš©)
                    ken_burns_effect = scene.get('ken_burns', None)
                    if not ken_burns_effect:
                        # ì”¬ë³„ë¡œ ë‹¤ì–‘í•œ íš¨ê³¼ ìë™ ë°°ì • (ë‹¤ì´ë‚˜ë¯¹í•œ ì˜ìƒì„ ìœ„í•´)
                        effects_cycle = ['zoom_in', 'pan_right', 'zoom_out', 'pan_left', 'zoom_in', 'pan_up']
                        ken_burns_effect = effects_cycle[idx % len(effects_cycle)]

                    ken_burns_filter = _get_ken_burns_filter(ken_burns_effect, duration)
                    print(f"[VIDEO-WORKER-SEQUENTIAL] Scene {idx + 1} Ken Burns: {ken_burns_effect}")

                    # ì”¬ í´ë¦½ ìƒì„± (Ken Burns íš¨ê³¼ í¬í•¨)
                    clip_path = os.path.join(work_dir, f"clip_{idx:03d}.mp4")
                    if audio_path and os.path.exists(audio_path):
                        cmd = [
                            "ffmpeg", "-y",
                            "-loop", "1",
                            "-framerate", "24",
                            "-i", img_path,
                            "-i", audio_path,
                            "-vf", ken_burns_filter,
                            "-c:v", "libx264", "-preset", "fast",
                            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                            "-pix_fmt", "yuv420p",
                            "-shortest", "-t", str(duration),
                            clip_path
                        ]
                    else:
                        cmd = [
                            "ffmpeg", "-y",
                            "-loop", "1",
                            "-framerate", "24",
                            "-i", img_path,
                            "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
                            "-vf", ken_burns_filter,
                            "-c:v", "libx264", "-preset", "fast",
                            "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                            "-pix_fmt", "yuv420p",
                            "-t", str(duration), "-shortest",
                            clip_path
                        ]

                    # ë©”ëª¨ë¦¬ ìµœì í™”: stdout DEVNULL, stderrë§Œ PIPE (OOM ë°©ì§€)
                    result = subprocess.run(
                        cmd,
                        stdout=subprocess.DEVNULL,
                        stderr=subprocess.PIPE,
                        timeout=600
                    )
                    if result.returncode == 0 and os.path.exists(clip_path):
                        scene_videos.append(clip_path)
                        print(f"[VIDEO-WORKER-SEQUENTIAL] Clip {idx+1} created successfully")
                        del result
                        gc.collect()
                    else:
                        stderr = result.stderr.decode('utf-8', errors='ignore')[:500] if result.stderr else 'no stderr'
                        print(f"[VIDEO-WORKER-SEQUENTIAL] Clip {idx+1} FAILED: {stderr[:200]}")
                        del result
                        gc.collect()

                        # Ken Burns ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„
                        print(f"[VIDEO-WORKER-SEQUENTIAL] Clip {idx+1} ë‹¨ìˆœ ë°©ì‹ìœ¼ë¡œ ì¬ì‹œë„...")
                        simple_filter = "scale=1280:720:force_original_aspect_ratio=decrease,pad=1280:720:(ow-iw)/2:(oh-ih)/2"
                        if audio_path and os.path.exists(audio_path):
                            fallback_cmd = [
                                "ffmpeg", "-y",
                                "-loop", "1",
                                "-i", img_path,
                                "-i", audio_path,
                                "-vf", simple_filter,
                                "-c:v", "libx264", "-preset", "fast",
                                "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                                "-pix_fmt", "yuv420p",
                                "-shortest", "-t", str(duration),
                                clip_path
                            ]
                        else:
                            fallback_cmd = [
                                "ffmpeg", "-y",
                                "-loop", "1",
                                "-i", img_path,
                                "-f", "lavfi", "-i", "anullsrc=r=44100:cl=stereo",
                                "-vf", simple_filter,
                                "-c:v", "libx264", "-preset", "fast",
                                "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                                "-pix_fmt", "yuv420p",
                                "-t", str(duration), "-shortest",
                                clip_path
                            ]

                        fallback_result = subprocess.run(
                            fallback_cmd,
                            stdout=subprocess.DEVNULL,
                            stderr=subprocess.PIPE,
                            timeout=600
                        )
                        if fallback_result.returncode == 0 and os.path.exists(clip_path):
                            scene_videos.append(clip_path)
                            print(f"[VIDEO-WORKER-SEQUENTIAL] Clip {idx+1} ë‹¨ìˆœ ë°©ì‹ ì„±ê³µ")
                        else:
                            fallback_stderr = fallback_result.stderr.decode('utf-8', errors='ignore')[:300] if fallback_result.stderr else ''
                            print(f"[VIDEO-WORKER-SEQUENTIAL] Clip {idx+1} ë‹¨ìˆœ ë°©ì‹ë„ ì‹¤íŒ¨: {fallback_stderr}")
                        del fallback_result
                        gc.collect()

                print(f"[VIDEO-WORKER-SEQUENTIAL] ìˆœì°¨ ì²˜ë¦¬ ì™„ë£Œ - ì„±ê³µ: {len(scene_videos)}/{total_scenes}")

            print(f"[VIDEO-WORKER] Total clips created: {len(scene_videos)} / {total_scenes}")

            if not scene_videos:
                raise Exception("ì˜ìƒ í´ë¦½ ìƒì„± ì‹¤íŒ¨")

            # 2. í´ë¦½ ë³‘í•© (ì „í™˜ íš¨ê³¼ ì˜µì…˜)
            _update_job_status(job_id, progress=75, message='í´ë¦½ ë³‘í•© ì¤‘...')

            merged_path = os.path.join(work_dir, "merged.mp4")

            # ì „í™˜ íš¨ê³¼ ì„¤ì • í™•ì¸
            transitions_config = video_effects.get('transitions', {})
            transition_style = transitions_config.get('style', 'none')  # ê¸°ë³¸ê°’: none (ë¹ ë¥¸ ì²˜ë¦¬)
            transition_duration = transitions_config.get('duration', 0.5)

            if transition_style and transition_style != 'none' and len(scene_videos) > 1:
                # ì „í™˜ íš¨ê³¼ ì ìš©
                print(f"[VIDEO-WORKER] ì „í™˜ íš¨ê³¼ ì ìš©: {transition_style}, {transition_duration}ì´ˆ")
                _update_job_status(job_id, progress=76, message=f'ì „í™˜ íš¨ê³¼ ì ìš© ì¤‘ ({transition_style})...')

                if _apply_transitions(scene_videos, merged_path, transition_style, transition_duration):
                    print(f"[VIDEO-WORKER] ì „í™˜ íš¨ê³¼ ì ìš© ì™„ë£Œ")
                else:
                    # ì „í™˜ íš¨ê³¼ ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ concatìœ¼ë¡œ í´ë°±
                    print(f"[VIDEO-WORKER] ì „í™˜ íš¨ê³¼ ì‹¤íŒ¨, ë‹¨ìˆœ concatìœ¼ë¡œ í´ë°±")
                    transition_style = 'none'

            if transition_style == 'none' or not os.path.exists(merged_path):
                # ì „í™˜ íš¨ê³¼ ì—†ì´ ë‹¨ìˆœ concat
                concat_list = os.path.join(work_dir, "concat.txt")
                with open(concat_list, 'w') as f:
                    for clip in scene_videos:
                        # ì ˆëŒ€ ê²½ë¡œ ì‚¬ìš©
                        abs_clip = os.path.abspath(clip)
                        f.write(f"file '{abs_clip}'\n")

                print(f"[VIDEO-WORKER] Concat list created with {len(scene_videos)} clips")

                # í´ë¦½ íŒŒì¼ ì¡´ì¬ í™•ì¸
                for clip in scene_videos:
                    if os.path.exists(clip):
                        file_size = os.path.getsize(clip)
                        print(f"[VIDEO-WORKER] Clip exists: {clip} ({file_size} bytes)")
                    else:
                        print(f"[VIDEO-WORKER] Clip MISSING: {clip}")

                # IMPORTANT: stdout=DEVNULL, stderr=PIPE to avoid OOM from buffering all FFmpeg output
                concat_result = subprocess.run(
                    ["ffmpeg", "-y", "-f", "concat", "-safe", "0", "-i", concat_list, "-c", "copy", merged_path],
                    stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=600
                )

                if concat_result.returncode != 0:
                    stderr = concat_result.stderr.decode('utf-8', errors='ignore') if concat_result.stderr else ""
                    print(f"[VIDEO-WORKER] Concat FAILED (code {concat_result.returncode}): {stderr[:500]}")
                    del concat_result
                    gc.collect()
                    raise Exception(f"í´ë¦½ ë³‘í•© ì‹¤íŒ¨: {stderr[:200]}")

                del concat_result
                gc.collect()

            if not os.path.exists(merged_path):
                raise Exception("merged.mp4 íŒŒì¼ì´ ìƒì„±ë˜ì§€ ì•ŠìŒ")

            # 3. ASS ìë§‰ ìƒì„± (ìƒ‰ìƒ ê°•ì¡° ì§€ì›)
            _update_job_status(job_id, progress=85, message='ìë§‰ ì²˜ë¦¬ ì¤‘...')

            # ìë§‰ ê°•ì¡° í‚¤ì›Œë“œ ê°€ì ¸ì˜¤ê¸°
            subtitle_highlights = video_effects.get('subtitle_highlights', [])
            if subtitle_highlights:
                print(f"[VIDEO-WORKER] ìë§‰ ê°•ì¡° í‚¤ì›Œë“œ: {[h.get('keyword') for h in subtitle_highlights]}")
                print(f"[VIDEO-WORKER] ìë§‰ ê°•ì¡° ìƒ‰ìƒ: {[h.get('color') for h in subtitle_highlights]}")
            else:
                print(f"[VIDEO-WORKER] âš ï¸ ìë§‰ ê°•ì¡° í‚¤ì›Œë“œ ì—†ìŒ - GPTê°€ subtitle_highlightsë¥¼ ìƒì„±í•˜ì§€ ì•ŠìŒ")

            # ASS í˜•ì‹ ì‚¬ìš© (ìƒ‰ìƒ ê°•ì¡° ì§€ì›)
            ass_path = os.path.join(work_dir, "subtitles.ass")
            _generate_ass_subtitles(all_subtitles, subtitle_highlights, ass_path, lang=detected_lang)

            # 4. ìë§‰ burn-in + í™”ë©´ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
            _update_job_status(job_id, progress=90, message='ìë§‰ ë° íš¨ê³¼ ì‚½ì… ì¤‘...')

            final_path = os.path.join(work_dir, "final.mp4")

            # í°íŠ¸ ë””ë ‰í† ë¦¬ ì ˆëŒ€ ê²½ë¡œ ì„¤ì • (ìŠ¤í¬ë¦½íŠ¸ ìœ„ì¹˜ ê¸°ì¤€)
            script_dir = os.path.dirname(os.path.abspath(__file__))
            fonts_dir = os.path.join(script_dir, "fonts")
            print(f"[VIDEO-WORKER] í°íŠ¸ ë””ë ‰í† ë¦¬: {fonts_dir}, ì¡´ì¬: {os.path.exists(fonts_dir)}")

            # ASS íŒŒì¼ ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜í•˜ê³  FFmpegìš© ì´ìŠ¤ì¼€ì´í”„
            ass_abs_path = os.path.abspath(ass_path)
            # FFmpeg subtitle filterëŠ” : \ ' ë“±ì„ ì´ìŠ¤ì¼€ì´í”„í•´ì•¼ í•¨
            ass_escaped = ass_abs_path.replace('\\', '/').replace(':', '\\:')
            fonts_escaped = fonts_dir.replace('\\', '/').replace(':', '\\:')

            # ê¸°ë³¸ ìë§‰ í•„í„° (ASS í˜•ì‹ì€ force_style ë¶ˆí•„ìš” - íŒŒì¼ì— ìŠ¤íƒ€ì¼ í¬í•¨)
            vf_filter = f"ass={ass_escaped}:fontsdir={fonts_escaped}"

            # â˜… VRCS 2.0: screen_overlays, lower_thirds, news_ticker ë¹„í™œì„±í™”
            # ì •ë³´ ì „ë‹¬ íš¨ê³¼ê°€ ë‚®ê³  í™”ë©´ì„ ì–´ì§€ëŸ½í˜
            # screen_overlays = video_effects.get('screen_overlays', [])  # ë¹„í™œì„±í™”
            # lower_thirds = video_effects.get('lower_thirds', [])  # ë¹„í™œì„±í™”
            # news_ticker = video_effects.get('news_ticker', {})  # ë¹„í™œì„±í™”
            print(f"[VIDEO-WORKER] VRCS 2.0: screen_overlays, lower_thirds, news_ticker ë¹„í™œì„±í™”ë¨")

            print(f"[VIDEO-WORKER] ASS path: {ass_abs_path}")
            print(f"[VIDEO-WORKER] VF filter ê¸¸ì´: {len(vf_filter)} chars")
            print(f"[VIDEO-WORKER] VF filter (ì²˜ìŒ 500ì): {vf_filter[:500]}")
            print(f"[VIDEO-WORKER] Fonts directory: {fonts_dir}")

            # IMPORTANT: stdout=DEVNULL, stderr=PIPE to avoid OOM from buffering FFmpeg output
            # FFmpeg video encoding generates massive amounts of progress output to stderr
            # YouTube í˜¸í™˜ ì„¤ì •: -profile:v high -level 4.0, AAC ì˜¤ë””ì˜¤, +faststart
            result = subprocess.run([
                "ffmpeg", "-y", "-i", merged_path,
                "-vf", vf_filter,
                "-c:v", "libx264", "-preset", "fast", "-profile:v", "high", "-level", "4.0",
                "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                "-movflags", "+faststart",
                final_path
            ], stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=1800)  # 30ë¶„ íƒ€ì„ì•„ì›ƒ

            if result.returncode != 0:
                # stderr ì „ì²´ì—ì„œ ì‹¤ì œ ì—ëŸ¬ ë©”ì‹œì§€ ì¶”ì¶œ (FFmpegëŠ” ë§ˆì§€ë§‰ì— ì—ëŸ¬ ì¶œë ¥)
                stderr_full = result.stderr.decode('utf-8', errors='ignore') if result.stderr else ""
                # ë§ˆì§€ë§‰ 800ì ì¶œë ¥ (ì‹¤ì œ ì—ëŸ¬ ë©”ì‹œì§€ í¬í•¨)
                stderr_tail = stderr_full[-800:] if len(stderr_full) > 800 else stderr_full
                print(f"[VIDEO-WORKER] Subtitle burn-in failed (code {result.returncode})")
                print(f"[VIDEO-WORKER] stderr (ë§ˆì§€ë§‰ 800ì): {stderr_tail}")

                # ìë§‰ burn-in ì‹¤íŒ¨ ì‹œ ìë§‰ ì—†ì´ YouTube í˜¸í™˜ ì¸ì½”ë”© ì‹œë„
                print(f"[VIDEO-WORKER] ìë§‰ ì—†ì´ YouTube í˜¸í™˜ ì¬ì¸ì½”ë”© ì‹œë„...")
                fallback_result = subprocess.run([
                    "ffmpeg", "-y", "-i", merged_path,
                    "-c:v", "libx264", "-preset", "fast", "-profile:v", "high", "-level", "4.0",
                    "-c:a", "aac", "-b:a", "128k", "-ar", "44100",
                    "-movflags", "+faststart",
                    final_path
                ], stdout=subprocess.DEVNULL, stderr=subprocess.PIPE, timeout=1800)

                if fallback_result.returncode != 0:
                    print(f"[VIDEO-WORKER] Fallback ì¸ì½”ë”©ë„ ì‹¤íŒ¨, ì›ë³¸ ì‚¬ìš©")
                    final_path = merged_path
                else:
                    print(f"[VIDEO-WORKER] Fallback ì¸ì½”ë”© ì„±ê³µ (ìë§‰ ì—†ìŒ)")

            del result
            gc.collect()

            # 5. BGM ë¯¹ì‹± (ì˜µì…˜) - ì”¬ë³„ BGM ë³€ê²½ ì§€ì›
            bgm_mood = video_effects.get('bgm_mood', '')
            scene_bgm_changes = video_effects.get('scene_bgm_changes', [])
            if bgm_mood:
                _update_job_status(job_id, progress=95, message='BGM ë¯¹ì‹± ì¤‘...')
                bgm_output_path = os.path.join(work_dir, "with_bgm.mp4")

                # ì”¬ë³„ BGM ë³€ê²½ì´ ìˆìœ¼ë©´ ìƒˆë¡œìš´ í•¨ìˆ˜ ì‚¬ìš©
                if scene_bgm_changes:
                    print(f"[VIDEO-WORKER] ì”¬ë³„ BGM ë¯¹ì‹± ì‹œì‘ (ë³€ê²½ {len(scene_bgm_changes)}íšŒ)")
                    if _mix_scene_bgm_with_video(final_path, scenes, video_effects, bgm_output_path):
                        final_path = bgm_output_path
                        print(f"[VIDEO-WORKER] ì”¬ë³„ BGM ë¯¹ì‹± ì™„ë£Œ")
                    else:
                        print(f"[VIDEO-WORKER] ì”¬ë³„ BGM ë¯¹ì‹± ì‹¤íŒ¨, BGM ì—†ì´ ì§„í–‰")
                else:
                    # ê¸°ì¡´ ë°©ì‹: ì „ì²´ ì˜ìƒì— í•˜ë‚˜ì˜ BGM
                    bgm_file = _get_bgm_file(bgm_mood)
                    if bgm_file:
                        if _mix_bgm_with_video(final_path, bgm_file, bgm_output_path):
                            final_path = bgm_output_path
                            print(f"[VIDEO-WORKER] BGM ë¯¹ì‹± ì™„ë£Œ: {bgm_mood}")
                        else:
                            print(f"[VIDEO-WORKER] BGM ë¯¹ì‹± ì‹¤íŒ¨, BGM ì—†ì´ ì§„í–‰")
                    else:
                        print(f"[VIDEO-WORKER] BGM íŒŒì¼ ì—†ìŒ: {bgm_mood}")

            # 6. íš¨ê³¼ìŒ ë¯¹ì‹± (ì˜µì…˜)
            sound_effects = video_effects.get('sound_effects', [])
            if sound_effects:
                _update_job_status(job_id, progress=96, message='íš¨ê³¼ìŒ ì¶”ê°€ ì¤‘...')
                sfx_output_path = os.path.join(work_dir, "with_sfx.mp4")
                if _mix_sfx_into_video(final_path, sound_effects, scenes, sfx_output_path):
                    final_path = sfx_output_path
                    print(f"[VIDEO-WORKER] íš¨ê³¼ìŒ {len(sound_effects)}ê°œ ì¶”ê°€ ì™„ë£Œ")
                else:
                    print(f"[VIDEO-WORKER] íš¨ê³¼ìŒ ë¯¹ì‹± ì‹¤íŒ¨, íš¨ê³¼ìŒ ì—†ì´ ì§„í–‰")

            # 7. ì•„ì›ƒíŠ¸ë¡œ ì¶”ê°€ (ì˜µì…˜)
            add_outro = video_effects.get('add_outro', True)  # ê¸°ë³¸ê°’: ì¶”ê°€
            if add_outro:
                _update_job_status(job_id, progress=98, message='ì•„ì›ƒíŠ¸ë¡œ ì¶”ê°€ ì¤‘...')
                outro_path = os.path.join(work_dir, "outro.mp4")
                if _generate_outro_video(outro_path, duration=5, fonts_dir=fonts_dir):
                    outro_output_path = os.path.join(work_dir, "with_outro.mp4")
                    if _append_outro_to_video(final_path, outro_path, outro_output_path):
                        final_path = outro_output_path
                        print(f"[VIDEO-WORKER] ì•„ì›ƒíŠ¸ë¡œ ì¶”ê°€ ì™„ë£Œ")
                    else:
                        print(f"[VIDEO-WORKER] ì•„ì›ƒíŠ¸ë¡œ ì—°ê²° ì‹¤íŒ¨, ì•„ì›ƒíŠ¸ë¡œ ì—†ì´ ì§„í–‰")
                else:
                    print(f"[VIDEO-WORKER] ì•„ì›ƒíŠ¸ë¡œ ìƒì„± ì‹¤íŒ¨")

            # 8. ê²°ê³¼ ì €ì¥
            output_filename = f"video_{session_id}.mp4"
            output_path = os.path.join(upload_dir, output_filename)
            shutil.copy(final_path, output_path)

            # ì‘ì—… ë””ë ‰í† ë¦¬ ì •ë¦¬
            shutil.rmtree(work_dir, ignore_errors=True)

            minutes = int(current_time // 60)
            seconds = int(current_time % 60)

            _update_job_status(job_id,
                status='completed',
                progress=100,
                message='ì™„ë£Œ!',
                video_url=f"/uploads/{output_filename}",
                duration=f"{minutes}ë¶„ {seconds}ì´ˆ",
                subtitle_count=len(all_subtitles)
            )

            print(f"[VIDEO-WORKER] Completed: {output_path}")

        except Exception as e:
            shutil.rmtree(work_dir, ignore_errors=True)
            raise e

    except Exception as e:
        print(f"[VIDEO-WORKER] Error: {e}")
        import traceback
        traceback.print_exc()
        _update_job_status(job_id, status='failed', error=str(e), message=f'ì˜¤ë¥˜: {str(e)}')
    finally:
        # ì„¸ë§ˆí¬ì–´ í•´ì œ (ë‹¤ìŒ FFmpeg ì‘ì—… í—ˆìš©)
        ffmpeg_semaphore.release()
        print(f"[VIDEO-WORKER] FFmpeg ì„¸ë§ˆí¬ì–´ í•´ì œë¨")


@app.route('/api/image/generate-video', methods=['POST'])
def api_image_generate_video():
    """ì˜ìƒ ìƒì„± ì‹œì‘ (ë°±ê·¸ë¼ìš´ë“œ) - job_id ë°˜í™˜"""
    import threading
    import uuid as uuid_module
    from datetime import datetime

    data = request.get_json()
    session_id = data.get('session_id', str(uuid_module.uuid4())[:8])
    scenes = data.get('scenes', [])
    detected_lang = data.get('language', 'en')
    video_effects = data.get('video_effects', {})  # ìƒˆ ê¸°ëŠ¥: BGM, íš¨ê³¼ìŒ, ìë§‰ ê°•ì¡°, Ken Burns ë“±

    if not scenes:
        return jsonify({"ok": False, "error": "ì”¬ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}), 400

    total_duration = sum(s.get('duration', 0) for s in scenes)
    job_id = f"vj_{uuid_module.uuid4().hex[:12]}"

    # ì‘ì—… ìƒíƒœ ì´ˆê¸°í™” (íŒŒì¼ ê¸°ë°˜)
    _save_job_status(job_id, {
        'status': 'queued',
        'progress': 0,
        'message': 'ëŒ€ê¸° ì¤‘...',
        'video_url': None,
        'error': None,
        'duration': None,
        'subtitle_count': 0,
        'created_at': datetime.now().isoformat(),
        'total_duration': total_duration
    })

    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
    thread = threading.Thread(
        target=_generate_video_worker,
        args=(job_id, session_id, scenes, detected_lang, video_effects),
        daemon=True
    )
    thread.start()

    print(f"[IMAGE-VIDEO] Job started: {job_id}, {len(scenes)} scenes, {total_duration:.1f}s")

    return jsonify({
        "ok": True,
        "job_id": job_id,
        "message": "ì˜ìƒ ìƒì„±ì´ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤. ìƒíƒœë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.",
        "estimated_time": f"{int(total_duration // 60)}ë¶„ {int(total_duration % 60)}ì´ˆ ì˜ˆìƒ"
    })


@app.route('/api/image/video-status/<job_id>', methods=['GET'])
def api_image_video_status(job_id):
    """ì˜ìƒ ìƒì„± ì‘ì—… ìƒíƒœ í™•ì¸ (íŒŒì¼ ê¸°ë°˜)"""
    job = _load_job_status(job_id)
    if not job:
        return jsonify({"ok": False, "error": "ì‘ì—…ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}), 404

    return jsonify({
        "ok": True,
        "job_id": job_id,
        "status": job.get('status', 'unknown'),
        "progress": job.get('progress', 0),
        "message": job.get('message', ''),
        "video_url": job.get('video_url'),
        "duration": job.get('duration'),
        "subtitle_count": job.get('subtitle_count', 0),
        "error": job.get('error')
    })


# ===== ì¸ë„¤ì¼ ìë™ ìƒì„± API =====

@app.route('/thumbnail')
def thumbnail_page():
    """ì¸ë„¤ì¼ ìë™ ìƒì„± í˜ì´ì§€"""
    return render_template('thumbnail.html')


@app.route('/thumbnail-ai')
def thumbnail_ai_page():
    """AI ì¸ë„¤ì¼ ìƒì„± í˜ì´ì§€ (GPT-5.1 + Gemini 3 Pro)"""
    return render_template('thumbnail-ai.html')


# ===== í†µí•© ì¸ë„¤ì¼ ë””ìì¸ ìë™ ìƒì„± API (ìŠ¤íƒ€ì¼ í¬í•¨) =====
THUMBNAIL_STYLE_PRESETS = {
    "nostalgia": {
        "name": "ì‹œë‹ˆì–´ ê°ì„±",
        "description": "ì„¸í”¼ì•„, ì¶”ì–µ, ë”°ëœ»í•œ íšŒìƒ ëŠë‚Œ",
        "audience": "senior",
        "colors": {
            "background": "#F7EFE5",
            "text": "#373431",
            "accent": "#D19C66",
            "outline": "#2B2B2B"
        },
        "font": {
            "family": "NanumSquareB",
            "weight": "700",
            "size": "72px",
            "letter_spacing": "2px"
        },
        "layout": {
            "position": "left-top",
            "padding": "32px",
            "text_box": True,
            "text_box_opacity": 0.7
        },
        "image_style": "warm sepia tone, soft focus, nostalgic film grain, 1970s Korean aesthetic"
    },
    "clinic_warm": {
        "name": "ë”°ëœ»í•œ ë³‘ì›",
        "description": "ì²­ê²°í•˜ë©´ì„œë„ ë”°ëœ»í•œ ì˜ë£Œ ì»¨ì…‰",
        "audience": "senior",
        "colors": {
            "background": "#E8F4F8",
            "text": "#1A365D",
            "accent": "#4299E1",
            "outline": "#FFFFFF"
        },
        "font": {
            "family": "NanumBarunGothicBold",
            "weight": "700",
            "size": "68px",
            "letter_spacing": "1px"
        },
        "layout": {
            "position": "top-center",
            "padding": "28px",
            "text_box": True,
            "text_box_opacity": 0.85
        },
        "image_style": "clean Korean clinic interior, soft natural light, warm atmosphere, modern medical setting"
    },
    "dramatic_conflict": {
        "name": "ê°•ë ¬í•œ ê°ˆë“±",
        "description": "ì–´ë‘ìš´ ë°°ê²½ + ê°•ë ¬í•œ ë…¸ë€ ê°•ì¡°",
        "audience": "senior",
        "colors": {
            "background": "#1A1A1A",
            "text": "#FFD700",
            "accent": "#FF4444",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumSquareB",
            "weight": "900",
            "size": "80px",
            "letter_spacing": "0px"
        },
        "layout": {
            "position": "center",
            "padding": "24px",
            "text_box": False,
            "text_box_opacity": 0
        },
        "image_style": "dark moody atmosphere, dramatic lighting, high contrast shadows, intense emotional moment"
    },
    "family_tearjerker": {
        "name": "ê°€ì¡± ê°ë™",
        "description": "íŒŒìŠ¤í…”í†¤, ê°€ì¡±/ë¶€ëª¨ í…Œë§ˆ",
        "audience": "senior",
        "colors": {
            "background": "#FFF5F5",
            "text": "#4A3728",
            "accent": "#E57373",
            "outline": "#FFFFFF"
        },
        "font": {
            "family": "NanumMyeongjoBold",
            "weight": "700",
            "size": "64px",
            "letter_spacing": "3px"
        },
        "layout": {
            "position": "center",
            "padding": "36px",
            "text_box": True,
            "text_box_opacity": 0.6
        },
        "image_style": "soft pastel colors, gentle lighting, family moments, warm emotional scene, Korean home setting"
    },
    "calm_documentary": {
        "name": "ì°¨ë¶„í•œ ë‹¤í",
        "description": "ì‹¤ì œ ì‚¬ì§„ ê·¸ëŒ€ë¡œ, ë‹´ë°±í•œ í†¤",
        "audience": "senior",
        "colors": {
            "background": "#F5F5F5",
            "text": "#2D3748",
            "accent": "#3182CE",
            "outline": "#FFFFFF"
        },
        "font": {
            "family": "NanumBarunGothic",
            "weight": "600",
            "size": "60px",
            "letter_spacing": "1px"
        },
        "layout": {
            "position": "bottom-left",
            "padding": "24px",
            "text_box": True,
            "text_box_opacity": 0.9
        },
        "image_style": "realistic photography, natural colors, documentary style, authentic Korean setting"
    },
    "newspaper_retro": {
        "name": "ì‹ ë¬¸ ë ˆíŠ¸ë¡œ",
        "description": "í‘ë°± í—¤ë“œë¼ì¸ ìŠ¤íƒ€ì¼",
        "audience": "senior",
        "colors": {
            "background": "#FFFEF0",
            "text": "#1A1A1A",
            "accent": "#8B0000",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumMyeongjoBold",
            "weight": "900",
            "size": "76px",
            "letter_spacing": "4px"
        },
        "layout": {
            "position": "top-center",
            "padding": "20px",
            "text_box": False,
            "text_box_opacity": 0
        },
        "image_style": "black and white photo, newspaper grain texture, vintage print style, bold headline aesthetic"
    },
    # ===== ì¼ë°˜ìš© ìŠ¤íƒ€ì¼ (General Audience) =====
    "breaking_news": {
        "name": "ì†ë³´/ê¸´ê¸‰",
        "description": "ë¶‰ì€ ë°°ê²½, ì†ë³´/ë“œë””ì–´/ë°©ê¸ˆ",
        "audience": "general",
        "colors": {
            "background": "#8B0000",
            "text": "#FFFFFF",
            "accent": "#FFD700",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumSquareB",
            "weight": "900",
            "size": "84px",
            "letter_spacing": "0px"
        },
        "layout": {
            "position": "center",
            "padding": "20px",
            "text_box": False,
            "text_box_opacity": 0
        },
        "image_style": "high contrast dramatic lighting, dark silhouette, red warning atmosphere, news broadcast style, empty space for text, YouTube thumbnail composition, no text, 16:9"
    },
    "crime": {
        "name": "ì‚¬ê±´/ë²”ì£„",
        "description": "ì–´ë‘ìš´ ì¸ë¬¼ ì‹¤ë£¨ì—£, ê°•í•œ ëŒ€ë¹„",
        "audience": "general",
        "colors": {
            "background": "#131313",
            "text": "#FFFFFF",
            "accent": "#E60000",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumSquareB",
            "weight": "900",
            "size": "80px",
            "letter_spacing": "0px"
        },
        "layout": {
            "position": "center",
            "padding": "24px",
            "text_box": True,
            "text_box_opacity": 0.5
        },
        "image_style": "high contrast dark background, silhouette of unknown person, red warning light, dramatic shadow, cinematic noir style, empty space for bold text, YouTube thumbnail composition, no text, 16:9"
    },
    "tech": {
        "name": "í…Œí¬/ì„¤ëª…",
        "description": "íŒŒë€ìƒ‰ ê³„ì—´, ë°©ë²•/í•´ê²°/ìµœì ",
        "audience": "general",
        "colors": {
            "background": "#0A1628",
            "text": "#FFFFFF",
            "accent": "#00D4FF",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumBarunGothicBold",
            "weight": "700",
            "size": "72px",
            "letter_spacing": "1px"
        },
        "layout": {
            "position": "left-center",
            "padding": "28px",
            "text_box": False,
            "text_box_opacity": 0
        },
        "image_style": "clean tech aesthetic, blue gradient background, modern digital style, futuristic lighting, sharp details, empty space for text, YouTube thumbnail composition, no text, 16:9"
    },
    "money": {
        "name": "ê²½ì œ/ì¬í…Œí¬",
        "description": "ìˆ«ì ê°•ì¡°, ê¸°íšŒ/ìˆ˜ìµ",
        "audience": "general",
        "colors": {
            "background": "#1A1A2E",
            "text": "#00FF88",
            "accent": "#FFD700",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumSquareB",
            "weight": "900",
            "size": "80px",
            "letter_spacing": "0px"
        },
        "layout": {
            "position": "center",
            "padding": "24px",
            "text_box": False,
            "text_box_opacity": 0
        },
        "image_style": "financial chart background, money growth concept, green and gold colors, stock market aesthetic, clean composition, empty space for text, YouTube thumbnail style, no text, 16:9"
    },
    "vlog": {
        "name": "ë¸Œì´ë¡œê·¸/ì¼ìƒ",
        "description": "ë°ì€ ì‹¤ì œ ì‚¬ì§„, ì§„ì§œ/ì²˜ìŒ/í•´ë´¤ë‹¤",
        "audience": "general",
        "colors": {
            "background": "#FFFFFF",
            "text": "#1A1A1A",
            "accent": "#FF6B6B",
            "outline": "#FFFFFF"
        },
        "font": {
            "family": "NanumSquareRoundB",
            "weight": "700",
            "size": "68px",
            "letter_spacing": "1px"
        },
        "layout": {
            "position": "bottom-center",
            "padding": "24px",
            "text_box": True,
            "text_box_opacity": 0.8
        },
        "image_style": "bright natural lighting, lifestyle photography, warm friendly atmosphere, authentic moment, clean background, empty space for text, YouTube thumbnail style, no text, 16:9"
    },
    "dramatic": {
        "name": "ë“œë¼ë§ˆ/ê°ì •í­ë°œ",
        "description": "ì–¼êµ´ í´ë¡œì¦ˆì—…, ì™œ/ëª°ëë‹¤/ê·¸ë‚ ",
        "audience": "general",
        "colors": {
            "background": "#0D0D0D",
            "text": "#FFFFFF",
            "accent": "#FF4444",
            "outline": "#000000"
        },
        "font": {
            "family": "NanumSquareB",
            "weight": "900",
            "size": "88px",
            "letter_spacing": "-2px"
        },
        "layout": {
            "position": "center",
            "padding": "20px",
            "text_box": False,
            "text_box_opacity": 0
        },
        "image_style": "extreme close-up face, intense emotion, dramatic side lighting, high contrast shadows, cinematic portrait, dark background, empty space for text, YouTube thumbnail style, no text, 16:9"
    }
}

THUMBNAIL_DESIGN_SYSTEM_PROMPT = """You are an AI system that generates fully structured YouTube thumbnail design data
based on a single scene description.
You must follow the "Thumbnail JSON Schema v1".

Your output must ALWAYS be a valid JSON that matches the "result" structure.
Do not include explanations, plain text, or markdown â€” ONLY output JSON.

====================
PRIMARY OBJECTIVE
====================

Given a scene summary and metadata (audience type, channel type, style preference),
generate:

1) Thumbnail short text candidates (for Korean thumbnails)
2) Emotion and intensity classification
3) Style selection (auto if needed)
4) Typography recommendation (font, weight, size hint)
5) Layout suggestion (alignment, position, padding)
6) Color palette suggestion (HEX codes)
7) Image-generation prompt (for AI tools like ImageFX, DALL-E, Midjourney)
8) Optional "notes" to guide background-only image creation

====================
AUDIENCE RULES
====================

If "audience": "senior":

- Text length: 8â€“12 Korean characters
- Use emotions: íšŒìƒ, í›„íšŒ, ê·¸ë¦¬ì›€, ê°ì‚¬, ê¹¨ë‹¬ìŒ, ê¸°ë‹¤ë¦¼
- Avoid clickbait, avoid slang, avoid excessive punctuation
- Preferred tones: nostalgia, calm, warm, old photo, clinic, family
- Friendly and reflective titles
- Recommended style keys:
  - "nostalgia"
  - "clinic_warm"
  - "family_tearjerker"
  - "calm_documentary"
  - "dramatic_conflict"
  - "newspaper_retro"
- Colors: low contrast, pastel, film, vintage tones

If "audience": "general":

- Text length: 4â€“7 Korean characters
- Use emotions: ê¸´ì¥, ê¶ê¸ˆ, ë¶„ë…¸, ìœ„ê¸°, ì¶©ê²©
- Clickbait allowed (but stay concise, clear, not abusive)
- Preferred tones: dramatic, breaking_news, crime, tech, money
- Recommended style keys:
  - "breaking_news"
  - "crime"
  - "tech"
  - "money"
  - "vlog"
  - "dramatic"
- Colors: high contrast, red/yellow/black/white dominant

====================
TEXT GENERATION RULES
====================

- ONLY Korean text for "text" field
- Character count must not exceed "max_length"
- Avoid banned words included in "ban_words"
- At least one candidate must focus on a clear emotional center
- Do not generate English mixed headlines
- NEVER include "ìœ íŠœë¸Œ", "í´ë¦­", "êµ¬ë…" words

====================
IMAGE PROMPT RULES
====================

Image-generation prompts must:

- NOT contain text
- NOT contain watermark
- MUST describe background only (no title text rendered inside image)
- MUST include clear space ("negative space") for text placement
- ALWAYS include cinematic composition instruction
- Format: 16:9, no characters unless silhouette is needed

Senior image prompt guidance:
- "soft light", "vintage photo", "nostalgic Korean street",
- "film texture", "pastel tones", "calm spring morning",
- "empty clinic entrance", "falling cherry blossoms"

General image prompt guidance:
- "high contrast dramatic lighting", "dark background",
- "silhouette", "red warning light", "empty urban alley",
- "strong color accent", "center composition", "sharp clarity"

====================
STYLE AUTO-SELECTION RULES
====================

If "style": "auto",
choose style from the "recommended style keys" based on:

- scene_summary keywords
- audience type
- channel_type

Examples:
- scene contains "first day, ì§„ë£Œì†Œ, ë³‘ì›" â†’ "clinic_warm"
- scene contains "ì‚¬ê±´, í”¼í•´, ì¦ê±°, ì§„ì‹¤" â†’ "crime"
- scene contains "ê¸°ì–µ, í¸ì§€, ë§ˆì§€ë§‰" â†’ "nostalgia"
- scene contains "ëˆ, íˆ¬ì, ìˆ˜ìµ" â†’ "money"
- scene contains "ê¸°ìˆ , ë°©ë²•, í•´ê²°" â†’ "tech"
- scene contains "ê°€ì¡±, ë¶€ëª¨, ì—„ë§ˆ, ì•„ë¹ " â†’ "family_tearjerker"

====================
REQUIRED OUTPUT FORMAT (JSON only)
====================

The final output MUST be a JSON object shaped as:

{
  "scene_summary": "...",
  "audience": "...",
  "channel_type": "...",
  "style_auto_selected": "...",
  "candidates": [
    {
      "id": "thumb_001",
      "text": "...",
      "length": 7,
      "audience": "...",
      "emotion": "...",
      "intensity": 0.7,
      "style_profile": {
        "style_key": "...",
        "tone": "...",
        "category": "..."
      },
      "design": {
        "layout": {
          "position": "bottom-left",
          "text_box": true,
          "padding": 32,
          "max_lines": 2,
          "alignment": "left"
        },
        "colors": {
          "background": "#F2E7D5",
          "text": "#2B2B2B",
          "accent": "#A67C52",
          "suggested_palette": [
            "#F2E7D5",
            "#2B2B2B",
            "#A67C52",
            "#FFFFFF"
          ]
        },
        "font": {
          "family": "Noto Sans KR",
          "weight": "900",
          "size_hint": "72px",
          "line_spacing": 1.1
        }
      },
      "image_prompt": {
        "prompt": "...(AI image-generation prompt)...",
        "notes": "Background only for thumbnail. No text."
      }
    }
  ]
}

====================
VALIDATION RULES
====================

- ALWAYS return at least 3 candidates
- NEVER leave any field empty
- HEX codes must be valid (#RRGGBB)
- "size_hint" must contain "px"
- intensity value must be between 0.0 and 1.0

====================
OUTPUT LANGUAGE
====================

- Korean for "text"
- English for "image_prompt"

====================
FAIL CASE INSTRUCTIONS
====================

If the request lacks "scene_summary", reply with:

{
  "error": "scene_summary is required"
}

NO free text, NO apology.

====================
END OF SYSTEM PROMPT
====================
"""

@app.route('/api/thumbnail/generate', methods=['POST'])
def api_thumbnail_generate():
    """í†µí•© ì¸ë„¤ì¼ ë””ìì¸ ìë™ ìƒì„± API v1 (ìŠ¤íƒ€ì¼ + ë””ìì¸ + ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ í¬í•¨)"""
    try:
        from openai import OpenAI
        client = OpenAI()

        data = request.get_json() or {}

        # v1 ìŠ¤í‚¤ë§ˆ íŒŒë¼ë¯¸í„°
        scene_summary = data.get("scene_summary", "")
        audience = data.get("audience", "senior")  # senior / general
        channel_type = data.get("channel_type", "drama")  # drama / issue / vlog / sermon / news
        style = data.get("style", "auto")  # auto = AIê°€ ìë™ ì„ íƒ
        num_candidates = data.get("num_candidates", 10)
        max_length = data.get("max_length", 12 if audience == "senior" else 7)
        language = data.get("language", "ko")
        keywords = data.get("keywords", [])
        ban_words = data.get("ban_words", ["êµ¬ë…", "ìœ íŠœë¸Œ", "í´ë¦­"])
        options = data.get("options", {
            "generate_layout": True,
            "generate_palette": True,
            "generate_image_prompt": True
        })

        if not scene_summary:
            return jsonify({"ok": False, "error": "scene_summary is required"}), 400

        # audienceì— ë§ëŠ” ìŠ¤íƒ€ì¼ë§Œ í•„í„°ë§
        available_styles = [
            key for key, preset in THUMBNAIL_STYLE_PRESETS.items()
            if preset.get("audience") == audience
        ]

        # ê¸°ë³¸ ìŠ¤íƒ€ì¼ (audienceì— ë§ê²Œ)
        default_style = "nostalgia" if audience == "senior" else "breaking_news"

        user_payload = {
            "scene_summary": scene_summary,
            "audience": audience,
            "channel_type": channel_type,
            "style": style,
            "available_styles": available_styles,
            "num_candidates": num_candidates,
            "max_length": max_length,
            "language": language,
            "keywords": keywords,
            "ban_words": ban_words,
            "options": options
        }

        print(f"[THUMBNAIL-DESIGN-V1] í†µí•© ì¸ë„¤ì¼ ìƒì„± ìš”ì²­")
        print(f"  - audience: {audience}, channel_type: {channel_type}, style: {style}")
        print(f"  - available_styles: {available_styles}")

        # GPT í˜¸ì¶œ
        completion = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": THUMBNAIL_DESIGN_SYSTEM_PROMPT},
                {"role": "user", "content": json.dumps(user_payload, ensure_ascii=False)}
            ],
            temperature=0.8,
            response_format={"type": "json_object"}
        )

        result = completion.choices[0].message.content
        result_json = json.loads(result)

        # ì—ëŸ¬ ì²´í¬
        if "error" in result_json:
            return jsonify({"ok": False, "error": result_json["error"]}), 400

        # ì¶”ì²œëœ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
        style_auto_selected = result_json.get("style_auto_selected", default_style)
        if style != "auto" and style in THUMBNAIL_STYLE_PRESETS:
            style_auto_selected = style  # ì‚¬ìš©ìê°€ ì§ì ‘ ì§€ì •í•œ ê²½ìš°

        # ìŠ¤íƒ€ì¼ì´ audienceì— ë§ëŠ”ì§€ í™•ì¸
        if style_auto_selected not in available_styles:
            style_auto_selected = default_style

        style_preset = THUMBNAIL_STYLE_PRESETS.get(style_auto_selected, THUMBNAIL_STYLE_PRESETS[default_style])

        # ê° í›„ë³´ì— ë””ìì¸ ì •ë³´ ë³´ê°• (GPT ì¶œë ¥ì— ì—†ëŠ” ê²½ìš° í”„ë¦¬ì…‹ìœ¼ë¡œ ëŒ€ì²´)
        candidates = result_json.get("candidates", [])
        for i, c in enumerate(candidates):
            c["id"] = c.get("id", f"thumb_{str(i+1).zfill(3)}")
            c["length"] = len(c.get("text", ""))
            c["audience"] = audience

            # design ë³´ê°•
            if "design" not in c or not c["design"]:
                c["design"] = {
                    "layout": style_preset["layout"],
                    "colors": style_preset["colors"],
                    "font": style_preset["font"]
                }
            else:
                # ë¶€ë¶„ì ìœ¼ë¡œ ëˆ„ë½ëœ ê²½ìš° ë³´ê°•
                if "layout" not in c["design"]:
                    c["design"]["layout"] = style_preset["layout"]
                if "colors" not in c["design"]:
                    c["design"]["colors"] = style_preset["colors"]
                if "font" not in c["design"]:
                    c["design"]["font"] = style_preset["font"]

            # image_prompt ë³´ê°•
            if "image_prompt" not in c or not c["image_prompt"]:
                c["image_prompt"] = {
                    "prompt": style_preset["image_style"] + ", YouTube thumbnail composition, no text, 16:9",
                    "notes": "Background only for thumbnail. No text."
                }

        print(f"[THUMBNAIL-DESIGN-V1] ìƒì„± ì™„ë£Œ - style: {style_auto_selected}, {len(candidates)}ê°œ í›„ë³´")

        # v1 ìŠ¤í‚¤ë§ˆ ì‘ë‹µ
        return jsonify({
            "ok": True,
            "version": "1.0",
            "scene_summary": scene_summary,
            "audience": audience,
            "channel_type": channel_type,
            "style_auto_selected": style_auto_selected,
            "style_preset": {
                "key": style_auto_selected,
                "name": style_preset["name"],
                "description": style_preset["description"],
                "colors": style_preset["colors"],
                "font": style_preset["font"],
                "layout": style_preset["layout"],
                "image_style": style_preset["image_style"]
            },
            "candidates": candidates
        })

    except Exception as e:
        print(f"[THUMBNAIL-DESIGN-V1][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail/styles', methods=['GET'])
def api_thumbnail_styles():
    """ì‚¬ìš© ê°€ëŠ¥í•œ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ ëª©ë¡ ì¡°íšŒ (audience í•„í„° ì§€ì›)"""
    audience_filter = request.args.get("audience")  # senior / general / None(ì „ì²´)

    styles = []
    for key, preset in THUMBNAIL_STYLE_PRESETS.items():
        preset_audience = preset.get("audience", "senior")

        # audience í•„í„° ì ìš©
        if audience_filter and preset_audience != audience_filter:
            continue

        styles.append({
            "key": key,
            "name": preset["name"],
            "description": preset["description"],
            "audience": preset_audience,
            "colors": preset["colors"],
            "font": preset["font"],
            "layout": preset["layout"]
        })

    return jsonify({
        "ok": True,
        "audience_filter": audience_filter,
        "total": len(styles),
        "styles": styles
    })


# ===== ì¸ë„¤ì¼ AI ì‹œìŠ¤í…œ (GPT-5.1 + Gemini 3 Pro Image) =====
THUMBNAIL_AI_HISTORY_FILE = 'data/thumbnail_ai_history.json'
THUMBNAIL_PROMPT_CONFIG_FILE = 'data/thumbnail_prompt_config.json'


def load_thumbnail_prompt_config():
    """ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë“œ (ì›¹ UI + íŒŒì´í”„ë¼ì¸ ê³µí†µ)"""
    try:
        if os.path.exists(THUMBNAIL_PROMPT_CONFIG_FILE):
            with open(THUMBNAIL_PROMPT_CONFIG_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"[THUMBNAIL-AI] í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë“œ ì˜¤ë¥˜: {e}")
    # ê¸°ë³¸ ì„¤ì • ë°˜í™˜
    return {
        "style": {"default": "webtoon"},
        "language_settings": {
            "ko": {"lang_name": "í•œêµ­ì–´", "lang_english": "Korean", "text_lang_instruction": "í•œê¸€ë¡œ", "text_lang_desc": "í•œê¸€", "webtoon_style": "Korean webtoon style", "character_nationality": "Korean", "character_desc": "Korean man or woman"},
            "ja": {"lang_name": "æ—¥æœ¬èª", "lang_english": "Japanese", "text_lang_instruction": "æ—¥æœ¬èªã§", "text_lang_desc": "æ—¥æœ¬èª", "webtoon_style": "Japanese manga/anime style", "character_nationality": "Japanese", "character_desc": "Japanese man or woman"},
            "en": {"lang_name": "English", "lang_english": "English", "text_lang_instruction": "in English", "text_lang_desc": "English", "webtoon_style": "Western comic/illustration style", "character_nationality": "Western", "character_desc": "Western man or woman"}
        },
        "few_shot_enabled": True,
        "few_shot_count": 5,
        "model_settings": {"analysis_model": "gpt-5.1", "image_model": "google/gemini-3-pro-image-preview", "temperature": 0.8}
    }


def save_thumbnail_prompt_config(config):
    """ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(THUMBNAIL_PROMPT_CONFIG_FILE), exist_ok=True)
        config['updated_at'] = datetime.now().isoformat()
        with open(THUMBNAIL_PROMPT_CONFIG_FILE, 'w', encoding='utf-8') as f:
            json.dump(config, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[THUMBNAIL-AI] í”„ë¡¬í”„íŠ¸ ì„¤ì • ì €ì¥ ì˜¤ë¥˜: {e}")
        return False


@app.route('/api/thumbnail-ai/config', methods=['GET', 'POST'])
def api_thumbnail_ai_config():
    """
    ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ ì„¤ì • ì¡°íšŒ/ìˆ˜ì • API
    - GET: í˜„ì¬ ì„¤ì • ì¡°íšŒ
    - POST: ì„¤ì • ìˆ˜ì •
    """
    if request.method == 'GET':
        config = load_thumbnail_prompt_config()
        return jsonify({"ok": True, "config": config})

    elif request.method == 'POST':
        try:
            data = request.get_json() or {}
            current_config = load_thumbnail_prompt_config()

            # ë¶€ë¶„ ì—…ë°ì´íŠ¸ ì§€ì›
            for key in data:
                if key in ['version', 'updated_at']:
                    continue  # ìë™ ê´€ë¦¬ í•„ë“œëŠ” ìŠ¤í‚µ
                current_config[key] = data[key]

            if save_thumbnail_prompt_config(current_config):
                return jsonify({"ok": True, "message": "ì„¤ì •ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤", "config": current_config})
            else:
                return jsonify({"ok": False, "error": "ì„¤ì • ì €ì¥ ì‹¤íŒ¨"}), 500
        except Exception as e:
            return jsonify({"ok": False, "error": str(e)}), 500


def load_thumbnail_history():
    """ì¸ë„¤ì¼ í•™ìŠµ ë°ì´í„° ë¡œë“œ"""
    try:
        if os.path.exists(THUMBNAIL_AI_HISTORY_FILE):
            with open(THUMBNAIL_AI_HISTORY_FILE, 'r', encoding='utf-8') as f:
                return json.load(f)
    except Exception as e:
        print(f"[THUMBNAIL-AI] íˆìŠ¤í† ë¦¬ ë¡œë“œ ì˜¤ë¥˜: {e}")
    return {"selections": []}


def save_thumbnail_history(data):
    """ì¸ë„¤ì¼ í•™ìŠµ ë°ì´í„° ì €ì¥"""
    try:
        os.makedirs(os.path.dirname(THUMBNAIL_AI_HISTORY_FILE), exist_ok=True)
        with open(THUMBNAIL_AI_HISTORY_FILE, 'w', encoding='utf-8') as f:
            json.dump(data, f, ensure_ascii=False, indent=2)
        return True
    except Exception as e:
        print(f"[THUMBNAIL-AI] íˆìŠ¤í† ë¦¬ ì €ì¥ ì˜¤ë¥˜: {e}")
        return False


def get_learning_examples(limit=5):
    """í•™ìŠµìš© ì˜ˆì‹œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸° (ìµœê·¼ ì„ íƒ ë°ì´í„° ê¸°ë°˜)"""
    history = load_thumbnail_history()
    selections = history.get("selections", [])

    # ìµœê·¼ ì„ íƒ ë°ì´í„° ì¤‘ limitê°œ ê°€ì ¸ì˜¤ê¸°
    recent = selections[-limit:] if len(selections) > limit else selections

    examples = []
    for sel in recent:
        selected_key = sel.get("selected")  # "A" or "B"
        if selected_key and sel.get("prompts", {}).get(selected_key):
            examples.append({
                "genre": sel.get("genre", "ì¼ë°˜"),
                "script_summary": sel.get("script_summary", "")[:100],
                "selected_prompt": sel["prompts"][selected_key],
                "reason": sel.get("selection_reason", "")
            })

    return examples


@app.route('/api/thumbnail-ai/analyze', methods=['POST'])
def api_thumbnail_ai_analyze():
    """
    GPT-5.1ì´ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ 1ê°œ ìƒì„±
    í•™ìŠµ ë°ì´í„°ë¥¼ Few-shotìœ¼ë¡œ í™œìš©
    """
    try:
        from openai import OpenAI
        client = OpenAI()

        data = request.get_json() or {}
        script = data.get('script', '')
        title = data.get('title', '')
        additional_prompt = data.get('additional_prompt', '')  # ì‚¬ìš©ì ì¶”ê°€ ìš”ì²­ì‚¬í•­

        if not script:
            return jsonify({"ok": False, "error": "ëŒ€ë³¸ì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # ì–¸ì–´ ê°ì§€ (ëŒ€ë³¸ ê¸°ì¤€)
        def detect_language(text):
            """ëŒ€ë³¸ì˜ ì£¼ìš” ì–¸ì–´ë¥¼ ê°ì§€ (ë¹„ìœ¨ ê¸°ë°˜)

            íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ í•œê¸€ë³´ë‹¤ ë§ìœ¼ë©´ ì¼ë³¸ì–´ë¡œ íŒë‹¨.
            í•œê¸€ì´ ë” ë§ìœ¼ë©´ í•œêµ­ì–´ë¡œ íŒë‹¨.
            """
            import re
            # í•œêµ­ì–´ ê°ì§€
            ko_pattern = re.compile(r'[\uAC00-\uD7AF]')
            ko_count = len(ko_pattern.findall(text[:2000]))
            # ì¼ë³¸ì–´ ê°ì§€ (íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜)
            ja_pattern = re.compile(r'[\u3040-\u309F\u30A0-\u30FF]')
            ja_count = len(ja_pattern.findall(text[:2000]))

            print(f"[THUMBNAIL-AI] ì–¸ì–´ ê°ì§€ - í•œê¸€: {ko_count}ì, ì¼ë³¸ì–´: {ja_count}ì")

            # ë¹„ìœ¨ ê¸°ë°˜ íŒë‹¨: ë” ë§ì€ ìª½ ì„ íƒ
            if ja_count > ko_count:
                return 'ja', 'æ—¥æœ¬èª', 'Japanese'
            elif ko_count > 0:
                return 'ko', 'í•œêµ­ì–´', 'Korean'
            elif ja_count > 0:
                return 'ja', 'æ—¥æœ¬èª', 'Japanese'
            # ê¸°ë³¸ê°’: ì˜ì–´
            return 'en', 'English', 'English'

        lang_code, lang_name, lang_english = detect_language(script + title)
        print(f"[THUMBNAIL-AI] ë¶„ì„ ìš”ì²­ - ì œëª©: {title}")
        print(f"[THUMBNAIL-AI] ëŒ€ë³¸ ê¸¸ì´: {len(script)}ì, ê°ì§€ ì–¸ì–´: {lang_name} ({lang_code})")
        if additional_prompt:
            print(f"[THUMBNAIL-AI] ì¶”ê°€ ìš”ì²­ì‚¬í•­: {additional_prompt}")

        # í•™ìŠµ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        learning_examples = get_learning_examples(5)

        # Few-shot ì˜ˆì‹œ í…ìŠ¤íŠ¸ ìƒì„±
        examples_text = ""
        if learning_examples:
            examples_text = "\n\n[ê³¼ê±° ì‚¬ìš©ìê°€ ì„ í˜¸í•œ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ ì˜ˆì‹œ]\n"
            for i, ex in enumerate(learning_examples, 1):
                examples_text += f"""
ì˜ˆì‹œ {i}:
- ì¥ë¥´: {ex['genre']}
- ëŒ€ë³¸ ìš”ì•½: {ex['script_summary']}
- ì„ íƒëœ í”„ë¡¬í”„íŠ¸: {ex['selected_prompt']}
- ì„ íƒ ì´ìœ : {ex['reason'] or 'ì—†ìŒ'}
"""

        # ì¶”ê°€ ìš”ì²­ì‚¬í•­ í…ìŠ¤íŠ¸
        additional_instruction = ""
        if additional_prompt:
            additional_instruction = f"""

[ì‚¬ìš©ì ì¶”ê°€ ìš”ì²­ì‚¬í•­]
ë‹¤ìŒ ìš”ì²­ì‚¬í•­ì„ ë°˜ë“œì‹œ ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ì— ë°˜ì˜í•˜ì„¸ìš”:
{additional_prompt}
"""

        # ê³µí†µ í”„ë¡¬í”„íŠ¸ ì„¤ì • ë¡œë“œ
        prompt_config = load_thumbnail_prompt_config()
        lang_settings = prompt_config.get('language_settings', {}).get(lang_code, prompt_config.get('language_settings', {}).get('ko', {}))

        # ì–¸ì–´ë³„ ì„¤ì • (ì„¤ì • íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        text_lang_instruction = lang_settings.get('text_lang_instruction', 'í•œê¸€ë¡œ')
        text_lang_desc = lang_settings.get('text_lang_desc', 'í•œê¸€')
        webtoon_style = lang_settings.get('webtoon_style', 'Korean webtoon style')

        # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ (ì„¤ì • íŒŒì¼ í…œí”Œë¦¿ ë˜ëŠ” ê¸°ë³¸ê°’)
        system_prompt_template = prompt_config.get('system_prompt_template', '')
        if system_prompt_template:
            system_prompt = system_prompt_template.format(
                lang_name=lang_name,
                lang_code=lang_code,
                lang_english=lang_english,
                text_lang_instruction=text_lang_instruction,
                text_lang_desc=text_lang_desc,
                webtoon_style=webtoon_style,
                examples_text=examples_text,
                additional_instruction=additional_instruction
            )
        else:
            # ì„¤ì • íŒŒì¼ì— í…œí”Œë¦¿ì´ ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸ ì‚¬ìš©
            system_prompt = f"""ë‹¹ì‹ ì€ ìœ íŠœë¸Œ ì¸ë„¤ì¼ ì „ë¬¸ ë””ìì´ë„ˆì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ í´ë¦­ë¥ ì´ ë†’ì€ ì¸ë„¤ì¼ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ 1ê°œë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

â˜…â˜…â˜… ì¤‘ìš”: ëŒ€ë³¸ì´ {lang_name}ë¡œ ì‘ì„±ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ë„ ë°˜ë“œì‹œ {lang_name}ë¡œ ì‘ì„±í•˜ì„¸ìš”! â˜…â˜…â˜…

[í•µì‹¬ ì›ì¹™]
1. ìœ íŠœë¸Œ ì¸ë„¤ì¼ì€ "í˜¸ê¸°ì‹¬"ê³¼ "ê°ì •"ì„ ìê·¹í•´ì•¼ í•©ë‹ˆë‹¤
2. í…ìŠ¤íŠ¸ëŠ” {text_lang_instruction}, í¬ê³  êµµê²Œ, ì½ê¸° ì‰½ê²Œ
3. ëŒ€ë¹„ê°€ ê°•í•œ ìƒ‰ìƒ ì‚¬ìš© (ë¹¨ê°•/ë…¸ë‘/í°ìƒ‰ ë“±)
4. ì–¼êµ´ í‘œì •ì´ë‚˜ ê°ì •ì ì¸ ìš”ì†Œ í¬í•¨
5. {webtoon_style} (ì €ì‘ê¶Œ ì•ˆì „)

[ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì‘ì„± ê·œì¹™]
- ì˜ë¬¸ìœ¼ë¡œ ì‘ì„± (Gemini 3 Pro Imageê°€ ì´í•´í•  ìˆ˜ ìˆë„ë¡)
- 16:9 ê°€ë¡œ ë¹„ìœ¨ (YouTube ì¸ë„¤ì¼ í‘œì¤€)
- {lang_english} í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì§€ì‹œ í¬í•¨
- êµ¬ì²´ì ì¸ ìƒ‰ìƒ, ìŠ¤íƒ€ì¼, êµ¬ë„ ëª…ì‹œ
- {webtoon_style} í•„ìˆ˜
- ê³¼ì¥ëœ ê°ì • í‘œí˜„ (ë†€ëŒ, ì¶©ê²©, ê¸°ì¨ ë“±)
{examples_text}
{additional_instruction}

[ì‘ë‹µ í˜•ì‹]
ë°˜ë“œì‹œ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš”:
{{
  "script_summary": "ëŒ€ë³¸ í•µì‹¬ ìš”ì•½ (1-2ë¬¸ì¥, {lang_name}ë¡œ)",
  "thumbnail_concept": "ì¸ë„¤ì¼ ì»¨ì…‰ ì„¤ëª…",
  "prompts": {{
    "A": {{
      "description": "í”„ë¡¬í”„íŠ¸ ì„¤ëª…",
      "prompt": "ì˜ë¬¸ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ({webtoon_style} í¬í•¨ í•„ìˆ˜)",
      "text_overlay": {{
        "main": "ë©”ì¸ í…ìŠ¤íŠ¸ ({text_lang_desc}, ì§§ê³  ì„íŒ©íŠ¸ìˆê²Œ)",
        "sub": "ì„œë¸Œ í…ìŠ¤íŠ¸ ({text_lang_desc}, ì„ íƒ)"
      }},
      "style": "ìŠ¤íƒ€ì¼ í‚¤ì›Œë“œ"
    }}
  }},
  "lang": "{lang_code}"
}}"""

        # ì‚¬ìš©ì í”„ë¡¬í”„íŠ¸ (ì„¤ì • íŒŒì¼ í…œí”Œë¦¿ ë˜ëŠ” ê¸°ë³¸ê°’)
        user_prompt_template = prompt_config.get('user_prompt_template', '')
        if user_prompt_template:
            user_prompt = user_prompt_template.format(
                title=title,
                lang_name=lang_name,
                script=script[:3000],
                webtoon_style=webtoon_style
            )
        else:
            user_prompt = f"""[ì œëª©] {title}
[ì–¸ì–´] {lang_name}

[ëŒ€ë³¸]
{script[:3000]}

ìœ„ ëŒ€ë³¸ì„ ë¶„ì„í•˜ì—¬ í´ë¦­ë¥  ë†’ì€ ìœ íŠœë¸Œ ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ 1ê°œë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.
{webtoon_style}ë¡œ, ê³¼ì¥ëœ í‘œì •ê³¼ ê°ì •ì„ ë‹´ì•„ì£¼ì„¸ìš”.
â˜… ì¸ë„¤ì¼ì˜ í…ìŠ¤íŠ¸ëŠ” ë°˜ë“œì‹œ {lang_name}ë¡œ ì‘ì„±í•˜ì„¸ìš”! â˜…"""

        # GPT-4o Chat Completions API í˜¸ì¶œ
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": user_prompt}
            ],
            temperature=0.8,
            max_tokens=4096,
            response_format={"type": "json_object"}
        )

        # ê²°ê³¼ ì¶”ì¶œ
        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹± (ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±°)
        if result_text.startswith("```"):
            result_text = result_text.split("```")[1]
            if result_text.startswith("json"):
                result_text = result_text[4:]
        result_text = result_text.strip()

        try:
            result = json.loads(result_text)
        except json.JSONDecodeError as je:
            print(f"[THUMBNAIL-AI] JSON íŒŒì‹± ì˜¤ë¥˜: {je}")
            print(f"[THUMBNAIL-AI] ì›ë³¸ í…ìŠ¤íŠ¸: {result_text[:500]}")
            return jsonify({"ok": False, "error": f"AI ì‘ë‹µ íŒŒì‹± ì˜¤ë¥˜: {str(je)}"}), 200

        # ì„¸ì…˜ ID ìƒì„±
        session_id = f"thumb_{uuid.uuid4().hex[:12]}"

        print(f"[THUMBNAIL-AI] ë¶„ì„ ì™„ë£Œ - ì„¸ì…˜: {session_id}")

        return jsonify({
            "ok": True,
            "session_id": session_id,
            "script_summary": result.get("script_summary", ""),
            "thumbnail_concept": result.get("thumbnail_concept", ""),
            "prompts": result.get("prompts", {}),
            "title": title,
            "lang": lang_code,  # ê°ì§€ëœ ì–¸ì–´
            "learning_examples_used": len(learning_examples)
        })

    except Exception as e:
        print(f"[THUMBNAIL-AI][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail-ai/generate', methods=['POST'])
def api_thumbnail_ai_generate():
    """
    Gemini 3 Pro Imageë¡œ ì¸ë„¤ì¼ ì´ë¯¸ì§€ ìƒì„±
    í•œê¸€ í…ìŠ¤íŠ¸ ë Œë”ë§ ì§€ì›
    """
    try:
        import time
        import base64

        data = request.get_json() or {}
        prompt = data.get('prompt', '')
        text_overlay = data.get('text_overlay', {})
        style = data.get('style', 'comic')
        session_id = data.get('session_id', '')
        variant = data.get('variant', 'A')  # A or B

        if not prompt:
            return jsonify({"ok": False, "error": "í”„ë¡¬í”„íŠ¸ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        print(f"[THUMBNAIL-AI] ì´ë¯¸ì§€ ìƒì„± - ì„¸ì…˜: {session_id}, ë³€í˜•: {variant}")

        # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì§€ì‹œ ì¶”ê°€
        main_text = text_overlay.get('main', '')
        sub_text = text_overlay.get('sub', '')

        text_instruction = ""
        if main_text:
            text_instruction = f"""
IMPORTANT TEXT OVERLAY INSTRUCTIONS:
- Add large, bold Korean text "{main_text}" prominently in the image
- Text should be highly visible with strong contrast (white text with black outline or vice versa)
- Text position: center or top area of the image
"""
            if sub_text:
                text_instruction += f'- Add smaller subtitle "{sub_text}" below the main text\n'

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        enhanced_prompt = f"""Create a YouTube thumbnail image in 16:9 landscape aspect ratio.

{prompt}

{text_instruction}

Style requirements:
- High contrast, eye-catching colors
- Professional YouTube thumbnail quality
- Comic/illustration style (not photorealistic)
- Clean composition suitable for small preview
- {style} aesthetic"""

        # Gemini 3 Proë¡œ ì´ë¯¸ì§€ ìƒì„± (image ëª¨ë“ˆ ì‚¬ìš©)
        result = generate_image_base64(prompt=enhanced_prompt, model=GEMINI_PRO)
        if not result.get("ok"):
            return jsonify({"ok": False, "error": result.get("error", "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")}), 200

        base64_image_data = result.get("base64")
        if not base64_image_data:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"}), 200

        # íŒŒì¼ë¡œ ì €ì¥
        timestamp = int(time.time() * 1000)
        filename = f"thumbnail_ai_{session_id}_{variant}_{timestamp}.png"

        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
        os.makedirs(output_dir, exist_ok=True)
        filepath = os.path.join(output_dir, filename)

        with open(filepath, 'wb') as f:
            f.write(base64.b64decode(base64_image_data))

        image_url = f'/output/{filename}'
        print(f"[THUMBNAIL-AI] ì´ë¯¸ì§€ ì €ì¥ ì™„ë£Œ: {image_url}")

        return jsonify({
            "ok": True,
            "image_url": image_url,
            "session_id": session_id,
            "variant": variant,
            "prompt_used": enhanced_prompt[:500]
        })

    except Exception as e:
        print(f"[THUMBNAIL-AI][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail-ai/select', methods=['POST'])
def api_thumbnail_ai_select():
    """
    ì‚¬ìš©ìì˜ ì¸ë„¤ì¼ ì„ íƒ ì €ì¥ (í•™ìŠµ ë°ì´í„°)
    """
    try:
        data = request.get_json() or {}

        session_id = data.get('session_id', '')
        selected = data.get('selected', '')  # "A" or "B"
        prompts = data.get('prompts', {})
        script_summary = data.get('script_summary', '')
        genre = data.get('genre', 'ì¼ë°˜')
        title = data.get('title', '')
        selection_reason = data.get('selection_reason', '')
        image_urls = data.get('image_urls', {})

        if not session_id or not selected:
            return jsonify({"ok": False, "error": "ì„¸ì…˜ IDì™€ ì„ íƒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        print(f"[THUMBNAIL-AI] ì„ íƒ ì €ì¥ - ì„¸ì…˜: {session_id}, ì„ íƒ: {selected}")

        # í•™ìŠµ ë°ì´í„° ì €ì¥
        history = load_thumbnail_history()

        selection_data = {
            "id": session_id,
            "timestamp": dt.now().isoformat(),
            "title": title,
            "genre": genre,
            "script_summary": script_summary,
            "prompts": {
                "A": prompts.get("A", {}).get("prompt", ""),
                "B": prompts.get("B", {}).get("prompt", "")
            },
            "text_overlays": {
                "A": prompts.get("A", {}).get("text_overlay", {}),
                "B": prompts.get("B", {}).get("text_overlay", {})
            },
            "image_urls": image_urls,
            "selected": selected,
            "selection_reason": selection_reason
        }

        history["selections"].append(selection_data)

        # ìµœëŒ€ 100ê°œê¹Œì§€ë§Œ ìœ ì§€
        if len(history["selections"]) > 100:
            history["selections"] = history["selections"][-100:]

        save_thumbnail_history(history)

        print(f"[THUMBNAIL-AI] í•™ìŠµ ë°ì´í„° ì €ì¥ ì™„ë£Œ - ì´ {len(history['selections'])}ê°œ")

        return jsonify({
            "ok": True,
            "message": "ì„ íƒì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤",
            "session_id": session_id,
            "selected": selected,
            "total_selections": len(history["selections"])
        })

    except Exception as e:
        print(f"[THUMBNAIL-AI][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail-ai/history', methods=['GET'])
def api_thumbnail_ai_history():
    """
    ì¸ë„¤ì¼ í•™ìŠµ ë°ì´í„° íˆìŠ¤í† ë¦¬ ì¡°íšŒ
    """
    try:
        limit = request.args.get('limit', 20, type=int)
        genre_filter = request.args.get('genre', None)

        history = load_thumbnail_history()
        selections = history.get("selections", [])

        # ì¥ë¥´ í•„í„°
        if genre_filter:
            selections = [s for s in selections if s.get("genre") == genre_filter]

        # ìµœì‹ ìˆœ ì •ë ¬
        selections = sorted(selections, key=lambda x: x.get("timestamp", ""), reverse=True)

        # limit ì ìš©
        selections = selections[:limit]

        # í†µê³„ ê³„ì‚°
        all_selections = history.get("selections", [])
        stats = {
            "total": len(all_selections),
            "a_selected": sum(1 for s in all_selections if s.get("selected") == "A"),
            "b_selected": sum(1 for s in all_selections if s.get("selected") == "B"),
            "c_selected": sum(1 for s in all_selections if s.get("selected") == "C"),
            "genres": {}
        }

        for s in all_selections:
            g = s.get("genre", "ì¼ë°˜")
            stats["genres"][g] = stats["genres"].get(g, 0) + 1

        return jsonify({
            "ok": True,
            "selections": selections,
            "stats": stats,
            "limit": limit,
            "genre_filter": genre_filter
        })

    except Exception as e:
        print(f"[THUMBNAIL-AI][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail-ai/generate-single', methods=['POST'])
def api_thumbnail_ai_generate_single():
    """
    ë‹¨ì¼ ì¸ë„¤ì¼ ìƒì„± (ìë™í™” íŒŒì´í”„ë¼ì¸ìš© - A í•˜ë‚˜ë§Œ ìƒì„±)
    â˜… Geminiê°€ ì§ì ‘ í…ìŠ¤íŠ¸ ë Œë”ë§
    """
    try:
        import base64
        from PIL import Image
        import io

        data = request.get_json() or {}
        prompt_data = data.get('prompt', {})
        session_id = data.get('session_id', '')
        category = data.get('category', '')
        lang = data.get('lang', 'ko')
        style = prompt_data.get('style', '')

        if not prompt_data.get('prompt'):
            return jsonify({"ok": False, "error": "prompt í•„ë“œê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        print(f"[THUMBNAIL-AI] ë‹¨ì¼ ì¸ë„¤ì¼ ìƒì„± - ì„¸ì…˜: {session_id}, ì¹´í…Œê³ ë¦¬: {category}, ìŠ¤íƒ€ì¼: {style}")

        prompt = prompt_data.get('prompt', '')
        text_overlay = prompt_data.get('text_overlay', {})
        main_text = text_overlay.get('main', '')
        sub_text = text_overlay.get('sub', '')

        # ì–¸ì–´ì— ë”°ë¥¸ ì„¤ì •
        lang_config = {
            'ja': ("Japanese", "Japanese man or woman"),
            'en': ("Western", "Western man or woman"),
        }
        character_nationality, character_desc = lang_config.get(lang, ("Korean", "Korean man or woman"))

        # í”„ë¡¬í”„íŠ¸ì—ì„œ ë¶ˆí•„ìš”í•œ í‚¤ì›Œë“œ ì œê±°
        clean_prompt = prompt
        for kw in ['stickman', 'stick man', 'photorealistic', 'realistic', 'photograph', 'photo', 'Ghibli', 'anime']:
            clean_prompt = clean_prompt.replace(kw, '').replace(kw.lower(), '').replace(kw.capitalize(), '')

        # í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ì§€ì‹œ ì¶”ê°€
        text_instruction = ""
        if main_text:
            text_instruction = f"""
â˜… TEXT REQUIREMENTS (CRITICAL!) â˜…
- Add VERY LARGE, BOLD text "{main_text}" on LEFT side of image
- Text color: PURE WHITE with THICK BLACK outline (3-4px stroke)
- Split into 2-4 short lines for maximum impact
- Text takes 30-40% of image width
- NO yellow text, NO colored text - WHITE ONLY!
"""
            if sub_text:
                text_instruction += f'- Subtitle below: "{sub_text}"\n'

        # ìµœì¢… í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        enhanced_prompt = f"""Create a YouTube thumbnail image in 16:9 landscape aspect ratio.

{clean_prompt}

LAYOUT: Character/subject on RIGHT side (30-40% of frame)

{text_instruction}

Style: {character_nationality} webtoon style, comic illustration, clean bold outlines, vibrant colors. NOT photorealistic."""

        print(f"[THUMBNAIL-AI] Gemini í”„ë¡¬í”„íŠ¸ (í…ìŠ¤íŠ¸ ì§ì ‘ ìƒì„±): {enhanced_prompt[:200]}...")

        # Gemini 3 Proë¡œ ì´ë¯¸ì§€ ìƒì„± (í…ìŠ¤íŠ¸ í¬í•¨)
        result = generate_image_base64(prompt=enhanced_prompt, model=GEMINI_PRO)
        if not result.get("ok"):
            return jsonify({"ok": False, "error": result.get("error", "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")})

        base64_image_data = result.get("base64")
        if not base64_image_data:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"})

        # ì´ë¯¸ì§€ ì²˜ë¦¬
        upload_dir = "uploads/thumbnails"
        os.makedirs(upload_dir, exist_ok=True)

        image_bytes = base64.b64decode(base64_image_data)
        img = Image.open(io.BytesIO(image_bytes))

        # ë¦¬ì‚¬ì´ì¦ˆ (1280x720 ê³ ì •)
        target_width, target_height = 1280, 720
        if img.width != target_width or img.height != target_height:
            img = img.resize((target_width, target_height), Image.LANCZOS)

        # RGB ë³€í™˜ í›„ JPEG ì €ì¥
        if img.mode == 'RGBA':
            background = Image.new('RGB', img.size, (255, 255, 255))
            background.paste(img, mask=img.split()[3])
            img = background
        elif img.mode != 'RGB':
            img = img.convert('RGB')

        filename = f"thumb_{session_id}.jpg"
        filepath = os.path.join(upload_dir, filename)
        img.save(filepath, 'JPEG', quality=90, optimize=True)

        file_size = os.path.getsize(filepath)
        print(f"[THUMBNAIL-AI] ì¸ë„¤ì¼ ì €ì¥: {filepath} ({file_size / 1024:.1f}KB)")

        return jsonify({
            "ok": True,
            "image_url": f"/uploads/thumbnails/{filename}"
        })

    except Exception as e:
        print(f"[THUMBNAIL-AI][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail-ai/generate-both', methods=['POST'])
@app.route('/api/thumbnail-ai/generate-all', methods=['POST'])
def api_thumbnail_ai_generate_both():
    """
    A/B/C 3ê°œì˜ ì¸ë„¤ì¼ì„ í•œ ë²ˆì— ìƒì„± (YouTube Test & Compareìš©)
    """
    try:
        import time
        import base64
        from concurrent.futures import ThreadPoolExecutor

        data = request.get_json() or {}
        prompts = data.get('prompts', {})
        session_id = data.get('session_id', '')

        if not prompts.get('A') or not prompts.get('B'):
            return jsonify({"ok": False, "error": "A/B í”„ë¡¬í”„íŠ¸ê°€ ëª¨ë‘ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        has_c = prompts.get('C') is not None
        print(f"[THUMBNAIL-AI] A/B/C ë™ì‹œ ìƒì„± - ì„¸ì…˜: {session_id}, Cí¬í•¨: {has_c}")

        def generate_single(variant, prompt_data):
            """ë‹¨ì¼ ì¸ë„¤ì¼ ìƒì„± (image ëª¨ë“ˆ ì‚¬ìš©)"""
            prompt = prompt_data.get('prompt', '')
            text_overlay = prompt_data.get('text_overlay', {})
            style = prompt_data.get('style', 'comic')

            main_text = text_overlay.get('main', '')
            sub_text = text_overlay.get('sub', '')

            text_instruction = ""
            if main_text:
                text_instruction = f"""
IMPORTANT TEXT OVERLAY:
- Add VERY LARGE, BOLD Korean text "{main_text}" on the LEFT side
- Text style: WHITE text with THICK BLACK outline
- Split into 2-4 short lines (3-6 chars each) for maximum impact
- Add comic emphasis marks (!! effects) if appropriate
"""
                if sub_text:
                    text_instruction += f'- Subtitle: "{sub_text}" (below main text)\n'

            enhanced_prompt = f"""Create a YouTube thumbnail (16:9 landscape).

{prompt}

{text_instruction}

Style: {style}, comic/illustration, eye-catching, high contrast"""

            try:
                # Gemini 3 Proë¡œ ì´ë¯¸ì§€ ìƒì„± (image ëª¨ë“ˆ ì‚¬ìš©)
                result = generate_image_base64(prompt=enhanced_prompt, model=GEMINI_PRO)
                if not result.get("ok"):
                    return {"variant": variant, "ok": False, "error": result.get("error", "ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨")}

                base64_image_data = result.get("base64")
                if not base64_image_data:
                    return {"variant": variant, "ok": False, "error": "ì´ë¯¸ì§€ ë°ì´í„° ì¶”ì¶œ ì‹¤íŒ¨"}

                # íŒŒì¼ ì €ì¥
                timestamp = int(time.time() * 1000)
                filename = f"thumbnail_ai_{session_id}_{variant}_{timestamp}.png"
                output_dir = os.path.join(os.path.dirname(__file__), 'outputs')
                os.makedirs(output_dir, exist_ok=True)
                filepath = os.path.join(output_dir, filename)

                with open(filepath, 'wb') as f:
                    f.write(base64.b64decode(base64_image_data))

                return {"variant": variant, "ok": True, "image_url": f'/output/{filename}'}

            except Exception as e:
                return {"variant": variant, "ok": False, "error": str(e)}

        # ë³‘ë ¬ ìƒì„± (A/B/C)
        results = {"A": None, "B": None, "C": None}
        max_workers = 3 if has_c else 2

        with ThreadPoolExecutor(max_workers=max_workers) as executor:
            futures = {
                executor.submit(generate_single, "A", prompts["A"]): "A",
                executor.submit(generate_single, "B", prompts["B"]): "B"
            }
            if has_c:
                futures[executor.submit(generate_single, "C", prompts["C"])] = "C"

            for future in as_completed(futures):
                result = future.result()
                results[result["variant"]] = result

        if not has_c:
            del results["C"]

        status_msg = f"A: {results['A'].get('ok')}, B: {results['B'].get('ok')}"
        if has_c:
            status_msg += f", C: {results['C'].get('ok')}"
        print(f"[THUMBNAIL-AI] A/B/C ìƒì„± ì™„ë£Œ - {status_msg}")

        return jsonify({
            "ok": True,
            "session_id": session_id,
            "results": results
        })

    except Exception as e:
        print(f"[THUMBNAIL-AI][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/thumbnail-ai/download-zip', methods=['POST'])
def api_thumbnail_ai_download_zip():
    """
    ìƒì„±ëœ ì¸ë„¤ì¼ë“¤ì„ ZIP íŒŒì¼ë¡œ ë‹¤ìš´ë¡œë“œ
    YouTube Test & Compareìš© 3ê°œ ì¸ë„¤ì¼
    """
    try:
        import zipfile
        from io import BytesIO

        data = request.get_json() or {}
        image_urls = data.get('image_urls', {})
        session_id = data.get('session_id', 'thumbnails')

        if not image_urls:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ URLì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # ZIP íŒŒì¼ ìƒì„±
        zip_buffer = BytesIO()
        output_dir = os.path.join(os.path.dirname(__file__), 'outputs')

        with zipfile.ZipFile(zip_buffer, 'w', zipfile.ZIP_DEFLATED) as zip_file:
            for variant, url in image_urls.items():
                if not url:
                    continue

                # /output/xxx.png â†’ outputs/xxx.png
                if url.startswith('/output/'):
                    filename = url.replace('/output/', '')
                    filepath = os.path.join(output_dir, filename)

                    if os.path.exists(filepath):
                        # íŒŒì¼ëª…ì„ ê°„ë‹¨í•˜ê²Œ ë³€ê²½ (thumbnail_A.png, thumbnail_B.png, thumbnail_C.png)
                        zip_filename = f"thumbnail_{variant}.png"
                        zip_file.write(filepath, zip_filename)
                        print(f"[THUMBNAIL-ZIP] Added: {zip_filename}")

        zip_buffer.seek(0)

        # ZIP íŒŒì¼ ì €ì¥
        zip_filename = f"thumbnails_{session_id}_{int(time.time())}.zip"
        zip_filepath = os.path.join(output_dir, zip_filename)

        with open(zip_filepath, 'wb') as f:
            f.write(zip_buffer.getvalue())

        print(f"[THUMBNAIL-ZIP] ZIP ìƒì„± ì™„ë£Œ: {zip_filename}")

        return jsonify({
            "ok": True,
            "zip_url": f"/output/{zip_filename}",
            "filename": zip_filename
        })

    except Exception as e:
        print(f"[THUMBNAIL-ZIP][ERROR] {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ===== Google Sheets ìë™í™” ì‹œìŠ¤í…œ (ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦) =====
from google.oauth2 import service_account
from googleapiclient.discovery import build

def get_sheets_service_account():
    """ì„œë¹„ìŠ¤ ê³„ì •ì„ ì‚¬ìš©í•˜ì—¬ Google Sheets API ì„œë¹„ìŠ¤ ê°ì²´ ë°˜í™˜"""
    try:
        # í™˜ê²½ë³€ìˆ˜ì—ì„œ ì„œë¹„ìŠ¤ ê³„ì • JSON ë¡œë“œ
        service_account_json = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
        if not service_account_json:
            print("[SHEETS] GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•ŠìŒ")
            return None

        # JSON ë¬¸ìì—´ì„ dictë¡œ íŒŒì‹±
        service_account_info = json.loads(service_account_json)

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì •ë³´ ìƒì„±
        credentials = service_account.Credentials.from_service_account_info(
            service_account_info,
            scopes=[
                'https://www.googleapis.com/auth/spreadsheets',
                'https://www.googleapis.com/auth/spreadsheets.readonly'
            ]
        )

        # Sheets API ì„œë¹„ìŠ¤ ë¹Œë“œ
        service = build('sheets', 'v4', credentials=credentials)
        return service
    except json.JSONDecodeError as e:
        print(f"[SHEETS] ì„œë¹„ìŠ¤ ê³„ì • JSON íŒŒì‹± ì‹¤íŒ¨: {e}")
        return None
    except Exception as e:
        print(f"[SHEETS] ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return None


def sheets_read_rows(service, sheet_id, range_name='Sheet1!A:H', max_retries=3):
    """
    Google Sheetsì—ì„œ í–‰ ì½ê¸° (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    ë°˜í™˜: [[row1_values], [row2_values], ...] ë˜ëŠ” None (API ì‹¤íŒ¨ ì‹œ)

    Note: ë¹ˆ ì‹œíŠ¸ëŠ” [] ë°˜í™˜, API ì‹¤íŒ¨ëŠ” None ë°˜í™˜ (êµ¬ë¶„ í•„ìš”)
    """
    import time as time_module

    last_error = None
    for attempt in range(max_retries):
        try:
            result = service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range=range_name
            ).execute()
            return result.get('values', [])
        except Exception as e:
            last_error = e
            error_str = str(e).lower()

            # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì¼ì‹œì  ì˜¤ë¥˜ íŒ¨í„´
            transient_errors = [
                'authentication backend unknown error',
                'backend error',
                'internal error',
                'service unavailable',
                'deadline exceeded',
                'connection reset',
                'connection refused',
                'timeout',
                '500',
                '502',
                '503',
                '504'
            ]

            is_transient = any(pattern in error_str for pattern in transient_errors)

            if is_transient and attempt < max_retries - 1:
                wait_time = (2 ** attempt) * 2  # 2ì´ˆ, 4ì´ˆ, 8ì´ˆ
                print(f"[SHEETS] ì¼ì‹œì  ì˜¤ë¥˜ ë°œìƒ (ì‹œë„ {attempt + 1}/{max_retries}), {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                time_module.sleep(wait_time)
            else:
                print(f"[SHEETS] ì½ê¸° ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if not is_transient:
                    break  # ì¬ì‹œë„ ë¶ˆê°€ëŠ¥í•œ ì˜¤ë¥˜ëŠ” ë°”ë¡œ ì¢…ë£Œ

    print(f"[SHEETS] ìµœì¢… ì½ê¸° ì‹¤íŒ¨ (ëª¨ë“  ì¬ì‹œë„ ì†Œì§„): {last_error}")
    return None  # API ì‹¤íŒ¨ ì‹œ None ë°˜í™˜ (ë¹ˆ ì‹œíŠ¸ []ì™€ êµ¬ë¶„)


def sheets_update_cell(service, sheet_id, cell_range, value, max_retries=3):
    """
    Google Sheets íŠ¹ì • ì…€ ì—…ë°ì´íŠ¸ (ì¬ì‹œë„ ë¡œì§ í¬í•¨)
    cell_range ì˜ˆì‹œ: 'Sheet1!A2' ë˜ëŠ” 'Sheet1!G2:H2'
    """
    import time as time_module

    body = {
        'values': [[value]] if not isinstance(value, list) else [value]
    }

    last_error = None
    for attempt in range(max_retries):
        try:
            service.spreadsheets().values().update(
                spreadsheetId=sheet_id,
                range=cell_range,
                valueInputOption='RAW',
                body=body
            ).execute()
            return True
        except Exception as e:
            last_error = e
            error_str = str(e).lower()

            # ì¬ì‹œë„ ê°€ëŠ¥í•œ ì¼ì‹œì  ì˜¤ë¥˜ íŒ¨í„´
            transient_errors = [
                'authentication backend unknown error',
                'backend error',
                'internal error',
                'service unavailable',
                'deadline exceeded',
                'connection reset',
                'connection refused',
                'timeout',
                '500',
                '502',
                '503',
                '504'
            ]

            is_transient = any(pattern in error_str for pattern in transient_errors)

            if is_transient and attempt < max_retries - 1:
                wait_time = (2 ** attempt) * 2  # 2ì´ˆ, 4ì´ˆ, 8ì´ˆ
                print(f"[SHEETS] ì…€ ì—…ë°ì´íŠ¸ ì¼ì‹œì  ì˜¤ë¥˜ (ì‹œë„ {attempt + 1}/{max_retries}), {wait_time}ì´ˆ í›„ ì¬ì‹œë„: {e}")
                time_module.sleep(wait_time)
            else:
                print(f"[SHEETS] ì…€ ì—…ë°ì´íŠ¸ ì‹¤íŒ¨ (ì‹œë„ {attempt + 1}/{max_retries}): {e}")
                if not is_transient:
                    break

    print(f"[SHEETS] ì…€ ì—…ë°ì´íŠ¸ ìµœì¢… ì‹¤íŒ¨: {cell_range} - {last_error}")
    return False


# ========== ì‹œíŠ¸ ë™ì  ë§¤í•‘ í•¨ìˆ˜ë“¤ ==========

def get_all_sheet_names(service, sheet_id):
    """
    Google Sheets íŒŒì¼ì˜ ëª¨ë“  ì‹œíŠ¸(íƒ­) ì´ë¦„ ê°€ì ¸ì˜¤ê¸°
    ì œì™¸ ëŒ€ìƒ:
    - _ì„¤ì •, _í…œí”Œë¦¿ ë“± ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì‹œì‘í•˜ëŠ” ì‹œíŠ¸
    - SHORTS (ë³„ë„ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
    - BIBLE (ë³„ë„ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)

    ë°˜í™˜: ['ì±„ë„A', 'ì±„ë„B', ...] ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    # ë©”ì¸ íŒŒì´í”„ë¼ì¸ì—ì„œ ì œì™¸í•  ì‹œíŠ¸ ëª©ë¡ (ë³„ë„ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©)
    EXCLUDED_SHEETS = {'SHORTS', 'BIBLE'}

    try:
        spreadsheet = service.spreadsheets().get(spreadsheetId=sheet_id).execute()
        sheets = spreadsheet.get('sheets', [])

        sheet_names = []
        for sheet in sheets:
            name = sheet.get('properties', {}).get('title', '')
            # ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì‹œì‘í•˜ëŠ” ì‹œíŠ¸ëŠ” ì„¤ì •/í…œí”Œë¦¿ìš©ìœ¼ë¡œ ì œì™¸
            # SHORTS, BIBLEì€ ë³„ë„ íŒŒì´í”„ë¼ì¸ ì‚¬ìš©
            if name and not name.startswith('_') and name not in EXCLUDED_SHEETS:
                sheet_names.append(name)

        print(f"[SHEETS] ë°œê²¬ëœ ì±„ë„ ì‹œíŠ¸: {sheet_names}")
        return sheet_names
    except Exception as e:
        print(f"[SHEETS] ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return None


def get_column_mapping(headers):
    """
    í—¤ë” ì´ë¦„ìœ¼ë¡œ ì—´ ì¸ë±ìŠ¤/ë¬¸ì ë§¤í•‘ ìƒì„±

    headers: ['ìƒíƒœ', 'ê³µê°œì„¤ì •', 'í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID', ...]
    ë°˜í™˜: {
        'ìƒíƒœ': {'index': 0, 'letter': 'A'},
        'ê³µê°œì„¤ì •': {'index': 1, 'letter': 'B'},
        ...
    }
    """
    mapping = {}
    for idx, header in enumerate(headers):
        if header:  # ë¹ˆ í—¤ë” ë¬´ì‹œ
            # ì—´ ë¬¸ì ê³„ì‚° (0->A, 1->B, ..., 25->Z, 26->AA, ...)
            col_letter = ''
            temp_idx = idx
            while True:
                col_letter = chr(ord('A') + temp_idx % 26) + col_letter
                temp_idx = temp_idx // 26 - 1
                if temp_idx < 0:
                    break

            mapping[header] = {
                'index': idx,
                'letter': col_letter
            }

    return mapping


def get_sheet_channel_id(rows):
    """
    ì‹œíŠ¸ì˜ 1í–‰ì—ì„œ ì±„ë„ ID ì¶”ì¶œ

    ì‹œíŠ¸ êµ¬ì¡°:
    - A1: 'ì±„ë„ID'
    - B1: 'UCxxxx...'

    ë°˜í™˜: ì±„ë„ ID ë¬¸ìì—´ ë˜ëŠ” None
    """
    if not rows or len(rows) < 1:
        return None

    first_row = rows[0]
    if len(first_row) >= 2 and first_row[0] == 'ì±„ë„ID':
        return first_row[1].strip() if first_row[1] else None

    return None


def get_sheet_account_email(rows):
    """
    ì‹œíŠ¸ì˜ 1í–‰ì—ì„œ ê³„ì • ì´ë©”ì¼ ì¶”ì¶œ

    ì‹œíŠ¸ êµ¬ì¡°:
    - C1: 'ê³„ì •'
    - D1: 'user@gmail.com'

    ë°˜í™˜: ì´ë©”ì¼ ë¬¸ìì—´ ë˜ëŠ” None
    """
    if not rows or len(rows) < 1:
        return None

    first_row = rows[0]
    if len(first_row) >= 4 and first_row[2] == 'ê³„ì •':
        return first_row[3].strip() if first_row[3] else None

    return None


def get_row_value(row, col_map, header_name, default=''):
    """
    í—¤ë” ì´ë¦„ìœ¼ë¡œ í–‰ì—ì„œ ê°’ ê°€ì ¸ì˜¤ê¸°

    row: ë°ì´í„° í–‰ ë¦¬ìŠ¤íŠ¸
    col_map: get_column_mapping()ì˜ ë°˜í™˜ê°’
    header_name: ì—´ ì´ë¦„ (ì˜ˆ: 'ìƒíƒœ', 'ëŒ€ë³¸')
    default: ê°’ì´ ì—†ì„ ë•Œ ê¸°ë³¸ê°’
    """
    if header_name not in col_map:
        return default

    idx = col_map[header_name]['index']
    if idx < len(row):
        return row[idx] if row[idx] else default
    return default


def sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, header_name, value):
    """
    í—¤ë” ì´ë¦„ìœ¼ë¡œ íŠ¹ì • ì…€ ì—…ë°ì´íŠ¸

    sheet_name: ì‹œíŠ¸ ì´ë¦„ (ì˜ˆ: 'ë‰´ìŠ¤ì±„ë„')
    row_num: í–‰ ë²ˆí˜¸ (1-based)
    col_map: get_column_mapping()ì˜ ë°˜í™˜ê°’
    header_name: ì—´ ì´ë¦„ (ì˜ˆ: 'ìƒíƒœ')
    value: ì„¤ì •í•  ê°’
    """
    if header_name not in col_map:
        print(f"[SHEETS] ê²½ê³ : í—¤ë” '{header_name}'ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ")
        return False

    col_letter = col_map[header_name]['letter']
    cell_range = f"'{sheet_name}'!{col_letter}{row_num}"

    return sheets_update_cell(service, sheet_id, cell_range, value)


# ========== CTR ìë™í™” ì„¤ì • ==========
CTR_THRESHOLD = 3.0  # CTR 3% ë¯¸ë§Œì´ë©´ ì œëª© ë³€ê²½
CTR_CHECK_DAYS = 7   # ì—…ë¡œë“œ í›„ 7ì¼ í›„ë¶€í„° CTR ì²´í¬


def get_video_ctr_from_analytics(youtube_analytics, channel_id, video_id):
    """
    YouTube Analytics APIë¡œ ì˜ìƒì˜ CTR (í´ë¦­ë¥ ) ë° ì¡°íšŒìˆ˜/êµ¬ë…ì ë°ì´í„° ì¡°íšŒ

    ë°˜í™˜: {
        'ctr': 4.5,  # í´ë¦­ë¥  (%)
        'impressions': 10000,  # ë…¸ì¶œ ìˆ˜
        'views': 450,  # ì´ ì¡°íšŒ ìˆ˜ (28ì¼)
        'views_today': 50,  # ì˜¤ëŠ˜ ì¡°íšŒ ìˆ˜
        'views_yesterday': 45,  # ì–´ì œ ì¡°íšŒ ìˆ˜
        'subscribers_gained': 10,  # êµ¬ë…ì ì¦ê°€
        'subscribers_lost': 2  # êµ¬ë…ì ê°ì†Œ
    } ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    from datetime import datetime, timedelta

    try:
        # ìµœê·¼ 28ì¼ê°„ ë°ì´í„° ì¡°íšŒ (ì¡°íšŒìˆ˜, êµ¬ë…ì ë³€ë™)
        # ì°¸ê³ : impressions, impressionClickThroughRateëŠ” video dimensionê³¼ í•¨ê»˜ ì‚¬ìš© ë¶ˆê°€
        end_date = datetime.now().strftime('%Y-%m-%d')
        start_date = (datetime.now() - timedelta(days=28)).strftime('%Y-%m-%d')

        response = youtube_analytics.reports().query(
            ids=f'channel=={channel_id}',
            startDate=start_date,
            endDate=end_date,
            metrics='views,subscribersGained,subscribersLost',
            dimensions='video',
            filters=f'video=={video_id}'
        ).execute()

        result = {
            'views': 0,
            'impressions': 0,  # Analytics APIì—ì„œ videoë³„ ì¡°íšŒ ë¶ˆê°€
            'ctr': 0,  # Analytics APIì—ì„œ videoë³„ ì¡°íšŒ ë¶ˆê°€
            'subscribers_gained': 0,
            'subscribers_lost': 0,
            'views_today': 0,
            'views_yesterday': 0
        }

        rows = response.get('rows', [])
        if rows and len(rows) > 0:
            # [video_id, views, subscribersGained, subscribersLost]
            row = rows[0]
            result['views'] = int(row[1]) if len(row) > 1 else 0
            result['subscribers_gained'] = int(row[2]) if len(row) > 2 else 0
            result['subscribers_lost'] = int(row[3]) if len(row) > 3 else 0

        # ì˜¤ëŠ˜ê³¼ ì–´ì œ ì¡°íšŒìˆ˜ ë³„ë„ ì¡°íšŒ (ì¼ë³„ ë¹„êµìš©)
        try:
            today = datetime.now().strftime('%Y-%m-%d')
            yesterday = (datetime.now() - timedelta(days=1)).strftime('%Y-%m-%d')

            # ì˜¤ëŠ˜ ì¡°íšŒìˆ˜
            today_response = youtube_analytics.reports().query(
                ids=f'channel=={channel_id}',
                startDate=today,
                endDate=today,
                metrics='views',
                dimensions='video',
                filters=f'video=={video_id}'
            ).execute()
            today_rows = today_response.get('rows', [])
            if today_rows and len(today_rows) > 0:
                result['views_today'] = int(today_rows[0][1]) if len(today_rows[0]) > 1 else 0

            # ì–´ì œ ì¡°íšŒìˆ˜
            yesterday_response = youtube_analytics.reports().query(
                ids=f'channel=={channel_id}',
                startDate=yesterday,
                endDate=yesterday,
                metrics='views',
                dimensions='video',
                filters=f'video=={video_id}'
            ).execute()
            yesterday_rows = yesterday_response.get('rows', [])
            if yesterday_rows and len(yesterday_rows) > 0:
                result['views_yesterday'] = int(yesterday_rows[0][1]) if len(yesterday_rows[0]) > 1 else 0

        except Exception as e:
            print(f"[CTR] ì¼ë³„ ì¡°íšŒìˆ˜ ì¡°íšŒ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {e}")

        return result if result['views'] > 0 or result['impressions'] > 0 else None
    except Exception as e:
        print(f"[CTR] Analytics API ì˜¤ë¥˜: {e}")
        return None


def get_channel_subscriber_count(youtube, channel_id):
    """
    YouTube Data APIë¡œ ì±„ë„ì˜ ì´ êµ¬ë…ì ìˆ˜ ì¡°íšŒ

    ë°˜í™˜: êµ¬ë…ì ìˆ˜ (int) ë˜ëŠ” None (ì‹¤íŒ¨ ì‹œ)
    """
    try:
        response = youtube.channels().list(
            part='statistics',
            id=channel_id
        ).execute()

        items = response.get('items', [])
        if items and len(items) > 0:
            stats = items[0].get('statistics', {})
            subscriber_count = stats.get('subscriberCount', '0')
            return int(subscriber_count)

        return None
    except Exception as e:
        print(f"[CTR] ì±„ë„ êµ¬ë…ì ìˆ˜ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None


def get_video_stats_from_data_api(youtube, video_id):
    """
    YouTube Data API v3ë¡œ ì˜ìƒì˜ ì¡°íšŒìˆ˜/ì¢‹ì•„ìš” ë“± ì¡°íšŒ (ê³µê°œ ì •ë³´)

    Analytics APIê°€ ê¶Œí•œ ë¬¸ì œë¡œ ì‹¤íŒ¨í•  ë•Œ fallbackìœ¼ë¡œ ì‚¬ìš©

    ë°˜í™˜: {'views': 123, 'likes': 10, 'comments': 5} ë˜ëŠ” None
    """
    try:
        response = youtube.videos().list(
            part='statistics',
            id=video_id
        ).execute()

        items = response.get('items', [])
        if items and len(items) > 0:
            stats = items[0].get('statistics', {})
            return {
                'views': int(stats.get('viewCount', 0)),
                'likes': int(stats.get('likeCount', 0)),
                'comments': int(stats.get('commentCount', 0))
            }
        return None
    except Exception as e:
        print(f"[CTR] Data API ì˜ìƒ í†µê³„ ì¡°íšŒ ì˜¤ë¥˜: {e}")
        return None


def extract_video_id_from_url(url):
    """YouTube URLì—ì„œ video ID ì¶”ì¶œ"""
    import re

    if not url:
        return None

    # ë‹¤ì–‘í•œ YouTube URL í˜•ì‹ ì§€ì›
    patterns = [
        r'(?:youtube\.com/watch\?v=|youtu\.be/|youtube\.com/embed/)([a-zA-Z0-9_-]{11})',
        r'(?:youtube\.com/shorts/)([a-zA-Z0-9_-]{11})'
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)

    return None


# ========== TubeLens í†µí•© ê¸°ëŠ¥ (ìë™í™” íŒŒì´í”„ë¼ì¸ìš©) ==========

# ì±„ë„ë³„ ìµœì  ì—…ë¡œë“œ ì‹œê°„ ìºì‹œ (ë©”ëª¨ë¦¬ + íŒŒì¼)
_channel_optimal_time_cache = {}


def analyze_channel_best_time(channel_id: str) -> dict:
    """
    ì±„ë„ì˜ ì‹¤ì œ ì—…ë¡œë“œ ì„±ê³¼ ë°ì´í„°ë¥¼ ë¶„ì„í•˜ì—¬ ìµœì  ì‹œê°„ëŒ€ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    YouTube APIë¥¼ í˜¸ì¶œí•˜ì—¬ ìµœê·¼ 50ê°œ ì˜ìƒì˜ ì„±ê³¼ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
    {
        "bestTime": "ì €ë… (18-24ì‹œ)",
        "bestHour": 19,  # ì¶”ì²œ ì‹œê°„ (ì •ê°)
        "bestDay": "ìˆ˜",
        "analyzed": True
    }
    """
    import os
    import json

    # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
    if channel_id in _channel_optimal_time_cache:
        cached = _channel_optimal_time_cache[channel_id]
        print(f"[TUBELENS] ì±„ë„ ìµœì  ì‹œê°„ ìºì‹œ íˆíŠ¸: {channel_id} -> {cached.get('bestHour', 19)}:00")
        return cached

    # 2. íŒŒì¼ ìºì‹œ í™•ì¸ (7ì¼ê°„ ìœ íš¨)
    cache_file = f"/tmp/tubelens_cache_{channel_id}.json"
    try:
        if os.path.exists(cache_file):
            from datetime import datetime, timedelta
            file_mtime = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_mtime < timedelta(days=7):
                with open(cache_file, 'r') as f:
                    cached = json.load(f)
                    _channel_optimal_time_cache[channel_id] = cached
                    print(f"[TUBELENS] íŒŒì¼ ìºì‹œ ë¡œë“œ: {channel_id} -> {cached.get('bestHour', 19)}:00")
                    return cached
    except Exception as e:
        print(f"[TUBELENS] ìºì‹œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    # 3. YouTube APIë¡œ ì‹¤ì œ ë¶„ì„
    try:
        import requests
        # TubeLens API ë‚´ë¶€ í˜¸ì¶œ
        base_url = os.environ.get('BASE_URL', 'http://localhost:5002')
        api_key = os.environ.get('YOUTUBE_API_KEY', '')

        if not api_key:
            print(f"[TUBELENS] YouTube API í‚¤ ì—†ìŒ, ê¸°ë³¸ê°’ ì‚¬ìš©")
            return {"bestHour": 19, "bestTime": "ì €ë…", "analyzed": False}

        resp = requests.post(
            f"{base_url}/api/tubelens/upload-pattern",
            json={"channelId": channel_id, "apiKeys": [api_key]},
            timeout=30
        )

        if resp.status_code == 200:
            data = resp.json()
            if data.get("success"):
                pattern_data = data.get("data", {})
                time_pattern = pattern_data.get("timePattern", {})
                best_time_str = time_pattern.get("bestTime", "ì €ë… (18-24ì‹œ)")

                # ì‹œê°„ëŒ€ ë¬¸ìì—´ì„ ì‹œê°„ìœ¼ë¡œ ë³€í™˜
                time_mapping = {
                    "ìƒˆë²½ (0-6ì‹œ)": 5,
                    "ì˜¤ì „ (6-12ì‹œ)": 9,
                    "ì˜¤í›„ (12-18ì‹œ)": 15,
                    "ì €ë… (18-24ì‹œ)": 20,
                    "ìƒˆë²½": 5,
                    "ì˜¤ì „": 9,
                    "ì˜¤í›„": 15,
                    "ì €ë…": 20,
                }
                best_hour = time_mapping.get(best_time_str, 19)

                result = {
                    "bestTime": best_time_str,
                    "bestHour": best_hour,
                    "bestDay": pattern_data.get("dayPattern", {}).get("bestDay", ""),
                    "analyzed": True
                }

                # ìºì‹œ ì €ì¥
                _channel_optimal_time_cache[channel_id] = result
                try:
                    with open(cache_file, 'w') as f:
                        json.dump(result, f)
                except:
                    pass

                print(f"[TUBELENS] ì±„ë„ ë¶„ì„ ì™„ë£Œ: {channel_id} -> ìµœì  ì‹œê°„: {best_hour}:00 ({best_time_str})")
                return result

    except Exception as e:
        print(f"[TUBELENS] ì±„ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")

    # 4. ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ê°’
    return {"bestHour": 19, "bestTime": "ì €ë…", "analyzed": False}


def get_optimal_publish_time(channel_id: str, date_str: str, category: str = "") -> str:
    """
    ë‚ ì§œë§Œ ì…ë ¥ë˜ë©´ ìµœì  ì—…ë¡œë“œ ì‹œê°„ì„ ìë™ ì„¤ì •í•©ë‹ˆë‹¤.

    ìš°ì„ ìˆœìœ„:
    1. ì±„ë„ ë°ì´í„° ë¶„ì„ ê²°ê³¼ (TubeLens API)
    2. ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ê°’ (news: 08:00, story: 19:00)

    ì…ë ¥: "2024-12-10" ë˜ëŠ” "12/10"
    ì¶œë ¥: "2024-12-10 20:00" (ì±„ë„ ë¶„ì„ ê²°ê³¼) ë˜ëŠ” "2024-12-10 08:00" (ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬)
    """
    from datetime import datetime

    date_str = str(date_str).strip()
    category = str(category).strip().lower() if category else ""

    # ì´ë¯¸ ì‹œê°„ì´ í¬í•¨ë˜ì–´ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ë°˜í™˜
    if ':' in date_str:
        return date_str

    # 1. ì±„ë„ ë°ì´í„° ë¶„ì„ìœ¼ë¡œ ìµœì  ì‹œê°„ ê²°ì •
    optimal_hour = 19  # ê¸°ë³¸ê°’
    analysis_source = "ê¸°ë³¸ê°’"

    if channel_id:
        try:
            analysis = analyze_channel_best_time(channel_id)
            if analysis.get("analyzed"):
                optimal_hour = analysis.get("bestHour", 19)
                analysis_source = f"ì±„ë„ë¶„ì„({analysis.get('bestTime', '')})"
        except Exception as e:
            print(f"[TUBELENS] ì±„ë„ ë¶„ì„ ì‹¤íŒ¨, ì¹´í…Œê³ ë¦¬ ê¸°ë³¸ê°’ ì‚¬ìš©: {e}")

    # 2. ì±„ë„ ë¶„ì„ ì‹¤íŒ¨ ì‹œ ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ê°’ ì‚¬ìš©
    if analysis_source == "ê¸°ë³¸ê°’":
        category_optimal_hours = {
            "news": 8,       # ë‰´ìŠ¤: ì•„ì¹¨ 8ì‹œ
            "ë‰´ìŠ¤": 8,
            "story": 19,     # ìŠ¤í† ë¦¬: ì €ë… 7ì‹œ
            "drama": 19,
            "ë“œë¼ë§ˆ": 19,
        }
        if category in category_optimal_hours:
            optimal_hour = category_optimal_hours[category]
            analysis_source = f"ì¹´í…Œê³ ë¦¬({category})"

    optimal_time = f"{optimal_hour:02d}:00"

    # ë‚ ì§œë§Œ ìˆëŠ” ê²½ìš° íŒŒì‹±
    date_only_formats = [
        "%Y-%m-%d",
        "%Y/%m/%d",
        "%m/%d",
        "%m-%d",
    ]

    for fmt in date_only_formats:
        try:
            parsed = datetime.strptime(date_str, fmt)
            if parsed.year == 1900:
                parsed = parsed.replace(year=datetime.now().year)

            result = parsed.strftime("%Y-%m-%d") + f" {optimal_time}"
            print(f"[TUBELENS] ìµœì  ì‹œê°„ ì„¤ì •: {date_str} -> {result} (KST, {analysis_source})")
            return result
        except ValueError:
            continue

    return date_str


# ì±„ë„ë³„ ì¸ë„¤ì¼/ì‡¼ì¸  ìŠ¤íƒ€ì¼ ìºì‹œ
_channel_thumbnail_style_cache = {}
_channel_shorts_style_cache = {}


def analyze_channel_thumbnail_style(channel_id: str) -> dict:
    """
    ì±„ë„ì˜ ë¡±í¼ ì˜ìƒ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    ìµœê·¼ ì„±ê³¼ ì¢‹ì€ ì˜ìƒë“¤ì˜ ì¸ë„¤ì¼ íŒ¨í„´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
    {
        "common_elements": ["ì¶©ê²© í‘œì •", "ë¹¨ê°„ í…ìŠ¤íŠ¸", ...],
        "color_patterns": ["ë…¸ë€ìƒ‰ ê°•ì¡°", "ê²€ì • ë°°ê²½", ...],
        "text_usage": ["ì§§ì€ ì„íŒ©íŠ¸ ë¬¸êµ¬", "ìˆ«ì ê°•ì¡°", ...],
        "composition": ["ì¸ë¬¼ í´ë¡œì¦ˆì—…", "ì™¼ìª½ ë°°ì¹˜", ...],
        "summary": "ì´ ì±„ë„ì€ ì¶©ê²©ì ì¸ í‘œì •ê³¼ ë…¸ë€ìƒ‰ í…ìŠ¤íŠ¸ë¥¼ ì£¼ë¡œ ì‚¬ìš©...",
        "analyzed": True
    }
    """
    import os
    import json

    # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
    if channel_id in _channel_thumbnail_style_cache:
        cached = _channel_thumbnail_style_cache[channel_id]
        print(f"[TUBELENS] ë¡±í¼ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ ìºì‹œ íˆíŠ¸: {channel_id}")
        return cached

    # 2. íŒŒì¼ ìºì‹œ í™•ì¸ (7ì¼ê°„ ìœ íš¨)
    cache_file = f"/tmp/tubelens_thumbnail_{channel_id}.json"
    try:
        if os.path.exists(cache_file):
            from datetime import datetime, timedelta
            file_mtime = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_mtime < timedelta(days=7):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached = json.load(f)
                    _channel_thumbnail_style_cache[channel_id] = cached
                    print(f"[TUBELENS] ë¡±í¼ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ íŒŒì¼ ìºì‹œ ë¡œë“œ: {channel_id}")
                    return cached
    except Exception as e:
        print(f"[TUBELENS] ì¸ë„¤ì¼ ìºì‹œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    # 3. YouTube API + TubeLens ë¶„ì„
    try:
        import requests
        base_url = os.environ.get('BASE_URL', 'http://localhost:5002')
        api_key = os.environ.get('YOUTUBE_API_KEY', '')

        if not api_key:
            print(f"[TUBELENS] YouTube API í‚¤ ì—†ìŒ, ê¸°ë³¸ ìŠ¤íƒ€ì¼ ì‚¬ìš©")
            return {"analyzed": False, "summary": "ì±„ë„ ë¶„ì„ ë¶ˆê°€"}

        # ì±„ë„ì˜ ìµœê·¼ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° (ë¡±í¼ë§Œ, ì‡¼ì¸  ì œì™¸)
        # ë¨¼ì € ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        channel_resp = requests.get(
            f"https://www.googleapis.com/youtube/v3/channels",
            params={
                "part": "contentDetails",
                "id": channel_id,
                "key": api_key
            },
            timeout=10
        )

        if channel_resp.status_code != 200:
            print(f"[TUBELENS] ì±„ë„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨: {channel_resp.status_code}")
            return {"analyzed": False, "summary": "ì±„ë„ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨"}

        channel_data = channel_resp.json()
        items = channel_data.get("items", [])
        if not items:
            return {"analyzed": False, "summary": "ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŒ"}

        upload_playlist = items[0].get("contentDetails", {}).get("relatedPlaylists", {}).get("uploads", "")
        if not upload_playlist:
            return {"analyzed": False, "summary": "ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì—†ìŒ"}

        # ìµœê·¼ ì˜ìƒ 50ê°œ ê°€ì ¸ì˜¤ê¸°
        playlist_resp = requests.get(
            f"https://www.googleapis.com/youtube/v3/playlistItems",
            params={
                "part": "contentDetails",
                "playlistId": upload_playlist,
                "maxResults": 50,
                "key": api_key
            },
            timeout=10
        )

        if playlist_resp.status_code != 200:
            return {"analyzed": False, "summary": "í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¡°íšŒ ì‹¤íŒ¨"}

        video_ids = [item["contentDetails"]["videoId"] for item in playlist_resp.json().get("items", [])]
        if not video_ids:
            return {"analyzed": False, "summary": "ì˜ìƒ ì—†ìŒ"}

        # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ë¡±í¼ë§Œ í•„í„°ë§)
        videos_resp = requests.get(
            f"https://www.googleapis.com/youtube/v3/videos",
            params={
                "part": "snippet,statistics,contentDetails",
                "id": ",".join(video_ids[:25]),  # ìµœëŒ€ 25ê°œ
                "key": api_key
            },
            timeout=10
        )

        if videos_resp.status_code != 200:
            return {"analyzed": False, "summary": "ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨"}

        # ë¡±í¼ë§Œ í•„í„°ë§ (60ì´ˆ ì´ˆê³¼) + ì¡°íšŒìˆ˜ ìƒìœ„ 10ê°œ
        longform_videos = []
        for vid in videos_resp.json().get("items", []):
            duration = vid.get("contentDetails", {}).get("duration", "PT0S")
            # ISO 8601 duration íŒŒì‹± (ê°„ë‹¨ ë²„ì „)
            import re
            match = re.search(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
            if match:
                hours = int(match.group(1) or 0)
                minutes = int(match.group(2) or 0)
                seconds = int(match.group(3) or 0)
                total_seconds = hours * 3600 + minutes * 60 + seconds
                if total_seconds > 60:  # ì‡¼ì¸  ì œì™¸ (60ì´ˆ ì´ˆê³¼ë§Œ)
                    view_count = int(vid.get("statistics", {}).get("viewCount", 0))
                    longform_videos.append({
                        "title": vid.get("snippet", {}).get("title", ""),
                        "thumbnail": vid.get("snippet", {}).get("thumbnails", {}).get("high", {}).get("url", ""),
                        "viewCount": view_count
                    })

        # ì¡°íšŒìˆ˜ ìƒìœ„ 10ê°œ ì„ íƒ
        longform_videos.sort(key=lambda x: x["viewCount"], reverse=True)
        top_videos = longform_videos[:10]

        if len(top_videos) < 3:
            return {"analyzed": False, "summary": "ë¶„ì„í•  ë¡±í¼ ì˜ìƒì´ ë¶€ì¡±í•¨"}

        # TubeLens ì¸ë„¤ì¼ ë¶„ì„ API í˜¸ì¶œ
        analysis_resp = requests.post(
            f"{base_url}/api/tubelens/analyze-thumbnails",
            json={"videos": top_videos},
            timeout=60
        )

        if analysis_resp.status_code == 200:
            analysis_data = analysis_resp.json()
            if analysis_data.get("success"):
                result = analysis_data.get("data", {})
                result["analyzed"] = True
                result["video_count"] = len(top_videos)

                # ìºì‹œ ì €ì¥
                _channel_thumbnail_style_cache[channel_id] = result
                try:
                    with open(cache_file, 'w', encoding='utf-8') as f:
                        json.dump(result, f, ensure_ascii=False)
                except:
                    pass

                print(f"[TUBELENS] ë¡±í¼ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ ë¶„ì„ ì™„ë£Œ: {channel_id} ({len(top_videos)}ê°œ ì˜ìƒ)")
                return result

    except Exception as e:
        print(f"[TUBELENS] ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")

    return {"analyzed": False, "summary": "ë¶„ì„ ì‹¤íŒ¨"}


def analyze_channel_shorts_style(channel_id: str) -> dict:
    """
    ì±„ë„ì˜ ì‡¼ì¸  ì˜ìƒ ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•©ë‹ˆë‹¤.
    ì„¸ë¡œ ì˜ìƒì˜ í…œí”Œë¦¿/êµ¬ì„± íŒ¨í„´ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    ë°˜í™˜ê°’:
    {
        "common_elements": ["í›„í‚¹ í…ìŠ¤íŠ¸ ìƒë‹¨", "ìë§‰ í•˜ë‹¨", ...],
        "text_style": ["í° ê¸€ì”¨", "ë…¸ë€ìƒ‰", ...],
        "hook_patterns": ["ì§ˆë¬¸í˜•", "ì¶©ê²© ìˆ«ì", ...],
        "summary": "ì´ ì±„ë„ì˜ ì‡¼ì¸ ëŠ” ìƒë‹¨ì— í›„í‚¹ í…ìŠ¤íŠ¸...",
        "analyzed": True
    }
    """
    import os
    import json

    # 1. ë©”ëª¨ë¦¬ ìºì‹œ í™•ì¸
    if channel_id in _channel_shorts_style_cache:
        cached = _channel_shorts_style_cache[channel_id]
        print(f"[TUBELENS] ì‡¼ì¸  ìŠ¤íƒ€ì¼ ìºì‹œ íˆíŠ¸: {channel_id}")
        return cached

    # 2. íŒŒì¼ ìºì‹œ í™•ì¸ (7ì¼ê°„ ìœ íš¨)
    cache_file = f"/tmp/tubelens_shorts_{channel_id}.json"
    try:
        if os.path.exists(cache_file):
            from datetime import datetime, timedelta
            file_mtime = datetime.fromtimestamp(os.path.getmtime(cache_file))
            if datetime.now() - file_mtime < timedelta(days=7):
                with open(cache_file, 'r', encoding='utf-8') as f:
                    cached = json.load(f)
                    _channel_shorts_style_cache[channel_id] = cached
                    print(f"[TUBELENS] ì‡¼ì¸  ìŠ¤íƒ€ì¼ íŒŒì¼ ìºì‹œ ë¡œë“œ: {channel_id}")
                    return cached
    except Exception as e:
        print(f"[TUBELENS] ì‡¼ì¸  ìºì‹œ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")

    # 3. YouTube APIë¡œ ì‡¼ì¸  ê²€ìƒ‰
    try:
        import requests
        api_key = os.environ.get('YOUTUBE_API_KEY', '')
        base_url = os.environ.get('BASE_URL', 'http://localhost:5002')

        if not api_key:
            return {"analyzed": False, "summary": "API í‚¤ ì—†ìŒ"}

        # ì±„ë„ì˜ ì‡¼ì¸  ê²€ìƒ‰ (ì œëª©ì— #shorts ë˜ëŠ” ì§§ì€ ì˜ìƒ)
        search_resp = requests.get(
            f"https://www.googleapis.com/youtube/v3/search",
            params={
                "part": "snippet",
                "channelId": channel_id,
                "type": "video",
                "videoDuration": "short",  # 4ë¶„ ë¯¸ë§Œ
                "maxResults": 25,
                "order": "viewCount",
                "key": api_key
            },
            timeout=10
        )

        if search_resp.status_code != 200:
            return {"analyzed": False, "summary": "ì‡¼ì¸  ê²€ìƒ‰ ì‹¤íŒ¨"}

        video_ids = [item["id"]["videoId"] for item in search_resp.json().get("items", []) if "videoId" in item.get("id", {})]

        if not video_ids:
            return {"analyzed": False, "summary": "ì‡¼ì¸  ì—†ìŒ"}

        # ì˜ìƒ ìƒì„¸ ì •ë³´
        videos_resp = requests.get(
            f"https://www.googleapis.com/youtube/v3/videos",
            params={
                "part": "snippet,statistics,contentDetails",
                "id": ",".join(video_ids[:15]),
                "key": api_key
            },
            timeout=10
        )

        if videos_resp.status_code != 200:
            return {"analyzed": False, "summary": "ì˜ìƒ ì •ë³´ ì¡°íšŒ ì‹¤íŒ¨"}

        # 60ì´ˆ ì´í•˜ë§Œ í•„í„°ë§ (ì§„ì§œ ì‡¼ì¸ )
        shorts_videos = []
        for vid in videos_resp.json().get("items", []):
            duration = vid.get("contentDetails", {}).get("duration", "PT0S")
            import re
            match = re.search(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
            if match:
                hours = int(match.group(1) or 0)
                minutes = int(match.group(2) or 0)
                seconds = int(match.group(3) or 0)
                total_seconds = hours * 3600 + minutes * 60 + seconds
                if total_seconds <= 60:  # ì‡¼ì¸ ë§Œ (60ì´ˆ ì´í•˜)
                    view_count = int(vid.get("statistics", {}).get("viewCount", 0))
                    shorts_videos.append({
                        "title": vid.get("snippet", {}).get("title", ""),
                        "thumbnail": vid.get("snippet", {}).get("thumbnails", {}).get("high", {}).get("url", ""),
                        "viewCount": view_count
                    })

        # ì¡°íšŒìˆ˜ ìƒìœ„ ì„ íƒ
        shorts_videos.sort(key=lambda x: x["viewCount"], reverse=True)
        top_shorts = shorts_videos[:8]

        if len(top_shorts) < 2:
            return {"analyzed": False, "summary": "ë¶„ì„í•  ì‡¼ì¸ ê°€ ë¶€ì¡±í•¨"}

        # ì‡¼ì¸  ì¸ë„¤ì¼ ë¶„ì„ (GPT-5.1 Responses API ì‚¬ìš©)
        from openai import OpenAI
        client = OpenAI()

        # GPT-5.1 Responses APIìš© input êµ¬ì„±
        system_prompt = "ë‹¹ì‹ ì€ YouTube Shorts ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì„±ê³µì ì¸ ì‡¼ì¸ ì˜ ì‹œê°ì  íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."

        user_content = [
            {"type": "input_text", "text": """ë‹¤ìŒ YouTube Shorts ì¸ë„¤ì¼ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ì‡¼ì¸ ì˜ íŠ¹ì„± (ì„¸ë¡œ 9:16)ì„ ê³ ë ¤í•˜ì—¬ ë‹¤ìŒì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
1. í›„í‚¹ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ (ìƒë‹¨ ë°°ì¹˜, ê¸€ì”¨ í¬ê¸°, ìƒ‰ìƒ)
2. ìë§‰ ìŠ¤íƒ€ì¼
3. ì¸ë¬¼/ì´ë¯¸ì§€ ë°°ì¹˜
4. ì „ì²´ì ì¸ í…œí”Œë¦¿ íŒ¨í„´

JSON í˜•ì‹ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”:
{
  "hook_text_style": ["ìŠ¤íƒ€ì¼1", "ìŠ¤íƒ€ì¼2"],
  "text_colors": ["ìƒ‰ìƒ1", "ìƒ‰ìƒ2"],
  "layout_pattern": ["íŒ¨í„´1", "íŒ¨í„´2"],
  "common_elements": ["ìš”ì†Œ1", "ìš”ì†Œ2"],
  "recommendations": ["ì¶”ì²œ1", "ì¶”ì²œ2"],
  "summary": "ì „ì²´ ìš”ì•½ (2ë¬¸ì¥)"
}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""}
        ]

        for i, v in enumerate(top_shorts[:6]):
            thumbnail_url = v.get("thumbnail", "")
            if thumbnail_url:
                user_content.append({"type": "input_image", "image_url": thumbnail_url})
                user_content.append({"type": "input_text", "text": f"[ì‡¼ì¸  {i+1}] {v.get('title', '')} (ì¡°íšŒìˆ˜: {v.get('viewCount', 0):,})"})

        response = client.responses.create(
            model="gpt-5.1",
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": system_prompt}]},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7
        )

        # GPT-5.1 ì‘ë‹µ ì¶”ì¶œ
        if getattr(response, "output_text", None):
            result_text = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content_item in getattr(item, "content", []) or []:
                    if getattr(content_item, "type", "") == "text":
                        text_chunks.append(getattr(content_item, "text", ""))
            result_text = "\n".join(text_chunks).strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        result = json.loads(result_text)
        result["analyzed"] = True
        result["shorts_count"] = len(top_shorts)

        # ìºì‹œ ì €ì¥
        _channel_shorts_style_cache[channel_id] = result
        try:
            with open(cache_file, 'w', encoding='utf-8') as f:
                json.dump(result, f, ensure_ascii=False)
        except:
            pass

        print(f"[TUBELENS] ì‡¼ì¸  ìŠ¤íƒ€ì¼ ë¶„ì„ ì™„ë£Œ: {channel_id} ({len(top_shorts)}ê°œ ì‡¼ì¸ )")
        return result

    except json.JSONDecodeError as e:
        print(f"[TUBELENS] ì‡¼ì¸  ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
    except Exception as e:
        print(f"[TUBELENS] ì‡¼ì¸  ìŠ¤íƒ€ì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")

    return {"analyzed": False, "summary": "ë¶„ì„ ì‹¤íŒ¨"}


def get_channel_style_for_prompt(channel_id: str) -> str:
    """
    ì±„ë„ì˜ ì¸ë„¤ì¼/ì‡¼ì¸  ìŠ¤íƒ€ì¼ì„ GPT í”„ë¡¬í”„íŠ¸ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    """
    result_parts = []

    # ë¡±í¼ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼
    try:
        thumb_style = analyze_channel_thumbnail_style(channel_id)
        if thumb_style.get("analyzed"):
            parts = []
            if thumb_style.get("common_elements"):
                parts.append(f"ê³µí†µìš”ì†Œ: {', '.join(thumb_style['common_elements'][:3])}")
            if thumb_style.get("color_patterns"):
                parts.append(f"ìƒ‰ìƒ: {', '.join(thumb_style['color_patterns'][:2])}")
            if thumb_style.get("summary"):
                parts.append(f"íŠ¹ì§•: {thumb_style['summary'][:100]}")
            if parts:
                result_parts.append(f"[ë¡±í¼ ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼] {'; '.join(parts)}")
    except Exception as e:
        print(f"[TUBELENS] ë¡±í¼ ìŠ¤íƒ€ì¼ ë³€í™˜ ì˜¤ë¥˜: {e}")

    # ì‡¼ì¸  ìŠ¤íƒ€ì¼
    try:
        shorts_style = analyze_channel_shorts_style(channel_id)
        if shorts_style.get("analyzed"):
            parts = []
            if shorts_style.get("hook_text_style"):
                parts.append(f"í›„í‚¹: {', '.join(shorts_style['hook_text_style'][:2])}")
            if shorts_style.get("text_colors"):
                parts.append(f"ìƒ‰ìƒ: {', '.join(shorts_style['text_colors'][:2])}")
            if shorts_style.get("summary"):
                parts.append(f"íŠ¹ì§•: {shorts_style['summary'][:100]}")
            if parts:
                result_parts.append(f"[ì‡¼ì¸  ìŠ¤íƒ€ì¼] {'; '.join(parts)}")
    except Exception as e:
        print(f"[TUBELENS] ì‡¼ì¸  ìŠ¤íƒ€ì¼ ë³€í™˜ ì˜¤ë¥˜: {e}")

    return "\n".join(result_parts) if result_parts else ""


def calculate_seo_score_for_automation(title: str, description: str = "", tags: list = None) -> dict:
    """
    SEO ì ìˆ˜ ê³„ì‚° - ìë™í™” íŒŒì´í”„ë¼ì¸ìš©
    (TubeLens calculate_seo_score í•¨ìˆ˜ ê¸°ë°˜)
    """
    import re

    score = 0
    details = []

    # ì œëª© ë¶„ì„ (ìµœëŒ€ 40ì )
    title_len = len(title) if title else 0
    if 30 <= title_len <= 60:
        score += 20
        details.append("âœ… ì œëª© ê¸¸ì´ ì ì ˆ (30-60ì)")
    elif 20 <= title_len <= 70:
        score += 10
        details.append("âš ï¸ ì œëª© ê¸¸ì´ ë³´í†µ")
    else:
        details.append("âŒ ì œëª© ë„ˆë¬´ ì§§ê±°ë‚˜ ê¹€")

    # ì œëª©ì— ìˆ«ì í¬í•¨ (í´ë¦­ë¥  í–¥ìƒ)
    if title and re.search(r'\d+', title):
        score += 10
        details.append("âœ… ìˆ«ì í¬í•¨ (í´ë¦­ë¥  â†‘)")

    # ì œëª©ì— ê°ì • í‘œí˜„ í¬í•¨
    emotion_words = ['ì¶©ê²©', 'ë†€ë¼ìš´', 'ëŒ€ë°•', 'ê°ë™', 'ì‹¤í™”', 'ê²½ì•…', 'ë¹„ë°€', 'ë°˜ì „', 'ìµœì´ˆ', 'ë“œë””ì–´', 'ê²°êµ­', 'ì§„ì‹¤', 'í­ë¡œ']
    if title and any(word in title for word in emotion_words):
        score += 10
        details.append("âœ… ê°ì • ìœ ë°œ í‚¤ì›Œë“œ í¬í•¨")

    # ì„¤ëª…ë€ ë¶„ì„ (ìµœëŒ€ 30ì )
    desc_len = len(description) if description else 0
    if desc_len >= 500:
        score += 15
        details.append("âœ… ì„¤ëª…ë€ ì¶©ë¶„íˆ ì‘ì„±ë¨")
    elif desc_len >= 200:
        score += 8
        details.append("âš ï¸ ì„¤ëª…ë€ ë³´í†µ")
    else:
        details.append("âŒ ì„¤ëª…ë€ ë„ˆë¬´ ì§§ìŒ")

    # ì„¤ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
    if description and re.search(r'\d{1,2}:\d{2}', description):
        score += 10
        details.append("âœ… íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨")

    # í•´ì‹œíƒœê·¸ ë¶„ì„
    hashtags = re.findall(r'#\w+', title + (description or ''))
    if 3 <= len(hashtags) <= 10:
        score += 5
        details.append("âœ… í•´ì‹œíƒœê·¸ ì ì ˆ")
    elif len(hashtags) > 0:
        score += 2
        details.append("âš ï¸ í•´ì‹œíƒœê·¸ ë¶€ì¡±í•˜ê±°ë‚˜ ê³¼ë‹¤")

    # íƒœê·¸ ë¶„ì„ (ìµœëŒ€ 30ì )
    if tags and len(tags) >= 10:
        score += 15
        details.append("âœ… íƒœê·¸ ì¶©ë¶„íˆ ì„¤ì •ë¨")
    elif tags and len(tags) >= 5:
        score += 8
        details.append("âš ï¸ íƒœê·¸ ë³´í†µ")
    else:
        score += 5  # íƒœê·¸ ì •ë³´ ì—†ìœ¼ë©´ ê¸°ë³¸ì 

    # ë“±ê¸‰ ê²°ì •
    if score >= 80:
        grade = "A+"
    elif score >= 65:
        grade = "A"
    elif score >= 50:
        grade = "B"
    elif score >= 35:
        grade = "C"
    else:
        grade = "D"

    return {
        "score": min(100, score),
        "grade": grade,
        "details": details
    }


def enhance_description_for_youtube(description: str, title: str, hashtags: list = None, lang: str = 'ko') -> str:
    """
    YouTube ì„¤ëª…ë€ SEO ìµœì í™”
    - CTA (êµ¬ë…/ì¢‹ì•„ìš” ìœ ë„) ì¶”ê°€ - ì–¸ì–´ë³„ ì²˜ë¦¬
    - í•´ì‹œíƒœê·¸ ì •ë¦¬
    """
    if not description:
        description = ""

    # ì–¸ì–´ë³„ CTA í‚¤ì›Œë“œ ë° ë¬¸êµ¬
    cta_config = {
        'ko': {
            'keywords': ['êµ¬ë…', 'ì¢‹ì•„ìš”', 'ì•Œë¦¼', 'ëŒ“ê¸€'],
            'cta': [
                "ğŸ‘ ì´ ì˜ìƒì´ ë„ì›€ì´ ë˜ì…¨ë‹¤ë©´ ì¢‹ì•„ìš”ì™€ êµ¬ë… ë¶€íƒë“œë¦½ë‹ˆë‹¤!",
                "ğŸ”” ì•Œë¦¼ ì„¤ì •í•˜ì‹œë©´ ìƒˆë¡œìš´ ì˜ìƒì„ ë†“ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤.",
                "ğŸ’¬ ê¶ê¸ˆí•œ ì ì€ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”!"
            ]
        },
        'ja': {
            'keywords': ['ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²', 'é«˜è©•ä¾¡', 'é€šçŸ¥', 'ã‚³ãƒ¡ãƒ³ãƒˆ'],
            'cta': [
                "ğŸ‘ ã“ã®å‹•ç”»ãŒå½¹ã«ç«‹ã£ãŸã‚‰ã€é«˜è©•ä¾¡ã¨ãƒãƒ£ãƒ³ãƒãƒ«ç™»éŒ²ã‚’ãŠé¡˜ã„ã—ã¾ã™ï¼",
                "ğŸ”” é€šçŸ¥ã‚’ã‚ªãƒ³ã«ã™ã‚‹ã¨ã€æ–°ã—ã„å‹•ç”»ã‚’è¦‹é€ƒã—ã¾ã›ã‚“ã€‚",
                "ğŸ’¬ ã”è³ªå•ãŒã‚ã‚Œã°ã€ã‚³ãƒ¡ãƒ³ãƒˆã§ãŠçŸ¥ã‚‰ã›ãã ã•ã„ï¼"
            ]
        },
        'en': {
            'keywords': ['subscribe', 'like', 'notification', 'comment'],
            'cta': [
                "ğŸ‘ If you found this video helpful, please like and subscribe!",
                "ğŸ”” Turn on notifications so you never miss a new video.",
                "ğŸ’¬ Leave a comment if you have any questions!"
            ]
        }
    }

    config = cta_config.get(lang, cta_config['ko'])

    # ì´ë¯¸ CTAê°€ ìˆëŠ”ì§€ í™•ì¸
    has_cta = any(keyword.lower() in description.lower() for keyword in config['keywords'])

    # CTAê°€ ì—†ìœ¼ë©´ ì¶”ê°€
    if not has_cta:
        cta_text = "\n\n" + "=" * 30 + "\n"
        cta_text += "\n".join(config['cta'])
        description = description + cta_text

    return description


def run_automation_pipeline(row_data, row_index, selected_project=''):
    """
    ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ - ê¸°ì¡´ /image í˜ì´ì§€ API ì¬ì‚¬ìš©

    row_data: [ìƒíƒœ, ì˜ˆì•½ì‹œê°„, ì±„ë„ID, ëŒ€ë³¸, ì œëª©, ê³µê°œì„¤ì •, ì˜ìƒURL, ì—ëŸ¬ë©”ì‹œì§€]
    row_index: ì‹œíŠ¸ì—ì„œì˜ í–‰ ë²ˆí˜¸ (1-based, í—¤ë” ì œì™¸í•˜ë©´ ë°ì´í„°ëŠ” 2ë¶€í„°)
    selected_project: ë¯¸ë¦¬ ì„ íƒëœ YouTube í”„ë¡œì íŠ¸ ('', '_2') - api_sheets_check_and_processì—ì„œ ì „ë‹¬

    â˜…â˜…â˜… ì¤‘ìš”: ê¸°ì¡´ /image í˜ì´ì§€ì™€ ë™ì¼í•œ APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤ â˜…â˜…â˜…
    - /api/image/analyze-script (ëŒ€ë³¸ ë¶„ì„)
    - /api/drama/generate-image (ì´ë¯¸ì§€ ìƒì„±)
    - /api/image/generate-assets-zip (TTS + ìë§‰)
    - /api/thumbnail-ai/generate-all (ì¸ë„¤ì¼ ìƒì„±)
    - /api/image/generate-video (ì˜ìƒ ìƒì„±)
    - /api/youtube/upload (YouTube ì—…ë¡œë“œ)
    """
    import requests as req
    import time as time_module

    try:
        # ========== ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ ë¶„ê¸° (í™˜ê²½ë³€ìˆ˜: USE_AGENT_PIPELINE=1) ==========
        if os.environ.get("USE_AGENT_PIPELINE", "0") == "1":
            try:
                import asyncio
                from scripts.video_pipeline import run_agent_pipeline

                # row_dataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                row_dict = {
                    "ìƒíƒœ": row_data[0] if len(row_data) > 0 else '',
                    "ì‘ì—…ì‹œê°„": row_data[1] if len(row_data) > 1 else '',
                    "ì±„ë„ID": (row_data[2] if len(row_data) > 2 else '').strip(),
                    "ì±„ë„ëª…": row_data[3] if len(row_data) > 3 else '',
                    "ì˜ˆì•½ì‹œê°„": row_data[4] if len(row_data) > 4 else '',
                    "ëŒ€ë³¸": row_data[5] if len(row_data) > 5 else '',
                    "ì œëª©": row_data[6] if len(row_data) > 6 else '',
                    "ê³µê°œì„¤ì •": (row_data[10] if len(row_data) > 10 else '').strip() or 'private',
                    "ìŒì„±": (row_data[13] if len(row_data) > 13 else '').strip() or 'chirp3:Charon',  # â˜… ê¸°ë³¸ ìŒì„± ë³€ê²½
                    "íƒ€ê²Ÿ": (row_data[14] if len(row_data) > 14 else '').strip() or 'senior',
                    "ì¹´í…Œê³ ë¦¬": (row_data[15] if len(row_data) > 15 else '').strip(),
                    "í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID": (row_data[17] if len(row_data) > 17 else '').strip(),
                    "ì œëª©(ì…ë ¥)": (row_data[18] if len(row_data) > 18 else '').strip(),
                    "ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)": (row_data[19] if len(row_data) > 19 else '').strip(),
                    "ì¸ìš©ë§í¬": (row_data[20] if len(row_data) > 20 else '').strip(),  # â˜… ì¸ìš©ë§í¬ ì¶”ê°€
                }

                print(f"[AGENT] ========== ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ==========", flush=True)
                print(f"[AGENT] í–‰ {row_index}, ëŒ€ë³¸ {len(row_dict['ëŒ€ë³¸'])}ì, í”„ë¡œì íŠ¸={selected_project or 'ê¸°ë³¸'}", flush=True)

                # â˜… ìŒì„± ì‚¬ì „ ê²€ì¦ (ë¹„ì‹¼ ì‘ì—… ì „ì— í™•ì¸)
                agent_voice = row_dict.get("ìŒì„±", "chirp3:Charon")
                print(f"[AGENT] ìŒì„± ì‚¬ì „ ê²€ì¦: {agent_voice}", flush=True)
                voice_validation = validate_tts_voice(agent_voice)
                if not voice_validation["ok"]:
                    error_msg = f"ìŒì„± ì„¤ì • ì˜¤ë¥˜: {voice_validation['error']}"
                    print(f"[AGENT] âŒ {error_msg}", flush=True)
                    return {"ok": False, "error": error_msg, "video_url": None, "cost": 0}
                print(f"[AGENT] âœ… ìŒì„± ê²€ì¦ í†µê³¼: {voice_validation['voice_type']}", flush=True)

                # ë¹„ë™ê¸° ì‹¤í–‰
                video_url, error, cost = asyncio.run(
                    run_agent_pipeline(row_dict, row_index, sheet_name="", selected_project=selected_project)
                )

                if video_url:
                    print(f"[AGENT] âœ… ì™„ë£Œ: {video_url}, ë¹„ìš©=${cost:.4f}", flush=True)
                    return {"ok": True, "video_url": video_url, "cost": cost}
                else:
                    print(f"[AGENT] âŒ ì‹¤íŒ¨: {error}", flush=True)
                    return {"ok": False, "error": error, "video_url": None, "cost": cost}

            except Exception as agent_err:
                # â˜… í´ë°± ì œê±°: ì—ì´ì „íŠ¸ ì‹¤íŒ¨ ì‹œ ì™„ì „íˆ ì‹¤íŒ¨ (ì—ëŸ¬ ìˆ¨ê¸°ì§€ ì•ŠìŒ)
                print(f"[AGENT] âŒ ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ ì˜ˆì™¸ ë°œìƒ: {agent_err}", flush=True)
                import traceback
                traceback.print_exc()
                return {"ok": False, "error": f"ì—ì´ì „íŠ¸ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {agent_err}", "video_url": None, "cost": 0}

        # ì‹œíŠ¸ ì»¬ëŸ¼ êµ¬ì¡°:
        # ===== Google Sheets ì»¬ëŸ¼ êµ¬ì¡° (CLAUDE.md ê¸°ì¤€) =====
        # A(0): ìƒíƒœ, B(1): ì‘ì—…ì‹œê°„, C(2): ì±„ë„ID, D(3): ì±„ë„ëª…(ì°¸ê³ ìš©)
        # E(4): ì˜ˆì•½ì‹œê°„, F(5): ëŒ€ë³¸, G(6): ì œëª©
        # H(7): ì œëª©2(ì¶œë ¥), I(8): ì œëª©3(ì¶œë ¥), J(9): ë¹„ìš©(ì¶œë ¥)
        # K(10): ê³µê°œì„¤ì •, L(11): ì˜ìƒURL(ì¶œë ¥), M(12): ì—ëŸ¬ë©”ì‹œì§€(ì¶œë ¥)
        # N(13): ìŒì„±, O(14): íƒ€ê²Ÿ, P(15): ì¹´í…Œê³ ë¦¬(ì¶œë ¥), Q(16): ì‡¼ì¸ URL(ì¶œë ¥)
        # R(17): í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID (ì…ë ¥, ì„ íƒ)
        status = row_data[0] if len(row_data) > 0 else ''
        work_time = row_data[1] if len(row_data) > 1 else ''  # B: ì‘ì—…ì‹œê°„ (íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ìš©)
        channel_id = (row_data[2] if len(row_data) > 2 else '').strip()  # ê³µë°± ì œê±°
        channel_name = row_data[3] if len(row_data) > 3 else ''  # D: ì±„ë„ëª… (ì°¸ê³ ìš©, ì½”ë“œì—ì„œ ë¯¸ì‚¬ìš©)
        publish_time_raw = row_data[4] if len(row_data) > 4 else ''  # E: ì˜ˆì•½ì‹œê°„ (YouTube ê³µê°œìš©)
        script = row_data[5] if len(row_data) > 5 else ''
        title = row_data[6] if len(row_data) > 6 else ''
        # H(7), I(8), J(9)ëŠ” ì¶œë ¥ ì»¬ëŸ¼ (ì œëª©2, ì œëª©3, ë¹„ìš©)
        visibility = (row_data[10] if len(row_data) > 10 else '').strip() or 'private'  # Kì—´: ê³µê°œì„¤ì •
        # L(11), M(12)ëŠ” ì¶œë ¥ ì»¬ëŸ¼ (ì˜ìƒURL, ì—ëŸ¬ë©”ì‹œì§€)
        voice = (row_data[13] if len(row_data) > 13 else '').strip() or lang_ko.TTS['default_voice']  # Nì—´: ìŒì„± (ê¸°ë³¸: lang/ko.py)
        audience = (row_data[14] if len(row_data) > 14 else '').strip() or 'senior'  # Oì—´: íƒ€ê²Ÿ ì‹œì²­ì
        category = (row_data[15] if len(row_data) > 15 else '').strip()  # Pì—´: ì¹´í…Œê³ ë¦¬ (ë‰´ìŠ¤ ë“±)
        # Q(16): ì‡¼ì¸ URL(ì¶œë ¥)
        playlist_id = (row_data[17] if len(row_data) > 17 else '').strip()  # Rì—´: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID (ì„ íƒ)
        # â˜… ì‚¬ìš©ì ì…ë ¥ê°’ (GPT ìƒì„±ê°’ ëŒ€ì‹  ì‚¬ìš©)
        user_title = (row_data[18] if len(row_data) > 18 else '').strip()  # ì‚¬ìš©ì ì…ë ¥ ì œëª©
        user_thumbnail_text = (row_data[19] if len(row_data) > 19 else '').strip()  # ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬
        citation_links = (row_data[20] if len(row_data) > 20 else '').strip()  # ì¸ìš©ë§í¬ (ìœ íŠœë¸Œ ì„¤ëª…ì— í¬í•¨)

        # [TUBELENS] ë‚ ì§œë§Œ ì…ë ¥ëœ ê²½ìš° ì¹´í…Œê³ ë¦¬ë³„ ìµœì  ì‹œê°„ ìë™ ì¶”ê°€
        # news -> 08:00, story/drama -> 19:00, ê¸°ë³¸ -> 19:00
        publish_time = get_optimal_publish_time(channel_id, publish_time_raw, category) if publish_time_raw else ''

        # ë¹„ìš© ì¶”ì  ë³€ìˆ˜ ì´ˆê¸°í™”
        total_cost = 0.0

        print(f"[AUTOMATION] ========== íŒŒì´í”„ë¼ì¸ ì‹œì‘ (API ì¬ì‚¬ìš©) ==========", flush=True)
        print(f"[AUTOMATION] í–‰ {row_index}", flush=True)
        print(f"  - ì‘ì—…ì‹œê°„: {work_time}", flush=True)
        print(f"  - ì±„ë„: {channel_name or channel_id}", flush=True)
        print(f"  - ì˜ˆì•½ì‹œê°„: {publish_time or '(ì—†ìŒ - ì¦‰ì‹œ ê³µê°œ)'}", flush=True)
        print(f"  - ëŒ€ë³¸ ê¸¸ì´: {len(script)} ê¸€ì", flush=True)
        print(f"  - ì œëª©: {title or '(AI ìƒì„± ì˜ˆì •)'}", flush=True)
        print(f"  - ê³µê°œì„¤ì •: {visibility}", flush=True)
        print(f"  - ìŒì„±: {voice}", flush=True)
        print(f"  - íƒ€ê²Ÿ: {audience}")
        print(f"  - ì¹´í…Œê³ ë¦¬: {category or '(ì¼ë°˜)'}")
        print(f"  - í”Œë ˆì´ë¦¬ìŠ¤íŠ¸: {playlist_id or '(ì—†ìŒ)'}")
        print(f"  - â˜… ì‚¬ìš©ì ì…ë ¥ ì œëª©: {user_title or '(ì—†ìŒ - GPT ìƒì„±)'}")
        print(f"  - â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ë¬¸êµ¬: {user_thumbnail_text or '(ì—†ìŒ - GPT ìƒì„±)'}")

        if not script or len(script.strip()) < 10:
            return {"ok": False, "error": "ëŒ€ë³¸ì´ ë„ˆë¬´ ì§§ìŠµë‹ˆë‹¤ (ìµœì†Œ 10ì)", "video_url": None}

        # ========== 0-A. ìŒì„± ì‚¬ì „ ê²€ì¦ (ë¹„ì‹¼ ì‘ì—… ì „ì— í™•ì¸) ==========
        print(f"[AUTOMATION] 0-A. ìŒì„± ì‚¬ì „ ê²€ì¦: {voice}", flush=True)
        voice_validation = validate_tts_voice(voice)
        if not voice_validation["ok"]:
            error_msg = f"ìŒì„± ì„¤ì • ì˜¤ë¥˜: {voice_validation['error']}"
            print(f"[AUTOMATION] âŒ {error_msg}", flush=True)
            return {"ok": False, "error": error_msg, "video_url": None}
        print(f"[AUTOMATION] âœ… ìŒì„± ê²€ì¦ í†µê³¼: {voice_validation['voice_type']}", flush=True)

        # ========== 0. YouTube í”„ë¡œì íŠ¸ í™•ì¸ ==========
        # í• ë‹¹ëŸ‰ ì²´í¬ëŠ” api_sheets_check_and_processì—ì„œ ì´ë¯¸ ì™„ë£Œë¨
        # selected_project íŒŒë¼ë¯¸í„°ë¡œ ë¯¸ë¦¬ ì„ íƒëœ í”„ë¡œì íŠ¸ë¥¼ ë°›ìŒ
        print(f"[AUTOMATION] 0. YouTube í”„ë¡œì íŠ¸: {'ê¸°ë³¸' if not selected_project else selected_project} (ì‚¬ì „ ì²´í¬ ì™„ë£Œ)")

        session_id = f"auto_{row_index}_{int(time_module.time())}"
        base_url = "http://127.0.0.1:" + str(os.environ.get("PORT", 5059))

        # ========== 1. ëŒ€ë³¸ ë¶„ì„ (/api/image/analyze-script) ==========
        print(f"[AUTOMATION] 1. ëŒ€ë³¸ ë¶„ì„ ì‹œì‘...", flush=True)
        try:
            # [TUBELENS] ì±„ë„ë³„ ì¸ë„¤ì¼/ì‡¼ì¸  ìŠ¤íƒ€ì¼ ë¶„ì„ (7ì¼ ìºì‹œ)
            channel_style = ""
            if channel_id:
                try:
                    channel_style = get_channel_style_for_prompt(channel_id)
                    if channel_style:
                        print(f"[TUBELENS] ì±„ë„ ìŠ¤íƒ€ì¼ ë¶„ì„ ì™„ë£Œ:")
                        for line in channel_style.split('\n'):
                            print(f"  {line}")
                except Exception as style_err:
                    print(f"[TUBELENS] ì±„ë„ ìŠ¤íƒ€ì¼ ë¶„ì„ ì‹¤íŒ¨ (ë¬´ì‹œ): {style_err}")

            # ì˜ìƒ ê¸¸ì´ë³„ ì´ë¯¸ì§€ ê°œìˆ˜ ê²°ì • (image ëª¨ë“ˆ ì‚¬ìš©)
            image_count, estimated_minutes = get_image_count_by_script(len(script))
            print(f"[AUTOMATION] ëŒ€ë³¸ {len(script)}ì â†’ ì˜ˆìƒ {estimated_minutes:.1f}ë¶„ â†’ ì´ë¯¸ì§€ {image_count}ê°œ")

            # HTTP í˜¸ì¶œ ëŒ€ì‹  ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ (self-deadlock ë°©ì§€)
            # Flaskì˜ test_request_contextë¥¼ ì‚¬ìš©í•˜ì—¬ request ê°ì²´ ì‹œë®¬ë ˆì´ì…˜
            analyze_request_data = {
                "script": script,
                "content_type": "drama",
                "image_style": "animation",  # ì›¹íˆ° ìŠ¤íƒ€ì¼
                "image_count": image_count,
                "audience": audience,
                "category": category,  # ë‰´ìŠ¤ ë“± ì¹´í…Œê³ ë¦¬
                "output_language": "auto",
                "channel_style": channel_style  # [TUBELENS] ì±„ë„ë³„ ìŠ¤íƒ€ì¼ ì •ë³´
            }

            with app.test_request_context(
                '/api/image/analyze-script',
                method='POST',
                json=analyze_request_data,
                content_type='application/json'
            ):
                analyze_response = api_image_analyze_script()
                # Flask ì‘ë‹µ ì²˜ë¦¬: (response, status_code) íŠœí”Œ ë˜ëŠ” response ê°ì²´
                if isinstance(analyze_response, tuple):
                    analyze_data = analyze_response[0].get_json()
                else:
                    analyze_data = analyze_response.get_json()

            if not analyze_data.get('ok'):
                return {"ok": False, "error": f"ëŒ€ë³¸ ë¶„ì„ ì‹¤íŒ¨: {analyze_data.get('error')}", "video_url": None}

            scenes = analyze_data.get('scenes', [])
            youtube_meta = analyze_data.get('youtube', {})
            thumbnail_data = analyze_data.get('thumbnail', {})
            video_effects = analyze_data.get('video_effects', {})  # BGM, íš¨ê³¼ìŒ ë“±

            # â˜… ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ API í˜¸ì¶œ (ë” ë‚˜ì€ í”„ë¡¬í”„íŠ¸ ìƒì„±)
            print(f"[AUTOMATION] ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ API í˜¸ì¶œ ì‹œì‘...")
            ai_prompts = {}
            try:
                # ë‚´ë¶€ API í˜¸ì¶œ (ê°™ì€ ì„œë²„)
                thumb_analyze_response = requests.post(
                    f"http://127.0.0.1:{os.environ.get('PORT', 5000)}/api/thumbnail-ai/analyze",
                    json={"script": script, "title": youtube_meta.get('title', '')},
                    timeout=120
                )
                if thumb_analyze_response.status_code == 200:
                    thumb_result = thumb_analyze_response.json()
                    if thumb_result.get('ok'):
                        # prompts êµ¬ì¡°: {"A": {"prompt": "...", "text_overlay": {...}}, "B": {...}}
                        thumb_prompts = thumb_result.get('prompts', {})
                        if thumb_prompts:
                            ai_prompts = thumb_prompts
                            print(f"[AUTOMATION] ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ ì™„ë£Œ: {list(ai_prompts.keys())}")
                            if ai_prompts.get('A'):
                                print(f"[AUTOMATION] ì¸ë„¤ì¼ í”„ë¡¬í”„íŠ¸ A: {str(ai_prompts['A'].get('prompt', ''))[:100]}...")
                        else:
                            print(f"[AUTOMATION] ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ ê²°ê³¼ ë¹„ì–´ìˆìŒ, í´ë°± ì‚¬ìš©")
                    else:
                        print(f"[AUTOMATION] ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ ì‹¤íŒ¨: {thumb_result.get('error')}, í´ë°± ì‚¬ìš©")
                else:
                    print(f"[AUTOMATION] ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ HTTP ì˜¤ë¥˜: {thumb_analyze_response.status_code}")
            except Exception as te:
                print(f"[AUTOMATION] ì „ìš© ì¸ë„¤ì¼ ë¶„ì„ ì˜ˆì™¸: {te}")

            # ì¸ë„¤ì¼ ì „ëµ ë°ì´í„° ì¶”ì¶œ (ìƒˆ êµ¬ì¡°)
            thumbnail_text_candidates = thumbnail_data.get('thumbnail_text_candidates', [])
            best_combo = thumbnail_data.get('best_combo', {})
            layout_suggestion = thumbnail_data.get('layout_suggestion', {})
            consistency_check = thumbnail_data.get('consistency_check', {})
            design_notes = thumbnail_data.get('design_notes', '')

            # GPT-5.1ì´ ëŒ€ë³¸ ë¶„ì„ìœ¼ë¡œ ìë™ ê°ì§€í•œ ì¹´í…Œê³ ë¦¬ (news ë˜ëŠ” story)
            detected_category = analyze_data.get('detected_category', 'story')
            print(f"[AUTOMATION] GPT ê°ì§€ ì¹´í…Œê³ ë¦¬: {detected_category}")

            # ì¸ë„¤ì¼ ì „ëµ ë¡œê¹…
            if best_combo:
                print(f"[AUTOMATION] ì¸ë„¤ì¼ ì „ëµ:")
                print(f"  - ì„ íƒëœ ì œëª©: {best_combo.get('chosen_title', '')[:50]}")
                print(f"  - ì„ íƒëœ ë¬¸êµ¬: {best_combo.get('chosen_thumbnail_text', '')}")
                print(f"  - ì„ íƒ ì´ìœ : {best_combo.get('reason', '')[:80]}")
            if layout_suggestion:
                print(f"  - ë ˆì´ì•„ì›ƒ: {layout_suggestion.get('layout_type', '')}")
            if consistency_check:
                print(f"  - CTR ì ìˆ˜: {consistency_check.get('ctr_score', 0)}/10, Watch Time ì ìˆ˜: {consistency_check.get('watchtime_score', 0)}/10")

            generated_title = youtube_meta.get('title', '')
            title_options = youtube_meta.get('title_options', [])

            # description ì²˜ë¦¬: ìƒˆ êµ¬ì¡°(ê°ì²´) ë˜ëŠ” ê¸°ì¡´ êµ¬ì¡°(ë¬¸ìì—´) ì§€ì›
            desc_raw = youtube_meta.get('description', '')
            if isinstance(desc_raw, dict):
                description = desc_raw.get('full_text', '')
                description_chapters = desc_raw.get('chapters', [])
                description_preview = desc_raw.get('preview_2_lines', '')
            else:
                description = desc_raw
                description_chapters = []
                description_preview = ''

            # í•´ì‹œíƒœê·¸, íƒœê·¸, ê³ ì •ëŒ“ê¸€ ì¶”ì¶œ
            hashtags = youtube_meta.get('hashtags', [])
            tags = youtube_meta.get('tags', [])
            pin_comment = youtube_meta.get('pin_comment', '')

            # â˜… pin_comment Fallback: GPTê°€ ìƒì„± ì•ˆ í–ˆìœ¼ë©´ ê¸°ë³¸ ëŒ“ê¸€ ìƒì„±
            if not pin_comment or not pin_comment.strip():
                # ì¹´í…Œê³ ë¦¬ë³„ ê¸°ë³¸ ëŒ“ê¸€
                fallback_comments = {
                    'history': 'ì´ ì—­ì‚¬ ì´ì•¼ê¸°ê°€ í¥ë¯¸ë¡œìš°ì…¨ë‚˜ìš”? ë” ì•Œê³  ì‹¶ì€ ì—­ì‚¬ ì£¼ì œê°€ ìˆë‹¤ë©´ ëŒ“ê¸€ë¡œ ì•Œë ¤ì£¼ì„¸ìš”!',
                    'news': 'ì´ ì†Œì‹ì— ëŒ€í•´ ì–´ë–»ê²Œ ìƒê°í•˜ì‹œë‚˜ìš”? ì˜ê²¬ì„ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”!',
                    'mystery': 'ì´ ë¯¸ìŠ¤í„°ë¦¬ì— ëŒ€í•œ ì—¬ëŸ¬ë¶„ì˜ ì¶”ë¦¬ëŠ”? ëŒ“ê¸€ë¡œ ê³µìœ í•´ì£¼ì„¸ìš”!',
                }
                pin_comment = fallback_comments.get(detected_category, 'ì´ ì˜ìƒì´ ë„ì›€ì´ ë˜ì…¨ë‚˜ìš”? ê¶ê¸ˆí•œ ì ì€ ëŒ“ê¸€ë¡œ ë‚¨ê²¨ì£¼ì„¸ìš”!')
                print(f"[AUTOMATION] âš ï¸ pin_comment ì—†ìŒ â†’ ê¸°ë³¸ ëŒ“ê¸€ ì‚¬ìš©: {pin_comment[:30]}...")

            # ëŒ€ë³¸ ì–¸ì–´ ê°ì§€ (CTA ì–¸ì–´ ê²°ì •ìš©)
            def detect_lang_simple(text):
                """ì¼ë³¸ì–´ ë‰´ìŠ¤/ë¹„ì¦ˆë‹ˆìŠ¤ ëŒ€ë³¸ì€ í•œìê°€ ë§ê³  íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ ì ìŒ.
                í•œê¸€ì´ ì—†ê³  íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ 1ê°œ ì´ìƒ ìˆìœ¼ë©´ ì¼ë³¸ì–´ë¡œ íŒë‹¨."""
                if not text:
                    return 'ko'
                import re as re_detect
                korean = len(re_detect.findall(r'[ê°€-í£]', text))
                japanese = len(re_detect.findall(r'[\u3040-\u309F\u30A0-\u30FF]', text))
                # í•œêµ­ì–´ ìš°ì„  (í•œê¸€ì´ ìˆìœ¼ë©´ í•œêµ­ì–´)
                if korean > 0:
                    return 'ko'
                # ì¼ë³¸ì–´: íˆë¼ê°€ë‚˜/ê°€íƒ€ì¹´ë‚˜ê°€ 1ê°œ ì´ìƒ ìˆìœ¼ë©´ ì¼ë³¸ì–´
                if japanese > 0:
                    return 'ja'
                return 'en'
            detected_lang = detect_lang_simple(script)
            print(f"[AUTOMATION] ê°ì§€ëœ ì–¸ì–´: {detected_lang}")

            # ë¡œê¹…
            print(f"[AUTOMATION] ì„¤ëª…ë€: {len(description)}ì, ì±•í„°: {len(description_chapters)}ê°œ")
            print(f"[AUTOMATION] í•´ì‹œíƒœê·¸: {hashtags}")
            print(f"[AUTOMATION] íƒœê·¸: {len(tags)}ê°œ")

            # title_options ë¡œê¹… (3ê°€ì§€ ìŠ¤íƒ€ì¼ ì œëª©)
            if title_options:
                print(f"[AUTOMATION] ì œëª© ì˜µì…˜ (3ê°€ì§€ ìŠ¤íƒ€ì¼):")
                for opt in title_options:
                    print(f"  - [{opt.get('style', '?')}] {opt.get('title', '')}")

            # â˜… ì‚¬ìš©ì ì…ë ¥ ì œëª©ì´ ìˆìœ¼ë©´ ìš°ì„  ì‚¬ìš©
            if user_title:
                title = user_title
                print(f"[AUTOMATION] â˜… ì‚¬ìš©ì ì…ë ¥ ì œëª© ì‚¬ìš©: {title}")
            elif not title:
                title = generated_title or f"ìë™ ìƒì„± ì˜ìƒ #{row_index}"

            # [TUBELENS] SEO ì ìˆ˜ ê³„ì‚° ë° ë¡œê¹…
            try:
                seo_result = calculate_seo_score_for_automation(title, description, tags)
                print(f"[TUBELENS] SEO ì ìˆ˜: {seo_result['score']}ì  ({seo_result['grade']})")
                for detail in seo_result['details']:
                    print(f"  {detail}")
            except Exception as seo_err:
                print(f"[TUBELENS] SEO ì ìˆ˜ ê³„ì‚° ì‹¤íŒ¨ (ë¬´ì‹œ): {seo_err}")

            # â˜…â˜…â˜… ëŒ€ë³¸ ê°•ì œ ë¶„í• : GPTê°€ ìš”ì•½í•˜ì§€ ëª»í•˜ë„ë¡ ì›ë³¸ ëŒ€ë³¸ì„ ì”¬ë³„ë¡œ ê· ë“± ë¶„í•  â˜…â˜…â˜…
            # GPTê°€ í”„ë¡¬í”„íŠ¸ ì§€ì‹œë¥¼ ë¬´ì‹œí•˜ê³  ìš”ì•½í•˜ëŠ” ë¬¸ì œ í•´ê²°
            if scenes and script:
                original_len = len(script)
                scene_count = len(scenes)

                # ë¬¸ì¥ ë‹¨ìœ„ë¡œ ë¶„í•  (ìì—°ìŠ¤ëŸ¬ìš´ ëŠê¹€)
                import re as re_split
                # ë¬¸ì¥ ì¢…ê²° íŒ¨í„´: ë§ˆì¹¨í‘œ/ë¬¼ìŒí‘œ/ëŠë‚Œí‘œ + ê³µë°± ë˜ëŠ” ë
                sentences = re_split.split(r'(?<=[.?!ã€‚ï¼Ÿï¼])\s+', script)
                sentences = [s.strip() for s in sentences if s.strip()]

                if sentences:
                    # ê° ì”¬ì— ë°°ì •í•  ë¬¸ì¥ ìˆ˜ ê³„ì‚°
                    sentences_per_scene = max(1, len(sentences) // scene_count)

                    for i, scene in enumerate(scenes):
                        start_idx = i * sentences_per_scene
                        if i == scene_count - 1:
                            # ë§ˆì§€ë§‰ ì”¬ì€ ë‚¨ì€ ëª¨ë“  ë¬¸ì¥
                            end_idx = len(sentences)
                        else:
                            end_idx = start_idx + sentences_per_scene

                        scene_narration = ' '.join(sentences[start_idx:end_idx])
                        old_narration_len = len(scene.get('narration', ''))
                        scene['narration'] = scene_narration

                    # ê²€ì¦ ë¡œê¹…
                    total_forced_len = sum(len(s.get('narration', '')) for s in scenes)
                    print(f"[AUTOMATION] â˜… ëŒ€ë³¸ ê°•ì œ ë¶„í•  ì™„ë£Œ:")
                    print(f"  - ì›ë³¸: {original_len}ì â†’ ë¶„í•  í›„: {total_forced_len}ì (ìœ ì‹¤: {original_len - total_forced_len}ì)")
                    print(f"  - ë¬¸ì¥ ìˆ˜: {len(sentences)}ê°œ â†’ ì”¬ë‹¹ ~{sentences_per_scene}ë¬¸ì¥")
                else:
                    # ë¬¸ì¥ ë¶„ë¦¬ ì‹¤íŒ¨ ì‹œ ê¸€ììˆ˜ë¡œ ê· ë“± ë¶„í• 
                    chunk_size = len(script) // scene_count
                    for i, scene in enumerate(scenes):
                        start = i * chunk_size
                        end = len(script) if i == scene_count - 1 else (i + 1) * chunk_size
                        scene['narration'] = script[start:end]
                    print(f"[AUTOMATION] â˜… ëŒ€ë³¸ ê¸€ììˆ˜ ë¶„í•  (ë¬¸ì¥ ë¶„ë¦¬ ì‹¤íŒ¨): {original_len}ì â†’ {scene_count}ì”¬")

            # ë¹„ìš©: GPT-5.1 ëŒ€ë³¸ ë¶„ì„ (~$0.03)
            total_cost += 0.03
            print(f"[AUTOMATION] 1. ì™„ë£Œ: {len(scenes)}ê°œ ì”¬, ì œëª©: {title[:40]}... (ë¹„ìš©: $0.03)")
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {"ok": False, "error": f"ëŒ€ë³¸ ë¶„ì„ ì˜¤ë¥˜: {str(e)}", "video_url": None, "cost": total_cost}

        # ========== 2. ë³‘ë ¬ ì²˜ë¦¬: ì´ë¯¸ì§€ + TTS + ì¸ë„¤ì¼ ==========
        # í™˜ê²½ë³€ìˆ˜ ì‚¬ì „ ê²€ì¦
        openrouter_key = os.getenv("OPENROUTER_API_KEY", "")
        if not openrouter_key:
            print("[AUTOMATION][ERROR] OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤!")
            return {"ok": False, "error": "OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. Render ëŒ€ì‹œë³´ë“œì—ì„œ ì„¤ì •í•´ì£¼ì„¸ìš”.", "video_url": None, "cost": total_cost}
        else:
            key_preview = f"{openrouter_key[:8]}...{openrouter_key[-4:]}" if len(openrouter_key) > 12 else "***"
            print(f"[AUTOMATION] OpenRouter API í‚¤ í™•ì¸: {key_preview}")

        print(f"[AUTOMATION] 2. ë³‘ë ¬ ì²˜ë¦¬ ì‹œì‘ (ì´ë¯¸ì§€ {len(scenes)}ê°œ + TTS + ì¸ë„¤ì¼)...")
        from concurrent.futures import ThreadPoolExecutor, as_completed

        thumbnail_url = None
        parallel_errors = []

        def generate_images():
            """ì´ë¯¸ì§€ ìƒì„± (ë³‘ë ¬ ì‘ì—… 1) - 4ê°œì”© ë³‘ë ¬ ì²˜ë¦¬"""
            nonlocal total_cost
            from concurrent.futures import ThreadPoolExecutor as ImgExecutor, as_completed as img_completed

            print(f"[AUTOMATION][IMAGE] ì´ë¯¸ì§€ ìƒì„± ì‹œì‘ ({len(scenes)}ê°œ, 4ê°œì”© ë³‘ë ¬)...")

            def generate_single_image(idx, scene):
                """ë‹¨ì¼ ì´ë¯¸ì§€ ìƒì„± (ì‹¤íŒ¨ ì‹œ 3íšŒ ì¬ì‹œë„) - ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ"""
                prompt = scene.get('image_prompt', '')
                if not prompt:
                    return idx, None

                max_retries = 3
                for attempt in range(max_retries):
                    try:
                        # HTTP í˜¸ì¶œ ëŒ€ì‹  ì§ì ‘ í•¨ìˆ˜ í˜¸ì¶œ (self-deadlock ë°©ì§€)
                        result = image_generate(prompt=prompt, size="1280x720", model=GEMINI_PRO)

                        if result.get('ok') and result.get('image_url'):
                            print(f"[AUTOMATION][IMAGE] {idx+1}/{len(scenes)} ì™„ë£Œ")
                            return idx, result['image_url']
                        else:
                            error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')
                            print(f"[AUTOMATION][IMAGE] {idx+1} ì‹¤íŒ¨ (ì‹œë„ {attempt+1}/{max_retries}): {error_msg}")
                    except Exception as e:
                        print(f"[AUTOMATION][IMAGE] {idx+1} ì˜¤ë¥˜ (ì‹œë„ {attempt+1}/{max_retries}): {e}")

                    if attempt < max_retries - 1:
                        time_module.sleep(2)  # ì¬ì‹œë„ ì „ ëŒ€ê¸°

                print(f"[AUTOMATION][IMAGE] {idx+1} ìµœì¢… ì‹¤íŒ¨ (3íšŒ ì‹œë„)")
                return idx, None

            # 4ê°œì”© ë³‘ë ¬ ì²˜ë¦¬
            with ImgExecutor(max_workers=4) as img_executor:
                futures = {
                    img_executor.submit(generate_single_image, i, scene): i
                    for i, scene in enumerate(scenes)
                }

                for future in img_completed(futures):
                    idx, image_url = future.result()
                    if image_url:
                        scenes[idx]['image_url'] = image_url

            success_count = len([s for s in scenes if s.get('image_url')])
            image_cost = success_count * 0.05  # Gemini 3 Pro ë¹„ìš©
            total_cost += image_cost
            print(f"[AUTOMATION][IMAGE] ì™„ë£Œ: {success_count}/{len(scenes)}ê°œ (ë¹„ìš©: ${image_cost:.2f})")
            return success_count

        def generate_tts():
            """TTS ìƒì„± (ë³‘ë ¬ ì‘ì—… 2)"""
            nonlocal total_cost
            print(f"[AUTOMATION][TTS] TTS ìƒì„± ì‹œì‘...")
            try:
                scenes_for_tts = []
                for i, scene in enumerate(scenes):
                    scenes_for_tts.append({
                        "scene_number": i + 1,
                        "text": scene.get('narration', ''),
                        "image_url": scene.get('image_url', ''),
                        "subtitle_segments": scene.get('subtitle_segments', [])  # VRCS 2.0 ë¬¸ì¥ë³„ ìë§‰
                    })

                assets_resp = req.post(f"{base_url}/api/image/generate-assets-zip", json={
                    "session_id": session_id,
                    "scenes": scenes_for_tts,
                    "voice": voice,
                    "include_images": False
                }, timeout=900)  # 15ë¶„ (ê¸´ ëŒ€ë³¸ + Gemini Rate Limit ë°°ì¹˜ ì²˜ë¦¬ìš©)

                assets_data = assets_resp.json()
                if not assets_data.get('ok'):
                    raise Exception(f"TTS ì‹¤íŒ¨: {assets_data.get('error')}")

                scene_metadata = assets_data.get('scene_metadata', [])
                for sm in scene_metadata:
                    idx = sm.get('scene_idx', -1)
                    if 0 <= idx < len(scenes):
                        scenes[idx]['audio_url'] = sm.get('audio_url')
                        scenes[idx]['duration'] = sm.get('duration', 5)
                        scenes[idx]['subtitles'] = sm.get('subtitles', [])

                tts_cost = len(script) * 0.000004
                total_cost += tts_cost
                print(f"[AUTOMATION][TTS] ì™„ë£Œ: {len(scene_metadata)}ê°œ ì”¬ (ë¹„ìš©: ${tts_cost:.3f})")
                return True
            except Exception as e:
                print(f"[AUTOMATION][TTS] ì˜¤ë¥˜: {e}")
                parallel_errors.append(f"TTS: {str(e)}")
                return False

        def generate_thumbnail():
            """ì¸ë„¤ì¼ ìƒì„± (ë³‘ë ¬ ì‘ì—… 3) - ëŒ€ë³¸ ë¶„ì„ì—ì„œ ìƒì„±ëœ ai_prompts ì‚¬ìš© (ì›¹íˆ° ìŠ¤íƒ€ì¼)"""
            nonlocal thumbnail_url, total_cost
            print(f"[AUTOMATION][THUMB] ì¸ë„¤ì¼ ìƒì„± ì‹œì‘...")
            try:
                # GPT-5.1ì´ ëŒ€ë³¸ ë¶„ì„ìœ¼ë¡œ ìë™ ê°ì§€í•œ ì¹´í…Œê³ ë¦¬ ì‚¬ìš©
                is_news = detected_category == 'news'
                print(f"[AUTOMATION][THUMB] GPT ê°ì§€ ì¹´í…Œê³ ë¦¬: {detected_category} â†’ {'ë‰´ìŠ¤' if is_news else 'ìŠ¤í† ë¦¬(ì›¹íˆ°)'} ìŠ¤íƒ€ì¼")

                # â˜… ë‰´ìŠ¤ ì¹´í…Œê³ ë¦¬: ìƒˆë¡œìš´ thumbnail êµ¬ì¡° í™œìš© (ì´ìŠˆ í•´ì„¤ ì±„ë„ìš©)
                news_thumbnail_text = thumbnail_data.get('text', {})
                news_image_spec = thumbnail_data.get('image_spec', {})
                news_keywords = thumbnail_data.get('keywords', {})

                if is_news and news_image_spec:
                    # ìƒˆë¡œìš´ ë‰´ìŠ¤ ì¸ë„¤ì¼ êµ¬ì¡° ì‚¬ìš©
                    print(f"[AUTOMATION][THUMB] ë‰´ìŠ¤ ì´ìŠˆ í•´ì„¤ ìŠ¤íƒ€ì¼ - ìƒˆ êµ¬ì¡° ì‚¬ìš©")

                    # image_specì—ì„œ ì„¤ì • ì¶”ì¶œ
                    has_face = news_image_spec.get('face', True)
                    scene_type = news_image_spec.get('scene', 'generic')
                    text_position = news_image_spec.get('text_position', 'left')
                    expression = news_image_spec.get('expression', 'serious')

                    # â˜… í…ìŠ¤íŠ¸ ì¶”ì¶œ (ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìì…ë ¥ > text.line1 > best_combo > ai_prompts.A > ì œëª©)
                    line1 = ''
                    line2 = ''

                    # 0. ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©
                    if user_thumbnail_text:
                        # ì¤„ë°”ê¿ˆìœ¼ë¡œ line1/line2 ë¶„ë¦¬
                        if '\n' in user_thumbnail_text:
                            parts = user_thumbnail_text.split('\n', 1)
                            line1 = parts[0].strip()
                            line2 = parts[1].strip() if len(parts) > 1 else ''
                        else:
                            line1 = user_thumbnail_text
                        print(f"[AUTOMATION][THUMB] â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ ì‚¬ìš©: '{line1}' / '{line2}'")
                    else:
                        line1 = news_thumbnail_text.get('line1', '')
                        line2 = news_thumbnail_text.get('line2', '')
                        if not line1 and best_combo:
                            line1 = best_combo.get('chosen_thumbnail_text', '')
                        if not line1 and ai_prompts and ai_prompts.get('A'):
                            line1 = ai_prompts['A'].get('text_overlay', {}).get('main', '')
                        if not line1:
                            # ìµœí›„ ìˆ˜ë‹¨: ì œëª©ì—ì„œ ì• 10ì ì‚¬ìš©
                            line1 = (title or '')[:10]

                    # í‚¤ì›Œë“œ ë¡œê¹…
                    if news_keywords:
                        print(f"[AUTOMATION][THUMB] í‚¤ì›Œë“œ: primary={news_keywords.get('primary', [])}, category={news_keywords.get('category_focus', '?')}")

                    # scene íƒ€ì…ë³„ ë°°ê²½ ì„¤ëª…
                    scene_backgrounds = {
                        'courtroom': 'courthouse or courtroom interior',
                        'document': 'official documents, papers, or certificates',
                        'chart': 'graphs, charts, or statistical data visualization',
                        'city': 'city street or urban landscape',
                        'office': 'government office or corporate building interior',
                        'generic': 'professional news studio background'
                    }
                    scene_desc = scene_backgrounds.get(scene_type, scene_backgrounds['generic'])

                    # í‘œì • ë§µí•‘ (ë‰´ìŠ¤ í•´ì„¤ìš© - ê³¼ì¥ ê¸ˆì§€)
                    expression_map = {
                        'serious': 'serious focused expression',
                        'worried': 'concerned worried expression',
                        'thinking': 'thoughtful contemplating expression',
                        'confused': 'puzzled confused expression',
                        'focused': 'attentive focused expression'
                    }
                    expression_desc = expression_map.get(expression, expression_map['serious'])

                    # í”„ë¡¬í”„íŠ¸ ìƒì„± (face ìœ ë¬´ì— ë”°ë¼ ë¶„ê¸°)
                    if has_face:
                        prompt = f"""Korean webtoon style illustration, 16:9 aspect ratio.
Korean webtoon character with {expression_desc} (NOT screaming, NOT exaggerated panic), 40-50 year old Korean man or woman in professional attire.
Clean bold outlines, {scene_desc} background.
Text space on {text_position} side (30% of frame).
Credible news explainer tone, NOT sensational.
NO extreme expression, NO text, NO letters, NO speech bubbles.
NO photorealistic, NO stickman."""
                    else:
                        prompt = f"""Korean webtoon style illustration, 16:9 aspect ratio.
{scene_desc.capitalize()}, dramatic but credible news tone.
Clean bold outlines, vibrant colors.
Text space on {text_position} side (30% of frame).
NO characters, focus on scene/objects.
NO text, NO letters, NO signs, NO readable text.
NO photorealistic."""

                    thumb_prompt = {
                        "prompt": prompt,
                        "text_overlay": {"main": line1, "sub": line2},
                        "style": "news"
                    }
                    print(f"[AUTOMATION][THUMB] ë‰´ìŠ¤ ì¸ë„¤ì¼: face={has_face}, scene={scene_type}, text='{line1}'")

                # GPTê°€ ìƒì„±í•œ ai_prompts.A ì‚¬ìš© (story/health ë“± ëª¨ë“  ì¹´í…Œê³ ë¦¬)
                elif ai_prompts and ai_prompts.get('A'):
                    thumb_prompt = ai_prompts.get('A').copy() if isinstance(ai_prompts.get('A'), dict) else ai_prompts.get('A')

                    # â˜… í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìì…ë ¥ > thumbnail_data.text > best_combo > ai_prompts.A.text_overlay > ì œëª©
                    final_line1 = ''
                    final_line2 = ''

                    # 0. ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ê°€ ìˆìœ¼ë©´ ìµœìš°ì„  ì‚¬ìš©
                    if user_thumbnail_text:
                        # ì¤„ë°”ê¿ˆìœ¼ë¡œ line1/line2 ë¶„ë¦¬
                        if '\n' in user_thumbnail_text:
                            parts = user_thumbnail_text.split('\n', 1)
                            final_line1 = parts[0].strip()
                            final_line2 = parts[1].strip() if len(parts) > 1 else ''
                        else:
                            final_line1 = user_thumbnail_text
                        print(f"[AUTOMATION][THUMB] â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ ì‚¬ìš©: '{final_line1}' / '{final_line2}'")
                    # 1. thumbnail_data.textì—ì„œ ì¶”ì¶œ (news, story, health ì¹´í…Œê³ ë¦¬ì—ì„œ GPTê°€ ìƒì„±)
                    elif news_thumbnail_text.get('line1'):
                        final_line1 = news_thumbnail_text.get('line1', '')
                        final_line2 = news_thumbnail_text.get('line2', '')
                        print(f"[AUTOMATION][THUMB] thumbnail_data.text í…ìŠ¤íŠ¸ ì ìš©: '{final_line1}' / '{final_line2}'")
                    # 2. best_comboì—ì„œ ì„ íƒëœ í…ìŠ¤íŠ¸
                    elif best_combo and best_combo.get('chosen_thumbnail_text'):
                        chosen_text = best_combo.get('chosen_thumbnail_text', '')
                        if '\\n' in chosen_text:
                            parts = chosen_text.split('\\n', 1)
                            final_line1 = parts[0]
                            final_line2 = parts[1] if len(parts) > 1 else ''
                        else:
                            final_line1 = chosen_text
                        print(f"[AUTOMATION][THUMB] best_combo í…ìŠ¤íŠ¸ ì ìš©: '{chosen_text}'")
                    # 3. ai_prompts.A.text_overlay
                    elif isinstance(thumb_prompt, dict) and thumb_prompt.get('text_overlay', {}).get('main'):
                        final_line1 = thumb_prompt.get('text_overlay', {}).get('main', '')
                        final_line2 = thumb_prompt.get('text_overlay', {}).get('sub', '')
                        print(f"[AUTOMATION][THUMB] ai_prompts.A.text_overlay í…ìŠ¤íŠ¸ ì ìš©: '{final_line1}'")
                    # 4. í´ë°±: ì œëª©
                    else:
                        final_line1 = (title or '')[:10]
                        print(f"[AUTOMATION][THUMB] í´ë°±: ì œëª© í…ìŠ¤íŠ¸ ì ìš©: '{final_line1}'")

                    # text_overlay ì„¤ì •
                    if isinstance(thumb_prompt, dict):
                        thumb_prompt['text_overlay'] = {'main': final_line1, 'sub': final_line2}

                    print(f"[AUTOMATION][THUMB] GPT ìƒì„± í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ì¹´í…Œê³ ë¦¬: {detected_category}, ìŠ¤íƒ€ì¼: {thumb_prompt.get('style', 'unknown') if isinstance(thumb_prompt, dict) else 'unknown'})")
                elif is_news:
                    # í´ë°±: ë‰´ìŠ¤ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ (ìƒˆ êµ¬ì¡° ì—†ì„ ë•Œ)
                    print(f"[AUTOMATION][THUMB] í´ë°±: ë‰´ìŠ¤ ì›¹íˆ° ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸")
                    # â˜… í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìì…ë ¥ > thumbnail_data.text > best_combo > ai_prompts.A > ì œëª©
                    fallback_text = ''
                    fallback_sub = ''
                    if user_thumbnail_text:
                        if '\n' in user_thumbnail_text:
                            parts = user_thumbnail_text.split('\n', 1)
                            fallback_text = parts[0].strip()
                            fallback_sub = parts[1].strip() if len(parts) > 1 else ''
                        else:
                            fallback_text = user_thumbnail_text
                        print(f"[AUTOMATION][THUMB] â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ ì‚¬ìš©: '{fallback_text}'")
                    elif news_thumbnail_text.get('line1'):
                        fallback_text = news_thumbnail_text.get('line1', '')
                        fallback_sub = news_thumbnail_text.get('line2', '')
                    elif best_combo:
                        fallback_text = best_combo.get('chosen_thumbnail_text', '')
                    if not fallback_text and ai_prompts and ai_prompts.get('A'):
                        fallback_text = ai_prompts['A'].get('text_overlay', {}).get('main', '')
                    if not fallback_text:
                        fallback_text = (title or '')[:20]  # í´ë°±: ì œëª© (20ì)
                    thumb_prompt = {
                        "prompt": "Korean webtoon style YouTube thumbnail, 16:9 aspect ratio. Korean webtoon character with SERIOUS FOCUSED expression (NOT screaming), 40-50 year old Korean man in suit. Clean bold outlines, news studio background. Text space on left side. Credible news explainer tone. NO photorealistic, NO stickman.",
                        "text_overlay": {"main": fallback_text, "sub": fallback_sub},
                        "style": "news"
                    }
                else:
                    # í´ë°±: ì›¹íˆ° ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸
                    print(f"[AUTOMATION][THUMB] í´ë°±: ì›¹íˆ° ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸")
                    # â˜… í…ìŠ¤íŠ¸ ìš°ì„ ìˆœìœ„: ì‚¬ìš©ìì…ë ¥ > thumbnail_data.text > best_combo > ai_prompts.A > ì œëª©
                    fallback_text = ''
                    fallback_sub = ''
                    if user_thumbnail_text:
                        if '\n' in user_thumbnail_text:
                            parts = user_thumbnail_text.split('\n', 1)
                            fallback_text = parts[0].strip()
                            fallback_sub = parts[1].strip() if len(parts) > 1 else ''
                        else:
                            fallback_text = user_thumbnail_text
                        print(f"[AUTOMATION][THUMB] â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ ì‚¬ìš©: '{fallback_text}'")
                    elif news_thumbnail_text.get('line1'):
                        fallback_text = news_thumbnail_text.get('line1', '')
                        fallback_sub = news_thumbnail_text.get('line2', '')
                    elif best_combo:
                        fallback_text = best_combo.get('chosen_thumbnail_text', '')
                    if not fallback_text and ai_prompts and ai_prompts.get('A'):
                        fallback_text = ai_prompts['A'].get('text_overlay', {}).get('main', '')
                    if not fallback_text:
                        fallback_text = (title or '')[:20]  # í´ë°±: ì œëª© (20ì)

                    # â˜… thumbnail_data.image_promptê°€ ìˆìœ¼ë©´ ì‚¬ìš©, ì—†ìœ¼ë©´ ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
                    base_prompt = thumbnail_data.get('image_prompt', '')
                    if base_prompt and len(base_prompt) > 50:
                        # GPTê°€ ìƒì„±í•œ image_promptë¥¼ ì›¹íˆ° ìŠ¤íƒ€ì¼ë¡œ ë³€í™˜
                        thumb_prompt = {
                            "prompt": f"Korean WEBTOON style YouTube thumbnail based on: {base_prompt}. Style: Korean webtoon/manhwa illustration, exaggerated expression, clean bold outlines, vibrant colors, comic style. NO photorealistic, NO stickman. 16:9 aspect ratio.",
                            "text_overlay": {"main": fallback_text, "sub": fallback_sub}
                        }
                        print(f"[AUTOMATION][THUMB] thumbnail_data.image_prompt ì‚¬ìš©: {base_prompt[:80]}...")
                    else:
                        thumb_prompt = {
                            "prompt": "Korean WEBTOON style YouTube thumbnail, 16:9 aspect ratio. Korean webtoon/manhwa style character with EXTREMELY EXAGGERATED SHOCKED EXPRESSION - eyes 2x larger than normal with visible whites, mouth WIDE OPEN showing teeth, eyebrows raised extremely high, multiple sweat drops, hands on cheeks in disbelief. Clean bold outlines, vibrant flat colors. Comic-style expression marks, impact lines radiating from face. NO photorealistic, NO stickman, NO calm face, NO neutral expression.",
                            "text_overlay": {"main": fallback_text, "sub": fallback_sub}
                        }

                thumb_resp = req.post(f"{base_url}/api/thumbnail-ai/generate-single", json={
                    "session_id": f"thumb_{session_id}",
                    "prompt": thumb_prompt,
                    "category": detected_category,
                    "lang": detected_lang
                }, timeout=180)

                thumb_data = thumb_resp.json()
                if thumb_data.get('ok') and thumb_data.get('image_url'):
                    thumbnail_url = thumb_data['image_url']
                    total_cost += 0.03
                    print(f"[AUTOMATION][THUMB] ì™„ë£Œ (ë¹„ìš©: $0.03)")
                    return thumbnail_url
                else:
                    print(f"[AUTOMATION][THUMB] ì‹¤íŒ¨: {thumb_data.get('error', 'ì•Œ ìˆ˜ ì—†ìŒ')}")
                    return None
            except Exception as e:
                print(f"[AUTOMATION][THUMB] ì˜¤ë¥˜: {e}")
                return None

        # â˜… TTS ë¨¼ì € ì‹¤í–‰ (ì €ë¹„ìš©, ì‹¤íŒ¨ ì‹œ ì´ë¯¸ì§€ ìƒì„± ë¹„ìš© ì ˆì•½)
        print(f"[AUTOMATION] 2a. TTS ìƒì„± ì‹œì‘ (ì´ë¯¸ì§€ë³´ë‹¤ ë¨¼ì € ì‹¤í–‰)...", flush=True)
        tts_success = generate_tts()

        # TTS ì‹¤íŒ¨ ì‹œ ì¦‰ì‹œ ì¤‘ë‹¨ (ë¹„ì‹¼ ì´ë¯¸ì§€ ìƒì„± ë°©ì§€)
        if not tts_success or not any(s.get('audio_url') for s in scenes):
            return {"ok": False, "error": f"TTS ìƒì„± ì‹¤íŒ¨: {'; '.join(parallel_errors)}", "video_url": None, "cost": total_cost}

        print(f"[AUTOMATION] 2b. TTS ì„±ê³µ, ì´ë¯¸ì§€/ì¸ë„¤ì¼ ë³‘ë ¬ ìƒì„± ì‹œì‘...", flush=True)

        # TTS ì„±ê³µ í›„ ì´ë¯¸ì§€/ì¸ë„¤ì¼ ë³‘ë ¬ ì‹¤í–‰
        with ThreadPoolExecutor(max_workers=2) as executor:
            futures = {
                executor.submit(generate_images): "images",
                executor.submit(generate_thumbnail): "thumbnail"
            }

            for future in as_completed(futures):
                task_name = futures[future]
                try:
                    result = future.result()
                    print(f"[AUTOMATION] ë³‘ë ¬ ì‘ì—… ì™„ë£Œ: {task_name}")
                except Exception as e:
                    print(f"[AUTOMATION] ë³‘ë ¬ ì‘ì—… ì‹¤íŒ¨: {task_name} - {e}")
                    parallel_errors.append(f"{task_name}: {str(e)}")

        # ì´ë¯¸ì§€ ì‹¤íŒ¨ ì‹œ ì¤‘ë‹¨ (ìµœì†Œ 1ê°œ ì´ìƒ í•„ìš”)
        image_success_count = len([s for s in scenes if s.get('image_url')])
        if image_success_count == 0:
            return {"ok": False, "error": f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: ëª¨ë“  ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤", "video_url": None, "cost": total_cost}
        elif image_success_count < len(scenes):
            print(f"[AUTOMATION] ê²½ê³ : ì´ë¯¸ì§€ {image_success_count}/{len(scenes)}ê°œë§Œ ìƒì„±ë¨")

        print(f"[AUTOMATION] 2. ë³‘ë ¬ ì²˜ë¦¬ ì™„ë£Œ", flush=True)

        # ========== 3. ì˜ìƒ ìƒì„± (/api/image/generate-video) ==========
        print(f"[AUTOMATION] 3. ì˜ìƒ ìƒì„± ì‹œì‘...", flush=True)

        video_url_local = None
        video_generation_error = None
        max_video_retries = 2  # ìµœëŒ€ 2ë²ˆ ì‹œë„ (ì‹¤íŒ¨ ì‹œ 1íšŒ ì¬ì‹œë„)

        for video_attempt in range(max_video_retries):
            try:
                if video_attempt > 0:
                    print(f"[AUTOMATION] 3. ì˜ìƒ ìƒì„± ì¬ì‹œë„ ({video_attempt + 1}/{max_video_retries}) - 3ë¶„ í›„ ì‹œì‘...")
                    time_module.sleep(180)  # ì¬ì‹œë„ ì „ 3ë¶„ ëŒ€ê¸°

                video_resp = req.post(f"{base_url}/api/image/generate-video", json={
                    "session_id": session_id,
                    "scenes": scenes,
                    "language": "ko",  # í•œê¸€ ìë§‰ìš© NanumGothic í°íŠ¸ ì ìš©
                    "video_effects": video_effects  # ìƒˆ ê¸°ëŠ¥: BGM, íš¨ê³¼ìŒ, ìë§‰ ê°•ì¡°, Ken Burns ë“±
                }, timeout=600)

                video_data = video_resp.json()
                if not video_data.get('ok') and not video_data.get('job_id'):
                    video_generation_error = f"ì˜ìƒ ìƒì„± ì‹œì‘ ì‹¤íŒ¨: {video_data.get('error')}"
                    print(f"[AUTOMATION] 3. ì‹œë„ {video_attempt + 1} ì‹¤íŒ¨: {video_generation_error}")
                    continue  # ì¬ì‹œë„

                job_id = video_data.get('job_id')

                # ì˜ìƒ ìƒì„± ì™„ë£Œ ëŒ€ê¸° (í´ë§) - 40ë¶„ ëŒ€ê¸°
                # 10ë¶„ ì˜ìƒì— ~20ë¶„ ì†Œìš”ë˜ë¯€ë¡œ ì—¬ìœ ìˆê²Œ 40ë¶„
                for _ in range(1200):  # 1200 * 2ì´ˆ = 40ë¶„
                    time_module.sleep(2)
                    status_resp = req.get(f"{base_url}/api/image/video-status/{job_id}", timeout=30)
                    status_data = status_resp.json()

                    if status_data.get('status') == 'completed':
                        video_url_local = status_data.get('video_url')
                        break
                    elif status_data.get('status') == 'failed':
                        video_generation_error = f"ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {status_data.get('error')}"
                        print(f"[AUTOMATION] 3. ì‹œë„ {video_attempt + 1} ì‹¤íŒ¨: {video_generation_error}")
                        break  # ë‚´ë¶€ ë£¨í”„ íƒˆì¶œ, ì¬ì‹œë„

                if video_url_local:
                    print(f"[AUTOMATION] 3. ì™„ë£Œ: {video_url_local} (ì˜ìƒ ìƒì„±ì€ ë¬´ë£Œ)")
                    break  # ì„±ê³µ, ë£¨í”„ íƒˆì¶œ
                elif not video_generation_error:
                    video_generation_error = "ì˜ìƒ ìƒì„± íƒ€ì„ì•„ì›ƒ (40ë¶„ ì´ˆê³¼)"
                    print(f"[AUTOMATION] 3. ì‹œë„ {video_attempt + 1} ì‹¤íŒ¨: {video_generation_error}")

            except Exception as e:
                import traceback
                traceback.print_exc()
                video_generation_error = f"ì˜ìƒ ìƒì„± ì˜¤ë¥˜: {str(e)}"
                print(f"[AUTOMATION] 3. ì‹œë„ {video_attempt + 1} ì˜ˆì™¸: {video_generation_error}")

        # ëª¨ë“  ì‹œë„ í›„ì—ë„ ì‹¤íŒ¨í•˜ë©´ ì—ëŸ¬ ë°˜í™˜
        if not video_url_local:
            return {"ok": False, "error": video_generation_error or "ì˜ìƒ ìƒì„± ì‹¤íŒ¨", "video_url": None, "cost": total_cost}

        # ========== 4. YouTube ì—…ë¡œë“œ ==========
        print(f"[AUTOMATION] 4. YouTube ì—…ë¡œë“œ ì‹œì‘...", flush=True)

        # GPTê°€ ìƒì„±í•œ ì˜ˆìƒ ì±•í„° ì œê±° (ì‹¤ì œ duration ê¸°ë°˜ ì±•í„°ë¡œ ëŒ€ì²´)
        # ì˜ˆìƒ ì±•í„°ëŠ” "00:00 ì œëª©" ë˜ëŠ” "0:00 ì œëª©" í˜•ì‹ì˜ ì—°ì†ëœ ì¤„ë¡œ ì‹œì‘í•¨
        try:
            import re
            # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì‹œì‘í•˜ëŠ” ì—°ì†ëœ ì¤„ë“¤ì„ ì°¾ì•„ì„œ ì œê±° (ì˜ˆìƒ ì±•í„° ì„¹ì…˜)
            # íŒ¨í„´: ìˆ«ì:ìˆ«ì ë˜ëŠ” ìˆ«ì:ìˆ«ì:ìˆ«ìë¡œ ì‹œì‘í•˜ëŠ” ì¤„
            lines = description.split('\n')
            cleaned_lines = []
            in_chapter_section = False
            consecutive_timestamps = 0

            for i, line in enumerate(lines):
                stripped = line.strip()
                # íƒ€ì„ìŠ¤íƒ¬í”„ë¡œ ì‹œì‘í•˜ëŠ”ì§€ í™•ì¸ (0:00, 00:00, 1:30 ë“±)
                is_timestamp_line = bool(re.match(r'^\d{1,2}:\d{2}(?::\d{2})?\s', stripped))

                if is_timestamp_line:
                    consecutive_timestamps += 1
                    # ì—°ì†ìœ¼ë¡œ 3ê°œ ì´ìƒ íƒ€ì„ìŠ¤íƒ¬í”„ ì¤„ì´ë©´ ì±•í„° ì„¹ì…˜ìœ¼ë¡œ ê°„ì£¼
                    if consecutive_timestamps >= 3:
                        in_chapter_section = True
                        # ì´ì „ì— ì¶”ê°€í•œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¤„ë“¤ë„ ì œê±°
                        while cleaned_lines and re.match(r'^\d{1,2}:\d{2}(?::\d{2})?\s', cleaned_lines[-1].strip()):
                            cleaned_lines.pop()
                    if not in_chapter_section:
                        cleaned_lines.append(line)
                else:
                    consecutive_timestamps = 0
                    if in_chapter_section:
                        # ë¹ˆ ì¤„ì´ë©´ ì±•í„° ì„¹ì…˜ ì¢…ë£Œ
                        if not stripped:
                            in_chapter_section = False
                        # íƒ€ì„ìŠ¤íƒ¬í”„ê°€ ì•„ë‹Œ ì¤„ì´ ì˜¤ë©´ ì±•í„° ì„¹ì…˜ ì¢…ë£Œ
                        else:
                            in_chapter_section = False
                            cleaned_lines.append(line)
                    else:
                        cleaned_lines.append(line)

            description = '\n'.join(cleaned_lines)
            print(f"[AUTOMATION] GPT ì˜ˆìƒ ì±•í„° ì œê±° ì™„ë£Œ (ì‹¤ì œ duration ê¸°ë°˜ ì±•í„°ë¡œ ëŒ€ì²´)")
        except Exception as clean_err:
            print(f"[AUTOMATION] ì±•í„° ì •ë¦¬ ì˜¤ë¥˜ (ë¬´ì‹œë¨): {clean_err}")

        # ìë™ ì±•í„° ìƒì„± (ì”¬ë³„ chapter_titleê³¼ duration ê¸°ë°˜)
        try:
            chapters_text = "\n\nğŸ“‘ ì±•í„°\n"
            current_time = 0
            has_chapters = False
            for idx, scene in enumerate(scenes):
                chapter_title = scene.get('chapter_title', '')
                scene_duration = scene.get('duration', 0)
                if chapter_title:
                    has_chapters = True
                    # íƒ€ì„ìŠ¤íƒ¬í”„ í˜•ì‹: M:SS ë˜ëŠ” H:MM:SS
                    minutes = int(current_time // 60)
                    seconds = int(current_time % 60)
                    if minutes >= 60:
                        hours = minutes // 60
                        minutes = minutes % 60
                        timestamp = f"{hours}:{minutes:02d}:{seconds:02d}"
                    else:
                        timestamp = f"{minutes}:{seconds:02d}"
                    chapters_text += f"{timestamp} {chapter_title}\n"
                current_time += scene_duration

            if has_chapters:
                description = description + chapters_text
                print(f"[AUTOMATION] ìë™ ì±•í„° ìƒì„± ì™„ë£Œ ({len([s for s in scenes if s.get('chapter_title')])}ê°œ)")
        except Exception as chapter_err:
            print(f"[AUTOMATION] ì±•í„° ìƒì„± ì˜¤ë¥˜ (ë¬´ì‹œë¨): {chapter_err}")

        # í•´ì‹œíƒœê·¸ë¥¼ ì„¤ëª…ë€ ëì— ì¶”ê°€
        if hashtags and len(hashtags) > 0:
            hashtags_text = "\n\n" + " ".join(hashtags)
            description = description + hashtags_text
            print(f"[AUTOMATION] í•´ì‹œíƒœê·¸ ì¶”ê°€: {' '.join(hashtags)}")

        # â˜… ì¸ìš©ë§í¬ ì¶”ê°€ (ì‚¬ìš©ì ìˆ˜ë™ ì…ë ¥ - ì‹œíŠ¸ì—ì„œ ê°€ì ¸ì˜´)
        if citation_links:
            description = description + "\n\n" + citation_links
            print(f"[AUTOMATION] â˜… ì¸ìš©ë§í¬ ì¶”ê°€ ì™„ë£Œ ({len(citation_links)}ì)")

        # [TUBELENS] ì„¤ëª…ë€ SEO ìµœì í™” (CTA ìë™ ì¶”ê°€)
        try:
            description = enhance_description_for_youtube(description, title, hashtags, lang=detected_lang)
            print(f"[TUBELENS] ì„¤ëª…ë€ CTA ì¶”ê°€ ì™„ë£Œ (ì´ {len(description)}ì, lang={detected_lang})")
        except Exception as cta_err:
            print(f"[TUBELENS] ì„¤ëª…ë€ CTA ì¶”ê°€ ì‹¤íŒ¨ (ë¬´ì‹œ): {cta_err}")

        try:
            # [ìµœì í™”] public + ì˜ˆì•½ì‹œê°„ ì—†ìŒ = 15ë¶„ í›„ ê³µê°œ (YouTube ì²˜ë¦¬ ìµœì í™” + ì‡¼ì¸  ìƒì„± ëŒ€ê¸°)
            delayed_publish = False
            actual_visibility = visibility
            publish_at_iso = None

            if visibility.lower() == 'public' and not publish_time:
                from datetime import datetime, timedelta
                # 15ë¶„ í›„ ê³µê°œë¡œ ì„¤ì •
                publish_later = datetime.utcnow() + timedelta(minutes=15)
                publish_at_iso = publish_later.strftime("%Y-%m-%dT%H:%M:%S.000Z")
                actual_visibility = 'private'  # ë¨¼ì € ë¹„ê³µê°œë¡œ ì—…ë¡œë“œ
                delayed_publish = True
                print(f"[AUTOMATION] ğŸ• 15ë¶„ í›„ ê³µê°œ ì„¤ì • (YouTube ìµœì í™” + ì‡¼ì¸  ëŒ€ê¸°)")
                print(f"[AUTOMATION]    - ì—…ë¡œë“œ: private -> 15ë¶„ í›„ public")
                print(f"[AUTOMATION]    - ê³µê°œ ì˜ˆì •: {publish_later.strftime('%Y-%m-%d %H:%M')} UTC")

            upload_payload = {
                "videoPath": video_url_local,
                "title": title,
                "description": description,
                "privacyStatus": actual_visibility,
                "channelId": channel_id,
                "projectSuffix": selected_project  # í• ë‹¹ëŸ‰ ì²´í¬ì—ì„œ ê²°ì •ëœ í”„ë¡œì íŠ¸ ì‚¬ìš©
            }

            # 15ë¶„ í›„ ê³µê°œ ì„¤ì •
            if delayed_publish and publish_at_iso:
                upload_payload["publish_at"] = publish_at_iso

            # ì¸ë„¤ì¼ì´ ìˆìœ¼ë©´ ì¶”ê°€
            if thumbnail_url:
                upload_payload["thumbnailPath"] = thumbnail_url

            # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDê°€ ìˆìœ¼ë©´ ì¶”ê°€
            if playlist_id:
                upload_payload["playlistId"] = playlist_id
                print(f"[AUTOMATION] í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€ ì˜ˆì •: {playlist_id}")

            # GPT-5.1 ìƒì„± íƒœê·¸ ì¶”ê°€
            if tags and len(tags) > 0:
                upload_payload["tags"] = tags
                print(f"[AUTOMATION] YouTube íƒœê·¸ {len(tags)}ê°œ ì¶”ê°€")

            # ê³ ì • ëŒ“ê¸€ ì¶”ê°€ (GPT-5.1 ìƒì„± pin_comment ì‚¬ìš©)
            # pin_commentëŠ” youtube_metaì—ì„œ ì¶”ì¶œë¨ (video_effects.first_comment ëŒ€ì‹ )
            if pin_comment and pin_comment.strip():
                upload_payload["firstComment"] = pin_comment
                print(f"[AUTOMATION] ê³ ì • ëŒ“ê¸€ ì „ë‹¬: {pin_comment[:50]}...")

            # ì˜ˆì•½ì‹œê°„(Eì—´)ì´ ìˆìœ¼ë©´ ISO 8601 í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ì¶”ê°€ (15ë¶„ í›„ ê³µê°œë³´ë‹¤ ìš°ì„ )
            if publish_time:
                try:
                    from datetime import datetime
                    import re

                    # ë‹¤ì–‘í•œ í˜•ì‹ ì§€ì›: "2024-12-06 15:00", "2024/12/06 15:00", "12/06 15:00" ë“±
                    publish_time_str = str(publish_time).strip()

                    # ì´ë¯¸ ISO 8601 í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    if 'T' in publish_time_str and publish_time_str.endswith('Z'):
                        publish_at_iso = publish_time_str
                    else:
                        # ì¼ë°˜ì ì¸ ë‚ ì§œ í˜•ì‹ íŒŒì‹± ì‹œë„
                        parsed_dt = None
                        formats_to_try = [
                            "%Y-%m-%d %H:%M:%S",
                            "%Y-%m-%d %H:%M",
                            "%Y/%m/%d %H:%M:%S",
                            "%Y/%m/%d %H:%M",
                            "%m/%d %H:%M",  # ì›”/ì¼ë§Œ ìˆìœ¼ë©´ í˜„ì¬ ì—°ë„ ì‚¬ìš©
                            "%m-%d %H:%M",
                        ]

                        for fmt in formats_to_try:
                            try:
                                parsed_dt = datetime.strptime(publish_time_str, fmt)
                                # ì—°ë„ê°€ ì—†ëŠ” í˜•ì‹ì´ë©´ í˜„ì¬ ì—°ë„ ì¶”ê°€
                                if parsed_dt.year == 1900:
                                    parsed_dt = parsed_dt.replace(year=datetime.now().year)
                                break
                            except ValueError:
                                continue

                        if parsed_dt:
                            # UTCë¡œ ë³€í™˜ (í•œêµ­ ì‹œê°„ì€ UTC+9)
                            # ì‹œíŠ¸ì— ì…ë ¥ëœ ì‹œê°„ì´ í•œêµ­ ì‹œê°„ì´ë¼ê³  ê°€ì •
                            from datetime import timedelta
                            utc_dt = parsed_dt - timedelta(hours=9)
                            publish_at_iso = utc_dt.strftime("%Y-%m-%dT%H:%M:%S.000Z")
                        else:
                            print(f"[AUTOMATION] ì˜ˆì•½ì‹œê°„ íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸: {publish_time_str}")
                            publish_at_iso = None

                    if publish_at_iso:
                        upload_payload["publish_at"] = publish_at_iso
                        # ì˜ˆì•½ ì—…ë¡œë“œ ì‹œ privacyStatusëŠ” APIì—ì„œ ìë™ìœ¼ë¡œ privateë¡œ ì„¤ì •ë¨
                        print(f"[AUTOMATION] ì˜ˆì•½ ì—…ë¡œë“œ ì„¤ì •: {publish_time_str} -> {publish_at_iso}")
                except Exception as parse_err:
                    print(f"[AUTOMATION] ì˜ˆì•½ì‹œê°„ ì²˜ë¦¬ ì˜¤ë¥˜: {parse_err}")

            upload_resp = req.post(f"{base_url}/api/youtube/upload", json=upload_payload, timeout=600)

            print(f"[AUTOMATION] YouTube ì—…ë¡œë“œ ì‘ë‹µ ìƒíƒœ: {upload_resp.status_code}")
            upload_data = upload_resp.json()
            print(f"[AUTOMATION] YouTube ì—…ë¡œë“œ ì‘ë‹µ: ok={upload_data.get('ok')}, mode={upload_data.get('mode', 'N/A')}, videoUrl={upload_data.get('videoUrl', 'N/A')[:50] if upload_data.get('videoUrl') else 'N/A'}")

            # í…ŒìŠ¤íŠ¸ ëª¨ë“œ ê°ì§€ (ì‹¤ì œ ì—…ë¡œë“œ ì•ˆë¨)
            if upload_data.get('mode') == 'test':
                error_msg = "YouTube í† í°ì´ ì—†ì–´ í…ŒìŠ¤íŠ¸ ëª¨ë“œë¡œ ì‹¤í–‰ë¨. OAuth ë¡œê·¸ì¸ í•„ìš”."
                print(f"[AUTOMATION][ERROR] {error_msg}")
                sheets_update_cell(row_num, COL_STATUS, 'ì‹¤íŒ¨')
                sheets_update_cell(row_num, COL_ERROR, error_msg)
                return {"ok": False, "error": error_msg, "needsAuth": True}

            # OAuth ì¸ì¦ í•„ìš” ì—ëŸ¬ ì²˜ë¦¬
            if upload_data.get('needsAuth'):
                error_msg = upload_data.get('error', 'YouTube OAuth ë¡œê·¸ì¸ í•„ìš”')
                print(f"[AUTOMATION][ERROR] {error_msg}")
                sheets_update_cell(row_num, COL_STATUS, 'ì‹¤íŒ¨')
                sheets_update_cell(row_num, COL_ERROR, error_msg)
                return {"ok": False, "error": error_msg, "needsAuth": True}

            if upload_data.get('ok'):
                youtube_url = upload_data.get('videoUrl', '')  # camelCaseë¡œ ë°˜í™˜ë¨
                video_id = upload_data.get('videoId', '')
                print(f"[AUTOMATION] 4. ì™„ë£Œ: {youtube_url} (ì´ ë¹„ìš©: ${total_cost:.2f})")

                # ========== 5. ì‡¼ì¸  ë°±ê·¸ë¼ìš´ë“œ ìƒì„± (í˜„ì¬ ë¹„í™œì„±í™”) ==========
                # TODO: ì‡¼ì¸  í’ˆì§ˆ ê°œì„  í›„ ë‹¤ì‹œ í™œì„±í™”
                # ë¡±í¼ì´ ë” ì¤‘ìš”í•˜ë¯€ë¡œ ë¨¼ì € ê²°ê³¼ë¥¼ ë°˜í™˜í•˜ê³ , ì‡¼ì¸ ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬
                SHORTS_ENABLED = False  # ì‡¼ì¸  ìƒì„± ë¹„í™œì„±í™” (2025-12-09)

                if SHORTS_ENABLED:
                    shorts_info = video_effects.get('shorts', {})
                    highlight_scenes_nums = shorts_info.get('highlight_scenes', [])

                    # highlight_scenesê°€ ë¹„ì–´ìˆìœ¼ë©´ ê¸°ë³¸ê°’ìœ¼ë¡œ ì²˜ìŒ 2-3ê°œ ì”¬ ì„ íƒ
                    if not highlight_scenes_nums or len(highlight_scenes_nums) == 0:
                        total_scenes_count = len(scenes) if scenes else 0
                        if total_scenes_count >= 3:
                            mid = total_scenes_count // 2
                            highlight_scenes_nums = [1, mid, total_scenes_count]
                        elif total_scenes_count >= 2:
                            highlight_scenes_nums = [1, total_scenes_count]
                        elif total_scenes_count == 1:
                            highlight_scenes_nums = [1]
                else:
                    highlight_scenes_nums = []
                    print(f"[AUTOMATION] 5. ì‡¼ì¸  ìƒì„± ë¹„í™œì„±í™”ë¨ (SHORTS_ENABLED=False)")

                if highlight_scenes_nums and len(highlight_scenes_nums) > 0:
                    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ì‡¼ì¸  ìƒì„±
                    def generate_shorts_background():
                        # FFmpeg ì„¸ë§ˆí¬ì–´ íšë“ (ë‹¤ë¥¸ FFmpeg ì‘ì—…ê³¼ ë™ì‹œ ì‹¤í–‰ ë°©ì§€)
                        print(f"[SHORTS-BG] FFmpeg ì„¸ë§ˆí¬ì–´ ëŒ€ê¸° ì¤‘...")
                        ffmpeg_semaphore.acquire()
                        print(f"[SHORTS-BG] FFmpeg ì„¸ë§ˆí¬ì–´ íšë“, ì‡¼ì¸  ìƒì„± ì‹œì‘...")
                        try:
                            import requests as bg_req

                            # í•˜ì´ë¼ì´íŠ¸ ë‚˜ë ˆì´ì…˜ ì¶”ì¶œ
                            highlight_narrations = []
                            for scene_num in highlight_scenes_nums:
                                if 1 <= scene_num <= len(scenes):
                                    narration = scenes[scene_num - 1].get('narration', '')
                                    if narration:
                                        clean_narration = re.sub(r'<[^>]+>', '', narration)
                                        highlight_narrations.append(clean_narration)

                            if not highlight_narrations:
                                print(f"[SHORTS-BG] í•˜ì´ë¼ì´íŠ¸ ë‚˜ë ˆì´ì…˜ ì—†ìŒ, ìŠ¤í‚µ")
                                return

                            print(f"[SHORTS-BG] í•˜ì´ë¼ì´íŠ¸ ë‚˜ë ˆì´ì…˜ {len(highlight_narrations)}ê°œ ì¶”ì¶œ")

                            # GPT-5.1ë¡œ ì‡¼ì¸  ì½˜í…ì¸  ë¶„ì„
                            shorts_analysis = _analyze_shorts_content_gpt(
                                highlight_narrations=highlight_narrations,
                                title=title,
                                detected_category=detected_category,
                                audience=audience,
                                duration_target=45
                            )

                            if not shorts_analysis:
                                print(f"[SHORTS-BG] ì‡¼ì¸  ë¶„ì„ ì‹¤íŒ¨")
                                return

                            # beats ìœ„ì¹˜: result.beats ë˜ëŠ” result.structure.beats
                            beats = shorts_analysis.get("beats", []) or shorts_analysis.get("structure", {}).get("beats", [])
                            print(f"[SHORTS-BG] ì‡¼ì¸  ë¶„ì„ ì™„ë£Œ: {len(beats)}ê°œ beats")

                            # ì‡¼ì¸  ì œëª© ë° í•´ì‹œíƒœê·¸ ì¶”ì¶œ
                            platform_info = shorts_analysis.get("platform_specific", {}).get("youtube_shorts", {})
                            shorts_title = platform_info.get("title_suggestion", "") or shorts_info.get('title', f"{title} #Shorts")

                            # ì‡¼ì¸  í•´ì‹œíƒœê·¸: GPT ë¶„ì„ ê²°ê³¼ > ë©”ì¸ ì˜ìƒ í•´ì‹œíƒœê·¸ > ê¸°ë³¸ê°’
                            shorts_hashtags = platform_info.get("hashtags_hint", [])
                            if not shorts_hashtags or shorts_hashtags == ["#Shorts", "#ìœ íŠœë¸Œì‡¼ì¸ "]:
                                # ë©”ì¸ ì˜ìƒì˜ í•´ì‹œíƒœê·¸ í™œìš© + #Shorts ì¶”ê°€
                                if hashtags and len(hashtags) > 0:
                                    # ë©”ì¸ ì˜ìƒ í•´ì‹œíƒœê·¸ ì¤‘ ìµœëŒ€ 5ê°œ + #Shorts
                                    shorts_hashtags = ["#Shorts"] + [h for h in hashtags[:5] if h != "#Shorts"]
                                    print(f"[SHORTS-BG] ë©”ì¸ ì˜ìƒ í•´ì‹œíƒœê·¸ í™œìš©: {shorts_hashtags}")
                                else:
                                    # ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œí•˜ì—¬ í•´ì‹œíƒœê·¸ ìƒì„±
                                    title_keywords = [w for w in title.replace(",", " ").replace(".", " ").split() if len(w) >= 2][:3]
                                    shorts_hashtags = ["#Shorts"] + [f"#{kw}" for kw in title_keywords if not kw.startswith("#")]
                                    print(f"[SHORTS-BG] ì œëª© ê¸°ë°˜ í•´ì‹œíƒœê·¸ ìƒì„±: {shorts_hashtags}")

                            # ë©”ì¸ ì˜ìƒì˜ ì”¬ ì´ë¯¸ì§€ URL ì¶”ì¶œ (ì‡¼ì¸ ìš© í¬ë¡­ì— ì‚¬ìš©)
                            scene_image_urls = [s.get('image_url', '') for s in scenes if s.get('image_url')]
                            print(f"[SHORTS-BG] ë©”ì¸ ì˜ìƒ ì´ë¯¸ì§€ {len(scene_image_urls)}ê°œ ì‚¬ìš© ê°€ëŠ¥")

                            # ì‡¼ì¸  ì˜ìƒ ìƒì„±
                            shorts_output_path = os.path.join("uploads", f"shorts_{session_id}.mp4")
                            shorts_result = _generate_shorts_video_v2(
                                shorts_analysis=shorts_analysis,
                                voice_name=voice,
                                output_path=shorts_output_path,
                                base_url=base_url,
                                scene_images=scene_image_urls,
                                fixed_title=shorts_title  # ì˜ìƒ ì œëª©ì„ ê³ ì • íƒ€ì´í‹€ë¡œ ì „ë‹¬
                            )

                            if not shorts_result.get("ok"):
                                print(f"[SHORTS-BG] ì‡¼ì¸  ì˜ìƒ ìƒì„± ì‹¤íŒ¨: {shorts_result.get('error')}")
                                return

                            shorts_duration = shorts_result.get("duration", 0)
                            print(f"[SHORTS-BG] ì‡¼ì¸  ì˜ìƒ ìƒì„± ì™„ë£Œ: {shorts_duration:.1f}ì´ˆ")

                            # ì‡¼ì¸  ì—…ë¡œë“œ
                            shorts_description = f"""ğŸ¬ ì „ì²´ ì˜ìƒ ë³´ê¸°: {youtube_url}

{description[:200]}...

{' '.join(shorts_hashtags)}"""

                            # ì‡¼ì¸ ë„ ë©”ì¸ ì˜ìƒê³¼ ë™ì¼í•œ ê³µê°œ ì„¤ì • ì‚¬ìš©
                            # (15ë¶„ í›„ ê³µê°œ ë˜ëŠ” ì˜ˆì•½ì‹œê°„ì´ ìˆìœ¼ë©´ ë™ì‹œ ê³µê°œ)
                            shorts_upload_payload = {
                                "videoPath": shorts_output_path,
                                "title": shorts_title,
                                "description": shorts_description,
                                "privacyStatus": actual_visibility,  # ë©”ì¸ê³¼ ë™ì¼ (private if 15ë¶„ í›„ ê³µê°œ)
                                "channelId": channel_id
                            }

                            # ë©”ì¸ ì˜ìƒê³¼ ê°™ì€ ì˜ˆì•½ì‹œê°„ ì ìš© (15ë¶„ í›„ ê³µê°œ ë˜ëŠ” ì˜ˆì•½ì‹œê°„)
                            if publish_at_iso:
                                shorts_upload_payload["publish_at"] = publish_at_iso
                                print(f"[SHORTS-BG] ì‡¼ì¸ ë„ ë©”ì¸ ì˜ìƒê³¼ ë™ì‹œ ê³µê°œ ì˜ˆì •: {publish_at_iso}")

                            shorts_resp = bg_req.post(f"{base_url}/api/youtube/upload", json=shorts_upload_payload, timeout=300)
                            shorts_data = shorts_resp.json()

                            if shorts_data.get('ok'):
                                shorts_url = shorts_data.get('videoUrl', '')
                                print(f"[SHORTS-BG] ì‡¼ì¸  ì—…ë¡œë“œ ì™„ë£Œ: {shorts_url}")

                                # Google Sheets Qì—´ì— ì‡¼ì¸  URL ì—…ë°ì´íŠ¸
                                try:
                                    service = get_sheets_service_account()
                                    sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
                                    if service and sheet_id:
                                        sheets_update_cell(service, sheet_id, f'Sheet1!Q{row_index}', shorts_url)
                                        print(f"[SHORTS-BG] Google Sheets Q{row_index}ì— ì‡¼ì¸  URL ê¸°ë¡ ì™„ë£Œ")
                                except Exception as sheets_err:
                                    print(f"[SHORTS-BG] Sheets ì—…ë°ì´íŠ¸ ì‹¤íŒ¨: {sheets_err}")
                            else:
                                print(f"[SHORTS-BG] ì‡¼ì¸  ì—…ë¡œë“œ ì‹¤íŒ¨: {shorts_data.get('error')}")

                        except Exception as bg_err:
                            print(f"[SHORTS-BG] ë°±ê·¸ë¼ìš´ë“œ ì‡¼ì¸  ì˜¤ë¥˜: {bg_err}")
                            import traceback
                            traceback.print_exc()
                        finally:
                            # ì„¸ë§ˆí¬ì–´ í•´ì œ (ë‹¤ìŒ FFmpeg ì‘ì—… í—ˆìš©)
                            ffmpeg_semaphore.release()
                            print(f"[SHORTS-BG] FFmpeg ì„¸ë§ˆí¬ì–´ í•´ì œë¨")

                    # ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œ ì‹œì‘
                    shorts_thread = threading.Thread(target=generate_shorts_background, daemon=True)
                    shorts_thread.start()
                    print(f"[AUTOMATION] 5. ì‡¼ì¸  ìƒì„± ë°±ê·¸ë¼ìš´ë“œ ì‹œì‘ (ë¡±í¼ ë¨¼ì € ë°˜í™˜)")

                # ì—…ë¡œë“œ ê²°ê³¼ì—ì„œ ëŒ“ê¸€ ì‘ì„± ì—¬ë¶€ í™•ì¸
                comment_posted = upload_data.get('commentPosted', False)
                comment_id = upload_data.get('commentId', None)

                if comment_posted:
                    print(f"[AUTOMATION] âœ… ê³ ì • ëŒ“ê¸€ ìë™ ì‘ì„± ì™„ë£Œ (YouTube Studioì—ì„œ ê³ ì • í•„ìš”)")
                elif pin_comment:
                    print(f"[AUTOMATION] âš ï¸ ê³ ì • ëŒ“ê¸€ ì‘ì„± ì‹¤íŒ¨ (ëŒ“ê¸€ ë¹„í™œì„±í™” ë˜ëŠ” ê¶Œí•œ ë¬¸ì œ)")

                # ë¡±í¼ ê²°ê³¼ ì¦‰ì‹œ ë°˜í™˜ (ì‡¼ì¸ ëŠ” ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì§„í–‰)
                return {
                    "ok": True,
                    "video_url": youtube_url,
                    "shorts_url": None,  # ë°±ê·¸ë¼ìš´ë“œì—ì„œ ì²˜ë¦¬ ì¤‘
                    "error": None,
                    "cost": total_cost,
                    # ìƒˆë¡œ ì¶”ê°€: ì œëª© ì˜µì…˜ ë° ì‚¬ìš©ëœ ì„¤ì • ì •ë³´
                    "title": title,
                    "title_options": title_options,
                    "voice": voice,
                    "audience": audience,
                    "detected_category": detected_category,
                    # ìœ íŠœë¸Œ ë©”íƒ€ë°ì´í„° ì¶”ê°€
                    "hashtags": hashtags,
                    "tags": tags,
                    "pin_comment": pin_comment,  # ìƒì„±ëœ ëŒ“ê¸€ ë‚´ìš©
                    "comment_posted": comment_posted,  # ëŒ“ê¸€ ìë™ ì‘ì„± ì—¬ë¶€
                    "comment_id": comment_id  # ì‘ì„±ëœ ëŒ“ê¸€ ID (YouTube Studioì—ì„œ ê³ ì • í•„ìš”)
                }
            else:
                return {"ok": False, "error": f"YouTube ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_data.get('error')}", "video_url": None, "shorts_url": None, "cost": total_cost}
        except Exception as e:
            import traceback
            traceback.print_exc()
            return {"ok": False, "error": f"YouTube ì—…ë¡œë“œ ì˜¤ë¥˜: {str(e)}", "video_url": None, "shorts_url": None, "cost": total_cost}

    except Exception as e:
        print(f"[AUTOMATION] íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return {
            "ok": False,
            "error": str(e),
            "video_url": None,
            "cost": 0.0
        }


# NOTE: ë ˆê±°ì‹œ _automation_* í•¨ìˆ˜ë“¤ ì‚­ì œë¨ (2025-12-12)
# run_automation_pipeline()ì€ HTTP API í˜¸ì¶œ ë°©ì‹ ì‚¬ìš© (/api/image/analyze-script ë“±)


@app.route('/api/sheets/auth-status', methods=['GET'])
def api_sheets_auth_status():
    """Google Sheets ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ìƒíƒœ í™•ì¸"""
    try:
        service = get_sheets_service_account()
        if service:
            # AUTOMATION_SHEET_ID í™•ì¸
            sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
            return jsonify({
                "ok": True,
                "authenticated": True,
                "sheet_id_configured": bool(sheet_id),
                "message": "ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦ ì™„ë£Œ"
            })
        else:
            return jsonify({
                "ok": True,
                "authenticated": False,
                "sheet_id_configured": False,
                "message": "GOOGLE_SERVICE_ACCOUNT_JSON í™˜ê²½ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”"
            })
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sheets/check-and-process', methods=['POST'])
def api_sheets_check_and_process():
    """
    Google Sheetsì—ì„œ 'ëŒ€ê¸°' ìƒíƒœì¸ í–‰ì„ ì°¾ì•„ ì²˜ë¦¬ (ë‹¤ì¤‘ ì‹œíŠ¸ ì§€ì›)
    Render Cron Jobì—ì„œ 5ë¶„ë§ˆë‹¤ í˜¸ì¶œ

    ì‹œíŠ¸ êµ¬ì¡° (ì±„ë„ë³„ ì‹œíŠ¸):
    - í–‰1: ì±„ë„ ì„¤ì • (A1: 'ì±„ë„ID', B1: 'UCxxxx...')
    - í–‰2: í—¤ë” (ìƒíƒœ, ê³µê°œì„¤ì •, í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID, ì‘ì—…ì‹œê°„, ì˜ˆì•½ì‹œê°„, ...)
    - í–‰3~: ë°ì´í„°

    í—¤ë” (ì—´ ìˆœì„œëŠ” ë™ì  ë§¤í•‘):
    - ìƒíƒœ: ëŒ€ê¸°/ì²˜ë¦¬ì¤‘/ì™„ë£Œ/ì‹¤íŒ¨
    - ê³µê°œì„¤ì •: public/private/unlisted
    - í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID: YouTube í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID
    - ì‘ì—…ì‹œê°„: íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œê°„ (ì¶œë ¥)
    - ì˜ˆì•½ì‹œê°„: YouTube ê³µê°œ ì˜ˆì•½ ì‹œê°„
    - ì˜ìƒURL: ì—…ë¡œë“œëœ URL (ì¶œë ¥)
    - CTR: í´ë¦­ë¥  (ì¶œë ¥)
    - ë…¸ì¶œìˆ˜: impressions (ì¶œë ¥)
    - ì œëª©(GPTìƒì„±): ë©”ì¸ ì œëª©
    - ì œëª©2: ëŒ€ì•ˆ ì œëª© (solution)
    - ì œëª©3: ëŒ€ì•ˆ ì œëª© (authority)
    - ì œëª©ë³€ê²½ì¼: CTR ìë™í™”ìš© (ì¶œë ¥)
    - ëŒ€ë³¸: ì˜ìƒ ëŒ€ë³¸
    - ì¹´í…Œê³ ë¦¬: news/story (ì¶œë ¥)
    - ì—ëŸ¬ë©”ì‹œì§€: ì‹¤íŒ¨ ì‹œ ì—ëŸ¬ (ì¶œë ¥)
    - ë¹„ìš©: ìƒì„± ë¹„ìš© (ì¶œë ¥)

    ì²˜ë¦¬ ìš°ì„ ìˆœìœ„:
    1. ì˜ˆì•½ì‹œê°„ì´ ìˆëŠ” ê²½ìš°: ì˜ˆì•½ì‹œê°„ ë¹ ë¥¸ ìˆœ
    2. ì˜ˆì•½ì‹œê°„ì´ ì—†ëŠ” ê²½ìš°: ì‹œíŠ¸ ìˆœì„œ
    """
    import sys
    print(f"[SHEETS] ===== check-and-process í˜¸ì¶œë¨ =====", flush=True)

    # ========== ë™ì‹œ ì‹¤í–‰ ë°©ì§€ Lock ==========
    # ë‹¤ë¥¸ workerì—ì„œ ì´ë¯¸ íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ ì¤‘ì´ë©´ ì¦‰ì‹œ ë°˜í™˜
    if not pipeline_lock.acquire(blocking=False):
        print("[SHEETS] ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ - ìŠ¤í‚µ")
        return jsonify({
            "ok": True,
            "message": "ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤",
            "skipped": True,
            "processed": 0
        })

    try:
        from datetime import datetime, timedelta, timezone

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID
        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # í˜„ì¬ ì‹œê°„ (í•œêµ­ ì‹œê°„ KST = UTC+9)
        kst = timezone(timedelta(hours=9))
        now = datetime.now(kst).replace(tzinfo=None)

        # ========== 1. ëª¨ë“  ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ==========
        sheet_names = get_all_sheet_names(service, sheet_id)
        if sheet_names is None:
            return jsonify({
                "ok": False,
                "error": "ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨"
            }), 503

        if len(sheet_names) == 0:
            return jsonify({
                "ok": True,
                "message": "ì²˜ë¦¬í•  ì±„ë„ ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤ (ì–¸ë”ìŠ¤ì½”ì–´ë¡œ ì‹œì‘í•˜ì§€ ì•ŠëŠ” ì‹œíŠ¸ ì—†ìŒ)",
                "processed": 0
            })

        print(f"[SHEETS] ì´ {len(sheet_names)}ê°œ ì±„ë„ ì‹œíŠ¸ í™•ì¸: {sheet_names}")

        # ========== 2. ëª¨ë“  ì‹œíŠ¸ì—ì„œ ì²˜ë¦¬ì¤‘ ìƒíƒœ í™•ì¸ ==========
        # ì–´ë–¤ ì‹œíŠ¸ì—ì„œë“  ì²˜ë¦¬ì¤‘ì´ë©´ ìƒˆ ì‘ì—… ì‹œì‘ ì•ˆí•¨
        for sheet_name in sheet_names:
            rows = sheets_read_rows(service, sheet_id, f"'{sheet_name}'!A:AZ")
            if rows is None or len(rows) < 3:  # í–‰1: ì±„ë„ì„¤ì •, í–‰2: í—¤ë”, í–‰3~: ë°ì´í„°
                continue

            # í—¤ë”ì—ì„œ ì—´ ë§¤í•‘ ìƒì„± (í–‰2)
            headers = rows[1]
            col_map = get_column_mapping(headers)

            if 'ìƒíƒœ' not in col_map or 'ì‘ì—…ì‹œê°„' not in col_map:
                print(f"[SHEETS] ê²½ê³ : '{sheet_name}' ì‹œíŠ¸ì— í•„ìˆ˜ í—¤ë”(ìƒíƒœ, ì‘ì—…ì‹œê°„)ê°€ ì—†ìŒ")
                continue

            # ë°ì´í„° í–‰ ìˆœíšŒ (í–‰3ë¶€í„°)
            for i, row in enumerate(rows[2:], start=3):
                status = get_row_value(row, col_map, 'ìƒíƒœ')
                work_time = get_row_value(row, col_map, 'ì‘ì—…ì‹œê°„')

                if status == 'ì²˜ë¦¬ì¤‘':
                    # ì²˜ë¦¬ ì‹œì‘ ì‹œê°„ í™•ì¸
                    if work_time:
                        try:
                            work_dt = datetime.strptime(work_time, '%Y-%m-%d %H:%M:%S')
                            elapsed_minutes = (now - work_dt).total_seconds() / 60

                            # ì„œë²„ ì¬ì‹œì‘ ê°ì§€: ì‘ì—… ì‹œì‘ ì‹œê°„ì´ ì„œë²„ ì‹œì‘ ì‹œê°„ë³´ë‹¤ ì´ì „ì´ë©´ orphan ì‘ì—…
                            if work_dt < SERVER_START_TIME:
                                print(f"[SHEETS] [{sheet_name}] í–‰ {i}: ì„œë²„ ì¬ì‹œì‘ìœ¼ë¡œ orphan ì‘ì—… ê°ì§€ - ëŒ€ê¸°ë¡œ ë³€ê²½")
                                print(f"  - ì‘ì—… ì‹œì‘: {work_time}, ì„œë²„ ì‹œì‘: {SERVER_START_TIME.strftime('%Y-%m-%d %H:%M:%S')}")
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ìƒíƒœ', 'ëŒ€ê¸°')
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', '')
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì‘ì—…ì‹œê°„', '')
                                continue  # ë‹¤ìŒ í–‰ í™•ì¸

                            # í™˜ê²½ë³€ìˆ˜ë¡œ íƒ€ì„ì•„ì›ƒ ì„¤ì • ê°€ëŠ¥ (ê¸°ë³¸ 90ë¶„)
                            processing_timeout_minutes = int(os.environ.get('PROCESSING_TIMEOUT_MINUTES', '90'))
                            if elapsed_minutes > processing_timeout_minutes:
                                # íƒ€ì„ì•„ì›ƒ ì´ˆê³¼ â†’ ì‹¤íŒ¨ë¡œ ë³€ê²½
                                print(f"[SHEETS] [{sheet_name}] í–‰ {i}: ì²˜ë¦¬ì¤‘ ìƒíƒœ {elapsed_minutes:.1f}ë¶„ ê²½ê³¼ - íƒ€ì„ì•„ì›ƒìœ¼ë¡œ ì‹¤íŒ¨ ì²˜ë¦¬ (ì œí•œ: {processing_timeout_minutes}ë¶„)")
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', f'íƒ€ì„ì•„ì›ƒ: {elapsed_minutes:.0f}ë¶„ ê²½ê³¼')
                                continue
                            else:
                                # ì•„ì§ ì²˜ë¦¬ì¤‘ â†’ ì „ì²´ ëŒ€ê¸°
                                print(f"[SHEETS] [{sheet_name}] í–‰ {i}ì—ì„œ ì²˜ë¦¬ì¤‘ ({elapsed_minutes:.1f}ë¶„ ê²½ê³¼) - ìƒˆ ì‘ì—… ì‹œì‘ ì•ˆí•¨")
                                return jsonify({
                                    "ok": True,
                                    "message": f"[{sheet_name}] í–‰ {i}ì—ì„œ ì²˜ë¦¬ì¤‘ì¸ ì‘ì—…ì´ ìˆì–´ ëŒ€ê¸°í•©ë‹ˆë‹¤",
                                    "processing_sheet": sheet_name,
                                    "processing_row": i,
                                    "processed": 0
                                })
                        except ValueError:
                            # ì‹œê°„ í˜•ì‹ íŒŒì‹± ì‹¤íŒ¨ â†’ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                            print(f"[SHEETS] [{sheet_name}] í–‰ {i}: ì‹œì‘ì‹œê°„ í˜•ì‹ ì˜¤ë¥˜ - ì‹¤íŒ¨ ì²˜ë¦¬")
                            sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                            sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', 'ì‹œì‘ì‹œê°„ í˜•ì‹ ì˜¤ë¥˜ë¡œ ì‹¤íŒ¨')
                            continue
                    else:
                        # ì‹œì‘ì‹œê°„ ì—†ìŒ â†’ ì‹¤íŒ¨ë¡œ ì²˜ë¦¬
                        print(f"[SHEETS] [{sheet_name}] í–‰ {i}: ì‹œì‘ì‹œê°„ ì—†ìŒ - ì‹¤íŒ¨ ì²˜ë¦¬")
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', 'ì‹œì‘ì‹œê°„ ì—†ìŒ (ì„œë²„ ì¬ì‹œì‘)')
                        continue

        # ========== 2.5 HISTORY ì‹œíŠ¸ 'ì¤€ë¹„' â†’ ëŒ€ë³¸ ìƒì„± â†’ 'ëŒ€ê¸°' ==========
        # ì˜ìƒ ìƒì„± ì „ì— ë¨¼ì € ëŒ€ë³¸ì´ ì—†ëŠ” ì—í”¼ì†Œë“œì˜ ëŒ€ë³¸ì„ ìë™ ìƒì„±
        if 'HISTORY' in sheet_names:
            try:
                history_rows = sheets_read_rows(service, sheet_id, "'HISTORY'!A:AZ")
                if history_rows and len(history_rows) >= 3:
                    history_headers = history_rows[1]
                    history_col_map = get_column_mapping(history_headers)

                    # 'ì¤€ë¹„' ìƒíƒœì´ê³  ëŒ€ë³¸ì´ ì—†ëŠ” ì—í”¼ì†Œë“œ ì°¾ê¸°
                    has_ready_without_script = False
                    for i, row in enumerate(history_rows[2:], start=3):
                        status = get_row_value(row, history_col_map, 'ìƒíƒœ')
                        script = get_row_value(row, history_col_map, 'ëŒ€ë³¸')

                        if status == 'ì¤€ë¹„' and not script:
                            has_ready_without_script = True
                            print(f"[HISTORY] í–‰ {i}: 'ì¤€ë¹„' ìƒíƒœ, ëŒ€ë³¸ ì—†ìŒ â†’ ëŒ€ë³¸ ìë™ ìƒì„± ì‹œì‘")
                            break

                    if has_ready_without_script:
                        # OpenAI API í‚¤ í™•ì¸
                        if not os.environ.get('OPENAI_API_KEY'):
                            print("[HISTORY] OPENAI_API_KEY ì—†ìŒ, ëŒ€ë³¸ ìƒì„± ìŠ¤í‚µ")
                        else:
                            from scripts.history_pipeline import run_auto_script_pipeline

                            script_result = run_auto_script_pipeline(
                                sheet_id=sheet_id,
                                service=service,
                                max_scripts=1  # í•œ ë²ˆì— 1ê°œì”© ì²˜ë¦¬
                            )

                            if script_result.get("success"):
                                generated = script_result.get("scripts_generated", 0)
                                cost = script_result.get("total_cost", 0)
                                print(f"[HISTORY] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: {generated}ê°œ, ë¹„ìš© ${cost:.4f}")

                                if generated > 0:
                                    # ëŒ€ë³¸ ìƒì„± ì™„ë£Œ â†’ ë‹¤ìŒ cronì—ì„œ ì˜ìƒ ìƒì„±
                                    # (ì§€ê¸ˆ ë°”ë¡œ ì˜ìƒ ìƒì„±í•˜ì§€ ì•Šê³  ë‹¤ìŒ ì‚¬ì´í´ì—ì„œ ì²˜ë¦¬)
                                    return jsonify({
                                        "ok": True,
                                        "message": f"HISTORY ëŒ€ë³¸ {generated}ê°œ ìƒì„± ì™„ë£Œ, ë‹¤ìŒ ì‚¬ì´í´ì—ì„œ ì˜ìƒ ìƒì„±",
                                        "processed": 0,
                                        "script_generated": generated,
                                        "script_cost": cost,
                                        "details": script_result.get("details", [])
                                    })
                            else:
                                print(f"[HISTORY] ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {script_result.get('error')}")
            except Exception as history_err:
                print(f"[HISTORY] ëŒ€ë³¸ ìë™ ìƒì„± ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {history_err}")
                import traceback
                traceback.print_exc()

        # ========== 2.6 í˜ˆì˜ ì‹œíŠ¸ 'ì¤€ë¹„' â†’ ëŒ€ë³¸ ìƒì„± â†’ 'ëŒ€ê¸°' ==========
        # ë¬´í˜‘ ì†Œì„¤ ëŒ€ë³¸ ìë™ ìƒì„±
        if 'í˜ˆì˜' in sheet_names:
            try:
                wuxia_rows = sheets_read_rows(service, sheet_id, "'í˜ˆì˜'!A:AZ")
                if wuxia_rows and len(wuxia_rows) >= 3:
                    wuxia_headers = wuxia_rows[1]
                    wuxia_col_map = get_column_mapping(wuxia_headers)

                    # 'ì¤€ë¹„' ìƒíƒœì´ê³  ëŒ€ë³¸ì´ ì—†ëŠ” ì—í”¼ì†Œë“œ ì°¾ê¸°
                    has_ready_without_script = False
                    for i, row in enumerate(wuxia_rows[2:], start=3):
                        status = get_row_value(row, wuxia_col_map, 'ìƒíƒœ')
                        script = get_row_value(row, wuxia_col_map, 'ëŒ€ë³¸')

                        if status == 'ì¤€ë¹„' and not script:
                            has_ready_without_script = True
                            print(f"[WUXIA] í–‰ {i}: 'ì¤€ë¹„' ìƒíƒœ, ëŒ€ë³¸ ì—†ìŒ â†’ ëŒ€ë³¸ ìë™ ìƒì„± ì‹œì‘")
                            break

                    if has_ready_without_script:
                        # OpenRouter API í‚¤ í™•ì¸ (Claude Opus 4.5 ì‚¬ìš©)
                        if not os.environ.get('OPENROUTER_API_KEY'):
                            print("[WUXIA] OPENROUTER_API_KEY ì—†ìŒ, ëŒ€ë³¸ ìƒì„± ìŠ¤í‚µ")
                        else:
                            from scripts.wuxia_pipeline.run import run_auto_script_pipeline as run_wuxia_auto_script

                            script_result = run_wuxia_auto_script(max_scripts=1)

                            if script_result.get("success"):
                                generated = script_result.get("generated", 0)
                                cost = script_result.get("total_cost", 0)
                                print(f"[WUXIA] ëŒ€ë³¸ ìƒì„± ì™„ë£Œ: {generated}ê°œ, ë¹„ìš© ${cost:.4f}")

                                if generated > 0:
                                    # ëŒ€ë³¸ ìƒì„± ì™„ë£Œ â†’ ë‹¤ìŒ cronì—ì„œ ì˜ìƒ ìƒì„±
                                    return jsonify({
                                        "ok": True,
                                        "message": f"í˜ˆì˜ ëŒ€ë³¸ {generated}ê°œ ìƒì„± ì™„ë£Œ, ë‹¤ìŒ ì‚¬ì´í´ì—ì„œ ì˜ìƒ ìƒì„±",
                                        "processed": 0,
                                        "script_generated": generated,
                                        "script_cost": cost,
                                        "episodes": script_result.get("episodes", [])
                                    })
                            else:
                                print(f"[WUXIA] ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨: {script_result.get('error')}")
            except Exception as wuxia_err:
                print(f"[WUXIA] ëŒ€ë³¸ ìë™ ìƒì„± ì˜¤ë¥˜ (ë¬´ì‹œí•˜ê³  ê³„ì†): {wuxia_err}")
                import traceback
                traceback.print_exc()

        # ========== 3. ëª¨ë“  ì‹œíŠ¸ì—ì„œ ëŒ€ê¸° ì‘ì—… ìˆ˜ì§‘ ==========
        pending_tasks = []  # [(ì˜ˆì•½ì‹œê°„, ì‹œíŠ¸ìˆœì„œ, ì‹œíŠ¸ì´ë¦„, í–‰ë²ˆí˜¸, í–‰ë°ì´í„°, ì±„ë„ID, col_map)]

        for sheet_order, sheet_name in enumerate(sheet_names):
            rows = sheets_read_rows(service, sheet_id, f"'{sheet_name}'!A:AZ")
            if rows is None or len(rows) < 3:
                continue

            # ì±„ë„ ID (í–‰1)
            channel_id = get_sheet_channel_id(rows)
            if not channel_id:
                print(f"[SHEETS] ê²½ê³ : '{sheet_name}' ì‹œíŠ¸ì— ì±„ë„IDê°€ ì—†ìŒ (A1: 'ì±„ë„ID', B1: 'UCxxx' í˜•ì‹ í•„ìš”)")
                continue

            # í—¤ë”ì—ì„œ ì—´ ë§¤í•‘ ìƒì„± (í–‰2)
            headers = rows[1]
            col_map = get_column_mapping(headers)

            if 'ìƒíƒœ' not in col_map or 'ëŒ€ë³¸' not in col_map:
                print(f"[SHEETS] ê²½ê³ : '{sheet_name}' ì‹œíŠ¸ì— í•„ìˆ˜ í—¤ë”(ìƒíƒœ, ëŒ€ë³¸)ê°€ ì—†ìŒ")
                continue

            # ë°ì´í„° í–‰ ìˆœíšŒ (í–‰3ë¶€í„°)
            for i, row in enumerate(rows[2:], start=3):
                status = get_row_value(row, col_map, 'ìƒíƒœ')

                if status == 'ëŒ€ê¸°':
                    # ì˜ˆì•½ì‹œê°„ íŒŒì‹±
                    scheduled_time_str = get_row_value(row, col_map, 'ì˜ˆì•½ì‹œê°„')
                    scheduled_dt = None

                    if scheduled_time_str:
                        try:
                            scheduled_dt = datetime.strptime(scheduled_time_str, '%Y-%m-%d %H:%M')
                        except ValueError:
                            try:
                                scheduled_dt = datetime.strptime(scheduled_time_str, '%Y-%m-%d %H:%M:%S')
                            except ValueError:
                                pass  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ None ìœ ì§€

                    # ì˜ˆì•½ì‹œê°„ì´ ë¯¸ë˜ë©´ ê±´ë„ˆë›°ê¸°
                    if scheduled_dt and scheduled_dt > now:
                        print(f"[SHEETS] [{sheet_name}] í–‰ {i}: ì˜ˆì•½ì‹œê°„ {scheduled_time_str}ì´ ì•„ì§ ì•ˆë¨ - ê±´ë„ˆë›°ê¸°")
                        continue

                    # ëŒ€ê¸° ì‘ì—… ì¶”ê°€
                    # ì •ë ¬ í‚¤: (ì˜ˆì•½ì‹œê°„ ìˆìœ¼ë©´ ì˜ˆì•½ì‹œê°„, ì—†ìœ¼ë©´ ìµœëŒ€ê°’), (ì‹œíŠ¸ìˆœì„œ)
                    sort_key = (scheduled_dt if scheduled_dt else datetime.max, sheet_order)
                    pending_tasks.append((sort_key, sheet_name, i, row, channel_id, col_map))

        # ========== 4. ì˜ˆì•½ì‹œê°„ ê¸°ì¤€ ì •ë ¬ ==========
        print(f"[SHEETS] ëŒ€ê¸° ì‘ì—… {len(pending_tasks)}ê°œ ë°œê²¬, ì •ë ¬ ì¤‘...")
        for idx, task in enumerate(pending_tasks[:5]):  # ì²˜ìŒ 5ê°œë§Œ ë¡œê·¸
            sk, sn, rn, rd, ci, cm = task
            print(f"[SHEETS]   - íƒœìŠ¤í¬ {idx}: ì‹œíŠ¸={sn}, í–‰={rn}, sort_key={sk}")
        try:
            pending_tasks.sort(key=lambda x: x[0])
        except Exception as sort_err:
            print(f"[SHEETS] ì •ë ¬ ì˜¤ë¥˜: {sort_err}")
            # ì •ë ¬ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ê²ƒë§Œ ì²˜ë¦¬
            if pending_tasks:
                pending_tasks = [pending_tasks[0]]

        if not pending_tasks:
            # ========== SHORTS ìë™ ìˆ˜ì§‘ ë¹„í™œì„±í™” (2025-12-30) ==========
            # ë¡±í¼ ì½˜í…ì¸ ì— ì§‘ì¤‘í•˜ê¸° ìœ„í•´ ì‡¼ì¸  ìˆ˜ì§‘ ì¼ì‹œ ì¤‘ë‹¨
            # ì¬í™œì„±í™”í•˜ë ¤ë©´ ì•„ë˜ ì£¼ì„ í•´ì œ
            """
            if "SHORTS" in sheet_names:
                try:
                    from scripts.shorts_pipeline import run_news_collection
                    from datetime import datetime, timezone, timedelta

                    # í•œêµ­ ì‹œê°„ ê³„ì‚°
                    kst = timezone(timedelta(hours=9))
                    now_kst = datetime.now(kst)
                    current_hour = now_kst.hour
                    today = now_kst.strftime("%Y-%m-%d")

                    # ìˆ˜ì§‘ ì‹œê°„ëŒ€: 8ì‹œ(08:00-08:59), 17ì‹œ(17:00-17:59)
                    collection_hours = [8, 17]

                    if current_hour in collection_hours:
                        # ì´ë²ˆ ì‹œê°„ëŒ€ì— ì´ë¯¸ ìˆ˜ì§‘í–ˆëŠ”ì§€ í™•ì¸
                        time_slot = f"{today}_{current_hour}"
                        shorts_rows = sheets_read_rows(service, sheet_id, "'SHORTS'!A:AZ")

                        already_collected = False
                        if shorts_rows and len(shorts_rows) > 2:
                            headers = shorts_rows[1] if len(shorts_rows) > 1 else []
                            run_id_col = headers.index("run_id") if "run_id" in headers else -1

                            if run_id_col >= 0:
                                for row in shorts_rows[2:]:
                                    if len(row) > run_id_col and row[run_id_col] == time_slot:
                                        already_collected = True
                                        break

                        if not already_collected:
                            print(f"[SHORTS] {current_hour}ì‹œ ìˆ˜ì§‘ ì‹œì‘ (slot: {time_slot})")
                            news_result = run_news_collection(max_items=5, save_to_sheet=True, run_id=time_slot)
                            print(f"[SHORTS] ë‰´ìŠ¤ ìˆ˜ì§‘ ì™„ë£Œ: {news_result.get('collected', 0)}ê°œ ìˆ˜ì§‘, {news_result.get('saved', 0)}ê°œ ì €ì¥")

                            return jsonify({
                                "ok": True,
                                "message": f"SHORTS ë‰´ìŠ¤ {news_result.get('saved', 0)}ê°œ ìˆ˜ì§‘ ì™„ë£Œ ({current_hour}ì‹œ)",
                                "processed": 0,
                                "shorts_news_collected": news_result.get('saved', 0),
                                "time_slot": time_slot,
                                "sheets_checked": sheet_names
                            })
                        else:
                            print(f"[SHORTS] {current_hour}ì‹œ ì´ë¯¸ ìˆ˜ì§‘ë¨ â†’ ìŠ¤í‚µ")
                    else:
                        print(f"[SHORTS] ìˆ˜ì§‘ ì‹œê°„ ì•„ë‹˜ (í˜„ì¬: {current_hour}ì‹œ, ìˆ˜ì§‘: 8ì‹œ/17ì‹œ)")

                except Exception as shorts_err:
                    print(f"[SHORTS] ë‰´ìŠ¤ ìˆ˜ì§‘ ì˜¤ë¥˜ (ë¬´ì‹œ): {shorts_err}")
            """
            print("[SHORTS] ìë™ ìˆ˜ì§‘ ë¹„í™œì„±í™”ë¨ (ë¡±í¼ ì§‘ì¤‘ ëª¨ë“œ)")

            return jsonify({
                "ok": True,
                "message": "ì²˜ë¦¬í•  ëŒ€ê¸° ì‘ì—…ì´ ì—†ìŠµë‹ˆë‹¤",
                "processed": 0,
                "sheets_checked": sheet_names
            })

        # ========== 5. ì²« ë²ˆì§¸ ì‘ì—… ì‹¤í–‰ ==========
        sort_key, sheet_name, row_num, row_data, channel_id, col_map = pending_tasks[0]
        print(f"[SHEETS] [{sheet_name}] í–‰ {row_num} ì²˜ë¦¬ ì‹œì‘ (ì±„ë„: {channel_id})")

        # ========== 5.1 YouTube í• ë‹¹ëŸ‰/í† í° ì²´í¬ (íŒŒì´í”„ë¼ì¸ ì‹œì‘ ì „) ==========
        # ì˜ìƒ ìƒì„± í›„ ì—…ë¡œë“œ ì‹¤íŒ¨ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•´ ë¯¸ë¦¬ ì²´í¬
        print(f"[SHEETS] YouTube í† í°/í• ë‹¹ëŸ‰ ì²´í¬ ì¤‘... (ì±„ë„: {channel_id})")
        quota_ok, project_suffix, quota_error = check_youtube_quota_before_pipeline(channel_id)

        if not quota_ok:
            print(f"[SHEETS][ERROR] YouTube ì²´í¬ ì‹¤íŒ¨: {quota_error}")
            # í• ë‹¹ëŸ‰ ì´ˆê³¼ ë˜ëŠ” í† í° ì—†ìŒ - íŒŒì´í”„ë¼ì¸ ì‹œì‘í•˜ì§€ ì•ŠìŒ
            # Sheet ìƒíƒœë¥¼ 'ì‹¤íŒ¨'ë¡œ ì—…ë°ì´íŠ¸
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', f'YouTube ì²´í¬ ì‹¤íŒ¨: {quota_error}')
            return jsonify({
                "ok": False,
                "error": quota_error,
                "message": f"YouTube í† í°/í• ë‹¹ëŸ‰ ë¬¸ì œë¡œ íŒŒì´í”„ë¼ì¸ì„ ì‹œì‘í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {quota_error}",
                "sheet": sheet_name,
                "row": row_num,
                "channel_id": channel_id
            }), 503

        print(f"[SHEETS] YouTube ì²´í¬ ì™„ë£Œ - í”„ë¡œì íŠ¸: {project_suffix or 'ê¸°ë³¸'}")

        # ìƒíƒœë¥¼ 'ì²˜ë¦¬ì¤‘'ìœ¼ë¡œ ë³€ê²½ + ì‹œì‘ ì‹œê°„ ê¸°ë¡
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ìƒíƒœ', 'ì²˜ë¦¬ì¤‘')
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì‘ì—…ì‹œê°„', now.strftime('%Y-%m-%d %H:%M:%S'))

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ìƒˆ êµ¬ì¡°ì— ë§ê²Œ ë°ì´í„° ì „ë‹¬)
        # â˜… ì‚¬ìš©ì ì…ë ¥ê°’ ìš°ì„ : 'ì œëª©(ì…ë ¥)', 'ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)' ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ GPT ìƒì„±ê°’ ëŒ€ì‹  ì‚¬ìš©
        user_title = get_row_value(row_data, col_map, 'ì œëª©(ì…ë ¥)', '')
        user_thumbnail_text = get_row_value(row_data, col_map, 'ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)', '')

        pipeline_data = {
            'channel_id': channel_id,
            'script': get_row_value(row_data, col_map, 'ëŒ€ë³¸'),
            'title': get_row_value(row_data, col_map, 'ì œëª©(GPTìƒì„±)'),
            'privacy': get_row_value(row_data, col_map, 'ê³µê°œì„¤ì •', 'private'),
            'playlist_id': get_row_value(row_data, col_map, 'í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID'),
            'scheduled_time': get_row_value(row_data, col_map, 'ì˜ˆì•½ì‹œê°„'),
            # â˜… ì‚¬ìš©ì ì…ë ¥ê°’ (ìˆìœ¼ë©´ GPT ìƒì„±ê°’ ëŒ€ì‹  ì‚¬ìš©)
            'user_title': user_title,
            'user_thumbnail_text': user_thumbnail_text,
            # â˜… ì¸ìš©ë§í¬ (ìœ íŠœë¸Œ ì„¤ëª…ì— í¬í•¨)
            'citation_links': get_row_value(row_data, col_map, 'ì¸ìš©ë§í¬', ''),
            # â˜… ìŒì„± (ì‹œíŠ¸ì—ì„œ ê°€ì ¸ì˜´, ê¸°ë³¸ê°’: chirp3:Charon)
            'voice': get_row_value(row_data, col_map, 'ìŒì„±', ''),
        }

        if user_title:
            print(f"[SHEETS] â˜… ì‚¬ìš©ì ì…ë ¥ ì œëª© ì‚¬ìš©: {user_title[:50]}...")
        if user_thumbnail_text:
            print(f"[SHEETS] â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ë¬¸êµ¬ ì‚¬ìš©: {user_thumbnail_text}")

        print(f"[SHEETS] â˜…â˜…â˜… íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ ì§ì „ â˜…â˜…â˜…")
        print(f"[SHEETS]   - ì‹œíŠ¸: {sheet_name}, í–‰: {row_num}")
        print(f"[SHEETS]   - ì±„ë„: {channel_id}")

        try:
            # ========== ì‹œíŠ¸ë³„ ë¶„ê¸° ì²˜ë¦¬ ==========
            if sheet_name == "SHORTS":
                # â˜… SHORTS íŒŒì´í”„ë¼ì¸
                print(f"[SHORTS] ì‡¼ì¸  íŒŒì´í”„ë¼ì¸ ì‹œì‘: í–‰ {row_num}")
                from scripts.shorts_pipeline import generate_complete_shorts_package, format_script_for_sheet, run_video_generation
                from scripts.shorts_pipeline.sheets import update_status as shorts_update_status

                # row_dataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                # col_mapì€ {'í—¤ë”': {'index': N, 'letter': 'X'}} í˜•ì‹
                shorts_row_data = {}
                for header, col_info in col_map.items():
                    # col_infoê°€ dictë©´ index ì¶”ì¶œ, intë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                    idx = col_info['index'] if isinstance(col_info, dict) else col_info
                    if idx < len(row_data):
                        shorts_row_data[header] = row_data[idx]
                    else:
                        shorts_row_data[header] = ""
                shorts_row_data["row_number"] = row_num

                person = shorts_row_data.get("person", shorts_row_data.get("celebrity", ""))
                issue_type = shorts_row_data.get("issue_type", "ê·¼í™©")
                print(f"[SHORTS] ì¸ë¬¼: {person}, ì´ìŠˆ: {issue_type}")

                # 1) ëŒ€ë³¸ ìƒì„±
                script_result = generate_complete_shorts_package(shorts_row_data)
                if not script_result.get("ok"):
                    raise Exception(script_result.get("error", "ëŒ€ë³¸ ìƒì„± ì‹¤íŒ¨"))

                script_text = format_script_for_sheet(script_result.get("scenes", []))
                total_cost = script_result.get("cost", 0)

                # 2) ë¹„ë””ì˜¤ ìƒì„±
                video_result = run_video_generation(
                    script_result=script_result,
                    person=person,
                    issue_type=issue_type,
                )
                if video_result.get("ok"):
                    total_cost += video_result.get("cost", 0)

                result = {
                    "ok": video_result.get("ok", False),
                    "title": script_result.get("title", ""),
                    "cost": total_cost,
                    "video_url": video_result.get("video_url", ""),
                    "error": video_result.get("error"),
                    "type": "shorts"
                }

                # ì‹œíŠ¸ ì—…ë°ì´íŠ¸ (SHORTS ì „ìš© í•„ë“œ)
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ëŒ€ë³¸', script_text)
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì œëª©(GPTìƒì„±)', script_result.get("title", ""))

                # ========== YouTube ì—…ë¡œë“œ (SHORTS) ==========
                if video_result.get("ok") and video_result.get("video_path"):
                    print(f"[SHORTS] YouTube ì—…ë¡œë“œ ì‹œì‘...")

                    # ì‹œíŠ¸ì—ì„œ ì¶”ê°€ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    privacy_status = get_row_value(row_data, col_map, 'ê³µê°œì„¤ì •', 'public')
                    playlist_id = get_row_value(row_data, col_map, 'í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID', '')
                    scheduled_time = get_row_value(row_data, col_map, 'ì˜ˆì•½ì‹œê°„', '')

                    # YouTube ì„¤ëª… ìƒì„± (ì‡¼ì¸ ìš©) - youtube_seo ì‚¬ìš©
                    youtube_seo = script_result.get("youtube_seo", {})
                    shorts_description = youtube_seo.get("description", "")
                    if not shorts_description:
                        # fallback: ê¸°ë³¸ ì„¤ëª… ìƒì„±
                        shorts_description = f"{script_result.get('title', person)}\n\n"
                        shorts_description += f"#{person} #{issue_type} #Shorts #ì—°ì˜ˆë‰´ìŠ¤"

                    # ì—…ë¡œë“œ í˜ì´ë¡œë“œ êµ¬ì„±
                    shorts_upload_payload = {
                        "videoPath": video_result.get("video_path"),
                        "title": script_result.get("title", f"{person} - {issue_type}"),
                        "description": shorts_description,
                        "privacyStatus": privacy_status.lower() if privacy_status else "public",
                        "channelId": channel_id,
                    }

                    # ì¸ë„¤ì¼ì€ ì‡¼ì¸ ì—ì„œ ìë™ ìƒì„±ë˜ë¯€ë¡œ ë³„ë„ ì—…ë¡œë“œ ì•ˆí•¨

                    # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€
                    if playlist_id:
                        shorts_upload_payload["playlistId"] = playlist_id
                        print(f"[SHORTS] í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ì¶”ê°€: {playlist_id}")

                    # ì˜ˆì•½ ì—…ë¡œë“œ ì²˜ë¦¬
                    if scheduled_time:
                        try:
                            from datetime import datetime, timedelta

                            publish_time_str = str(scheduled_time).strip()

                            # ISO 8601 í˜•ì‹ì´ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©
                            if 'T' in publish_time_str and publish_time_str.endswith('Z'):
                                shorts_upload_payload["publish_at"] = publish_time_str
                            else:
                                # ì¼ë°˜ í˜•ì‹ íŒŒì‹±
                                formats_to_try = [
                                    "%Y-%m-%d %H:%M:%S",
                                    "%Y-%m-%d %H:%M",
                                    "%Y/%m/%d %H:%M",
                                    "%m/%d %H:%M",
                                ]
                                parsed_dt = None
                                for fmt in formats_to_try:
                                    try:
                                        parsed_dt = datetime.strptime(publish_time_str, fmt)
                                        if parsed_dt.year == 1900:
                                            parsed_dt = parsed_dt.replace(year=datetime.now().year)
                                        break
                                    except ValueError:
                                        continue

                                if parsed_dt:
                                    # UTCë¡œ ë³€í™˜ (í•œêµ­ ì‹œê°„ì€ UTC+9)
                                    utc_dt = parsed_dt - timedelta(hours=9)
                                    shorts_upload_payload["publish_at"] = utc_dt.strftime("%Y-%m-%dT%H:%M:%S.000Z")
                                    print(f"[SHORTS] ì˜ˆì•½ ì—…ë¡œë“œ ì„¤ì •: {publish_time_str}")
                        except Exception as sched_err:
                            print(f"[SHORTS] ì˜ˆì•½ì‹œê°„ ì²˜ë¦¬ ì˜¤ë¥˜ (ë¬´ì‹œ): {sched_err}")

                    # YouTube ì—…ë¡œë“œ API í˜¸ì¶œ
                    try:
                        import requests as req
                        # Renderì—ì„œëŠ” PORT í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©, ë¡œì»¬ì—ì„œëŠ” 5002
                        port = os.environ.get("PORT", "5002")
                        base_url = f"http://127.0.0.1:{port}"

                        upload_resp = req.post(
                            f"{base_url}/api/youtube/upload",
                            json=shorts_upload_payload,
                            timeout=600
                        )

                        upload_data = upload_resp.json()
                        print(f"[SHORTS] YouTube ì—…ë¡œë“œ ì‘ë‹µ: ok={upload_data.get('ok')}, videoUrl={upload_data.get('videoUrl', 'N/A')[:50] if upload_data.get('videoUrl') else 'N/A'}")

                        if upload_data.get('ok'):
                            youtube_url = upload_data.get('videoUrl', '')
                            result["video_url"] = youtube_url
                            result["ok"] = True
                            print(f"[SHORTS] âœ… YouTube ì—…ë¡œë“œ ì„±ê³µ: {youtube_url}")
                        elif upload_data.get('mode') == 'test':
                            result["error"] = "YouTube í† í° ì—†ìŒ (í…ŒìŠ¤íŠ¸ ëª¨ë“œ)"
                            result["ok"] = False
                            print(f"[SHORTS] âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ (í† í° í•„ìš”)")
                        elif upload_data.get('needsAuth'):
                            result["error"] = upload_data.get('error', 'OAuth ì¸ì¦ í•„ìš”')
                            result["ok"] = False
                            print(f"[SHORTS] âš ï¸ OAuth ì¸ì¦ í•„ìš”")
                        else:
                            result["error"] = upload_data.get('error', 'ì—…ë¡œë“œ ì‹¤íŒ¨')
                            result["ok"] = False
                            print(f"[SHORTS] âŒ ì—…ë¡œë“œ ì‹¤íŒ¨: {result['error']}")

                    except Exception as upload_err:
                        print(f"[SHORTS] YouTube ì—…ë¡œë“œ ì˜¤ë¥˜: {upload_err}")
                        result["error"] = f"ì—…ë¡œë“œ ì˜¤ë¥˜: {str(upload_err)}"
                        result["ok"] = False
                else:
                    print(f"[SHORTS] ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨ - ì—…ë¡œë“œ ìŠ¤í‚µ")
                    result["ok"] = False
                    if not result.get("error"):
                        result["error"] = video_result.get("error", "ë¹„ë””ì˜¤ ìƒì„± ì‹¤íŒ¨")

            elif sheet_name == "BIBLE":
                # â˜… BIBLE íŒŒì´í”„ë¼ì¸
                print(f"[BIBLE] ì„±ê²½í†µë… íŒŒì´í”„ë¼ì¸ ì‹œì‘: í–‰ {row_num}")

                # row_dataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (BIBLE í˜•ì‹)
                # col_mapì€ {'í—¤ë”': {'index': N, 'letter': 'X'}} í˜•ì‹
                bible_row_data = {}
                for header, col_info in col_map.items():
                    idx = col_info['index'] if isinstance(col_info, dict) else col_info
                    if idx < len(row_data):
                        bible_row_data[header] = row_data[idx]
                    else:
                        bible_row_data[header] = ""
                bible_row_data["row_idx"] = row_num

                bible_result = run_bible_episode_pipeline(
                    service=service,
                    sheet_id=sheet_id,
                    row_idx=row_num,
                    episode_data=bible_row_data,
                    channel_id=channel_id
                )

                result = {
                    "ok": bible_result.get("ok", False),
                    "title": bible_row_data.get("ì œëª©", ""),
                    "cost": bible_result.get("cost", 0),
                    "video_url": bible_result.get("video_url", ""),
                    "error": bible_result.get("error"),
                    "type": "bible"
                }

            elif sheet_name == "í˜ˆì˜ì´ì„¸ê³„":
                # â˜… í˜ˆì˜ ì´ì„¸ê³„í¸ ì „ìš© íŒŒì´í”„ë¼ì¸ (GPT ë¶„ì„ ìŠ¤í‚µ, ì´ë¯¸ì§€ 1ì¥)
                print(f"[ISEKAI] í˜ˆì˜ ì´ì„¸ê³„í¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘: í–‰ {row_num}")

                # row_dataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜
                isekai_row_data = {}
                for header, col_info in col_map.items():
                    idx = col_info['index'] if isinstance(col_info, dict) else col_info
                    if idx < len(row_data):
                        isekai_row_data[header] = row_data[idx]
                    else:
                        isekai_row_data[header] = ""
                isekai_row_data['ì±„ë„ID'] = channel_id

                # ì—í”¼ì†Œë“œ ì •ë³´ ì¶”ì¶œ (EP001 â†’ 1í™”)
                episode_col = isekai_row_data.get('episode', '')
                if episode_col:
                    try:
                        ep_num = int(episode_col.replace('EP', '').replace('ep', ''))
                        isekai_row_data['episode_num'] = ep_num
                    except:
                        isekai_row_data['episode_num'] = 1
                else:
                    isekai_row_data['episode_num'] = 1

                result = run_isekai_video_pipeline(
                    row_data=isekai_row_data,
                    row_index=row_num,
                    sheet_name=sheet_name,
                    col_map=col_map,
                    service=service,
                    sheet_id=sheet_id,
                    selected_project=project_suffix
                )

            elif sheet_name == "í˜ˆì˜":
                # â˜… í˜ˆì˜ (ë¬´í˜‘) ì „ìš© íŒŒì´í”„ë¼ì¸
                print(f"[WUXIA] í˜ˆì˜ íŒŒì´í”„ë¼ì¸ ì‹œì‘: í–‰ {row_num}")

                # row_dataë¥¼ ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜ (í˜ˆì˜ í˜•ì‹)
                wuxia_row_data = {}
                for header, col_info in col_map.items():
                    idx = col_info['index'] if isinstance(col_info, dict) else col_info
                    if idx < len(row_data):
                        wuxia_row_data[header] = row_data[idx]
                    else:
                        wuxia_row_data[header] = ""
                wuxia_row_data['ì±„ë„ID'] = channel_id

                # ì—í”¼ì†Œë“œ ì •ë³´ ì¶”ì¶œ (EP001 â†’ 1í™”)
                episode_col = wuxia_row_data.get('ì—í”¼ì†Œë“œ', wuxia_row_data.get('episode', ''))
                if episode_col:
                    try:
                        ep_num = int(episode_col.replace('EP', '').replace('ep', ''))
                        wuxia_row_data['episode_num'] = ep_num
                    except:
                        wuxia_row_data['episode_num'] = 1
                else:
                    wuxia_row_data['episode_num'] = 1

                result = run_wuxia_video_pipeline(
                    row_data=wuxia_row_data,
                    row_index=row_num,
                    sheet_name=sheet_name,
                    col_map=col_map,
                    service=service,
                    sheet_id=sheet_id,
                    selected_project=project_suffix
                )

            else:
                # â˜… ì¼ë°˜ íŒŒì´í”„ë¼ì¸ (NEWS, HISTORY, MYSTERY ë“±)
                print(f"[SHEETS]   - ëŒ€ë³¸ ê¸¸ì´: {len(pipeline_data.get('script', ''))}ì")
                result = run_automation_pipeline_v2(pipeline_data, sheet_name, row_num, col_map, selected_project=project_suffix)

            print(f"[SHEETS] â˜…â˜…â˜… íŒŒì´í”„ë¼ì¸ ì™„ë£Œ â˜…â˜…â˜… - ok: {result.get('ok')}, type: {result.get('type', 'normal')}")

        except Exception as pipeline_err:
            import traceback
            print(f"[SHEETS] â˜…â˜…â˜… íŒŒì´í”„ë¼ì¸ ì˜ˆì™¸ ë°œìƒ â˜…â˜…â˜…")
            print(f"[SHEETS] ì—ëŸ¬: {type(pipeline_err).__name__}: {pipeline_err}")
            traceback.print_exc()
            # ì‹œíŠ¸ì— ì‹¤íŒ¨ ê¸°ë¡
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', f'ì˜ˆì™¸: {str(pipeline_err)[:200]}')
            raise  # ë‹¤ì‹œ ë˜ì ¸ì„œ ìƒìœ„ì—ì„œ ì²˜ë¦¬

        # ========== 6. ê²°ê³¼ ê¸°ë¡ ==========
        # ë¹„ìš© ê¸°ë¡ (ì›í™”ë¡œ ë³€í™˜, 1 USD = 1,350 KRW)
        cost_usd = result.get('cost', 0.0)
        cost_krw = int(cost_usd * 1350)
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ë¹„ìš©', f'{cost_krw:,}ì›')

        # ì œëª© ê¸°ë¡
        if result.get('title'):
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì œëª©(GPTìƒì„±)', result['title'])
        title_options = result.get('title_options', [])
        if len(title_options) >= 1:
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì œëª©2', title_options[0].get('title', ''))
        if len(title_options) >= 2:
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì œëª©3', title_options[1].get('title', ''))

        # ì¹´í…Œê³ ë¦¬ ê¸°ë¡
        if result.get('detected_category'):
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì¹´í…Œê³ ë¦¬', result['detected_category'])

        if result.get('ok'):
            # ì„±ê³µ
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ìƒíƒœ', 'ì™„ë£Œ')
            if result.get('video_url'):
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì˜ìƒURL', result['video_url'])
            # ì—…ë¡œë“œ ì™„ë£Œ ì‹œê°„ ê¸°ë¡
            upload_time = datetime.now(timezone(timedelta(hours=9))).strftime('%Y-%m-%d %H:%M:%S')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì—…ë¡œë“œì‹œê°„', upload_time)
        else:
            # ì‹¤íŒ¨
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            error_msg = result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')[:500]
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_num, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)

        return jsonify({
            "ok": True,
            "message": f"[{sheet_name}] í–‰ {row_num} ì²˜ë¦¬ ì™„ë£Œ",
            "processed": 1,
            "sheet": sheet_name,
            "row": row_num,
            "result_ok": result.get('ok'),
            "error": result.get('error')
        })

    except Exception as e:
        print(f"[SHEETS] check-and-process ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500
    finally:
        # í•­ìƒ lock í•´ì œ
        pipeline_lock.release()
        print("[SHEETS] íŒŒì´í”„ë¼ì¸ Lock í•´ì œë¨")


def run_automation_pipeline_v2(pipeline_data, sheet_name, row_num, col_map, selected_project=''):
    """
    ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (v2 - ë™ì  ë§¤í•‘ ì§€ì›)

    pipeline_data: {
        'channel_id': ì±„ë„ ID,
        'script': ëŒ€ë³¸,
        'title': ì œëª© (ì„ íƒ),
        'privacy': ê³µê°œì„¤ì •,
        'playlist_id': í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID (ì„ íƒ),
        'scheduled_time': ì˜ˆì•½ì‹œê°„ (ì„ íƒ),
        'user_title': ì‚¬ìš©ì ì…ë ¥ ì œëª© (ì„ íƒ) - GPT ìƒì„± ì œëª© ëŒ€ì‹  ì‚¬ìš©,
        'user_thumbnail_text': ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ (ì„ íƒ) - GPT ìƒì„± ë¬¸êµ¬ ëŒ€ì‹  ì‚¬ìš©,
        'citation_links': ì¸ìš©ë§í¬ (ì„ íƒ) - ìœ íŠœë¸Œ ì„¤ëª…ì— í¬í•¨,
        'voice': ìŒì„± (ì„ íƒ) - TTS ìŒì„± ì„¤ì •
    }
    selected_project: ë¯¸ë¦¬ ì„ íƒëœ YouTube í”„ë¡œì íŠ¸ ('', '_2')
    """
    # ê¸°ì¡´ run_automation_pipeline í•¨ìˆ˜ í˜¸ì¶œì„ ìœ„í•´ row í˜•ì‹ìœ¼ë¡œ ë³€í™˜
    # ê¸°ì¡´ í•¨ìˆ˜ëŠ” row[ì¸ë±ìŠ¤] ë°©ì‹ìœ¼ë¡œ ì ‘ê·¼í•˜ë¯€ë¡œ í˜¸í™˜ì„± ìœ ì§€
    # ìƒˆ êµ¬ì¡°: channel_idëŠ” ì‹œíŠ¸ ë ˆë²¨ì—ì„œ ì „ë‹¬

    # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (channel_idë¥¼ ë³„ë„ë¡œ ì „ë‹¬, selected_project ì „ë‹¬)
    return run_automation_pipeline_with_channel(
        channel_id=pipeline_data['channel_id'],
        script=pipeline_data['script'],
        title=pipeline_data.get('title'),
        privacy=pipeline_data.get('privacy', 'private'),
        playlist_id=pipeline_data.get('playlist_id'),
        scheduled_time=pipeline_data.get('scheduled_time'),
        sheet_name=sheet_name,
        row_num=row_num,
        selected_project=selected_project,
        # â˜… ì‚¬ìš©ì ì…ë ¥ê°’ ì „ë‹¬
        user_title=pipeline_data.get('user_title'),
        user_thumbnail_text=pipeline_data.get('user_thumbnail_text'),
        # â˜… ì¸ìš©ë§í¬ ì „ë‹¬ (ìœ íŠœë¸Œ ì„¤ëª…ì— í¬í•¨)
        citation_links=pipeline_data.get('citation_links'),
        # â˜… ìŒì„± ì „ë‹¬ (TTS ìŒì„± ì„¤ì •)
        voice=pipeline_data.get('voice'),
    )


def run_automation_pipeline_with_channel(channel_id, script, title=None, privacy='private',
                                          playlist_id=None, scheduled_time=None,
                                          sheet_name=None, row_num=None, selected_project='',
                                          user_title=None, user_thumbnail_text=None,
                                          citation_links=None, voice=None):
    """
    ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ëª…ì‹œì  íŒŒë¼ë¯¸í„° ë²„ì „)
    ê¸°ì¡´ run_automation_pipelineì˜ ë¡œì§ì„ ì¬ì‚¬ìš©í•˜ë©´ì„œ ìƒˆ êµ¬ì¡° ì§€ì›

    selected_project: ë¯¸ë¦¬ ì„ íƒëœ YouTube í”„ë¡œì íŠ¸ ('', '_2')
    user_title: ì‚¬ìš©ì ì…ë ¥ ì œëª© (GPT ìƒì„± ì œëª© ëŒ€ì‹  ì‚¬ìš©)
    user_thumbnail_text: ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ (GPT ìƒì„± ë¬¸êµ¬ ëŒ€ì‹  ì‚¬ìš©)
    citation_links: ì¸ìš©ë§í¬ (ìœ íŠœë¸Œ ì„¤ëª…ì— í¬í•¨)
    voice: TTS ìŒì„± (ë¹ˆ ê°’ì´ë©´ ê¸°ë³¸ ìŒì„± ì‚¬ìš©)
    """
    # ê¸°ì¡´ í•¨ìˆ˜ì˜ row í˜•ì‹ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ í˜¸ì¶œ
    # ê¸°ì¡´ ì»¬ëŸ¼ êµ¬ì¡°: [ìƒíƒœ, ì‘ì—…ì‹œê°„, ì±„ë„ID, ì±„ë„ëª…, ì˜ˆì•½ì‹œê°„, ëŒ€ë³¸, ì œëª©, ...]
    # ìƒˆ êµ¬ì¡°ì—ì„œëŠ” ì±„ë„IDê°€ ì‹œíŠ¸ ë ˆë²¨ì´ë¯€ë¡œ ë”ë¯¸ row ìƒì„±

    # ë”ë¯¸ row ìƒì„± (ê¸°ì¡´ í•¨ìˆ˜ í˜¸í™˜ìš©)
    dummy_row = [
        'ëŒ€ê¸°',           # 0: ìƒíƒœ
        '',               # 1: ì‘ì—…ì‹œê°„
        channel_id,       # 2: ì±„ë„ID
        sheet_name or '', # 3: ì±„ë„ëª… (ì‹œíŠ¸ ì´ë¦„ ì‚¬ìš©)
        scheduled_time or '', # 4: ì˜ˆì•½ì‹œê°„
        script,           # 5: ëŒ€ë³¸
        title or '',      # 6: ì œëª©
        '',               # 7: ì œëª©2
        '',               # 8: ì œëª©3
        '',               # 9: ë¹„ìš©
        privacy,          # 10: ê³µê°œì„¤ì •
        '',               # 11: ì˜ìƒURL
        '',               # 12: ì—ëŸ¬ë©”ì‹œì§€
        voice or '',      # 13: ìŒì„± â˜… (ë¹ˆ ê°’ì´ë©´ run_automation_pipelineì—ì„œ ê¸°ë³¸ê°’ ì‚¬ìš©)
        'senior',         # 14: íƒ€ê²Ÿ
        '',               # 15: ì¹´í…Œê³ ë¦¬
        '',               # 16: ì‡¼ì¸ URL
        playlist_id or '', # 17: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID
        user_title or '', # 18: ì‚¬ìš©ì ì…ë ¥ ì œëª© â˜…
        user_thumbnail_text or '', # 19: ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ â˜…
        citation_links or '' # 20: ì¸ìš©ë§í¬ â˜…
    ]

    # ê¸°ì¡´ íŒŒì´í”„ë¼ì¸ í˜¸ì¶œ (selected_project ì „ë‹¬)
    return run_automation_pipeline(dummy_row, row_num or 0, selected_project=selected_project)


@app.route('/api/sheets/check-ctr-and-update-titles', methods=['GET', 'POST'])
def api_sheets_check_ctr_and_update_titles():
    """
    CTR ê¸°ë°˜ ìë™ ì œëª© ë³€ê²½ API

    ì™„ë£Œëœ ì˜ìƒë“¤ì˜ CTRì„ í™•ì¸í•˜ê³ , CTRì´ 3% ë¯¸ë§Œì¸ ê²½ìš° ì œëª©ì„ ìë™ìœ¼ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
    - ì—…ë¡œë“œ í›„ 7ì¼ ì´ìƒ ì§€ë‚œ ì˜ìƒë§Œ ëŒ€ìƒ
    - ì œëª© ë³€ê²½ ì´ë ¥ì´ ì—†ëŠ” ì˜ìƒë§Œ ëŒ€ìƒ
    - ì œëª©2 â†’ ì œëª©3 ìˆœì„œë¡œ ë³€ê²½ ì‹œë„

    Render Cron Jobì—ì„œ ë§¤ì¼ 1íšŒ í˜¸ì¶œ ê¶Œì¥
    """
    try:
        from datetime import datetime, timedelta, timezone

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID
        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # YouTube API ëª¨ë“ˆ ì„í¬íŠ¸
        from googleapiclient.discovery import build
        from google.oauth2.credentials import Credentials
        from google.auth.transport.requests import Request

        # í˜„ì¬ ì‹œê°„ (KST)
        kst = timezone(timedelta(hours=9))
        now = datetime.now(kst).replace(tzinfo=None)

        # ëª¨ë“  ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        sheet_names = get_all_sheet_names(service, sheet_id)
        if not sheet_names:
            return jsonify({
                "ok": True,
                "message": "ì²˜ë¦¬í•  ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤",
                "checked": 0,
                "updated": 0
            })

        checked_count = 0
        updated_count = 0
        results = []

        for sheet_name in sheet_names:
            rows = sheets_read_rows(service, sheet_id, f"'{sheet_name}'!A:AZ")
            if rows is None or len(rows) < 3:
                continue

            # ì±„ë„ ID (í–‰1)
            channel_id = get_sheet_channel_id(rows)
            if not channel_id:
                continue

            # ê³„ì • ì´ë©”ì¼ (í–‰1 Cì—´, Dì—´)
            account_email = get_sheet_account_email(rows)
            token_key = account_email or channel_id  # ê³„ì • ì´ë©”ì¼ ìš°ì„ , ì—†ìœ¼ë©´ ì±„ë„ID

            # í•´ë‹¹ ê³„ì •ì˜ YouTube í† í° ë¡œë“œ
            youtube_token = load_youtube_token_from_db(token_key)
            if not youtube_token:
                print(f"[CTR] [{sheet_name}] í† í° ì—†ìŒ (key: {token_key}), ê±´ë„ˆë›°ê¸°")
                results.append({
                    "sheet": sheet_name,
                    "channel_id": channel_id,
                    "account": account_email,
                    "status": "skipped",
                    "reason": f"í† í° ì—†ìŒ ({token_key})"
                })
                continue

            # YouTube API í´ë¼ì´ì–¸íŠ¸ ìƒì„±
            try:
                creds = Credentials(
                    token=youtube_token.get('token'),
                    refresh_token=youtube_token.get('refresh_token'),
                    token_uri=youtube_token.get('token_uri', 'https://oauth2.googleapis.com/token'),
                    client_id=youtube_token.get('client_id') or os.environ.get('YOUTUBE_CLIENT_ID'),
                    client_secret=youtube_token.get('client_secret') or os.environ.get('YOUTUBE_CLIENT_SECRET')
                )

                # í† í° ë§Œë£Œ ì‹œ ê°±ì‹ 
                if creds.expired and creds.refresh_token:
                    print(f"[CTR] [{sheet_name}] í† í° ê°±ì‹  ì¤‘...")
                    creds.refresh(Request())
                    updated_token = {
                        'token': creds.token,
                        'refresh_token': creds.refresh_token,
                        'token_uri': creds.token_uri,
                        'client_id': creds.client_id,
                        'client_secret': creds.client_secret,
                        'scopes': list(creds.scopes) if creds.scopes else []
                    }
                    save_youtube_token_to_db(updated_token, channel_id=token_key)

                youtube = build('youtube', 'v3', credentials=creds)
                youtube_analytics = build('youtubeAnalytics', 'v2', credentials=creds)
                print(f"[CTR] [{sheet_name}] YouTube API ì´ˆê¸°í™” ì„±ê³µ (account: {account_email or 'N/A'})")
            except Exception as e:
                print(f"[CTR] [{sheet_name}] YouTube API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
                results.append({
                    "sheet": sheet_name,
                    "channel_id": channel_id,
                    "account": account_email,
                    "status": "error",
                    "reason": f"API ì´ˆê¸°í™” ì‹¤íŒ¨: {e}"
                })
                continue

            # F1ì— ì±„ë„ êµ¬ë…ì ìˆ˜ ê¸°ë¡
            try:
                subscriber_count = get_channel_subscriber_count(youtube, channel_id)
                if subscriber_count is not None:
                    sheets_update_cell(service, sheet_id, f"'{sheet_name}'!F1", f"êµ¬ë…ì: {subscriber_count:,}ëª…")
                    print(f"[CTR] [{sheet_name}] F1ì— êµ¬ë…ì ìˆ˜ ê¸°ë¡: {subscriber_count:,}ëª…")
            except Exception as e:
                print(f"[CTR] [{sheet_name}] F1 êµ¬ë…ì ìˆ˜ ê¸°ë¡ ì‹¤íŒ¨: {e}")

            # í—¤ë”ì—ì„œ ì—´ ë§¤í•‘ ìƒì„± (í–‰2)
            headers = rows[1]
            col_map = get_column_mapping(headers)

            required_headers = ['ìƒíƒœ', 'ì˜ìƒURL', 'ì‘ì—…ì‹œê°„', 'ì œëª©(GPTìƒì„±)', 'ì œëª©2', 'ì œëª©3', 'CTR', 'ë…¸ì¶œìˆ˜', 'ì œëª©ë³€ê²½ì¼']
            if not all(h in col_map for h in ['ìƒíƒœ', 'ì˜ìƒURL', 'ì‘ì—…ì‹œê°„']):
                print(f"[CTR] [{sheet_name}] í•„ìˆ˜ í—¤ë” ì—†ìŒ, ê±´ë„ˆë›°ê¸°")
                continue

            # ë°ì´í„° í–‰ ìˆœíšŒ (í–‰3ë¶€í„°)
            for i, row in enumerate(rows[2:], start=3):
                status = get_row_value(row, col_map, 'ìƒíƒœ')
                video_url = get_row_value(row, col_map, 'ì˜ìƒURL')
                work_time_str = get_row_value(row, col_map, 'ì‘ì—…ì‹œê°„')
                title_changed_date = get_row_value(row, col_map, 'ì œëª©ë³€ê²½ì¼')

                # ì™„ë£Œ ìƒíƒœ + ì˜ìƒURL ìˆìŒ
                if status != 'ì™„ë£Œ' or not video_url:
                    continue

                # ë¹„ë””ì˜¤ ID ì¶”ì¶œ
                video_id = extract_video_id_from_url(video_url)
                if not video_id:
                    continue

                checked_count += 1

                # CTR ë° ì¡°íšŒìˆ˜/êµ¬ë… ë°ì´í„° ì¡°íšŒ (Analytics API)
                ctr_data = get_video_ctr_from_analytics(youtube_analytics, channel_id, video_id)

                # Analytics API ì‹¤íŒ¨ ì‹œ Data APIë¡œ ì¡°íšŒìˆ˜ë§Œ ê°€ì ¸ì˜¤ê¸° (fallback)
                if not ctr_data:
                    data_api_stats = get_video_stats_from_data_api(youtube, video_id)
                    if data_api_stats:
                        ctr_data = {
                            'views': data_api_stats.get('views', 0),
                            'impressions': 0,
                            'ctr': 0,
                            'subscribers_gained': 0,
                            'subscribers_lost': 0,
                            'views_today': 0,
                            'views_yesterday': 0
                        }
                        print(f"[CTR] Data API fallback ì‚¬ìš©: video={video_id}, views={ctr_data['views']}")

                if ctr_data:
                    ctr = ctr_data.get('ctr', 0)
                    impressions = ctr_data.get('impressions', 0)
                    views = ctr_data.get('views', 0)
                    views_today = ctr_data.get('views_today', 0)
                    views_yesterday = ctr_data.get('views_yesterday', 0)
                    subs_gained = ctr_data.get('subscribers_gained', 0)
                    subs_lost = ctr_data.get('subscribers_lost', 0)

                    # ì¡°íšŒìˆ˜ ê¸°ë¡ (Data APIë¡œë„ ê°€ëŠ¥)
                    if 'ì¡°íšŒìˆ˜' in col_map and views > 0:
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì¡°íšŒìˆ˜', str(views))
                        print(f"[CTR] [{sheet_name}] ì¡°íšŒìˆ˜ ê¸°ë¡: {views}")

                    # CTR, ë…¸ì¶œìˆ˜ ê¸°ë¡ (Analytics APIë§Œ ê°€ëŠ¥)
                    if 'CTR' in col_map and ctr > 0:
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'CTR', f'{ctr:.2f}%')
                    if 'ë…¸ì¶œìˆ˜' in col_map and impressions > 0:
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ë…¸ì¶œìˆ˜', str(impressions))

                    # ì „ì¼ëŒ€ë¹„ (ì˜¤ëŠ˜ - ì–´ì œ) - Analytics APIë§Œ ê°€ëŠ¥
                    if 'ì „ì¼ì¡°íšŒìˆ˜' in col_map and (views_today > 0 or views_yesterday > 0):
                        diff = views_today - views_yesterday
                        diff_str = f"+{diff}" if diff >= 0 else str(diff)
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì „ì¼ì¡°íšŒìˆ˜', diff_str)

                    # êµ¬ë…ì¦ê°€/ê°ì†Œ - Analytics APIë§Œ ê°€ëŠ¥
                    if 'êµ¬ë…ì¦ê°€' in col_map and subs_gained > 0:
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'êµ¬ë…ì¦ê°€', f"+{subs_gained}")
                    if 'êµ¬ë…ê°ì†Œ' in col_map and subs_lost > 0:
                        sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'êµ¬ë…ê°ì†Œ', f"-{subs_lost}")

                # ì œëª© ë³€ê²½ì€ 7ì¼ ì´ìƒ ì§€ë‚œ ì˜ìƒë§Œ, ì œëª©ë³€ê²½ ì´ë ¥ ì—†ëŠ” ê²½ìš°ë§Œ
                if title_changed_date:
                    continue  # ì´ë¯¸ ì œëª© ë³€ê²½ë¨

                # ì—…ë¡œë“œ í›„ 7ì¼ ì´ìƒ ì§€ë‚¬ëŠ”ì§€ í™•ì¸ (ì œëª© ë³€ê²½ìš©)
                if work_time_str:
                    try:
                        work_time = datetime.strptime(work_time_str, '%Y-%m-%d %H:%M:%S')
                        days_since_upload = (now - work_time).days
                        if days_since_upload < CTR_CHECK_DAYS:
                            continue  # ì•„ì§ 7ì¼ ì•ˆë¨
                    except ValueError:
                        continue

                if ctr_data:
                    ctr = ctr_data.get('ctr', 0)
                    impressions = ctr_data.get('impressions', 0)

                    # CTRì´ ê¸°ì¤€ ë¯¸ë§Œì´ë©´ ì œëª© ë³€ê²½
                    if ctr < CTR_THRESHOLD and impressions >= 100:  # ìµœì†Œ 100íšŒ ë…¸ì¶œ ì´ìƒ
                        current_title = get_row_value(row, col_map, 'ì œëª©(GPTìƒì„±)')
                        title2 = get_row_value(row, col_map, 'ì œëª©2')
                        title3 = get_row_value(row, col_map, 'ì œëª©3')

                        # ë‹¤ìŒ ì œëª© ì„ íƒ (ì œëª©2 â†’ ì œëª©3)
                        new_title = None
                        if title2 and title2 != current_title:
                            new_title = title2
                        elif title3 and title3 != current_title:
                            new_title = title3

                        if new_title:
                            # YouTube APIë¡œ ì œëª© ë³€ê²½
                            try:
                                youtube.videos().update(
                                    part='snippet',
                                    body={
                                        'id': video_id,
                                        'snippet': {
                                            'title': new_title,
                                            'categoryId': '22'  # People & Blogs
                                        }
                                    }
                                ).execute()

                                # ì‹œíŠ¸ì— ë³€ê²½ ê¸°ë¡
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì œëª©(GPTìƒì„±)', new_title)
                                sheets_update_cell_by_header(service, sheet_id, sheet_name, i, col_map, 'ì œëª©ë³€ê²½ì¼', now.strftime('%Y-%m-%d %H:%M'))

                                updated_count += 1
                                results.append({
                                    'sheet': sheet_name,
                                    'row': i,
                                    'video_id': video_id,
                                    'old_title': current_title,
                                    'new_title': new_title,
                                    'ctr': ctr,
                                    'impressions': impressions
                                })
                                print(f"[CTR] [{sheet_name}] í–‰ {i}: ì œëª© ë³€ê²½ ì™„ë£Œ (CTR {ctr:.2f}% < {CTR_THRESHOLD}%)")

                            except Exception as e:
                                print(f"[CTR] [{sheet_name}] í–‰ {i}: ì œëª© ë³€ê²½ ì‹¤íŒ¨ - {e}")

        return jsonify({
            "ok": True,
            "message": f"CTR í™•ì¸ ì™„ë£Œ: {checked_count}ê°œ í™•ì¸, {updated_count}ê°œ ì œëª© ë³€ê²½",
            "checked": checked_count,
            "updated": updated_count,
            "ctr_threshold": CTR_THRESHOLD,
            "results": results
        })

    except Exception as e:
        print(f"[CTR] check-ctr-and-update-titles ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sheets/read', methods=['GET'])
def api_sheets_read():
    """Google Sheets ë°ì´í„° ì½ê¸° (ë””ë²„ê¹…ìš©)"""
    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({"ok": False, "error": "ì„œë¹„ìŠ¤ ê³„ì • ë¯¸ì„¤ì •"}), 400

        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({"ok": False, "error": "AUTOMATION_SHEET_ID ë¯¸ì„¤ì •"}), 400

        range_name = request.args.get('range', 'Sheet1!A:H')
        rows = sheets_read_rows(service, sheet_id, range_name)

        return jsonify({
            "ok": True,
            "rows": rows,
            "count": len(rows)
        })
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sheets/update', methods=['POST'])
def api_sheets_update():
    """Google Sheets ì…€ ì—…ë°ì´íŠ¸ (ë””ë²„ê¹…ìš©)"""
    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({"ok": False, "error": "ì„œë¹„ìŠ¤ ê³„ì • ë¯¸ì„¤ì •"}), 400

        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({"ok": False, "error": "AUTOMATION_SHEET_ID ë¯¸ì„¤ì •"}), 400

        data = request.get_json() or {}
        cell_range = data.get('range')  # ì˜ˆ: 'Sheet1!A2'
        value = data.get('value')

        if not cell_range or value is None:
            return jsonify({"ok": False, "error": "rangeì™€ value í•„ìˆ˜"}), 400

        success = sheets_update_cell(service, sheet_id, cell_range, value)

        return jsonify({
            "ok": success,
            "message": "ì—…ë°ì´íŠ¸ ì™„ë£Œ" if success else "ì—…ë°ì´íŠ¸ ì‹¤íŒ¨"
        })
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== ë‰´ìŠ¤ ìë™í™” íŒŒì´í”„ë¼ì¸ API ==========

def _verify_news_cron_key():
    """
    NEWS_CRON_KEY ê²€ì¦ (ë³´ì•ˆ)
    í™˜ê²½ë³€ìˆ˜ê°€ ì„¤ì •ë˜ì–´ ìˆìœ¼ë©´ X-Cron-Key í—¤ë” ë˜ëŠ” key ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì™€ ë¹„êµ
    """
    expected_key = os.environ.get('NEWS_CRON_KEY')
    if not expected_key:
        return True  # í‚¤ ë¯¸ì„¤ì • ì‹œ ê²€ì¦ ìŠ¤í‚µ (ê°œë°œìš©)

    # í—¤ë” ë˜ëŠ” ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°ì—ì„œ í‚¤ í™•ì¸
    provided_key = request.headers.get('X-Cron-Key') or request.args.get('key')
    return provided_key == expected_key


def _check_today_already_run(service, sheet_id: str, channel: str = "ECON") -> bool:
    """
    ì˜¤ëŠ˜ ì´ë¯¸ íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ë˜ì—ˆëŠ”ì§€ í™•ì¸ (idempotency)
    OPUS_INPUT_{CHANNEL} íƒ­ì˜ run_idë¥¼ í™•ì¸
    """
    from datetime import datetime, timedelta, timezone
    kst = timezone(timedelta(hours=9))
    today = datetime.now(kst).strftime("%Y-%m-%d")

    try:
        opus_tab = f"OPUS_INPUT_{channel}"
        result = service.spreadsheets().values().get(
            spreadsheetId=sheet_id,
            range=f'{opus_tab}!A2:A11'
        ).execute()
        rows = result.get('values', [])

        for row in rows:
            if row and row[0] == today:
                return True
        return False
    except Exception as e:
        print(f"[NEWS] ì˜¤ëŠ˜ ì‹¤í–‰ ì—¬ë¶€ í™•ì¸ ì‹¤íŒ¨ (ê³„ì† ì§„í–‰): {e}")
        return False


def _ensure_news_sheets_exist(service, sheet_id: str, channel: str = "ECON") -> dict:
    """
    ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ìš© íƒ­ ì¡´ì¬ í™•ì¸ (ì±„ë„ë³„)
    ì—†ìœ¼ë©´ ìë™ ìƒì„±

    êµ¬ì¡°:
    - RAW_FEED: ê³µìš©
    - CANDIDATES_{CHANNEL}: ì±„ë„ë³„
    - OPUS_INPUT_{CHANNEL}: ì±„ë„ë³„
    """
    # ê³µìš© íƒ­ + ì±„ë„ë³„ íƒ­
    required_tabs = [
        'RAW_FEED',
        f'CANDIDATES_{channel}',
        f'OPUS_INPUT_{channel}'
    ]

    headers = {
        'RAW_FEED': ['ingested_at', 'source', 'feed_name', 'title', 'link', 'published_at', 'summary', 'keywords', 'hash'],
        f'CANDIDATES_{channel}': ['run_id', 'rank', 'category', 'angle', 'score_total', 'score_recency', 'score_relevance', 'score_uniqueness', 'title', 'link', 'published_at', 'why_selected'],
        f'OPUS_INPUT_{channel}': ['run_id', 'selected_rank', 'category', 'issue_one_line', 'core_points', 'script_brief', 'shorts_hook_lines', 'thumbnail_copy', 'status', 'opus_script']
    }

    result = {"checked": [], "created": [], "error": None}

    try:
        # ê¸°ì¡´ ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
        spreadsheet = service.spreadsheets().get(spreadsheetId=sheet_id).execute()
        existing_tabs = [s['properties']['title'] for s in spreadsheet.get('sheets', [])]

        for tab in required_tabs:
            if tab in existing_tabs:
                result["checked"].append(tab)
            else:
                # íƒ­ ìƒì„±
                try:
                    service.spreadsheets().batchUpdate(
                        spreadsheetId=sheet_id,
                        body={
                            "requests": [{
                                "addSheet": {
                                    "properties": {"title": tab}
                                }
                            }]
                        }
                    ).execute()

                    # í—¤ë” ì¶”ê°€
                    service.spreadsheets().values().update(
                        spreadsheetId=sheet_id,
                        range=f'{tab}!A1',
                        valueInputOption='RAW',
                        body={'values': [headers[tab]]}
                    ).execute()

                    result["created"].append(tab)
                    print(f"[NEWS] íƒ­ ìƒì„±: {tab}")
                except Exception as e:
                    print(f"[NEWS] íƒ­ ìƒì„± ì‹¤íŒ¨ ({tab}): {e}")
                    result["error"] = str(e)

    except Exception as e:
        result["error"] = str(e)
        print(f"[NEWS] ì‹œíŠ¸ í™•ì¸ ì‹¤íŒ¨: {e}")

    return result


@app.route('/api/news/run-pipeline', methods=['GET', 'POST'])
def api_news_run_pipeline():
    """
    ë‰´ìŠ¤ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì±„ë„ë³„)
    Render Cron Jobì—ì„œ ë§¤ì¼ í˜¸ì¶œ (ì˜ˆ: ì˜¤ì „ 7ì‹œ KST)
    ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥ (GET ì§€ì›)

    Google News RSS â†’ ì±„ë„ë³„ í›„ë³´ ì„ ì • â†’ OPUS ì…ë ¥ ìƒì„±

    íŒŒë¼ë¯¸í„°:
    - channel: ì±„ë„ í‚¤ (ECON, POLICY, SOCIETY, WORLD) - ê¸°ë³¸ê°’ ECON
    - force: "1"ì´ë©´ ì˜¤ëŠ˜ ì´ë¯¸ ì‹¤í–‰í–ˆì–´ë„ ê°•ì œ ì‹¤í–‰
    - key: ì¸ì¦ í‚¤ (ì¿¼ë¦¬ íŒŒë¼ë¯¸í„°, X-Cron-Key í—¤ë” ëŒ€ì²´)

    í™˜ê²½ë³€ìˆ˜:
    - NEWS_SHEET_ID: ë‰´ìŠ¤ìš© Google Sheets ID (ì—†ìœ¼ë©´ AUTOMATION_SHEET_ID ì‚¬ìš©)
    - NEWS_CRON_KEY: ë³´ì•ˆ í‚¤ (ì„¤ì • ì‹œ X-Cron-Key í—¤ë” í•„ìˆ˜)
    - NEWS_CHANNEL: ê¸°ë³¸ ì±„ë„ (ê¸°ë³¸ ECON)
    - LLM_ENABLED: "1"ì´ë©´ TOP 1ì— LLM í•µì‹¬í¬ì¸íŠ¸ ìƒì„±
    - LLM_MIN_SCORE: LLM í˜¸ì¶œ ìµœì†Œ ì ìˆ˜ (ê¸°ë³¸ 0, ë¹„ìš© ì ˆê°ìš©)
    - MAX_PER_FEED: í”¼ë“œë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ 30)
    - TOP_K: ì„ ì •í•  í›„ë³´ ìˆ˜ (ê¸°ë³¸ 5)

    ì‹œíŠ¸ êµ¬ì¡° (Aì•ˆ: ë§ˆìŠ¤í„° ì‹œíŠ¸ 1ê°œ + ì±„ë„ë³„ íƒ­):
    - RAW_FEED: RSS ì›ë³¸ ê¸°ì‚¬ (ê³µìš©)
    - CANDIDATES_{CHANNEL}: ì±„ë„ë³„ í›„ë³´
    - OPUS_INPUT_{CHANNEL}: ì±„ë„ë³„ ëŒ€ë³¸ ì…ë ¥

    í™œì„± ì±„ë„: ECON (ê²½ì œ)
    í™•ì¥ ì˜ˆì •: POLICY, SOCIETY, WORLD
    """
    print("[NEWS] ===== run-pipeline í˜¸ì¶œë¨ =====")

    # ë³´ì•ˆ í‚¤ ê²€ì¦
    if not _verify_news_cron_key():
        print("[NEWS] ë³´ì•ˆ í‚¤ ê²€ì¦ ì‹¤íŒ¨")
        return jsonify({
            "ok": False,
            "error": "ì¸ì¦ ì‹¤íŒ¨: X-Cron-Key í—¤ë”ê°€ ì˜¬ë°”ë¥´ì§€ ì•ŠìŠµë‹ˆë‹¤"
        }), 403

    try:
        from scripts.news_pipeline import run_news_pipeline

        # ì±„ë„ íŒŒë¼ë¯¸í„° (ì¿¼ë¦¬ìŠ¤íŠ¸ë§ ë˜ëŠ” í™˜ê²½ë³€ìˆ˜)
        channel = request.args.get('channel') or os.environ.get('NEWS_CHANNEL', 'ECON')
        channel = channel.upper()

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID
        sheet_id = os.environ.get('NEWS_SHEET_ID') or os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "NEWS_SHEET_ID ë˜ëŠ” AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ íƒ­ ì¡´ì¬ í™•ì¸/ìƒì„± (ì±„ë„ë³„)
        sheets_result = _ensure_news_sheets_exist(service, sheet_id, channel)
        if sheets_result["created"]:
            print(f"[NEWS] ìƒˆë¡œ ìƒì„±ëœ íƒ­: {sheets_result['created']}")

        # ì˜¤ëŠ˜ ì´ë¯¸ ì‹¤í–‰í–ˆëŠ”ì§€ í™•ì¸ (ì±„ë„ë³„ idempotency)
        force = request.args.get('force', '0') == '1'
        if not force and _check_today_already_run(service, sheet_id, channel):
            print(f"[NEWS] ì˜¤ëŠ˜ ì´ë¯¸ ì‹¤í–‰ë¨ ({channel}) - ìŠ¤í‚µ")
            return jsonify({
                "ok": True,
                "skipped": True,
                "channel": channel,
                "message": f"ì˜¤ëŠ˜ ì´ë¯¸ {channel} ì±„ë„ íŒŒì´í”„ë¼ì¸ì´ ì‹¤í–‰ë˜ì—ˆìŠµë‹ˆë‹¤",
                "hint": "force=1 íŒŒë¼ë¯¸í„°ë¡œ ê°•ì œ ì‹¤í–‰ ê°€ëŠ¥"
            })

        # ì„¤ì •
        max_per_feed = int(os.environ.get('MAX_PER_FEED', '30'))
        top_k = int(os.environ.get('TOP_K', '5'))
        llm_enabled = os.environ.get('LLM_ENABLED', '0') == '1'
        llm_min_score = int(os.environ.get('LLM_MIN_SCORE', '0'))

        print(f"[NEWS] ì„¤ì •: channel={channel}, sheet_id={sheet_id[:20]}..., max_per_feed={max_per_feed}, top_k={top_k}")

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = run_news_pipeline(
            sheet_id=sheet_id,
            service=service,
            channel=channel,
            max_per_feed=max_per_feed,
            top_k=top_k,
            llm_enabled=llm_enabled,
            llm_min_score=llm_min_score
        )

        # ===== íˆìŠ¤í† ë¦¬ íŒŒì´í”„ë¼ì¸ë„ í•¨ê»˜ ì‹¤í–‰ (ë§¤ì¼ 1íšŒ) =====
        history_result = None
        try:
            from scripts.history_pipeline import run_history_pipeline
            print("[NEWS] ===== íˆìŠ¤í† ë¦¬ íŒŒì´í”„ë¼ì¸ ì‹œì‘ =====")
            history_result = run_history_pipeline(
                sheet_id=sheet_id,
                service=service,
                force=False  # ì¤€ë¹„ 10ê°œ ë¯¸ë§Œì¼ ë•Œë§Œ ì¶”ê°€
            )
            print(f"[NEWS] íˆìŠ¤í† ë¦¬ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {history_result.get('episodes_added', 0)}ê°œ ì—í”¼ì†Œë“œ ì¶”ê°€")
        except Exception as hist_err:
            print(f"[NEWS] íˆìŠ¤í† ë¦¬ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜ (ë¬´ì‹œ): {hist_err}")
            history_result = {"error": str(hist_err)}

        # ===== ë¬´í˜‘ íŒŒì´í”„ë¼ì¸ë„ í•¨ê»˜ ì‹¤í–‰ (ë§¤ì¼ 1íšŒ) =====
        wuxia_result = None
        try:
            from scripts.wuxia_pipeline import run_auto_script_pipeline
            print("[NEWS] ===== ë¬´í˜‘(í˜ˆì˜) íŒŒì´í”„ë¼ì¸ ì‹œì‘ =====")
            wuxia_result = run_auto_script_pipeline(max_scripts=1)
            if wuxia_result.get("success"):
                print(f"[NEWS] ë¬´í˜‘ íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: {wuxia_result.get('scripts_generated', 0)}ê°œ ëŒ€ë³¸ ìƒì„±")
            else:
                print(f"[NEWS] ë¬´í˜‘ íŒŒì´í”„ë¼ì¸: {wuxia_result.get('message', 'ì²˜ë¦¬í•  ì—í”¼ì†Œë“œ ì—†ìŒ')}")
        except Exception as wuxia_err:
            print(f"[NEWS] ë¬´í˜‘ íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜ (ë¬´ì‹œ): {wuxia_err}")
            wuxia_result = {"error": str(wuxia_err)}

        return jsonify({
            "ok": result["success"],
            "result": result,
            "history": history_result,
            "wuxia": wuxia_result,
            "sheets_setup": sheets_result
        })

    except ImportError as e:
        print(f"[NEWS] ëª¨ë“ˆ import ì‹¤íŒ¨: {e}")
        return jsonify({
            "ok": False,
            "error": f"ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}. feedparser, python-dateutil ì„¤ì¹˜ í™•ì¸"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/news/test-rss', methods=['GET'])
def api_news_test_rss():
    """
    RSS ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ì‹œíŠ¸ ì €ì¥ ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜)

    íŒŒë¼ë¯¸í„°:
    - channel: ì±„ë„ í‚¤ (ECON, POLICY, SOCIETY, WORLD) - ê¸°ë³¸ê°’ ECON
    - max_per_feed: í”¼ë“œë‹¹ ìµœëŒ€ ê¸°ì‚¬ ìˆ˜ (ê¸°ë³¸ 10)
    - top_k: í›„ë³´ ìˆ˜ (ê¸°ë³¸ 5)
    """
    try:
        from scripts.news_pipeline import ingest_rss_feeds, score_and_select_candidates

        channel = request.args.get('channel', 'ECON').upper()
        max_per_feed = int(request.args.get('max_per_feed', '10'))
        top_k = int(request.args.get('top_k', '5'))

        # RSS ìˆ˜ì§‘
        raw_rows, items = ingest_rss_feeds(max_per_feed)

        # ì±„ë„ë³„ í›„ë³´ ì„ ì •
        candidates = score_and_select_candidates(items, channel, top_k)

        return jsonify({
            "ok": True,
            "channel": channel,
            "raw_count": len(raw_rows),
            "candidate_count": len(candidates),
            "candidates": [
                {
                    "rank": c[1],
                    "category": c[2],
                    "angle": c[3],
                    "score": c[4],
                    "title": c[8],
                    "link": c[9]
                }
                for c in candidates
            ]
        })

    except ImportError as e:
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}. feedparser, python-dateutil ì„¤ì¹˜ í™•ì¸"
        }), 500
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== í•œêµ­ì‚¬ ìë™í™” íŒŒì´í”„ë¼ì¸ API ==========

@app.route('/api/history/run-pipeline', methods=['GET', 'POST'])
def api_history_run_pipeline():
    """
    í•œêµ­ì‚¬ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì—í”¼ì†Œë“œ ìë™ ê´€ë¦¬)
    ë¸Œë¼ìš°ì €ì—ì„œ ì§ì ‘ í˜¸ì¶œ ê°€ëŠ¥ (GET ì§€ì›)

    â˜… ìë™ìœ¼ë¡œ PENDING 10ê°œ ìœ ì§€
    â˜… ì‹œëŒ€ ìˆœì„œ: ê³ ì¡°ì„  â†’ ë¶€ì—¬ â†’ ì‚¼êµ­ â†’ ë‚¨ë¶êµ­ â†’ ê³ ë ¤ â†’ ì¡°ì„ ì „ê¸° â†’ ì¡°ì„ í›„ê¸° â†’ ëŒ€í•œì œêµ­
    â˜… AIê°€ ì‹œëŒ€ë³„ ì—í”¼ì†Œë“œ ìˆ˜ ê²°ì •

    íŒŒë¼ë¯¸í„°:
    - force: "1"ì´ë©´ PENDING 10ê°œ ì´ìƒì´ì–´ë„ 1ê°œ ì¶”ê°€

    í™˜ê²½ë³€ìˆ˜:
    - NEWS_SHEET_ID: ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ê³¼ ê°™ì€ ì‹œíŠ¸ ì‚¬ìš© (ê¶Œì¥)
    - HISTORY_SHEET_ID: í•œêµ­ì‚¬ ì „ìš© ì‹œíŠ¸ (ì„ íƒ)
    - LLM_ENABLED: "1"ì´ë©´ AIê°€ ì—í”¼ì†Œë“œ ìˆ˜ ê²°ì • ë° í•µì‹¬í¬ì¸íŠ¸ ìƒì„±
    - MAX_RESULTS: ìˆ˜ì§‘í•  ìµœëŒ€ ìë£Œ ìˆ˜ (ê¸°ë³¸ 30)
    - TOP_K: ì„ ì •í•  í›„ë³´ ìˆ˜ (ê¸°ë³¸ 5)

    ì‹œíŠ¸ êµ¬ì¡°:
    - HISTORY_OPUS_INPUT: ì—í”¼ì†Œë“œë³„ ëŒ€ë³¸ ìë£Œ (â˜… ë‹¨ì¼ í†µí•© ì‹œíŠ¸)
      - episode: ì „ì²´ ì—í”¼ì†Œë“œ ë²ˆí˜¸ (1, 2, 3, ...)
      - era: ì‹œëŒ€ í‚¤
      - era_episode: ì‹œëŒ€ ë‚´ ì—í”¼ì†Œë“œ ë²ˆí˜¸ (1í™”, 2í™”, ...)
      - total_episodes: í•´ë‹¹ ì‹œëŒ€ ì´ ì—í”¼ì†Œë“œ ìˆ˜ (AI ê²°ì •)
      - status: PENDING/DONE
    - {ERA}_RAW: ì›ë¬¸ ìë£Œ (ì‹œëŒ€ë³„)
    - {ERA}_CANDIDATES: í›„ë³´ ìë£Œ (ì‹œëŒ€ë³„)
    """
    print("[HISTORY] ===== run-pipeline í˜¸ì¶œë¨ =====")

    try:
        from scripts.history_pipeline import run_history_pipeline

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID (ë‰´ìŠ¤ íŒŒì´í”„ë¼ì¸ê³¼ ê°™ì€ ì‹œíŠ¸ ì‚¬ìš© ê°€ëŠ¥)
        sheet_id = (
            os.environ.get('HISTORY_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID') or
            os.environ.get('AUTOMATION_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "HISTORY_SHEET_ID, NEWS_SHEET_ID, ë˜ëŠ” AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì„¤ì •
        force = request.args.get('force', '0') == '1'

        print(f"[HISTORY] force: {force}, ì‹œíŠ¸ ID: {sheet_id}")

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ (ì£¼ì œ ê¸°ë°˜ ìë™ ì—í”¼ì†Œë“œ ê´€ë¦¬)
        result = run_history_pipeline(
            sheet_id=sheet_id,
            service=service,
            force=force
        )

        if result.get("success"):
            return jsonify({
                "ok": True,
                "pending_before": result.get("pending_before", 0),
                "pending_after": result.get("pending_after", 0),
                "episodes_added": result.get("episodes_added", 0),
                "current_era": result.get("current_era"),
                "current_episode": result.get("current_episode", 0),
                "all_complete": result.get("all_complete", False),
                "details": result.get("details", []),
                "message": f"{result.get('episodes_added', 0)}ê°œ ì—í”¼ì†Œë“œ ì¶”ê°€, PENDING {result.get('pending_after', 0)}ê°œ"
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
                "details": result.get("details", [])
            }), 500

    except ImportError as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/history/test', methods=['GET'])
def api_history_test():
    """
    í•œêµ­ì‚¬ íŒŒì´í”„ë¼ì¸ í…ŒìŠ¤íŠ¸ (ì‹œíŠ¸ ì €ì¥ ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜)

    íŒŒë¼ë¯¸í„°:
    - era: ì‹œëŒ€ í‚¤ (ê¸°ë³¸ GOJOSEON)
    - max_results: ìˆ˜ì§‘í•  ìµœëŒ€ ìë£Œ ìˆ˜ (ê¸°ë³¸ 10)
    - top_k: í›„ë³´ ìˆ˜ (ê¸°ë³¸ 3)
    """
    try:
        from scripts.history_pipeline import ERAS, ERA_ORDER
        from scripts.history_pipeline.collector import collect_materials
        from scripts.history_pipeline.scoring import score_and_select_candidates

        era = request.args.get('era', 'GOJOSEON').upper()
        max_results = int(request.args.get('max_results', '10'))
        top_k = int(request.args.get('top_k', '3'))

        if era not in ERAS:
            return jsonify({
                "ok": False,
                "error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì‹œëŒ€: {era}",
                "valid_eras": list(ERAS.keys())
            }), 400

        era_info = ERAS[era]

        # ìë£Œ ìˆ˜ì§‘ (ì‹œíŠ¸ ì €ì¥ ì•ˆí•¨)
        raw_rows, items = collect_materials(era, max_results)

        # í›„ë³´ ì„ ì •
        candidates = score_and_select_candidates(items, era, top_k)

        return jsonify({
            "ok": True,
            "era": era,
            "era_name": era_info.get("name"),
            "period": era_info.get("period"),
            "raw_count": len(raw_rows),
            "candidate_count": len(candidates),
            "candidates": [
                {
                    "rank": c[1],
                    "topic": c[3],
                    "score": c[4],
                    "title": c[8],
                    "url": c[9]
                }
                for c in candidates
            ],
            "all_eras": [
                {"key": e, "name": ERAS[e].get("name"), "active": ERAS[e].get("active", False)}
                for e in ERA_ORDER
            ]
        })

    except ImportError as e:
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/history/test-topic', methods=['GET'])
def api_history_test_topic():
    """
    ì£¼ì œ ê¸°ë°˜ ìë£Œ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (2024-12 ê°œí¸)

    íŒŒë¼ë¯¸í„°:
    - era: ì‹œëŒ€ í‚¤ (ê¸°ë³¸ GOJOSEON)
    - episode: ì‹œëŒ€ ë‚´ ì—í”¼ì†Œë“œ ë²ˆí˜¸ (ê¸°ë³¸ 1)

    ì˜ˆì‹œ:
    - /api/history/test-topic?era=GOJOSEON&episode=1  â†’ ê³ ì¡°ì„  1í™” (ë‹¨êµ° ê±´êµ­)
    - /api/history/test-topic?era=SAMGUK&episode=3   â†’ ì‚¼êµ­ì‹œëŒ€ 3í™”
    """
    try:
        from scripts.history_pipeline import (
            ERAS, ERA_ORDER, HISTORY_TOPICS,
            collect_topic_materials,
            get_total_episode_count,
        )

        era = request.args.get('era', 'GOJOSEON').upper()
        episode = int(request.args.get('episode', '1'))

        if era not in ERAS:
            return jsonify({
                "ok": False,
                "error": f"ì•Œ ìˆ˜ ì—†ëŠ” ì‹œëŒ€: {era}",
                "valid_eras": list(ERAS.keys())
            }), 400

        topics = HISTORY_TOPICS.get(era, [])
        if episode < 1 or episode > len(topics):
            return jsonify({
                "ok": False,
                "error": f"{era}ì— {episode}í™” ì—†ìŒ (1~{len(topics)}í™” ê°€ëŠ¥)",
                "available_episodes": [
                    {"episode": i+1, "title": t.get("title")}
                    for i, t in enumerate(topics)
                ]
            }), 400

        era_info = ERAS[era]
        topic_info = topics[episode - 1]

        # ìë£Œ ìˆ˜ì§‘ (ì‹œíŠ¸ ì €ì¥ ì•ˆí•¨)
        collected = collect_topic_materials(era, episode)

        return jsonify({
            "ok": True,
            "era": era,
            "era_name": era_info.get("name"),
            "period": era_info.get("period"),
            "episode": episode,
            "total_episodes": len(topics),
            "topic": {
                "title": topic_info.get("title"),
                "topic": topic_info.get("topic"),
                "keywords": topic_info.get("keywords"),
                "description": topic_info.get("description"),
                "reference_links": topic_info.get("reference_links"),
            },
            "collected": {
                "materials_count": len(collected.get("materials", [])),
                "content_length": len(collected.get("full_content", "")),
                "sources": collected.get("sources", []),
                "content_preview": collected.get("full_content", "")[:2000],
            },
            "all_topics": [
                {"episode": i+1, "title": t.get("title"), "topic": t.get("topic")}
                for i, t in enumerate(topics)
            ],
            "total_series_episodes": get_total_episode_count(),
        })

    except ImportError as e:
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/history/auto-generate', methods=['GET', 'POST'])
def api_history_auto_generate():
    """
    í•œêµ­ì‚¬ ëŒ€ë³¸ ìë™ ìƒì„± (GPT-5.1 íŒŒíŠ¸ë³„ ìƒì„±)

    â˜… 'ì¤€ë¹„' ìƒíƒœ ì—í”¼ì†Œë“œë¥¼ ì°¾ì•„ GPT-5.1ë¡œ ëŒ€ë³¸ ìë™ ìƒì„±
    â˜… íŒŒíŠ¸ë³„ ìƒì„± (ì¸íŠ¸ë¡œ â†’ ë°°ê²½ â†’ ë³¸ë¡  â†’ ë§ˆë¬´ë¦¬)
    â˜… ì´íƒˆë°©ì§€ í›… ìë™ ì‚½ì…
    â˜… ì¶œì²˜ëŠ” YouTube ì„¤ëª…ë€ìš©ìœ¼ë¡œ ë³„ë„ ë°˜í™˜

    íŒŒë¼ë¯¸í„°:
    - max_scripts: í•œë²ˆì— ìƒì„±í•  ìµœëŒ€ ëŒ€ë³¸ ìˆ˜ (ê¸°ë³¸ 1)
    - force: "1"ì´ë©´ ì´ë¯¸ ëŒ€ë³¸ì´ ìˆì–´ë„ ì¬ìƒì„±

    í™˜ê²½ë³€ìˆ˜:
    - OPENAI_API_KEY: GPT-5.1 API í‚¤ (í•„ìˆ˜)
    - HISTORY_SHEET_ID ë˜ëŠ” NEWS_SHEET_ID: ì‹œíŠ¸ ID

    ë¹„ìš© ì˜ˆì¸¡ (GPT-5.1):
    - ì…ë ¥: ~$0.001/1K tokens
    - ì¶œë ¥: ~$0.003/1K tokens
    - 20,000ì ëŒ€ë³¸: ~$0.04

    ì‘ë‹µ ì˜ˆì‹œ:
    {
        "ok": true,
        "generated": 1,
        "episodes": [
            {
                "episode": 1,
                "title": "ê³ ì¡°ì„ ì˜ ê±´êµ­",
                "script_length": 20152,
                "cost": 0.041,
                "youtube_sources": "ğŸ“š ì°¸ê³  ìë£Œ ë° ì¶œì²˜..."
            }
        ],
        "total_cost": 0.041
    }
    """
    print("[HISTORY] ===== auto-generate í˜¸ì¶œë¨ =====")

    try:
        from scripts.history_pipeline import run_auto_script_pipeline

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # OpenAI API í‚¤ í™•ì¸
        if not os.environ.get('OPENAI_API_KEY'):
            return jsonify({
                "ok": False,
                "error": "OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID
        sheet_id = (
            os.environ.get('HISTORY_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID') or
            os.environ.get('AUTOMATION_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "HISTORY_SHEET_ID, NEWS_SHEET_ID, ë˜ëŠ” AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì„¤ì •
        max_scripts = int(request.args.get('max_scripts', '1'))
        force = request.args.get('force', '0') == '1'

        print(f"[HISTORY] max_scripts: {max_scripts}, force: {force}")

        # ëŒ€ë³¸ ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = run_auto_script_pipeline(
            sheet_id=sheet_id,
            service=service,
            max_scripts=max_scripts
        )

        if result.get("success"):
            return jsonify({
                "ok": True,
                "generated": result.get("generated", 0),
                "episodes": result.get("episodes", []),
                "total_cost": result.get("total_cost", 0),
                "message": f"{result.get('generated', 0)}ê°œ ëŒ€ë³¸ ìƒì„± ì™„ë£Œ"
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
                "details": result.get("details", [])
            }), 500

    except ImportError as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/history/status', methods=['GET'])
def api_history_status():
    """
    í•œêµ­ì‚¬ ì‹œë¦¬ì¦ˆ ì „ì²´ í˜„í™© ì¡°íšŒ

    ì‘ë‹µ:
    - ì „ì²´ ì—í”¼ì†Œë“œ ìˆ˜ (60í™”)
    - ì‹œëŒ€ë³„ ì—í”¼ì†Œë“œ ëª©ë¡
    - í˜„ì¬ ì§„í–‰ ìƒí™© (ì‹œíŠ¸ ì—°ê²° ì‹œ)
    """
    try:
        from scripts.history_pipeline import (
            ERAS, ERA_ORDER, HISTORY_TOPICS,
            get_total_episode_count,
        )

        status = {
            "ok": True,
            "total_episodes": get_total_episode_count(),
            "eras": [],
        }

        episode_num = 0
        for era in ERA_ORDER:
            topics = HISTORY_TOPICS.get(era, [])
            era_info = ERAS.get(era, {})

            era_data = {
                "key": era,
                "name": era_info.get("name", era),
                "period": era_info.get("period", ""),
                "episode_count": len(topics),
                "start_episode": episode_num + 1,
                "end_episode": episode_num + len(topics),
                "topics": [
                    {
                        "global_episode": episode_num + i + 1,
                        "era_episode": i + 1,
                        "title": t.get("title"),
                        "topic": t.get("topic"),
                    }
                    for i, t in enumerate(topics)
                ]
            }
            status["eras"].append(era_data)
            episode_num += len(topics)

        return jsonify(status)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== ë¬´í˜‘ íŒŒì´í”„ë¼ì¸ API (í˜ˆì˜ ì‹œë¦¬ì¦ˆ) ==========

@app.route('/api/wuxia/auto-generate', methods=['GET', 'POST'])
def api_wuxia_auto_generate():
    """
    ë¬´í˜‘ ì†Œì„¤ ëŒ€ë³¸ ìë™ ìƒì„± (Claude Opus 4.5)

    â˜… 'ì¤€ë¹„' ìƒíƒœ ì—í”¼ì†Œë“œë¥¼ ì°¾ì•„ ëŒ€ë³¸ ìë™ ìƒì„±
    â˜… ìƒì„± í›„ ìƒíƒœë¥¼ 'ëŒ€ê¸°'ë¡œ ë³€ê²½ â†’ check-and-processê°€ ì˜ìƒ ìƒì„±

    íŒŒë¼ë¯¸í„°:
    - max_scripts: í•œë²ˆì— ìƒì„±í•  ìµœëŒ€ ëŒ€ë³¸ ìˆ˜ (ê¸°ë³¸ 1)

    í™˜ê²½ë³€ìˆ˜:
    - OPENROUTER_API_KEY: Claude Opus 4.5 API í‚¤ (í•„ìˆ˜)
    - AUTOMATION_SHEET_ID: ì‹œíŠ¸ ID

    ì‘ë‹µ ì˜ˆì‹œ:
    {
        "ok": true,
        "generated": 1,
        "episodes": [
            {
                "episode": "EP001",
                "title": "ìš´ëª…ì˜ ì‹œì‘",
                "char_count": 13500,
                "scenes": 10,
                "cost": 0.15
            }
        ],
        "total_cost": 0.15
    }

    Cron ì„¤ì • ì˜ˆì‹œ:
    - ë§¤ì¼ ì˜¤ì „ 8ì‹œ: curl -X POST https://domain/api/wuxia/auto-generate
    """
    print("[WUXIA] ===== auto-generate í˜¸ì¶œë¨ =====")

    try:
        from scripts.wuxia_pipeline import run_auto_script_pipeline

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # OpenRouter API í‚¤ í™•ì¸
        if not os.environ.get('OPENROUTER_API_KEY'):
            return jsonify({
                "ok": False,
                "error": "OPENROUTER_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID í™•ì¸
        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì„¤ì •
        max_scripts = int(request.args.get('max_scripts', '1'))

        print(f"[WUXIA] max_scripts: {max_scripts}")

        # ëŒ€ë³¸ ìë™ ìƒì„± íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = run_auto_script_pipeline(max_scripts=max_scripts)

        if result.get("success"):
            return jsonify({
                "ok": True,
                "generated": result.get("generated", 0),
                "episodes": result.get("episodes", []),
                "errors": result.get("errors"),
                "total_cost": result.get("total_cost", 0),
                "message": f"{result.get('generated', 0)}ê°œ ëŒ€ë³¸ ìƒì„± ì™„ë£Œ"
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
            }), 500

    except ImportError as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}"
        }), 500

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== í˜ˆì˜ ì „ìš© ì˜ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸ ==========

def _parse_chapters_for_bgm(
    script: str,
    total_duration: float,
    bgm_map: dict,
    keyword_map: dict,
    bgm_dir: str
) -> list:
    """
    ëŒ€ë³¸ì—ì„œ ì±•í„°ë¥¼ íŒŒì‹±í•˜ê³  ì±•í„°ë³„ BGM ë¦¬ìŠ¤íŠ¸ ìƒì„±

    ëŒ€ë³¸ í˜•ì‹:
    - ã€ì œ1ì¥ã€‘, ã€ì œ2ì¥ã€‘ ë“±ì˜ ë§ˆì»¤ë¡œ ì±•í„° êµ¬ë¶„
    - ë˜ëŠ” "ì œ1ì¥:", "ì œ2ì¥:" í˜•íƒœ
    - ë§ˆì»¤ê°€ ì—†ìœ¼ë©´ ì‹œê°„ ê¸°ë°˜ìœ¼ë¡œ 5ë“±ë¶„ í›„ í‚¤ì›Œë“œ ê°ì§€

    Returns:
        [(ì‹œì‘ì´ˆ, ì¢…ë£Œì´ˆ, BGMíŒŒì¼ê²½ë¡œ), ...]
    """
    import re

    # ì±•í„° ë§ˆì»¤ íŒ¨í„´
    chapter_patterns = [
        r'ã€ì œ(\d+)ì¥[^ã€‘]*ã€‘',      # ã€ì œ1ì¥: ìš´ëª…ì˜ ë°¤ã€‘
        r'ì œ(\d+)ì¥[:\s]',           # ì œ1ì¥: ìš´ëª…ì˜ ë°¤
        r'\[ì œ(\d+)ì¥\]',            # [ì œ1ì¥]
    ]

    # ì±•í„° ìœ„ì¹˜ ì°¾ê¸°
    chapters = []
    for pattern in chapter_patterns:
        for match in re.finditer(pattern, script):
            chapter_num = int(match.group(1))
            char_pos = match.start()
            chapters.append((chapter_num, char_pos, match.end()))

        if chapters:
            break

    total_chars = len(script)

    # â˜… ì±•í„° ë§ˆì»¤ê°€ ì—†ìœ¼ë©´ ì‹œê°„ ê¸°ë°˜ 5ë“±ë¶„
    if not chapters:
        print("[BGM] ì±•í„° ë§ˆì»¤ ì—†ìŒ â†’ ì‹œê°„ ê¸°ë°˜ 5ë“±ë¶„ + í‚¤ì›Œë“œ ê°ì§€")
        num_sections = 5
        section_duration = total_duration / num_sections
        section_chars = total_chars // num_sections

        chapter_bgm_list = []
        for i in range(num_sections):
            start_time = i * section_duration
            end_time = (i + 1) * section_duration

            # í•´ë‹¹ êµ¬ê°„ í…ìŠ¤íŠ¸ì—ì„œ ë¶„ìœ„ê¸° ê°ì§€
            start_char = i * section_chars
            end_char = (i + 1) * section_chars if i < num_sections - 1 else total_chars
            section_text = script[start_char:end_char]

            detected_mood = _detect_mood_from_text(section_text, keyword_map)
            bgm_filename = bgm_map.get(detected_mood, bgm_map.get("main", "bgm_wuxia_main.mp3"))
            bgm_path = os.path.join(bgm_dir, bgm_filename)

            if os.path.exists(bgm_path):
                chapter_bgm_list.append((start_time, end_time, bgm_path))
                print(f"  êµ¬ê°„ {i+1}: {detected_mood} â†’ {bgm_filename}")

        return chapter_bgm_list

    # ì±•í„° ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬
    chapters.sort(key=lambda x: x[0])

    # ì±•í„°ë³„ í…ìŠ¤íŠ¸ ì¶”ì¶œ ë° ë¶„ìœ„ê¸° ê°ì§€
    chapter_bgm_list = []

    for i, (ch_num, start_pos, end_pos) in enumerate(chapters):
        # ì±•í„° ì¢…ë£Œ ìœ„ì¹˜
        if i < len(chapters) - 1:
            next_start = chapters[i + 1][1]
        else:
            next_start = total_chars

        # ì±•í„° í…ìŠ¤íŠ¸
        chapter_text = script[start_pos:next_start]

        # ì‹œê°„ ê³„ì‚° (ê¸€ì ìˆ˜ ë¹„ìœ¨)
        start_time = (start_pos / total_chars) * total_duration
        end_time = (next_start / total_chars) * total_duration

        # ì±•í„° ë¶„ìœ„ê¸° ê°ì§€ (í‚¤ì›Œë“œ ê¸°ë°˜)
        detected_mood = _detect_mood_from_text(chapter_text, keyword_map)

        # BGM íŒŒì¼ ê²½ë¡œ
        bgm_filename = bgm_map.get(detected_mood, bgm_map.get("main", "bgm_wuxia_main.mp3"))
        bgm_path = os.path.join(bgm_dir, bgm_filename)

        if os.path.exists(bgm_path):
            chapter_bgm_list.append((start_time, end_time, bgm_path))

    return chapter_bgm_list


def _detect_mood_from_text(text: str, keyword_map: dict) -> str:
    """
    í…ìŠ¤íŠ¸ì—ì„œ ë¶„ìœ„ê¸° ê°ì§€ (í‚¤ì›Œë“œ ë§¤ì¹­ ë¹ˆë„ ê¸°ë°˜)
    """
    mood_scores = {}

    for mood, keywords in keyword_map.items():
        score = 0
        for keyword in keywords:
            count = text.count(keyword)
            score += count

        if score > 0:
            mood_scores[mood] = score

    if not mood_scores:
        return "main"  # ê¸°ë³¸

    # ê°€ì¥ ì ìˆ˜ ë†’ì€ ë¶„ìœ„ê¸° ë°˜í™˜
    best_mood = max(mood_scores, key=mood_scores.get)
    return best_mood


def _generate_youtube_chapters(script: str, total_duration: float) -> str:
    """
    ëŒ€ë³¸ì—ì„œ ì±•í„°ë¥¼ íŒŒì‹±í•˜ì—¬ YouTube ì±•í„° íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ìì—´ ìƒì„±

    YouTube ì±•í„° í˜•ì‹:
    0:00 ì¸íŠ¸ë¡œ
    2:30 ì œ1ì¥: ìš´ëª…ì˜ ë°¤
    12:45 ì œ2ì¥: ì²« ë²ˆì§¸ ì‹œë ¨
    ...

    Returns:
        YouTube ì„¤ëª…ë€ì— ë„£ì„ ì±•í„° íƒ€ì„ìŠ¤íƒ¬í”„ ë¬¸ìì—´
    """
    import re

    # ì±•í„° ë§ˆì»¤ íŒ¨í„´
    chapter_patterns = [
        r'ã€ì œ(\d+)ì¥[:\s]*([^ã€‘]*)ã€‘',  # ã€ì œ1ì¥: ìš´ëª…ì˜ ë°¤ã€‘
        r'ì œ(\d+)ì¥[:\s]*([^\n\[]+)',    # ì œ1ì¥: ìš´ëª…ì˜ ë°¤
    ]

    chapters = []
    for pattern in chapter_patterns:
        for match in re.finditer(pattern, script):
            chapter_num = int(match.group(1))
            chapter_title = match.group(2).strip() if match.group(2) else f"ì œ{chapter_num}ì¥"
            char_pos = match.start()
            chapters.append((chapter_num, chapter_title, char_pos))

        if chapters:
            break

    if not chapters:
        # ì±•í„° ë§ˆì»¤ê°€ ì—†ìœ¼ë©´ ê¸°ë³¸ íƒ€ì„ìŠ¤íƒ¬í”„ë§Œ
        return "0:00 ì‹œì‘"

    # ì±•í„° ë²ˆí˜¸ ìˆœìœ¼ë¡œ ì •ë ¬
    chapters.sort(key=lambda x: x[0])

    # ì „ì²´ ê¸€ììˆ˜
    total_chars = len(script)

    # íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„±
    timestamps = ["0:00 ì¸íŠ¸ë¡œ"]

    for ch_num, ch_title, char_pos in chapters:
        # ì‹œê°„ ê³„ì‚° (ê¸€ì ìˆ˜ ë¹„ìœ¨)
        time_seconds = (char_pos / total_chars) * total_duration

        # MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜
        minutes = int(time_seconds // 60)
        seconds = int(time_seconds % 60)
        timestamp = f"{minutes}:{seconds:02d}"

        # ì±•í„° ì œëª© ì •ë¦¬
        if ch_title:
            timestamps.append(f"{timestamp} ì œ{ch_num}ì¥: {ch_title}")
        else:
            timestamps.append(f"{timestamp} ì œ{ch_num}ì¥")

    return "\n".join(timestamps)


def run_wuxia_video_pipeline(
    row_data: dict,
    row_index: int,
    sheet_name: str,
    col_map: dict,
    service,
    sheet_id: str,
    selected_project: str = ''
) -> dict:
    """
    í˜ˆì˜ ì‹œë¦¬ì¦ˆ ì „ìš© ì˜ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸

    ì¼ë°˜ íŒŒì´í”„ë¼ì¸ê³¼ ì°¨ì´ì :
    1. ë‹¤ì¤‘ ìŒì„± TTS (ìºë¦­í„°ë³„ ìŒì„±)
    2. ë¬´í˜‘ ì „ìš© BGM (WUXIA_BGM_MAP)
    3. ì‹œíŠ¸ì— ì €ì¥ëœ ì”¬ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ì‚¬ìš© (ìºë¦­í„° ì™¸ëª¨ ì¼ê´€ì„±)
    4. ì „í†µ í•œë³µ/ë¬´í˜‘ ì˜ìƒ ê°•ì œ

    Args:
        row_data: ì‹œíŠ¸ í–‰ ë°ì´í„° (ë”•ì…”ë„ˆë¦¬)
        row_index: í–‰ ë²ˆí˜¸
        sheet_name: ì‹œíŠ¸ ì´ë¦„ ("í˜ˆì˜")
        col_map: ì—´ ë§¤í•‘
        service: Google Sheets ì„œë¹„ìŠ¤
        sheet_id: ì‹œíŠ¸ ID
        selected_project: YouTube í”„ë¡œì íŠ¸

    Returns:
        {"ok": True, "video_url": "...", "cost": 0.xx}
    """
    import time as time_module
    from datetime import datetime, timedelta, timezone

    print(f"\n[WUXIA-VIDEO] ========== í˜ˆì˜ ì „ìš© íŒŒì´í”„ë¼ì¸ ì‹œì‘ ==========")
    print(f"[WUXIA-VIDEO] í–‰ {row_index}, ì‹œíŠ¸ '{sheet_name}'")

    try:
        # í•„ìš”í•œ ëª¨ë“ˆ ì„í¬íŠ¸
        from scripts.wuxia_pipeline.config import (
            VOICE_MAP, CHARACTER_APPEARANCES, IMAGE_STYLE,
            WUXIA_BGM_MAP, BGM_KEYWORD_MAP, DEFAULT_BGM, BGM_DIR
        )
        from scripts.wuxia_pipeline.multi_voice_tts import (
            parse_script_to_segments,
            generate_single_voice_tts,  # ë‹¨ì¼ ìŒì„± TTS (ìë§‰ ì‹±í¬ ì•ˆì •)
            generate_srt_from_timeline,
        )

        # ë°ì´í„° ì¶”ì¶œ
        script = row_data.get('ëŒ€ë³¸', '').strip()
        title = row_data.get('ì œëª©(ì…ë ¥)', '').strip() or row_data.get('ì œëª©(GPTìƒì„±)', '').strip()
        channel_id = row_data.get('ì±„ë„ID', '').strip()
        visibility = row_data.get('ê³µê°œì„¤ì •', 'private').strip() or 'private'
        scheduled_time = row_data.get('ì˜ˆì•½ì‹œê°„', '').strip()
        playlist_id = row_data.get('í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID', '').strip()
        thumbnail_text = row_data.get('ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)', '').strip()

        if not script:
            return {"ok": False, "error": "ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤", "video_url": None, "cost": 0}

        if not channel_id:
            return {"ok": False, "error": "ì±„ë„IDê°€ ì—†ìŠµë‹ˆë‹¤", "video_url": None, "cost": 0}

        # ì—í”¼ì†Œë“œ ë²ˆí˜¸ ì¶”ì¶œ
        ep_num = row_data.get('episode_num', 1)
        ep_title = row_data.get('title', row_data.get('ì œëª©', '')).strip() or 'ë¬´ì œ'

        # ê¸°ë³¸ ì œëª© ì„¤ì • (í•œì ë³‘ê¸° + ê²€ìƒ‰ ìµœì í™”)
        # í˜•ì‹: [í˜ˆì˜(è¡€å½±)] ì œNí™”: ë¶€ì œëª© | ë¬´í˜‘ ì˜¤ë””ì˜¤ë¶
        # ë²¤ì¹˜ë§ˆí‚¹: ë¬´ë¦¼ì¼ì´ˆ ì±„ë„ ìŠ¤íƒ€ì¼
        if not title:
            title = f"[í˜ˆì˜(è¡€å½±)] ì œ{ep_num}í™”: {ep_title} | ë¬´í˜‘ ì˜¤ë””ì˜¤ë¶"
        elif "[í˜ˆì˜]" in title or "ë¬´í˜‘ ì˜¤ë””ì˜¤ë¶" not in title:
            # ê¸°ì¡´ í˜•ì‹ â†’ í•œì ë³‘ê¸° í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            title = f"[í˜ˆì˜(è¡€å½±)] ì œ{ep_num}í™”: {ep_title} | ë¬´í˜‘ ì˜¤ë””ì˜¤ë¶"

        print(f"[WUXIA-VIDEO] ëŒ€ë³¸: {len(script)}ì")
        print(f"[WUXIA-VIDEO] ì œëª©: {title}")
        print(f"[WUXIA-VIDEO] ì±„ë„: {channel_id}")

        total_cost = 0.0
        kst = timezone(timedelta(hours=9))
        now = datetime.now(kst).strftime('%Y-%m-%d %H:%M:%S')

        # ìƒíƒœë¥¼ 'ì²˜ë¦¬ì¤‘'ìœ¼ë¡œ ë³€ê²½
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì²˜ë¦¬ì¤‘')
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì‘ì—…ì‹œê°„', now)
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', '')

        # ========== 1. ëŒ€ë³¸ ì •ì œ ==========
        print(f"\n[WUXIA-VIDEO] 1. ëŒ€ë³¸ ì •ì œ...")

        # JSON escape ë¬¸ì ì œê±°
        import re
        script = script.replace('\\"', '"')
        script = re.sub(r'"{2,}', '"', script)
        script = script.replace('\\n', '\n')
        script = script.replace('\\\\', '')

        print(f"[WUXIA-VIDEO] ì •ì œ í›„: {len(script)}ì")

        # ========== 2. ë‹¤ì¤‘ ìŒì„± TTS ìƒì„± ==========
        print(f"\n[WUXIA-VIDEO] 2. ë‹¤ì¤‘ ìŒì„± TTS ìƒì„±...")

        # ìŠ¤í¬ë¦½íŠ¸ íŒŒì‹±
        segments = parse_script_to_segments(script)
        print(f"[WUXIA-VIDEO] ì„¸ê·¸ë¨¼íŠ¸: {len(segments)}ê°œ")

        # ìºë¦­í„°ë³„ í†µê³„
        char_stats = {}
        for seg in segments:
            char_stats[seg.tag] = char_stats.get(seg.tag, 0) + 1
        print(f"[WUXIA-VIDEO] ìºë¦­í„° ë¶„í¬: {char_stats}")

        # TTS ìƒì„± (ë‹¨ì¼ ìŒì„± - ìë§‰ ì‹±í¬ ì•ˆì •ì„±)
        episode_id = row_data.get('episode', f'row{row_index}')
        # â˜… ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜ (ì„œë²„ ì‹¤í–‰ ìœ„ì¹˜ì™€ ë¬´ê´€í•˜ê²Œ ë™ì‘)
        script_dir_base = os.path.dirname(os.path.abspath(__file__))
        tts_output_dir = os.path.join(script_dir_base, "outputs", "wuxia", "audio", episode_id)
        os.makedirs(tts_output_dir, exist_ok=True)

        tts_result = generate_single_voice_tts(
            segments=segments,
            output_dir=tts_output_dir,
            episode_id=episode_id.replace('EP', 'ep'),
            voice="chirp3:Charon"  # ë‚˜ë ˆì´ì…˜ ìŒì„±
        )

        if not tts_result.get("ok"):
            error_msg = f"TTS ìƒì„± ì‹¤íŒ¨: {tts_result.get('error')}"
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        audio_path = tts_result.get("merged_audio")
        total_duration = tts_result.get("total_duration", 0)
        timeline = tts_result.get("timeline", [])

        print(f"[WUXIA-VIDEO] TTS ì™„ë£Œ: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")

        # ========== 3. SRT ìë§‰ ìƒì„± ==========
        print(f"\n[WUXIA-VIDEO] 3. SRT ìë§‰ ìƒì„±...")

        srt_output_dir = os.path.join(script_dir_base, "outputs", "wuxia", "subtitles")
        os.makedirs(srt_output_dir, exist_ok=True)
        srt_path = os.path.join(srt_output_dir, f"{episode_id.replace('EP', 'ep')}.srt")

        generate_srt_from_timeline(timeline, srt_path)
        print(f"[WUXIA-VIDEO] ìë§‰ ì™„ë£Œ: {len(timeline)}ê°œ í•­ëª©")

        # ========== 4. ì‹œë¦¬ì¦ˆ ëŒ€í‘œ ì´ë¯¸ì§€ (Aì•ˆ: 1ê°œ ì¬ì‚¬ìš©) ==========
        print(f"\n[WUXIA-VIDEO] 4. ì‹œë¦¬ì¦ˆ ëŒ€í‘œ ì´ë¯¸ì§€ ì¤€ë¹„ (Aì•ˆ)...")

        # configì—ì„œ ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ì„¤ì • ê°€ì ¸ì˜¤ê¸°
        from scripts.wuxia_pipeline.config import THUMBNAIL_CONFIG
        series_image_path = THUMBNAIL_CONFIG.get("series_image_path", "static/images/wuxia/hyulyoung_series.png")
        series_image_prompt = THUMBNAIL_CONFIG.get("series_image_prompt", "")

        # ë””ë ‰í† ë¦¬ ìƒì„±
        os.makedirs(os.path.dirname(series_image_path), exist_ok=True)

        # ì‹œë¦¬ì¦ˆ ëŒ€í‘œ ì´ë¯¸ì§€ í™•ì¸/ìƒì„±
        if os.path.exists(series_image_path):
            # â˜… ê¸°ì¡´ ì´ë¯¸ì§€ ì¬ì‚¬ìš© (ë¹„ìš© $0)
            print(f"[WUXIA-VIDEO] âœ… ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ì¬ì‚¬ìš©: {series_image_path}")
            main_image_path = series_image_path
        else:
            # â˜… ìµœì´ˆ 1íšŒë§Œ ìƒì„± (OpenRouter ê²½ìœ  Gemini ì‚¬ìš©)
            print(f"[WUXIA-VIDEO] ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ì—†ìŒ â†’ OpenRouter Geminië¡œ ìƒì„± ì¤‘...")

            try:
                # image/gemini.py ëª¨ë“ˆ ì‚¬ìš© (ì•ˆì •ì ì¸ OpenRouter ê²½ìœ )
                from image.gemini import generate_image, GEMINI_PRO

                # ë¬´í˜‘ ìŠ¤íƒ€ì¼ í”„ë¡¬í”„íŠ¸ ê°•í™”
                wuxia_negative = IMAGE_STYLE.get('negative_prompt', '')
                full_prompt = f"{series_image_prompt}. Avoid: {wuxia_negative}"

                img_result = generate_image(
                    prompt=full_prompt,
                    size="1920x1080",
                    output_dir=os.path.dirname(series_image_path),
                    model=GEMINI_PRO,  # ê³ í’ˆì§ˆ Pro ëª¨ë¸ ì‚¬ìš©
                    add_aspect_instruction=True
                )

                if img_result.get("ok"):
                    # ìƒì„±ëœ ì´ë¯¸ì§€ ê²½ë¡œ (ì ˆëŒ€ ê²½ë¡œë¡œ ë°˜í™˜ë¨)
                    generated_path = img_result.get("image_url", "")

                    # ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ê²½ë¡œë¡œ ë³µì‚¬
                    import shutil
                    if os.path.exists(generated_path):
                        shutil.copy(generated_path, series_image_path)
                        main_image_path = series_image_path
                    else:
                        # ì ˆëŒ€ ê²½ë¡œê°€ ì•„ë‹Œ ê²½ìš° (fallback)
                        main_image_path = generated_path

                    total_cost += img_result.get("cost", 0.05)
                    print(f"[WUXIA-VIDEO] âœ… ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {main_image_path}")
                else:
                    error_msg = f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {img_result.get('error', 'ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜')}"
                    print(f"[WUXIA-VIDEO] âŒ {error_msg}")
                    sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                    sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                    return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

            except Exception as img_err:
                import traceback
                traceback.print_exc()
                error_msg = f"ì´ë¯¸ì§€ ìƒì„± ì˜ˆì™¸: {img_err}"
                print(f"[WUXIA-VIDEO] âŒ {error_msg}")
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ (Aì•ˆ: 1ê°œë§Œ)
        image_paths = [main_image_path]
        print(f"[WUXIA-VIDEO] ì˜ìƒìš© ì´ë¯¸ì§€: {len(image_paths)}ê°œ")

        # ========== 5. BGM ì„ íƒ (ë¬´í˜‘ ì „ìš© - ì±•í„°ë³„) ==========
        print(f"\n[WUXIA-VIDEO] 5. BGM ì„ íƒ (ë¬´í˜‘ ì „ìš©)...")

        # â˜… ì±•í„°ë³„ BGM ë¦¬ìŠ¤íŠ¸ ìƒì„±
        chapter_bgm_list = _parse_chapters_for_bgm(
            script=script,
            total_duration=total_duration,
            bgm_map=WUXIA_BGM_MAP,
            keyword_map=BGM_KEYWORD_MAP,
            bgm_dir=BGM_DIR
        )

        if chapter_bgm_list and len(chapter_bgm_list) > 1:
            print(f"[WUXIA-VIDEO] ì±•í„°ë³„ BGM: {len(chapter_bgm_list)}ê°œ")
            for start, end, bgm_file in chapter_bgm_list:
                print(f"  - {start:.0f}ì´ˆ~{end:.0f}ì´ˆ: {os.path.basename(bgm_file)}")
        else:
            print(f"[WUXIA-VIDEO] ì±•í„° ê°ì§€ ì‹¤íŒ¨, ê¸°ë³¸ BGM ì‚¬ìš©")

        # ê¸°ë³¸ BGM ê²½ë¡œ (í´ë°±ìš©)
        bgm_path = os.path.join(BGM_DIR, DEFAULT_BGM)
        if not os.path.exists(bgm_path):
            bgm_path = None

        # ========== 6. ì˜ìƒ ë Œë”ë§ (ê¸°ì¡´ í•¨ìˆ˜ ì‚¬ìš©) ==========
        print(f"\n[WUXIA-VIDEO] 6. ì˜ìƒ ë Œë”ë§...")

        # ê¸°ì¡´ ì˜ìƒ ìƒì„± í•¨ìˆ˜ í˜¸ì¶œ (ì ˆëŒ€ ê²½ë¡œ)
        video_output_dir = os.path.join(script_dir_base, "outputs", "wuxia", "videos")
        os.makedirs(video_output_dir, exist_ok=True)
        video_path = os.path.join(video_output_dir, f"{episode_id}.mp4")

        try:
            # ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + BGM í•©ì„± (ì±•í„°ë³„ BGM í¬í•¨)
            render_result = render_video_with_bgm(
                image_paths=[p for p in image_paths if p],
                audio_path=audio_path,
                srt_path=srt_path,
                bgm_path=bgm_path if bgm_path and os.path.exists(bgm_path) else None,
                output_path=video_path,
                duration=total_duration,
                chapter_bgm_list=chapter_bgm_list  # â˜… ì±•í„°ë³„ BGM
            )

            if not render_result.get("ok"):
                error_msg = f"ì˜ìƒ ë Œë”ë§ ì‹¤íŒ¨: {render_result.get('error')}"
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

            video_path = render_result.get("video_path", video_path)
            print(f"[WUXIA-VIDEO] ì˜ìƒ ì™„ë£Œ: {video_path}")

        except Exception as render_err:
            error_msg = f"ì˜ìƒ ë Œë”ë§ ì˜ˆì™¸: {render_err}"
            print(f"[WUXIA-VIDEO] âŒ {error_msg}")
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        # ========== 7. ì‹œë¦¬ì¦ˆ í†µì¼ ì¸ë„¤ì¼ ìƒì„± (Aì•ˆ) ==========
        print(f"\n[WUXIA-VIDEO] 7. ì‹œë¦¬ì¦ˆ í†µì¼ ì¸ë„¤ì¼ ìƒì„± (Aì•ˆ)...")

        thumbnail_path = None
        try:
            from PIL import Image, ImageDraw, ImageFont

            # ì¸ë„¤ì¼ ì¶œë ¥ ë””ë ‰í† ë¦¬ (ì ˆëŒ€ ê²½ë¡œ)
            thumbnail_dir = os.path.join(script_dir_base, "outputs", "wuxia", "thumbnails")
            os.makedirs(thumbnail_dir, exist_ok=True)

            # â˜… ì‹œë¦¬ì¦ˆ ëŒ€í‘œ ì´ë¯¸ì§€ ì¬ì‚¬ìš© (ì´ë¯¸ 4ë‹¨ê³„ì—ì„œ ì¤€ë¹„ë¨)
            if main_image_path and os.path.exists(main_image_path):
                base_thumbnail = main_image_path
                print(f"[WUXIA-VIDEO] âœ… ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ì¬ì‚¬ìš© (ë¹„ìš© $0)")
            else:
                print(f"[WUXIA-VIDEO] âš ï¸ ì‹œë¦¬ì¦ˆ ì´ë¯¸ì§€ ì—†ìŒ, ì¸ë„¤ì¼ ìƒì„± ìŠ¤í‚µ")
                base_thumbnail = None

            if base_thumbnail:
                # PILë¡œ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
                img = Image.open(base_thumbnail)
                if img.mode != 'RGBA':
                    img = img.convert('RGBA')

                width, height = img.size
                draw = ImageDraw.Draw(img)

                # í°íŠ¸ ë¡œë“œ (í•œê¸€ ì§€ì› í°íŠ¸ í•„ìˆ˜) - ì ˆëŒ€ ê²½ë¡œë¡œ ë³€í™˜
                script_dir_fonts = os.path.dirname(os.path.abspath(__file__))
                font_paths = [
                    os.path.join(script_dir_fonts, "static", "fonts", "NotoSansKR-Bold.ttf"),
                    os.path.join(script_dir_fonts, "static", "fonts", "NanumSquareRoundB.ttf"),
                    "/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf",  # Linux ì‹œìŠ¤í…œ í°íŠ¸
                    "/usr/share/fonts/opentype/noto/NotoSansCJK-Bold.ttc",  # Noto CJK
                ]

                font_path = None
                for fp in font_paths:
                    if os.path.exists(fp):
                        font_path = fp
                        break

                print(f"[WUXIA-VIDEO] í°íŠ¸ ê²½ë¡œ: {font_path}")

                # configì—ì„œ í…ìŠ¤íŠ¸ ìŠ¤íƒ€ì¼ ê°€ì ¸ì˜¤ê¸°
                text_style = THUMBNAIL_CONFIG.get("text_style", {})
                series_title = text_style.get("series_title", "í˜ˆì˜ [è¡€å½±]")
                series_color = text_style.get("series_font_color", (255, 215, 0))
                episode_color = text_style.get("episode_font_color", (255, 255, 255))
                outline_color = text_style.get("outline_color", (0, 0, 0))
                outline_width = text_style.get("outline_width", 4)

                # ì¸ë„¤ì¼ í…ìŠ¤íŠ¸ êµ¬ì„±
                # â˜… ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬ ìš°ì„  ì‚¬ìš©
                if thumbnail_text:
                    # ì¤„ë°”ê¿ˆìœ¼ë¡œ line1/line2 ë¶„ë¦¬
                    lines = thumbnail_text.split('\n')
                    thumbnail_lines = [
                        lines[0].strip() if len(lines) > 0 else f"ì œ{ep_num}í™”",
                        lines[1].strip() if len(lines) > 1 else ep_title
                    ]
                    print(f"[WUXIA-VIDEO] ì‚¬ìš©ì ì¸ë„¤ì¼ ë¬¸êµ¬ ì‚¬ìš©: {thumbnail_lines}")
                else:
                    # ê¸°ë³¸ê°’: ì‹œë¦¬ì¦ˆëª… + ì—í”¼ì†Œë“œ ì •ë³´
                    thumbnail_lines = [
                        series_title,
                        f"ì œ{ep_num}í™”: {ep_title}"
                    ]
                    print(f"[WUXIA-VIDEO] ê¸°ë³¸ ì¸ë„¤ì¼ ë¬¸êµ¬ ì‚¬ìš©: {thumbnail_lines}")

                # í°íŠ¸ í¬ê¸°
                title_font_size = int(height * 0.10)
                episode_font_size = int(height * 0.08)

                if font_path:
                    try:
                        title_font = ImageFont.truetype(font_path, title_font_size)
                        episode_font = ImageFont.truetype(font_path, episode_font_size)
                        print(f"[WUXIA-VIDEO] í°íŠ¸ ë¡œë“œ ì„±ê³µ: {font_path}")
                    except Exception as font_err:
                        print(f"[WUXIA-VIDEO] í°íŠ¸ ë¡œë“œ ì‹¤íŒ¨: {font_err}")
                        font_path = None

                if not font_path:
                    # í°íŠ¸ê°€ ì—†ìœ¼ë©´ í…ìŠ¤íŠ¸ ì—†ì´ ì €ì¥
                    print(f"[WUXIA-VIDEO] âš ï¸ í•œê¸€ í°íŠ¸ ì—†ìŒ - í…ìŠ¤íŠ¸ ì—†ì´ ì €ì¥")
                    thumbnail_path = os.path.join(thumbnail_dir, f"thumb_ep{ep_num:03d}.png")
                    img.save(thumbnail_path)
                    print(f"[WUXIA-VIDEO] âœ… ì¸ë„¤ì¼ ì €ì¥ (í…ìŠ¤íŠ¸ ì—†ìŒ): {thumbnail_path}")
                else:
                    # â˜… í°íŠ¸ê°€ ìˆìœ¼ë©´ í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´
                    # í…ìŠ¤íŠ¸ ìœ„ì¹˜ ê³„ì‚° (í•˜ë‹¨ ì¤‘ì•™)
                    y_start = height - int(height * 0.25)

                    # ì‹œë¦¬ì¦ˆëª… (ê¸ˆìƒ‰)
                    line1 = thumbnail_lines[0]
                    bbox1 = draw.textbbox((0, 0), line1, font=title_font)
                    x1 = (width - (bbox1[2] - bbox1[0])) // 2
                    y1 = y_start

                    # í…Œë‘ë¦¬
                    for dx in range(-outline_width, outline_width + 1):
                        for dy in range(-outline_width, outline_width + 1):
                            if dx != 0 or dy != 0:
                                draw.text((x1 + dx, y1 + dy), line1, font=title_font, fill=(*outline_color, 255))
                    draw.text((x1, y1), line1, font=title_font, fill=(*series_color, 255))

                    # ì—í”¼ì†Œë“œ ì •ë³´ (í°ìƒ‰)
                    line2 = thumbnail_lines[1]
                    bbox2 = draw.textbbox((0, 0), line2, font=episode_font)
                    x2 = (width - (bbox2[2] - bbox2[0])) // 2
                    y2 = y1 + title_font_size + 15

                    # í…Œë‘ë¦¬
                    for dx in range(-outline_width, outline_width + 1):
                        for dy in range(-outline_width, outline_width + 1):
                            if dx != 0 or dy != 0:
                                draw.text((x2 + dx, y2 + dy), line2, font=episode_font, fill=(*outline_color, 255))
                    draw.text((x2, y2), line2, font=episode_font, fill=(*episode_color, 255))

                    # ì €ì¥
                    thumbnail_path = os.path.join(thumbnail_dir, f"thumb_ep{ep_num:03d}.png")
                    img.save(thumbnail_path)
                    print(f"[WUXIA-VIDEO] âœ… ì¸ë„¤ì¼ ì™„ë£Œ: {thumbnail_path}")

        except Exception as thumb_err:
            print(f"[WUXIA-VIDEO] âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì˜ˆì™¸: {thumb_err}")
            import traceback
            traceback.print_exc()

        # ========== 8. YouTube ì—…ë¡œë“œ ==========
        print(f"\n[WUXIA-VIDEO] 8. YouTube ì—…ë¡œë“œ...")

        # â˜… YouTube ì±•í„° íƒ€ì„ìŠ¤íƒ¬í”„ ìƒì„± (SEO ìµœì í™”)
        chapter_timestamps = _generate_youtube_chapters(script, total_duration)

        # ì„¤ëª… ìƒì„± (SEO ìµœì í™”)
        description = f"""ğŸ—¡ï¸ ë¬´í˜‘ ì˜¤ë””ì˜¤ë¶ ã€Œí˜ˆì˜(è¡€å½±)ã€ ì œ{ep_num}í™”: {ep_title}

{row_data.get('summary', '')}

{'â”€' * 40}
ğŸ“– ì±•í„° ë°”ë¡œê°€ê¸°
{'â”€' * 40}
{chapter_timestamps}

{'â”€' * 40}
ğŸ“š ì‹œë¦¬ì¦ˆ ì •ë³´
{'â”€' * 40}
â€¢ ì¥ë¥´: ë¬´í˜‘ íŒíƒ€ì§€ ì˜¤ë””ì˜¤ë¶
â€¢ ì£¼ì¸ê³µ: ë¬´ì˜ - ë…¸ë¹„ ì¶œì‹ ì˜ ì ˆì„¸ ê³ ìˆ˜
â€¢ ì—¬ì£¼ì¸ê³µ: ì„¤í•˜ - ëª…ë¬¸ ì„¸ê°€ì˜ ì ˆì„¸ë¯¸ë…€
â€¢ ì—…ë°ì´íŠ¸: ë§¤ì£¼ ìƒˆë¡œìš´ ì—í”¼ì†Œë“œ

{'â”€' * 40}
ğŸ”” êµ¬ë…ê³¼ ì¢‹ì•„ìš”ëŠ” í° í˜ì´ ë©ë‹ˆë‹¤!
{'â”€' * 40}
ğŸ‘ ì¢‹ì•„ìš” ëˆ„ë¥´ì‹œë©´ ë” ì¢‹ì€ ì½˜í…ì¸ ë¡œ ë³´ë‹µí•˜ê² ìŠµë‹ˆë‹¤
ğŸ”” ì•Œë¦¼ ì„¤ì •í•˜ì‹œë©´ ìƒˆ ì—í”¼ì†Œë“œë¥¼ ë†“ì¹˜ì§€ ì•ŠìŠµë‹ˆë‹¤
ğŸ’¬ ëŒ“ê¸€ë¡œ ì—¬ëŸ¬ë¶„ì˜ ì´ì•¼ê¸°ë¥¼ ë“¤ë ¤ì£¼ì„¸ìš”

#ë¬´í˜‘ #ì˜¤ë””ì˜¤ë¶ #í˜ˆì˜ #ë¬´í˜‘ì†Œì„¤ #í•œêµ­ë¬´í˜‘ #ì›¹ì†Œì„¤ #ì›¹ì†Œì„¤ë‚­ë… #íŒíƒ€ì§€ #ë¬´í˜‘íŒíƒ€ì§€ #ASMRë¬´í˜‘ #ì ë“¤ê¸°ì „ë“£ê¸°ì¢‹ì€ #í˜ˆì˜{ep_num}í™”
"""

        # SEO ìµœì í™” íƒœê·¸ (ê²€ìƒ‰ ë…¸ì¶œ ê·¹ëŒ€í™”)
        seo_tags = [
            # í•µì‹¬ í‚¤ì›Œë“œ
            "ë¬´í˜‘", "ì˜¤ë””ì˜¤ë¶", "í˜ˆì˜", "ë¬´í˜‘ì†Œì„¤",
            # ê´€ë ¨ í‚¤ì›Œë“œ
            "í•œêµ­ë¬´í˜‘", "ì›¹ì†Œì„¤", "ì›¹ì†Œì„¤ë‚­ë…", "íŒíƒ€ì§€ì†Œì„¤",
            # ê²€ìƒ‰ ì˜ë„ í‚¤ì›Œë“œ
            "ë¬´í˜‘íŒíƒ€ì§€", "ASMR", "ì ë“¤ê¸°ì „ë“£ê¸°ì¢‹ì€", "ê·€ë¡œë“£ëŠ”ì†Œì„¤",
            # ì‹œë¦¬ì¦ˆ í‚¤ì›Œë“œ
            f"í˜ˆì˜{ep_num}í™”", f"ì œ{ep_num}í™”", ep_title,
            # ë¡±í…Œì¼ í‚¤ì›Œë“œ
            "ë¬´í˜‘ì†Œì„¤ì¶”ì²œ", "ì˜¤ë””ì˜¤ë¶ì¶”ì²œ", "ë¬´í˜‘ì˜¤ë””ì˜¤ë¶", "í•œêµ­ë¬´í˜‘ì†Œì„¤",
        ]

        try:
            upload_result = upload_to_youtube(
                video_path=video_path,
                title=title,
                description=description,
                tags=seo_tags,
                channel_id=channel_id,
                privacy_status=visibility,
                scheduled_time=scheduled_time if scheduled_time else None,
                playlist_id=playlist_id if playlist_id else None,
                thumbnail_path=thumbnail_path,
                selected_project=selected_project
            )

            if upload_result.get("ok"):
                video_url = upload_result.get("video_url")
                print(f"[WUXIA-VIDEO] âœ… ì—…ë¡œë“œ ì™„ë£Œ: {video_url}")

                # ì‹œíŠ¸ ì—…ë°ì´íŠ¸
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì™„ë£Œ')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì˜ìƒURL', video_url)
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ë¹„ìš©', f'${total_cost:.4f}')

                return {"ok": True, "video_url": video_url, "cost": total_cost}
            else:
                error_msg = f"ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.get('error')}"
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        except Exception as upload_err:
            error_msg = f"ì—…ë¡œë“œ ì˜ˆì™¸: {upload_err}"
            print(f"[WUXIA-VIDEO] âŒ {error_msg}")
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

    except Exception as e:
        import traceback
        traceback.print_exc()
        error_msg = f"íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}"
        try:
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
        except:
            pass
        return {"ok": False, "error": error_msg, "video_url": None, "cost": 0}


def _generate_isekai_tts(
    paragraphs: list,
    output_dir: str,
    episode_id: str,
    voice: str = "chirp3:Charon"
) -> dict:
    """
    ì´ì„¸ê³„ ì†Œì„¤ì²´ ëŒ€ë³¸ìš© TTS ìƒì„±

    ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ TTSë¥¼ ìƒì„±í•˜ê³  ë³‘í•©í•©ë‹ˆë‹¤.
    íƒœê·¸ íŒŒì‹± ì—†ì´ ì§ì ‘ ì²˜ë¦¬í•©ë‹ˆë‹¤.
    """
    import subprocess
    import tempfile
    import struct

    print(f"[ISEKAI-TTS] ë¬¸ë‹¨ {len(paragraphs)}ê°œ TTS ìƒì„± ì‹œì‘")

    try:
        from google import genai
        from google.genai import types

        api_key = os.environ.get("GOOGLE_API_KEY", "")
        if not api_key:
            return {"ok": False, "error": "GOOGLE_API_KEY ì—†ìŒ"}

        client = genai.Client(api_key=api_key)

        # ì „ì²´ í…ìŠ¤íŠ¸ë¥¼ í•˜ë‚˜ë¡œ í•©ì¹¨ (ìì—°ìŠ¤ëŸ¬ìš´ íë¦„)
        full_text = "\n\n".join(paragraphs)
        print(f"[ISEKAI-TTS] ì „ì²´ í…ìŠ¤íŠ¸: {len(full_text)}ì")

        # Gemini TTS í˜¸ì¶œ (chirp3 ëª¨ë¸)
        # ê¸´ í…ìŠ¤íŠ¸ëŠ” ì²­í¬ë¡œ ë¶„í• 
        MAX_CHARS = 4000  # Gemini TTS ì œí•œ
        chunks = []
        current_chunk = ""

        for para in paragraphs:
            if len(current_chunk) + len(para) + 2 > MAX_CHARS:
                if current_chunk:
                    chunks.append(current_chunk.strip())
                current_chunk = para
            else:
                current_chunk += "\n\n" + para if current_chunk else para

        if current_chunk:
            chunks.append(current_chunk.strip())

        print(f"[ISEKAI-TTS] ì²­í¬ ìˆ˜: {len(chunks)}ê°œ")

        audio_files = []
        timeline = []
        current_time = 0.0
        total_cost = 0.0

        for i, chunk in enumerate(chunks):
            print(f"[ISEKAI-TTS] ì²­í¬ {i+1}/{len(chunks)} ì²˜ë¦¬ ì¤‘... ({len(chunk)}ì)")

            try:
                response = client.models.generate_content(
                    model="gemini-2.5-flash-preview-tts",
                    contents=chunk,
                    config=types.GenerateContentConfig(
                        response_modalities=["AUDIO"],
                        speech_config=types.SpeechConfig(
                            voice_config=types.VoiceConfig(
                                prebuilt_voice_config=types.PrebuiltVoiceConfig(
                                    voice_name=voice.replace("chirp3:", "") if ":" in voice else voice
                                )
                            )
                        )
                    )
                )

                # ì˜¤ë””ì˜¤ ë°ì´í„° ì¶”ì¶œ
                audio_data = None
                if response.candidates:
                    for part in response.candidates[0].content.parts:
                        if hasattr(part, 'inline_data') and part.inline_data:
                            audio_data = part.inline_data.data
                            break

                if not audio_data:
                    print(f"[ISEKAI-TTS] ì²­í¬ {i+1} ì˜¤ë””ì˜¤ ë°ì´í„° ì—†ìŒ")
                    continue

                # WAV íŒŒì¼ë¡œ ì €ì¥
                chunk_path = os.path.join(output_dir, f"chunk_{i:03d}.wav")
                with open(chunk_path, 'wb') as f:
                    f.write(audio_data)

                # ê¸¸ì´ ê³„ì‚° (WAV í—¤ë” íŒŒì‹±)
                try:
                    with open(chunk_path, 'rb') as f:
                        f.seek(24)
                        sample_rate = struct.unpack('<I', f.read(4))[0]
                        f.seek(40)
                        data_size = struct.unpack('<I', f.read(4))[0]
                        duration = data_size / (sample_rate * 2)  # 16-bit mono
                except:
                    duration = len(chunk) / 15  # fallback: 15ì/ì´ˆ

                audio_files.append(chunk_path)

                # íƒ€ì„ë¼ì¸ (ë¬¸ì¥ ë‹¨ìœ„)
                sentences = [s.strip() for s in chunk.replace('\n', ' ').split('.') if s.strip()]
                sent_duration = duration / max(len(sentences), 1)

                for sent in sentences:
                    if sent:
                        timeline.append({
                            "start": current_time,
                            "end": current_time + sent_duration,
                            "text": sent + "." if not sent.endswith(('.', '?', '!')) else sent
                        })
                        current_time += sent_duration

                total_cost += 0.001 * len(chunk) / 1000  # ëŒ€ëµì  ë¹„ìš©

            except Exception as chunk_err:
                print(f"[ISEKAI-TTS] ì²­í¬ {i+1} ì˜¤ë¥˜: {chunk_err}")
                continue

        if not audio_files:
            return {"ok": False, "error": "ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„± ì‹¤íŒ¨"}

        # ì˜¤ë””ì˜¤ íŒŒì¼ ë³‘í•© (FFmpeg)
        merged_path = os.path.join(output_dir, f"{episode_id}_merged.wav")

        if len(audio_files) == 1:
            import shutil
            shutil.copy(audio_files[0], merged_path)
        else:
            # concat íŒŒì¼ ìƒì„±
            concat_file = os.path.join(output_dir, "concat.txt")
            with open(concat_file, 'w') as f:
                for af in audio_files:
                    f.write(f"file '{af}'\n")

            subprocess.run([
                "ffmpeg", "-y", "-f", "concat", "-safe", "0",
                "-i", concat_file, "-c", "copy", merged_path
            ], capture_output=True, timeout=300)

        if not os.path.exists(merged_path):
            return {"ok": False, "error": "ì˜¤ë””ì˜¤ ë³‘í•© ì‹¤íŒ¨"}

        # ìµœì¢… ê¸¸ì´ ê³„ì‚°
        try:
            result = subprocess.run([
                "ffprobe", "-v", "error", "-show_entries", "format=duration",
                "-of", "default=noprint_wrappers=1:nokey=1", merged_path
            ], capture_output=True, text=True, timeout=30)
            total_duration = float(result.stdout.strip())
        except:
            total_duration = current_time

        print(f"[ISEKAI-TTS] ì™„ë£Œ: {total_duration:.1f}ì´ˆ, íŒŒì¼ {len(audio_files)}ê°œ")

        return {
            "ok": True,
            "merged_audio": merged_path,
            "total_duration": total_duration,
            "timeline": timeline,
            "cost": total_cost
        }

    except Exception as e:
        import traceback
        traceback.print_exc()
        return {"ok": False, "error": str(e)}


def run_isekai_video_pipeline(
    row_data: dict,
    row_index: int,
    sheet_name: str,
    col_map: dict,
    service,
    sheet_id: str,
    selected_project: str = ''
) -> dict:
    """
    í˜ˆì˜ ì´ì„¸ê³„í¸ ì „ìš© ì˜ìƒ ìƒì„± íŒŒì´í”„ë¼ì¸

    í•µì‹¬ íŠ¹ì§•:
    1. GPT ëŒ€ë³¸ ë¶„ì„ ìŠ¤í‚µ (ì´ë¯¸ Claudeê°€ ëª¨ë“  ê²ƒ ìƒì„±)
    2. ì‹œíŠ¸ì˜ image_promptë¡œ ì´ë¯¸ì§€ 1ì¥ë§Œ ìƒì„±
    3. TTS (chirp3:Charon)
    4. ì¸ë„¤ì¼ (ì´ë¯¸ì§€ ì¬ì‚¬ìš©)
    5. ë¹„ìš© ìµœì†Œí™” (~100ì›)
    """
    import time as time_module
    from datetime import datetime, timedelta, timezone

    print(f"\n[ISEKAI] ========== í˜ˆì˜ ì´ì„¸ê³„í¸ íŒŒì´í”„ë¼ì¸ ì‹œì‘ ==========")
    print(f"[ISEKAI] í–‰ {row_index}, ì‹œíŠ¸ '{sheet_name}'")

    try:
        # ë°ì´í„° ì¶”ì¶œ
        script = row_data.get('ëŒ€ë³¸', '').strip()
        image_prompt = row_data.get('image_prompt', '').strip()
        title = row_data.get('ì œëª©(ì…ë ¥)', '').strip() or row_data.get('ì œëª©(GPTìƒì„±)', '').strip()
        channel_id = row_data.get('ì±„ë„ID', '').strip()
        visibility = row_data.get('ê³µê°œì„¤ì •', 'private').strip() or 'private'
        scheduled_time = row_data.get('ì˜ˆì•½ì‹œê°„', '').strip()
        playlist_id = row_data.get('í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID', '').strip()
        thumbnail_text = row_data.get('ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)', '').strip()
        summary = row_data.get('summary', '').strip()

        if not script:
            return {"ok": False, "error": "ëŒ€ë³¸ì´ ì—†ìŠµë‹ˆë‹¤", "video_url": None, "cost": 0}

        if not channel_id:
            return {"ok": False, "error": "ì±„ë„IDê°€ ì—†ìŠµë‹ˆë‹¤", "video_url": None, "cost": 0}

        # ì—í”¼ì†Œë“œ ì •ë³´
        ep_num = row_data.get('episode_num', 1)
        ep_title = row_data.get('title', '').strip() or 'ë¬´ì œ'

        # ê¸°ë³¸ ì œëª©
        if not title:
            title = f"[í˜ˆì˜ ì´ì„¸ê³„í¸] ì œ{ep_num}í™” - {ep_title} | ë¬´í˜‘ íŒíƒ€ì§€ ì˜¤ë””ì˜¤ë¶"

        print(f"[ISEKAI] ëŒ€ë³¸: {len(script)}ì")
        print(f"[ISEKAI] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸: {len(image_prompt)}ì")
        print(f"[ISEKAI] ì œëª©: {title}")

        total_cost = 0.0
        kst = timezone(timedelta(hours=9))
        now = datetime.now(kst).strftime('%Y-%m-%d %H:%M:%S')

        # ìƒíƒœ ì—…ë°ì´íŠ¸
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì²˜ë¦¬ì¤‘')
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì‘ì—…ì‹œê°„', now)
        sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', '')

        # ì ˆëŒ€ ê²½ë¡œ ì„¤ì •
        script_dir_base = os.path.dirname(os.path.abspath(__file__))
        episode_id = row_data.get('episode', f'EP{ep_num:03d}')

        # ========== 1. TTS ìƒì„± (ë‹¨ì¼ ìŒì„±) ==========
        print(f"\n[ISEKAI] 1. TTS ìƒì„± (chirp3:Charon)...")

        tts_output_dir = os.path.join(script_dir_base, "outputs", "isekai", "audio", episode_id)
        os.makedirs(tts_output_dir, exist_ok=True)

        # ëŒ€ë³¸ ì •ì œ
        import re
        clean_script = script.replace('\\"', '"')
        clean_script = re.sub(r'"{2,}', '"', clean_script)
        clean_script = clean_script.replace('\\n', '\n')

        # â˜… ì´ì„¸ê³„ ëŒ€ë³¸ì€ ì†Œì„¤ì²´ â†’ íƒœê·¸ íŒŒì‹± ì—†ì´ ì§ì ‘ TTS í˜¸ì¶œ
        # ë¬¸ë‹¨ ë‹¨ìœ„ë¡œ ë¶„í•  (ë¹ˆ ì¤„ ê¸°ì¤€)
        paragraphs = [p.strip() for p in clean_script.split('\n\n') if p.strip()]
        if not paragraphs:
            # ë¬¸ë‹¨ ë¶„í•  ì‹¤íŒ¨ ì‹œ ì¤„ ë‹¨ìœ„
            paragraphs = [p.strip() for p in clean_script.split('\n') if p.strip()]

        print(f"[ISEKAI] ë¬¸ë‹¨ ìˆ˜: {len(paragraphs)}ê°œ")

        if not paragraphs:
            error_msg = "ëŒ€ë³¸ì—ì„œ í…ìŠ¤íŠ¸ë¥¼ ì¶”ì¶œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        # Gemini TTS ì§ì ‘ í˜¸ì¶œ (ë¬¸ë‹¨ ë‹¨ìœ„)
        from scripts.wuxia_pipeline.multi_voice_tts import generate_srt_from_timeline

        tts_result = _generate_isekai_tts(
            paragraphs=paragraphs,
            output_dir=tts_output_dir,
            episode_id=episode_id.lower(),
            voice="chirp3:Charon"
        )

        if not tts_result.get("ok"):
            error_msg = f"TTS ìƒì„± ì‹¤íŒ¨: {tts_result.get('error')}"
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        audio_path = tts_result.get("merged_audio")
        total_duration = tts_result.get("total_duration", 0)
        timeline = tts_result.get("timeline", [])
        total_cost += tts_result.get("cost", 0.03)

        print(f"[ISEKAI] TTS ì™„ë£Œ: {total_duration:.1f}ì´ˆ ({total_duration/60:.1f}ë¶„)")

        # ========== 2. SRT ìë§‰ ìƒì„± ==========
        print(f"\n[ISEKAI] 2. SRT ìë§‰ ìƒì„±...")

        srt_output_dir = os.path.join(script_dir_base, "outputs", "isekai", "subtitles")
        os.makedirs(srt_output_dir, exist_ok=True)
        srt_path = os.path.join(srt_output_dir, f"{episode_id.lower()}.srt")

        generate_srt_from_timeline(timeline, srt_path)
        print(f"[ISEKAI] ìë§‰ ì™„ë£Œ: {len(timeline)}ê°œ í•­ëª©")

        # ========== 3. ì´ë¯¸ì§€ 1ì¥ ìƒì„± (ì‹œíŠ¸ì˜ image_prompt ì‚¬ìš©) ==========
        print(f"\n[ISEKAI] 3. ì´ë¯¸ì§€ 1ì¥ ìƒì„±...")

        image_output_dir = os.path.join(script_dir_base, "outputs", "isekai", "images", episode_id)
        os.makedirs(image_output_dir, exist_ok=True)
        main_image_path = os.path.join(image_output_dir, "main.png")

        # ì´ë¯¸ ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ ì¬ì‚¬ìš©
        if os.path.exists(main_image_path):
            print(f"[ISEKAI] âœ… ê¸°ì¡´ ì´ë¯¸ì§€ ì¬ì‚¬ìš©: {main_image_path}")
        elif image_prompt:
            # ì´ë¯¸ì§€ ìƒì„±
            try:
                from image.gemini import generate_image, GEMINI_PRO

                img_result = generate_image(
                    prompt=image_prompt,
                    size="1920x1080",
                    output_dir=image_output_dir,
                    model=GEMINI_PRO,
                    add_aspect_instruction=True
                )

                if img_result.get("ok"):
                    generated_path = img_result.get("image_url", "")
                    if os.path.exists(generated_path) and generated_path != main_image_path:
                        import shutil
                        shutil.copy(generated_path, main_image_path)
                    total_cost += img_result.get("cost", 0.05)
                    print(f"[ISEKAI] âœ… ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {main_image_path}")
                else:
                    error_msg = f"ì´ë¯¸ì§€ ìƒì„± ì‹¤íŒ¨: {img_result.get('error')}"
                    print(f"[ISEKAI] âŒ {error_msg}")
                    sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                    sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                    return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}
            except Exception as img_err:
                error_msg = f"ì´ë¯¸ì§€ ìƒì„± ì˜ˆì™¸: {img_err}"
                print(f"[ISEKAI] âŒ {error_msg}")
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}
        else:
            error_msg = "ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤"
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        # ========== 4. ì¸ë„¤ì¼ ìƒì„± (ì´ë¯¸ì§€ ì¬ì‚¬ìš© + í…ìŠ¤íŠ¸) ==========
        print(f"\n[ISEKAI] 4. ì¸ë„¤ì¼ ìƒì„±...")

        thumbnail_path = None
        try:
            from PIL import Image, ImageDraw, ImageFont

            thumbnail_dir = os.path.join(script_dir_base, "outputs", "isekai", "thumbnails")
            os.makedirs(thumbnail_dir, exist_ok=True)

            if os.path.exists(main_image_path):
                img = Image.open(main_image_path)
                if img.mode != 'RGBA':
                    img = img.convert('RGBA')

                width, height = img.size
                draw = ImageDraw.Draw(img)

                # í°íŠ¸ ë¡œë“œ
                font_paths = [
                    os.path.join(script_dir_base, "static", "fonts", "NotoSansKR-Bold.ttf"),
                    "/usr/share/fonts/truetype/nanum/NanumGothicBold.ttf",
                ]
                font_path = None
                for fp in font_paths:
                    if os.path.exists(fp):
                        font_path = fp
                        break

                if font_path:
                    # ì¸ë„¤ì¼ í…ìŠ¤íŠ¸
                    if thumbnail_text:
                        lines = thumbnail_text.split('\n')
                    else:
                        lines = ["í˜ˆì˜ ì´ì„¸ê³„í¸", f"ì œ{ep_num}í™”", ep_title]

                    title_font_size = int(height * 0.08)
                    title_font = ImageFont.truetype(font_path, title_font_size)

                    y_start = height - int(height * 0.30)
                    outline_color = (0, 0, 0)
                    outline_width = 4

                    for i, line in enumerate(lines[:3]):
                        line = line.strip()
                        if not line:
                            continue
                        bbox = draw.textbbox((0, 0), line, font=title_font)
                        x = (width - (bbox[2] - bbox[0])) // 2
                        y = y_start + i * (title_font_size + 10)

                        # ê¸ˆìƒ‰ (ì²« ì¤„) ë˜ëŠ” í°ìƒ‰
                        fill_color = (255, 215, 0, 255) if i == 0 else (255, 255, 255, 255)

                        # í…Œë‘ë¦¬
                        for dx in range(-outline_width, outline_width + 1):
                            for dy in range(-outline_width, outline_width + 1):
                                if dx != 0 or dy != 0:
                                    draw.text((x + dx, y + dy), line, font=title_font, fill=(*outline_color, 255))
                        draw.text((x, y), line, font=title_font, fill=fill_color)

                thumbnail_path = os.path.join(thumbnail_dir, f"thumb_{episode_id.lower()}.png")
                img.save(thumbnail_path)
                print(f"[ISEKAI] âœ… ì¸ë„¤ì¼ ì™„ë£Œ: {thumbnail_path}")

        except Exception as thumb_err:
            print(f"[ISEKAI] âš ï¸ ì¸ë„¤ì¼ ìƒì„± ì˜ˆì™¸ (ê³„ì† ì§„í–‰): {thumb_err}")

        # ========== 5. ì˜ìƒ ë Œë”ë§ ==========
        print(f"\n[ISEKAI] 5. ì˜ìƒ ë Œë”ë§...")

        video_output_dir = os.path.join(script_dir_base, "outputs", "isekai", "videos")
        os.makedirs(video_output_dir, exist_ok=True)
        video_path = os.path.join(video_output_dir, f"{episode_id}.mp4")

        try:
            render_result = render_video_with_bgm(
                image_paths=[main_image_path],
                audio_path=audio_path,
                srt_path=srt_path,
                bgm_path=None,  # BGM ì—†ìŒ (ì¶”í›„ ì¶”ê°€ ê°€ëŠ¥)
                output_path=video_path,
                duration=total_duration
            )

            if not render_result.get("ok"):
                error_msg = f"ì˜ìƒ ë Œë”ë§ ì‹¤íŒ¨: {render_result.get('error')}"
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

            video_path = render_result.get("video_path", video_path)
            print(f"[ISEKAI] âœ… ì˜ìƒ ì™„ë£Œ: {video_path}")

        except Exception as render_err:
            error_msg = f"ì˜ìƒ ë Œë”ë§ ì˜ˆì™¸: {render_err}"
            print(f"[ISEKAI] âŒ {error_msg}")
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        # ========== 6. YouTube ì—…ë¡œë“œ ==========
        print(f"\n[ISEKAI] 6. YouTube ì—…ë¡œë“œ...")

        description = f"""ğŸ—¡ï¸ í˜ˆì˜ ì´ì„¸ê³„í¸ ì œ{ep_num}í™” - {ep_title}

{summary}

{'â”€' * 40}
ğŸ“– ì‹œë¦¬ì¦ˆ ì†Œê°œ
{'â”€' * 40}
ë¬´ë¦¼ ìµœê°•ì˜ ê²€ê°ì´ ì´ì„¸ê³„ë¡œ ë–¨ì–´ì¡Œë‹¤.
ëª¨ë“  ë‚´ê³µì„ ìƒì—ˆì§€ë§Œ, ê·¸ì˜ ê²€ìˆ ê³¼ ì‹¬ë²• ì§€ì‹ì€ ë‚¨ì•„ìˆë‹¤.
ë§ˆë‚˜ë¼ëŠ” ìƒˆë¡œìš´ í˜ì„ ë§Œë‚œ ê·¸ëŠ”, ë‹¤ì‹œ ìµœê°•ì„ í–¥í•´ ë‚˜ì•„ê°„ë‹¤.

{'â”€' * 40}
ğŸ”” êµ¬ë…ê³¼ ì¢‹ì•„ìš”ëŠ” í° í˜ì´ ë©ë‹ˆë‹¤!
{'â”€' * 40}

#ì´ì„¸ê³„ #ë¬´í˜‘ #íŒíƒ€ì§€ #ì˜¤ë””ì˜¤ë¶ #ì›¹ì†Œì„¤ #í˜ˆì˜ #ì†Œë“œë§ˆìŠ¤í„° #ë¬´í˜‘ì†Œì„¤
"""

        try:
            import requests as req
            port = os.environ.get("PORT", "5002")
            base_url = f"http://127.0.0.1:{port}"

            upload_payload = {
                "videoPath": video_path,
                "title": title,
                "description": description,
                "privacyStatus": visibility,
                "channelId": channel_id,
                "selectedProject": selected_project
            }

            if thumbnail_path and os.path.exists(thumbnail_path):
                upload_payload["thumbnailPath"] = thumbnail_path

            if playlist_id:
                upload_payload["playlistId"] = playlist_id

            # ì˜ˆì•½ ì—…ë¡œë“œ
            if scheduled_time and visibility == "private":
                try:
                    parsed_dt = datetime.strptime(scheduled_time, '%Y-%m-%d %H:%M')
                    utc_dt = parsed_dt - timedelta(hours=9)
                    upload_payload["publishAt"] = utc_dt.strftime("%Y-%m-%dT%H:%M:%S.000Z")
                    upload_payload["privacyStatus"] = "private"
                except:
                    pass

            upload_resp = req.post(
                f"{base_url}/api/youtube/upload",
                json=upload_payload,
                timeout=600
            )

            upload_result = upload_resp.json()

            if upload_result.get('ok'):
                video_url = upload_result.get('videoUrl', '')
                print(f"[ISEKAI] âœ… ì—…ë¡œë“œ ì™„ë£Œ: {video_url}")

                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì™„ë£Œ')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì˜ìƒURL', video_url)
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ë¹„ìš©', f'${total_cost:.4f}')

                return {"ok": True, "video_url": video_url, "cost": total_cost, "title": title}
            else:
                error_msg = f"ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.get('error')}"
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
                sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
                return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

        except Exception as upload_err:
            error_msg = f"ì—…ë¡œë“œ ì˜ˆì™¸: {upload_err}"
            print(f"[ISEKAI] âŒ {error_msg}")
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
            return {"ok": False, "error": error_msg, "video_url": None, "cost": total_cost}

    except Exception as e:
        import traceback
        traceback.print_exc()
        error_msg = f"íŒŒì´í”„ë¼ì¸ ì˜¤ë¥˜: {e}"
        try:
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ìƒíƒœ', 'ì‹¤íŒ¨')
            sheets_update_cell_by_header(service, sheet_id, sheet_name, row_index, col_map, 'ì—ëŸ¬ë©”ì‹œì§€', error_msg)
        except:
            pass
        return {"ok": False, "error": error_msg, "video_url": None, "cost": 0}


def render_video_with_bgm(
    image_paths: list,
    audio_path: str,
    srt_path: str,
    bgm_path: str,
    output_path: str,
    duration: float,
    chapter_bgm_list: list = None  # â˜… ì±•í„°ë³„ BGM [(start_time, end_time, bgm_path), ...]
) -> dict:
    """
    ì´ë¯¸ì§€ + ì˜¤ë””ì˜¤ + BGM + ìë§‰ìœ¼ë¡œ ì˜ìƒ ë Œë”ë§

    Args:
        chapter_bgm_list: ì±•í„°ë³„ BGM ë¦¬ìŠ¤íŠ¸ [(ì‹œì‘ì´ˆ, ì¢…ë£Œì´ˆ, BGMê²½ë¡œ), ...]
                          ì˜ˆ: [(0, 600, "fight.mp3"), (600, 1200, "calm.mp3"), ...]
    """
    import subprocess
    import tempfile

    if not image_paths:
        return {"ok": False, "error": "ì´ë¯¸ì§€ê°€ ì—†ìŠµë‹ˆë‹¤"}

    if not os.path.exists(audio_path):
        return {"ok": False, "error": f"ì˜¤ë””ì˜¤ íŒŒì¼ ì—†ìŒ: {audio_path}"}

    os.makedirs(os.path.dirname(output_path), exist_ok=True)

    try:
        # ì´ë¯¸ì§€ë‹¹ í‘œì‹œ ì‹œê°„
        image_duration = duration / len(image_paths)

        # ì´ë¯¸ì§€ ë¦¬ìŠ¤íŠ¸ íŒŒì¼ ìƒì„±
        with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
            for img_path in image_paths:
                f.write(f"file '{os.path.abspath(img_path)}'\n")
                f.write(f"duration {image_duration}\n")
            # ë§ˆì§€ë§‰ ì´ë¯¸ì§€ í•œë²ˆ ë” (FFmpeg ìš”êµ¬ì‚¬í•­)
            f.write(f"file '{os.path.abspath(image_paths[-1])}'\n")
            image_list_file = f.name

        # ========== ì±•í„°ë³„ BGM ë¯¹ì‹± ==========
        if chapter_bgm_list and len(chapter_bgm_list) > 1:
            # ì±•í„° ê¸°ë°˜ BGM ë¯¹ì‹± (crossfade ì „í™˜)
            print(f"[RENDER] ì±•í„°ë³„ BGM ë¯¹ì‹±: {len(chapter_bgm_list)}ê°œ ì±•í„°")

            mixed_bgm_path = _create_chapter_bgm_mix(chapter_bgm_list, duration, output_path)

            if mixed_bgm_path and os.path.exists(mixed_bgm_path):
                bgm_path = mixed_bgm_path
                print(f"[RENDER] ì±•í„° BGM ë¯¹ìŠ¤ ì™„ë£Œ: {bgm_path}")
            else:
                print(f"[RENDER] ì±•í„° BGM ë¯¹ìŠ¤ ì‹¤íŒ¨, ê¸°ë³¸ BGM ì‚¬ìš©")

        # FFmpeg ëª…ë ¹ì–´ êµ¬ì„±
        ffmpeg_cmd = [
            "ffmpeg", "-y",
            "-f", "concat", "-safe", "0", "-i", image_list_file,
            "-i", audio_path,
        ]

        # BGM ì¶”ê°€ (ìˆìœ¼ë©´)
        if bgm_path and os.path.exists(bgm_path):
            ffmpeg_cmd.extend(["-i", bgm_path])
            # ì˜¤ë””ì˜¤ ë¯¹ì‹±: TTS ë³¼ë¥¨ 1.0, BGM ë³¼ë¥¨ 0.07 (7%)
            ffmpeg_cmd.extend([
                "-filter_complex",
                "[1:a]volume=1.0[tts];[2:a]volume=0.07,aloop=loop=-1:size=2e+09[bgm];[tts][bgm]amix=inputs=2:duration=first[aout]",
                "-map", "0:v",
                "-map", "[aout]"
            ])
        else:
            ffmpeg_cmd.extend(["-map", "0:v", "-map", "1:a"])

        # â˜… ìë§‰ ë¹„í™œì„±í™” (ì‹±í¬ ë¬¸ì œë¡œ ì œê±°)
        # if srt_path and os.path.exists(srt_path):
        #     subtitle_style = "..."
        #     ffmpeg_cmd.extend(["-vf", f"subtitles={srt_path}:..."])

        # ì¶œë ¥ ì„¤ì •
        ffmpeg_cmd.extend([
            "-c:v", "libx264",
            "-preset", "medium",
            "-crf", "23",
            "-c:a", "aac",
            "-b:a", "128k",
            "-ar", "44100",
            "-movflags", "+faststart",
            "-t", str(duration),
            output_path
        ])

        print(f"[RENDER] FFmpeg ì‹¤í–‰ ì¤‘...")
        result = subprocess.run(ffmpeg_cmd, capture_output=True, timeout=1800)  # 30ë¶„ íƒ€ì„ì•„ì›ƒ

        if result.returncode != 0:
            stderr = result.stderr.decode('utf-8', errors='ignore')[-500:]
            return {"ok": False, "error": f"FFmpeg ì˜¤ë¥˜: {stderr}"}

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        try:
            os.unlink(image_list_file)
        except:
            pass

        if os.path.exists(output_path):
            return {"ok": True, "video_path": output_path}
        else:
            return {"ok": False, "error": "ì˜ìƒ íŒŒì¼ ìƒì„± ì‹¤íŒ¨"}

    except subprocess.TimeoutExpired:
        return {"ok": False, "error": "FFmpeg íƒ€ì„ì•„ì›ƒ (30ë¶„ ì´ˆê³¼)"}
    except Exception as e:
        return {"ok": False, "error": str(e)}


def _create_chapter_bgm_mix(chapter_bgm_list: list, total_duration: float, output_path: str) -> str:
    """
    ì±•í„°ë³„ BGMì„ í¬ë¡œìŠ¤í˜ì´ë“œë¡œ ë¯¹ì‹±í•˜ì—¬ ë‹¨ì¼ ì˜¤ë””ì˜¤ íŒŒì¼ ìƒì„±

    Args:
        chapter_bgm_list: [(ì‹œì‘ì´ˆ, ì¢…ë£Œì´ˆ, BGMê²½ë¡œ), ...]
        total_duration: ì´ ì˜ìƒ ê¸¸ì´ (ì´ˆ)
        output_path: ì¶œë ¥ ì˜ìƒ ê²½ë¡œ (BGM íŒŒì¼ëª… ìƒì„±ìš©)

    Returns:
        ë¯¹ì‹±ëœ BGM íŒŒì¼ ê²½ë¡œ
    """
    import subprocess

    if not chapter_bgm_list:
        return None

    # ì¶œë ¥ ê²½ë¡œ
    bgm_output = output_path.replace('.mp4', '_bgm_mixed.mp3')

    # ìœ íš¨í•œ BGMë§Œ í•„í„°ë§
    valid_chapters = []
    for start, end, bgm_file in chapter_bgm_list:
        if bgm_file and os.path.exists(bgm_file):
            valid_chapters.append((start, end, bgm_file))

    if not valid_chapters:
        return None

    if len(valid_chapters) == 1:
        # ì±•í„°ê°€ 1ê°œë©´ ê·¸ëƒ¥ ë³µì‚¬
        return valid_chapters[0][2]

    try:
        # FFmpeg ë³µí•© í•„í„°ë¡œ ì±•í„°ë³„ BGM ì—°ê²° + í¬ë¡œìŠ¤í˜ì´ë“œ
        # ê° ì±•í„° BGMì„ í•´ë‹¹ êµ¬ê°„ ê¸¸ì´ë§Œí¼ íŠ¸ë¦¼ í›„ concat

        inputs = []
        filter_parts = []
        crossfade_duration = 3.0  # 3ì´ˆ í¬ë¡œìŠ¤í˜ì´ë“œ

        for i, (start, end, bgm_file) in enumerate(valid_chapters):
            chapter_duration = end - start
            inputs.extend(["-i", bgm_file])

            # í•´ë‹¹ êµ¬ê°„ ê¸¸ì´ë§Œí¼ íŠ¸ë¦¼ + í˜ì´ë“œ
            if i < len(valid_chapters) - 1:
                # ë§ˆì§€ë§‰ì´ ì•„ë‹ˆë©´ ëì— í˜ì´ë“œì•„ì›ƒ
                filter_parts.append(
                    f"[{i}:a]atrim=0:{chapter_duration},asetpts=PTS-STARTPTS,"
                    f"afade=t=in:st=0:d=2,afade=t=out:st={chapter_duration-crossfade_duration}:d={crossfade_duration}[a{i}]"
                )
            else:
                # ë§ˆì§€ë§‰ ì±•í„°ëŠ” í˜ì´ë“œì¸ë§Œ
                filter_parts.append(
                    f"[{i}:a]atrim=0:{chapter_duration},asetpts=PTS-STARTPTS,"
                    f"afade=t=in:st=0:d=2[a{i}]"
                )

        # ëª¨ë“  ì˜¤ë””ì˜¤ concat
        audio_labels = "".join([f"[a{i}]" for i in range(len(valid_chapters))])
        filter_parts.append(f"{audio_labels}concat=n={len(valid_chapters)}:v=0:a=1[aout]")

        filter_complex = ";".join(filter_parts)

        ffmpeg_cmd = ["ffmpeg", "-y"] + inputs + [
            "-filter_complex", filter_complex,
            "-map", "[aout]",
            "-c:a", "libmp3lame",
            "-b:a", "192k",
            bgm_output
        ]

        print(f"[RENDER] ì±•í„° BGM ë¯¹ì‹± ì¤‘... ({len(valid_chapters)}ê°œ)")
        result = subprocess.run(ffmpeg_cmd, capture_output=True, timeout=300)

        if result.returncode == 0 and os.path.exists(bgm_output):
            return bgm_output
        else:
            stderr = result.stderr.decode('utf-8', errors='ignore')[-200:]
            print(f"[RENDER] BGM ë¯¹ì‹± ì‹¤íŒ¨: {stderr}")
            return None

    except Exception as e:
        print(f"[RENDER] BGM ë¯¹ì‹± ì˜ˆì™¸: {e}")
        return None


def upload_to_youtube(
    video_path: str,
    title: str,
    description: str,
    tags: list,
    channel_id: str,
    privacy_status: str = "private",
    scheduled_time: str = None,
    playlist_id: str = None,
    thumbnail_path: str = None,
    selected_project: str = ""
) -> dict:
    """
    YouTube ì—…ë¡œë“œ ë˜í¼ í•¨ìˆ˜ (ê¸°ì¡´ API í™œìš©)

    Args:
        video_path: ì˜ìƒ íŒŒì¼ ê²½ë¡œ
        title: ì˜ìƒ ì œëª©
        description: ì˜ìƒ ì„¤ëª…
        tags: íƒœê·¸ ëª©ë¡
        channel_id: ì±„ë„ ID
        privacy_status: ê³µê°œ ì„¤ì • (private/unlisted/public)
        scheduled_time: ì˜ˆì•½ ì‹œê°„ (ISO 8601)
        playlist_id: í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID
        thumbnail_path: ì¸ë„¤ì¼ ì´ë¯¸ì§€ ê²½ë¡œ
        selected_project: YouTube í”„ë¡œì íŠ¸ ì ‘ë¯¸ì‚¬
    """
    try:
        import requests as req

        # ë‚´ë¶€ ì—…ë¡œë“œ API í˜¸ì¶œ (ì¸ë„¤ì¼ í¬í•¨)
        upload_data = {
            "videoPath": video_path,
            "title": title,
            "description": description,
            "tags": tags,
            "channelId": channel_id,
            "privacyStatus": privacy_status,
            "playlistId": playlist_id,
            "projectSuffix": selected_project,
        }

        if scheduled_time:
            upload_data["publish_at"] = scheduled_time

        if thumbnail_path:
            upload_data["thumbnailPath"] = thumbnail_path

        # API í˜¸ì¶œ (Render í™˜ê²½ì—ì„œëŠ” PORT í™˜ê²½ë³€ìˆ˜ ì‚¬ìš©)
        port = os.environ.get("PORT", "5059")
        base_url = f"http://127.0.0.1:{port}"
        response = req.post(
            f"{base_url}/api/youtube/upload",
            json=upload_data,
            timeout=300
        )

        if response.status_code == 200:
            return response.json()
        else:
            return {"ok": False, "error": f"ì—…ë¡œë“œ API ì˜¤ë¥˜: {response.status_code}"}

    except Exception as e:
        return {"ok": False, "error": str(e)}


# ========== ë²¤ì¹˜ë§ˆí‚¹ ì˜ìƒ ë¶„ì„ API ==========

@app.route('/api/benchmark/analyze-video', methods=['GET', 'POST'])
def api_benchmark_analyze_video():
    """
    ë²¤ì¹˜ë§ˆí‚¹ ì˜ìƒ ìŠ¤í† ë¦¬í…”ë§ ë¶„ì„ (Gemini 2.0 Flash ì‚¬ìš©)

    YouTube URLì„ ë°›ì•„ì„œ ì˜ìƒì˜ ìŠ¤í† ë¦¬í…”ë§ ë°©ì‹ì„ ë¶„ì„í•©ë‹ˆë‹¤.

    GET ìš”ì²­ (ë¸Œë¼ìš°ì €ì—ì„œ ë°”ë¡œ í…ŒìŠ¤íŠ¸):
    /api/benchmark/analyze-video?youtube_url=https://www.youtube.com/watch?v=...&type=storytelling

    POST ìš”ì²­:
    {
        "youtube_url": "https://www.youtube.com/watch?v=...",
        "analyze_type": "storytelling" | "visual" | "full"
    }

    Response:
    {
        "ok": true,
        "analysis": {
            "opening_hook": "ì˜¤í”„ë‹ í›… ë¶„ì„",
            "narrative_structure": "ì„œì‚¬ êµ¬ì¡°",
            "pacing": "í˜ì´ì‹± ë¶„ì„",
            "narration_tone": "ë‚˜ë ˆì´ì…˜ í†¤",
            "scene_transitions": "ì”¬ ì „í™˜ ë°©ì‹",
            "ending_style": "ì—”ë”© ìŠ¤íƒ€ì¼",
            "key_techniques": ["ê¸°ë²•1", "ê¸°ë²•2"],
            "applicable_tips": ["ì ìš© ê°€ëŠ¥í•œ íŒ1", "íŒ2"]
        }
    }
    """
    import google.generativeai as genai

    try:
        # GET ë˜ëŠ” POSTì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        if request.method == 'GET':
            youtube_url = request.args.get('youtube_url', '')
            analyze_type = request.args.get('type', 'storytelling')
        else:
            data = request.get_json() or {}
            youtube_url = data.get('youtube_url', '')
            analyze_type = data.get('analyze_type', 'storytelling')

        if not youtube_url:
            return jsonify({"ok": False, "error": "youtube_urlì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # YouTube URL ê²€ì¦
        if 'youtube.com' not in youtube_url and 'youtu.be' not in youtube_url:
            return jsonify({"ok": False, "error": "ìœ íš¨í•œ YouTube URLì´ ì•„ë‹™ë‹ˆë‹¤"}), 400

        # Gemini API ì„¤ì •
        api_key = os.environ.get('GOOGLE_API_KEY')
        if not api_key:
            return jsonify({"ok": False, "error": "GOOGLE_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 400

        genai.configure(api_key=api_key)

        # ë¶„ì„ ìœ í˜•ë³„ í”„ë¡¬í”„íŠ¸
        if analyze_type == 'storytelling':
            analysis_prompt = """ì´ ì˜ìƒì˜ ìŠ¤í† ë¦¬í…”ë§ ë°©ì‹ì„ ìƒì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{
    "opening_hook": "ì˜ìƒ ì‹œì‘ 30ì´ˆì˜ í›… ë°©ì‹ (ì–´ë–»ê²Œ ì‹œì²­ìë¥¼ ëŒì–´ë“¤ì´ëŠ”ì§€)",
    "narrative_structure": "ì „ì²´ ì„œì‚¬ êµ¬ì¡° (ì‹œê°„ìˆœ/ì—­ìˆœ/ë¯¸ìŠ¤í„°ë¦¬í˜• ë“±)",
    "pacing": "í˜ì´ì‹± ë¶„ì„ (ê¸´ì¥-ì´ì™„ ë¦¬ë“¬, ì”¬ ê¸¸ì´ ë³€í™”)",
    "narration_tone": "ë‚˜ë ˆì´ì…˜ í†¤ê³¼ ìŠ¤íƒ€ì¼ (ë‹´ë‹´/ê·¹ì /ì§ˆë¬¸í˜• ë“±)",
    "scene_transitions": "ì”¬ ì „í™˜ ë°©ì‹ (ì–´ë–¤ ë¬¸ì¥/ê¸°ë²•ìœ¼ë¡œ ì „í™˜í•˜ëŠ”ì§€)",
    "ending_style": "ì—”ë”© ìŠ¤íƒ€ì¼ (êµí›ˆ/ì—¬ìš´/ì˜ˆê³  ë“±)",
    "tension_building": "ê¸´ì¥ê°ì„ ë§Œë“œëŠ” ë°©ë²•",
    "key_techniques": ["í•µì‹¬ ìŠ¤í† ë¦¬í…”ë§ ê¸°ë²• 3-5ê°œ"],
    "example_phrases": ["ì¸ìƒì ì¸ ë¬¸ì¥/í‘œí˜„ 3-5ê°œ"],
    "applicable_tips": ["ë‚´ ì±„ë„ì— ì ìš©í•  ìˆ˜ ìˆëŠ” íŒ 3-5ê°œ"]
}

JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”."""

        elif analyze_type == 'visual':
            analysis_prompt = """ì´ ì˜ìƒì˜ ì‹œê°ì  ìŠ¤íƒ€ì¼ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{
    "thumbnail_style": "ì¸ë„¤ì¼ ìŠ¤íƒ€ì¼ (êµ¬ë„, ìƒ‰ê°, í…ìŠ¤íŠ¸)",
    "color_grading": "ì „ì²´ ìƒ‰ë³´ì • ìŠ¤íƒ€ì¼",
    "scene_composition": "ì”¬ êµ¬ì„± ë°©ì‹",
    "text_overlay_style": "ìë§‰/í…ìŠ¤íŠ¸ ì˜¤ë²„ë ˆì´ ìŠ¤íƒ€ì¼",
    "image_style": "ì´ë¯¸ì§€/ì˜ìƒ ìŠ¤íƒ€ì¼ (ì‹¤ì‚¬/ì¼ëŸ¬ìŠ¤íŠ¸/í˜¼í•©)",
    "key_visual_elements": ["í•µì‹¬ ì‹œê° ìš”ì†Œ 3-5ê°œ"],
    "applicable_tips": ["ì ìš© ê°€ëŠ¥í•œ ì‹œê° íŒ 3-5ê°œ"]
}

JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”."""

        else:  # full
            analysis_prompt = """ì´ ì˜ìƒì„ ì¢…í•©ì ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ í•­ëª©ì„ JSON í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

{
    "summary": "ì˜ìƒ ì£¼ì œ ë° ë‚´ìš© ìš”ì•½",
    "storytelling": {
        "opening_hook": "ì˜¤í”„ë‹ í›… ë°©ì‹",
        "narrative_structure": "ì„œì‚¬ êµ¬ì¡°",
        "pacing": "í˜ì´ì‹±",
        "key_techniques": ["í•µì‹¬ ê¸°ë²•"]
    },
    "visual": {
        "style": "ì‹œê° ìŠ¤íƒ€ì¼",
        "color_grading": "ìƒ‰ë³´ì •",
        "composition": "êµ¬ì„±"
    },
    "audio": {
        "narration_tone": "ë‚˜ë ˆì´ì…˜ í†¤",
        "bgm_usage": "BGM í™œìš©"
    },
    "engagement": {
        "hook_effectiveness": "í›… íš¨ê³¼ (1-10)",
        "retention_techniques": ["ì‹œì²­ ìœ ì§€ ê¸°ë²•"],
        "cta_style": "CTA ìŠ¤íƒ€ì¼"
    },
    "applicable_tips": ["ì ìš© ê°€ëŠ¥í•œ íŒ 5-7ê°œ"]
}

JSONë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš”."""

        print(f"[BENCHMARK] ì˜ìƒ ë¶„ì„ ì‹œì‘: {youtube_url}")
        print(f"[BENCHMARK] ë¶„ì„ ìœ í˜•: {analyze_type}")

        # Gemini 2.0 Flashë¡œ ì˜ìƒ ë¶„ì„
        model = genai.GenerativeModel('gemini-2.0-flash-exp')

        # YouTube URLì„ Geminiì— ì „ë‹¬
        response = model.generate_content([
            analysis_prompt,
            {"file_data": {"file_uri": youtube_url, "mime_type": "video/*"}}
        ])

        # ì‘ë‹µ íŒŒì‹±
        response_text = response.text.strip()

        # JSON ì¶”ì¶œ (ë§ˆí¬ë‹¤ìš´ ì½”ë“œ ë¸”ë¡ ì œê±°)
        if response_text.startswith('```'):
            lines = response_text.split('\n')
            json_lines = []
            in_json = False
            for line in lines:
                if line.startswith('```json'):
                    in_json = True
                    continue
                elif line.startswith('```'):
                    in_json = False
                    continue
                if in_json:
                    json_lines.append(line)
            response_text = '\n'.join(json_lines)

        try:
            import json
            analysis = json.loads(response_text)
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            analysis = {"raw_analysis": response_text}

        print(f"[BENCHMARK] ë¶„ì„ ì™„ë£Œ")

        return jsonify({
            "ok": True,
            "youtube_url": youtube_url,
            "analyze_type": analyze_type,
            "analysis": analysis
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        print(f"[BENCHMARK] ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/benchmark/save-style', methods=['POST'])
def api_benchmark_save_style():
    """
    ë¶„ì„ëœ ìŠ¤íƒ€ì¼ì„ ì €ì¥í•˜ì—¬ ëŒ€ë³¸ ìƒì„± ì‹œ ì°¸ì¡°

    Request:
    {
        "style_name": "ë‹¤í ìŠ¤íƒ€ì¼ A",
        "category": "history",
        "analysis": { ... ë¶„ì„ ê²°ê³¼ ... },
        "selected_fields": ["opening_hook", "pacing", "narration_tone"],  # ì„ íƒí•œ í•­ëª©ë§Œ
        "notes": "ì¶”ê°€ ë©”ëª¨"
    }
    """
    try:
        data = request.get_json() or {}
        style_name = data.get('style_name', '')
        category = data.get('category', 'history')
        analysis = data.get('analysis', {})
        selected_fields = data.get('selected_fields', [])  # ì„ íƒí•œ í•„ë“œë§Œ ì €ì¥
        notes = data.get('notes', '')

        # ì„ íƒí•œ í•„ë“œë§Œ í•„í„°ë§
        if selected_fields and isinstance(analysis, dict):
            analysis = {k: v for k, v in analysis.items() if k in selected_fields}

        if not style_name:
            return jsonify({"ok": False, "error": "style_nameì´ í•„ìš”í•©ë‹ˆë‹¤"}), 400

        # ìŠ¤íƒ€ì¼ ì €ì¥ ê²½ë¡œ
        styles_dir = os.path.join(os.path.dirname(__file__), 'benchmark_styles')
        os.makedirs(styles_dir, exist_ok=True)

        style_file = os.path.join(styles_dir, f"{category}_{style_name.replace(' ', '_')}.json")

        import json
        from datetime import datetime

        style_data = {
            "style_name": style_name,
            "category": category,
            "analysis": analysis,
            "notes": notes,
            "created_at": datetime.now().isoformat(),
        }

        with open(style_file, 'w', encoding='utf-8') as f:
            json.dump(style_data, f, ensure_ascii=False, indent=2)

        print(f"[BENCHMARK] ìŠ¤íƒ€ì¼ ì €ì¥: {style_file}")

        return jsonify({
            "ok": True,
            "message": f"ìŠ¤íƒ€ì¼ '{style_name}' ì €ì¥ ì™„ë£Œ",
            "file_path": style_file
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/benchmark/list-styles', methods=['GET'])
def api_benchmark_list_styles():
    """ì €ì¥ëœ ë²¤ì¹˜ë§ˆí‚¹ ìŠ¤íƒ€ì¼ ëª©ë¡ ì¡°íšŒ"""
    try:
        category = request.args.get('category', '')

        styles_dir = os.path.join(os.path.dirname(__file__), 'benchmark_styles')

        if not os.path.exists(styles_dir):
            return jsonify({"ok": True, "styles": []})

        import json
        styles = []

        for filename in os.listdir(styles_dir):
            if filename.endswith('.json'):
                if category and not filename.startswith(f"{category}_"):
                    continue

                file_path = os.path.join(styles_dir, filename)
                with open(file_path, 'r', encoding='utf-8') as f:
                    style_data = json.load(f)
                    styles.append({
                        "filename": filename,
                        "style_name": style_data.get("style_name"),
                        "category": style_data.get("category"),
                        "created_at": style_data.get("created_at"),
                    })

        return jsonify({"ok": True, "styles": styles})

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== í•´ì™¸ ë¯¸ìŠ¤í…Œë¦¬ ìë™í™” íŒŒì´í”„ë¼ì¸ API ==========

@app.route('/api/mystery/run-pipeline', methods=['GET', 'POST'])
def api_mystery_run_pipeline():
    """
    í•´ì™¸ ë¯¸ìŠ¤í…Œë¦¬ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    â˜… PENDING 5ê°œ ìë™ ìœ ì§€
    â˜… ì˜ì–´ ìœ„í‚¤ë°±ê³¼ì—ì„œ ë¯¸ìŠ¤í…Œë¦¬ ì‚¬ê±´ ìˆ˜ì§‘
    â˜… Opusê°€ í•œêµ­ì–´ ëŒ€ë³¸ìœ¼ë¡œ ê°ìƒ‰

    íŒŒë¼ë¯¸í„°:
    - force: "1"ì´ë©´ PENDING ì¶©ë¶„í•´ë„ ì¶”ê°€
    - max_add: í•œ ë²ˆì— ì¶”ê°€í•  ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ 3)

    í™˜ê²½ë³€ìˆ˜:
    - MYSTERY_SHEET_ID: ë¯¸ìŠ¤í…Œë¦¬ ì „ìš© ì‹œíŠ¸
    - NEWS_SHEET_ID ë˜ëŠ” AUTOMATION_SHEET_ID: ê³µìš© ì‹œíŠ¸

    ì‹œíŠ¸ êµ¬ì¡°:
    - MYSTERY_OPUS_INPUT: ì—í”¼ì†Œë“œë³„ ëŒ€ë³¸ ìë£Œ
      - episode: ì—í”¼ì†Œë“œ ë²ˆí˜¸
      - title_en/title_ko: ì˜ë¬¸/í•œê¸€ ì œëª©
      - wiki_url: ìœ„í‚¤ë°±ê³¼ URL
      - full_content: ìˆ˜ì§‘ëœ ì „ì²´ ë‚´ìš©
      - opus_prompt: Opusìš© í”„ë¡¬í”„íŠ¸
      - status: PENDING/WRITING/DONE
    """
    print("[MYSTERY] ===== run-pipeline í˜¸ì¶œë¨ =====")

    try:
        from scripts.mystery_pipeline import run_mystery_pipeline

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID
        sheet_id = (
            os.environ.get('MYSTERY_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID') or
            os.environ.get('AUTOMATION_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "MYSTERY_SHEET_ID, NEWS_SHEET_ID, ë˜ëŠ” AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì„¤ì •
        force = request.args.get('force', '0') == '1'
        max_add = int(request.args.get('max_add', '3'))

        print(f"[MYSTERY] force: {force}, max_add: {max_add}, ì‹œíŠ¸ ID: {sheet_id}")

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = run_mystery_pipeline(
            sheet_id=sheet_id,
            service=service,
            force=force,
            max_add=max_add
        )

        if result.get("success"):
            return jsonify({
                "ok": True,
                "pending_before": result.get("pending_before", 0),
                "pending_after": result.get("pending_after", 0),
                "episodes_added": result.get("episodes_added", 0),
                "added_mysteries": result.get("added_mysteries", []),
                "available_count": result.get("available_count", 0),
                "message": f"{result.get('episodes_added', 0)}ê°œ ì¶”ê°€, PENDING {result.get('pending_after', 0)}ê°œ"
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
            }), 500

    except ImportError as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/mystery/run-kr-pipeline', methods=['GET', 'POST'])
def api_mystery_run_kr_pipeline():
    """
    í•œêµ­ ë¯¸ìŠ¤í…Œë¦¬ ìë™í™” íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    â˜… PENDING 5ê°œ ìë™ ìœ ì§€
    â˜… ë‚˜ë¬´ìœ„í‚¤ì—ì„œ í•œêµ­ ë¯¸ìŠ¤í…Œë¦¬ ì‚¬ê±´ ìˆ˜ì§‘
    â˜… Opusê°€ í•œêµ­ì–´ ëŒ€ë³¸ ì‘ì„±

    íŒŒë¼ë¯¸í„°:
    - force: "1"ì´ë©´ PENDING ì¶©ë¶„í•´ë„ ì¶”ê°€
    - max_add: í•œ ë²ˆì— ì¶”ê°€í•  ìµœëŒ€ ê°œìˆ˜ (ê¸°ë³¸ 3)
    - category: íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ (TOP3, MURDER, MISSING ë“±)

    í™˜ê²½ë³€ìˆ˜:
    - MYSTERY_SHEET_ID: ë¯¸ìŠ¤í…Œë¦¬ ì „ìš© ì‹œíŠ¸
    - NEWS_SHEET_ID ë˜ëŠ” AUTOMATION_SHEET_ID: ê³µìš© ì‹œíŠ¸

    ì‚¬ìš© ì˜ˆì‹œ:
    - POST /api/mystery/run-kr-pipeline
    - POST /api/mystery/run-kr-pipeline?force=1
    - POST /api/mystery/run-kr-pipeline?category=TOP3
    """
    print("[KR_MYSTERY] ===== run-kr-pipeline í˜¸ì¶œë¨ =====")

    try:
        from scripts.mystery_pipeline import run_kr_mystery_pipeline

        # ì„œë¹„ìŠ¤ ê³„ì • ì¸ì¦
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        # ì‹œíŠ¸ ID
        sheet_id = (
            os.environ.get('MYSTERY_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID') or
            os.environ.get('AUTOMATION_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "MYSTERY_SHEET_ID, NEWS_SHEET_ID, ë˜ëŠ” AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ì„¤ì •
        force = request.args.get('force', '0') == '1'
        max_add = int(request.args.get('max_add', '3'))
        category = request.args.get('category')  # Noneì´ë©´ ì „ì²´

        print(f"[KR_MYSTERY] force: {force}, max_add: {max_add}, category: {category}, ì‹œíŠ¸ ID: {sheet_id}")

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = run_kr_mystery_pipeline(
            sheet_id=sheet_id,
            service=service,
            force=force,
            max_add=max_add,
            category=category
        )

        if result.get("success"):
            return jsonify({
                "ok": True,
                "type": "korean",
                "pending_before": result.get("pending_before", 0),
                "pending_after": result.get("pending_after", 0),
                "episodes_added": result.get("episodes_added", 0),
                "added_mysteries": result.get("added_mysteries", []),
                "available_count": result.get("available_count", 0),
                "message": f"í•œêµ­ ë¯¸ìŠ¤í…Œë¦¬ {result.get('episodes_added', 0)}ê°œ ì¶”ê°€, PENDING {result.get('pending_after', 0)}ê°œ"
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error", "ì•Œ ìˆ˜ ì—†ëŠ” ì˜¤ë¥˜"),
            }), 500

    except ImportError as e:
        import traceback
        traceback.print_exc()
        return jsonify({
            "ok": False,
            "error": f"ëª¨ë“ˆ ë¡œë“œ ì‹¤íŒ¨: {e}"
        }), 500
    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/mystery/test', methods=['GET'])
def api_mystery_test():
    """
    ë¯¸ìŠ¤í…Œë¦¬ ìˆ˜ì§‘ í…ŒìŠ¤íŠ¸ (ì‹œíŠ¸ ì €ì¥ ì—†ì´ ê²°ê³¼ë§Œ ë°˜í™˜)

    íŒŒë¼ë¯¸í„°:
    - title: ìœ„í‚¤ë°±ê³¼ ë¬¸ì„œ ì œëª© (ê¸°ë³¸ Dyatlov_Pass_incident)
    """
    try:
        from scripts.mystery_pipeline.run import test_collect_mystery

        title = request.args.get('title', 'Dyatlov_Pass_incident')

        print(f"[MYSTERY] í…ŒìŠ¤íŠ¸ ìˆ˜ì§‘: {title}")

        result = test_collect_mystery(title)

        if result.get("success"):
            return jsonify({
                "ok": True,
                "title_en": result.get("title_en"),
                "title_ko": result.get("title_ko"),
                "category": result.get("category"),
                "year": result.get("year"),
                "country": result.get("country"),
                "hook": result.get("hook"),
                "url": result.get("url"),
                "summary": result.get("summary"),
                "content_length": len(result.get("content", "")),
                "opus_prompt_preview": result.get("opus_prompt", "")[:1000] + "...",
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error", "ìˆ˜ì§‘ ì‹¤íŒ¨"),
            }), 400

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/mystery/list', methods=['GET'])
def api_mystery_list():
    """
    ì‚¬ìš© ê°€ëŠ¥í•œ ë¯¸ìŠ¤í…Œë¦¬ ëª©ë¡ ë°˜í™˜

    íŒŒë¼ë¯¸í„°:
    - category: íŠ¹ì • ì¹´í…Œê³ ë¦¬ë§Œ (DISAPPEARANCE/DEATH/LOCATION/CRIME/PHENOMENON)
    """
    try:
        from scripts.mystery_pipeline.config import FEATURED_MYSTERIES, MYSTERY_CATEGORIES

        category = request.args.get('category', '').upper()

        mysteries = []
        for m in FEATURED_MYSTERIES:
            if category and m.get("category") != category:
                continue

            mysteries.append({
                "title": m.get("title"),
                "title_ko": m.get("title_ko"),
                "category": m.get("category"),
                "category_name": MYSTERY_CATEGORIES.get(m.get("category"), {}).get("name", ""),
                "year": m.get("year"),
                "country": m.get("country"),
                "hook": m.get("hook"),
            })

        return jsonify({
            "ok": True,
            "count": len(mysteries),
            "categories": list(MYSTERY_CATEGORIES.keys()),
            "mysteries": mysteries,
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ========== í†µí•© ì‹œíŠ¸ ìƒì„± API ==========

# í†µí•© ì‹œíŠ¸ ì„¤ì •
UNIFIED_SHEETS_CONFIG = {
    "NEWS": {
        "description": "ë‰´ìŠ¤ ì±„ë„ - ìˆ˜ì§‘ë¶€í„° ì˜ìƒ ì—…ë¡œë“œê¹Œì§€",
        "collect_headers": [
            "run_id",           # ì‹¤í–‰ ë‚ ì§œ
            "selected_rank",    # ìˆœìœ„ (1, 2, 3)
            "category",         # ì¹´í…Œê³ ë¦¬ (ê²½ì œ/ì •ì±…/ì‚¬íšŒ/êµ­ì œ)
            "issue_one_line",   # ì´ìŠˆ í•œ ì¤„ ìš”ì•½
            "core_points",      # í•µì‹¬í¬ì¸íŠ¸ (LLM ìƒì„±)
            "brief",            # ëŒ€ë³¸ ì§€ì‹œë¬¸
            "thumbnail_copy",   # ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì²œ
            "opus_prompt_pack", # Opus í”„ë¡¬í”„íŠ¸
        ],
    },
    "HISTORY": {
        "description": "ì—­ì‚¬ ì±„ë„ - ìˆ˜ì§‘ë¶€í„° ì˜ìƒ ì—…ë¡œë“œê¹Œì§€",
        "collect_headers": [
            "era",              # ì‹œëŒ€
            "episode_slot",     # ìŠ¬ë¡¯ ë²ˆí˜¸
            "core_question",    # í•µì‹¬ ì§ˆë¬¸/ì—í”¼ì†Œë“œ ì œëª©
            "source_url",       # ì¶œì²˜ URL
            "opus_prompt_pack", # Opus í”„ë¡¬í”„íŠ¸
            "thumbnail_copy",   # ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì²œ
        ],
    },
    "MYSTERY": {
        "description": "ë¯¸ìŠ¤í…Œë¦¬ ì±„ë„ - ìˆ˜ì§‘ë¶€í„° ì˜ìƒ ì—…ë¡œë“œê¹Œì§€",
        "collect_headers": [
            "episode",          # ì—í”¼ì†Œë“œ ë²ˆí˜¸
            "category",         # ì¹´í…Œê³ ë¦¬ (ì‹¤ì¢…/ì‚¬ë§/ì¥ì†Œ/ì‚¬ê±´/í˜„ìƒ)
            "title_en",         # ì˜ë¬¸ ì œëª©
            "title_ko",         # í•œê¸€ ì œëª©
            "wiki_url",         # ìœ„í‚¤ë°±ê³¼ URL
            "summary",          # ì‚¬ê±´ ìš”ì•½
            "full_content",     # ì „ì²´ ë‚´ìš© (Opusìš©)
            "opus_prompt",      # Opus í”„ë¡¬í”„íŠ¸
            "thumbnail_copy",   # ì¸ë„¤ì¼ ë¬¸êµ¬ ì¶”ì²œ
        ],
    },
    "í˜ˆì˜": {
        "description": "ë¬´í˜‘ ì†Œì„¤ ì±„ë„ - í˜ˆì˜ ì‹œë¦¬ì¦ˆ (ë‹¤ì¤‘ ìŒì„± TTS)",
        "collect_headers": [
            "episode",          # ì—í”¼ì†Œë“œ ë²ˆí˜¸ (EP001, EP002, ...)
            "title",            # ì—í”¼ì†Œë“œ ì œëª©
            "summary",          # ì—í”¼ì†Œë“œ ìš”ì•½
            "characters",       # ë“±ì¥ ìºë¦­í„° (ì‰¼í‘œ êµ¬ë¶„)
            "key_events",       # ì£¼ìš” ì‚¬ê±´ (ì¤„ë°”ê¿ˆ êµ¬ë¶„)
            "prev_episode",     # ì´ì „ ì—í”¼ì†Œë“œ ìš”ì•½ (ì—°ê²°ìš©)
            "next_preview",     # ë‹¤ìŒ ì—í”¼ì†Œë“œ ì˜ˆê³ 
            "thumbnail_copy",   # ì¸ë„¤ì¼ ë¬¸êµ¬
        ],
    },
}

# ì˜ìƒ ìë™í™” ê³µí†µ í—¤ë”
VIDEO_AUTOMATION_HEADERS = [
    "ìƒíƒœ",             # ëŒ€ê¸°/ì²˜ë¦¬ì¤‘/ì™„ë£Œ/ì‹¤íŒ¨
    "ëŒ€ë³¸",             # ì˜ìƒ ëŒ€ë³¸ (â˜… í•µì‹¬)
    "ì¸ìš©ë§í¬",         # ìœ íŠœë¸Œ ì„¤ëª…ì— í¬í•¨í•  ì¶œì²˜ ë§í¬ (ì‚¬ìš©ì ìˆ˜ë™ ì…ë ¥)
    "ì œëª©(GPTìƒì„±)",    # GPTê°€ ìƒì„±í•œ ì œëª©
    "ì œëª©(ì…ë ¥)",       # ì‚¬ìš©ì ì…ë ¥ ì œëª© (GPT ëŒ€ì‹  ì‚¬ìš©)
    "ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)", # ì‚¬ìš©ì ì…ë ¥ ì¸ë„¤ì¼ ë¬¸êµ¬
    "ê³µê°œì„¤ì •",         # public/private/unlisted
    "ì˜ˆì•½ì‹œê°„",         # YouTube ì˜ˆì•½ ê³µê°œ ì‹œê°„
    "í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID",   # YouTube í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ID
    "ìŒì„±",             # TTS ìŒì„± ì„¤ì •
    "ì˜ìƒURL",          # ì—…ë¡œë“œëœ YouTube URL
    "ì‡¼ì¸ URL",          # ì‡¼ì¸  URL
    "ì œëª©2",            # ëŒ€ì•ˆ ì œëª© (CTR ìë™í™”ìš©)
    "ì œëª©3",            # ëŒ€ì•ˆ ì œëª© (CTR ìë™í™”ìš©)
    "ë¹„ìš©",             # ìƒì„± ë¹„ìš©
    "ì—ëŸ¬ë©”ì‹œì§€",       # ì‹¤íŒ¨ ì‹œ ì—ëŸ¬
    "ì‘ì—…ì‹œê°„",         # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰ ì‹œê°„
]


@app.route('/api/sheets/create-unified', methods=['GET', 'POST'])
def api_create_unified_sheets():
    """
    í†µí•© ì‹œíŠ¸ ìƒì„± API

    NEWS, HISTORY, MYSTERY 3ê°œì˜ í†µí•© ì‹œíŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
    - í–‰ 1: ì±„ë„ID ì„¤ì •
    - í–‰ 2: í—¤ë” (ìˆ˜ì§‘ ë°ì´í„° + ì˜ìƒ ìë™í™”)

    íŒŒë¼ë¯¸í„°:
    - sheets: ìƒì„±í•  ì‹œíŠ¸ ëª©ë¡ (ì½¤ë§ˆ êµ¬ë¶„, ê¸°ë³¸: NEWS,HISTORY,MYSTERY)
    - channel_id_{name}: ê° ì‹œíŠ¸ì˜ ì±„ë„ ID (ì˜ˆ: channel_id_NEWS=UCxxx)

    ì˜ˆì‹œ:
    - GET /api/sheets/create-unified
    - GET /api/sheets/create-unified?sheets=NEWS,MYSTERY
    - GET /api/sheets/create-unified?channel_id_NEWS=UCxxx&channel_id_MYSTERY=UCyyy
    """
    print("[UNIFIED] ===== create-unified í˜¸ì¶œë¨ =====")

    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        sheet_id = (
            os.environ.get('AUTOMATION_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ìƒì„±í•  ì‹œíŠ¸ ëª©ë¡
        sheets_param = request.args.get('sheets', 'NEWS,HISTORY,MYSTERY')
        sheet_names = [s.strip().upper() for s in sheets_param.split(',')]

        # ìœ íš¨í•œ ì‹œíŠ¸ë§Œ í•„í„°ë§
        valid_sheets = [s for s in sheet_names if s in UNIFIED_SHEETS_CONFIG]
        if not valid_sheets:
            return jsonify({
                "ok": False,
                "error": f"ìœ íš¨í•œ ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê°’: {list(UNIFIED_SHEETS_CONFIG.keys())}"
            }), 400

        print(f"[UNIFIED] ìƒì„±í•  ì‹œíŠ¸: {valid_sheets}")

        # ê¸°ì¡´ ì‹œíŠ¸ ëª©ë¡ í™•ì¸
        spreadsheet = service.spreadsheets().get(spreadsheetId=sheet_id).execute()
        existing_sheets = [
            sheet['properties']['title']
            for sheet in spreadsheet.get('sheets', [])
        ]

        results = []
        created_count = 0

        for sheet_name in valid_sheets:
            config = UNIFIED_SHEETS_CONFIG[sheet_name]

            # ì±„ë„ ID íŒŒë¼ë¯¸í„°
            channel_id = request.args.get(f'channel_id_{sheet_name}', '')

            if sheet_name in existing_sheets:
                results.append({
                    "sheet": sheet_name,
                    "status": "already_exists",
                    "message": f"ì‹œíŠ¸ '{sheet_name}'ì´(ê°€) ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤"
                })
                continue

            try:
                # 1) ì‹œíŠ¸ ìƒì„±
                requests_body = [{
                    "addSheet": {
                        "properties": {"title": sheet_name}
                    }
                }]
                service.spreadsheets().batchUpdate(
                    spreadsheetId=sheet_id,
                    body={"requests": requests_body}
                ).execute()

                # 2) í–‰ 1: ì±„ë„ID
                row1 = ["ì±„ë„ID", channel_id]

                # 3) í–‰ 2: í—¤ë” (ìˆ˜ì§‘ + ì˜ìƒ ìë™í™”)
                collect_headers = config.get("collect_headers", [])
                row2 = collect_headers + VIDEO_AUTOMATION_HEADERS

                # 4) ì‹œíŠ¸ì— ì“°ê¸°
                service.spreadsheets().values().update(
                    spreadsheetId=sheet_id,
                    range=f"{sheet_name}!A1",
                    valueInputOption="RAW",
                    body={"values": [row1, row2]}
                ).execute()

                created_count += 1
                results.append({
                    "sheet": sheet_name,
                    "status": "created",
                    "collect_headers": len(collect_headers),
                    "video_headers": len(VIDEO_AUTOMATION_HEADERS),
                    "total_columns": len(row2),
                    "message": f"ì‹œíŠ¸ '{sheet_name}' ìƒì„± ì™„ë£Œ ({len(row2)}ê°œ ì—´)"
                })
                print(f"[UNIFIED] ì‹œíŠ¸ '{sheet_name}' ìƒì„± ì™„ë£Œ")

            except Exception as e:
                results.append({
                    "sheet": sheet_name,
                    "status": "error",
                    "message": str(e)
                })
                print(f"[UNIFIED] ì‹œíŠ¸ '{sheet_name}' ìƒì„± ì‹¤íŒ¨: {e}")

        return jsonify({
            "ok": True,
            "created_count": created_count,
            "results": results,
            "message": f"{created_count}ê°œ ì‹œíŠ¸ ìƒì„±ë¨"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sheets/create-wuxia', methods=['GET', 'POST'])
def api_create_wuxia_sheet():
    """
    ë¬´í˜‘ ì†Œì„¤ (í˜ˆì˜) ì‹œíŠ¸ ìƒì„± API

    - ì‹œë¦¬ì¦ˆ ì œëª© "í˜ˆì˜"ìœ¼ë¡œ ì‹œíŠ¸ íƒ­ ìƒì„±
    - ì—í”¼ì†Œë“œ í…œí”Œë¦¿ ë°ì´í„° ìë™ ë“±ë¡ (5ê°œ ì—í”¼ì†Œë“œ)
    - ë‹¤ì¤‘ ìŒì„± TTS ì§€ì›

    íŒŒë¼ë¯¸í„°:
    - channel_id: YouTube ì±„ë„ ID (ì„ íƒ)
    - with_templates: "1"ì´ë©´ ì—í”¼ì†Œë“œ í…œí”Œë¦¿ ë°ì´í„° ìë™ ë“±ë¡ (ê¸°ë³¸: 1)

    ì˜ˆì‹œ:
    - GET /api/sheets/create-wuxia
    - GET /api/sheets/create-wuxia?channel_id=UCxxx
    - GET /api/sheets/create-wuxia?with_templates=0  (ì‹œíŠ¸ë§Œ ìƒì„±, ë°ì´í„° ì—†ìŒ)
    """
    print("[WUXIA] ===== create-wuxia í˜¸ì¶œë¨ =====")

    try:
        from scripts.wuxia_pipeline.sheets import (
            create_wuxia_sheet,
            initialize_sheet_with_templates,
        )
        from scripts.wuxia_pipeline.config import SERIES_INFO

        channel_id = request.args.get('channel_id', '')
        with_templates = request.args.get('with_templates', '1') == '1'

        if with_templates:
            # ì‹œíŠ¸ ìƒì„± + í…œí”Œë¦¿ ë°ì´í„° ë“±ë¡
            result = initialize_sheet_with_templates(channel_id)
        else:
            # ì‹œíŠ¸ë§Œ ìƒì„±
            result = create_wuxia_sheet(channel_id)

        if result.get("ok"):
            return jsonify({
                "ok": True,
                "series": SERIES_INFO["title"],
                **result
            })
        else:
            return jsonify(result), 400

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sheets/create-bible', methods=['GET', 'POST'])
def api_create_bible_sheet():
    """
    ì„±ê²½í†µë… BIBLE ì‹œíŠ¸ ìƒì„± API

    - 106ê°œ ì—í”¼ì†Œë“œ ë°ì´í„° ìë™ ë“±ë¡
    - ìƒíƒœ='ëŒ€ê¸°'ë¡œ ì„¤ì •í•˜ë©´ íŒŒì´í”„ë¼ì¸ íŠ¸ë¦¬ê±°

    íŒŒë¼ë¯¸í„°:
    - channel_id: YouTube ì±„ë„ ID (ì„ íƒ)
    - force: "1"ì´ë©´ ê¸°ì¡´ ì‹œíŠ¸ ì‚­ì œ í›„ ì¬ìƒì„±

    ì˜ˆì‹œ:
    - GET /api/sheets/create-bible
    - GET /api/sheets/create-bible?channel_id=UCxxx
    - GET /api/sheets/create-bible?force=1
    """
    print("[BIBLE-SHEETS] ===== create-bible í˜¸ì¶œë¨ =====")

    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        channel_id = request.args.get('channel_id', '')
        force_recreate = request.args.get('force', '0') == '1'

        # bible_pipeline ëª¨ë“ˆ import
        from scripts.bible_pipeline.sheets import create_bible_sheet

        result = create_bible_sheet(
            service=service,
            sheet_id=sheet_id,
            channel_id=channel_id,
            force_recreate=force_recreate
        )

        if result.get("ok"):
            return jsonify(result)
        else:
            return jsonify(result), 500

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/bible/add-test', methods=['GET', 'POST'])
def api_add_bible_test():
    """
    ì„±ê²½í†µë… BIBLE ì‹œíŠ¸ì— í…ŒìŠ¤íŠ¸ìš© í–‰ ì¶”ê°€

    íŒŒë¼ë¯¸í„°:
    - book: ì±… ì´ë¦„ (ê¸°ë³¸: ì°½ì„¸ê¸°)
    - chapter: ì¥ ë²ˆí˜¸ (ê¸°ë³¸: 1)
    - start_verse: ì‹œì‘ ì ˆ (ê¸°ë³¸: 1)
    - end_verse: ë ì ˆ (ê¸°ë³¸: 10)
    - status: ìƒíƒœ (ê¸°ë³¸: ëŒ€ê¸°)

    ì˜ˆì‹œ:
    - GET /api/bible/add-test
    - GET /api/bible/add-test?book=ì°½ì„¸ê¸°&chapter=1&start_verse=1&end_verse=10
    - GET /api/bible/add-test?status=ëŒ€ê¸°
    """
    print("[BIBLE-TEST] ===== add-test í˜¸ì¶œë¨ =====")

    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # íŒŒë¼ë¯¸í„° ì²˜ë¦¬
        book = request.args.get('book', 'ì°½ì„¸ê¸°')
        chapter = int(request.args.get('chapter', 1))
        start_verse = int(request.args.get('start_verse', 1))
        end_verse = int(request.args.get('end_verse', 10))
        status = request.args.get('status', 'ëŒ€ê¸°')

        from scripts.bible_pipeline.sheets import add_test_episode

        result = add_test_episode(
            service=service,
            sheet_id=sheet_id,
            book=book,
            start_chapter=chapter,
            end_chapter=chapter,
            start_verse=start_verse,
            end_verse=end_verse,
            status=status
        )

        if result.get("ok"):
            return jsonify(result)
        else:
            return jsonify(result), 500

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ============================================================
# ì„±ê²½í†µë… íŒŒì´í”„ë¼ì¸
# ============================================================

def run_bible_episode_pipeline(
    service,
    sheet_id: str,
    row_idx: int,
    episode_data: dict,
    channel_id: str = ""
) -> dict:
    """
    ì„±ê²½í†µë… ì—í”¼ì†Œë“œ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰

    Args:
        service: Google Sheets API ì„œë¹„ìŠ¤ ê°ì²´
        sheet_id: ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ID
        row_idx: í–‰ ë²ˆí˜¸
        episode_data: ì‹œíŠ¸ì—ì„œ ì½ì€ ì—í”¼ì†Œë“œ ë°ì´í„°
        channel_id: YouTube ì±„ë„ ID

    Returns:
        {"ok": True, "video_url": str} ë˜ëŠ” {"ok": False, "error": str}
    """
    import time as time_module
    from datetime import datetime

    start_time = time_module.time()

    try:
        # ì—í”¼ì†Œë“œ ì •ë³´ íŒŒì‹±
        episode_id = episode_data.get("ì—í”¼ì†Œë“œ", "")  # EP001
        day_number = int(episode_id.replace("EP", "")) if episode_id.startswith("EP") else 1
        book = episode_data.get("ì±…", "")
        title = episode_data.get("ì œëª©", f"[100ì¼ ì„±ê²½í†µë…] Day {day_number}")
        voice = episode_data.get("ìŒì„±", "").strip() or "chirp3:Charon"
        visibility = episode_data.get("ê³µê°œì„¤ì •", "").strip() or "unlisted"
        playlist_id = episode_data.get("í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ID", "").strip()
        publish_time = episode_data.get("ì˜ˆì•½ì‹œê°„", "").strip()

        print(f"[BIBLE] ========== íŒŒì´í”„ë¼ì¸ ì‹œì‘: Day {day_number} ==========")
        print(f"[BIBLE] ì±…: {book}")
        print(f"[BIBLE] ì œëª©: {title}")
        print(f"[BIBLE] ìŒì„±: {voice}")
        print(f"[BIBLE] ê³µê°œì„¤ì •: {visibility}")

        # â˜… í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ì²˜ë¦¬ (TESTë¡œ ì‹œì‘í•˜ëŠ” ê²½ìš°)
        is_test_episode = episode_id.startswith("TEST")
        test_verse_range = None
        if is_test_episode:
            # ì œëª©ì—ì„œ (verses:1-10) í˜•ì‹ íŒŒì‹±
            import re
            verse_match = re.search(r'\(verses:(\d+)-(\d+)\)', title)
            if verse_match:
                test_verse_range = (int(verse_match.group(1)), int(verse_match.group(2)))
                print(f"[BIBLE] â˜… í…ŒìŠ¤íŠ¸ ëª¨ë“œ: {book} {episode_data.get('ì‹œì‘ì¥', 1)}ì¥ {test_verse_range[0]}-{test_verse_range[1]}ì ˆ", flush=True)

        # ìƒíƒœë¥¼ 'ì²˜ë¦¬ì¤‘'ìœ¼ë¡œ ë³€ê²½ + ì‹œì‘ ì‹œê°„ ê¸°ë¡ (KST - orphan ê°ì§€ì™€ ë™ì¼ ì‹œê°„ëŒ€)
        from scripts.bible_pipeline.sheets import update_episode_status
        from datetime import timezone, timedelta
        kst = timezone(timedelta(hours=9))
        start_time_str = dt.now(kst).strftime('%Y-%m-%d %H:%M:%S')
        update_episode_status(service, sheet_id, row_idx, "ì²˜ë¦¬ì¤‘", work_time=start_time_str)

        # BiblePipelineì—ì„œ ì—í”¼ì†Œë“œ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
        from scripts.bible_pipeline.run import BiblePipeline, Episode, Chapter, Verse
        from scripts.bible_pipeline.config import BIBLE_TTS_VOICE

        pipeline = BiblePipeline()

        # â˜… í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ: íŠ¹ì • ì ˆ ë²”ìœ„ë§Œ ê°€ì ¸ì˜¤ê¸°
        if is_test_episode and test_verse_range:
            start_chapter = int(episode_data.get("ì‹œì‘ì¥", 1))
            chapter = pipeline.get_chapter(book, start_chapter)
            if not chapter:
                return {"ok": False, "error": f"ì¥ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {book} {start_chapter}ì¥"}

            # íŠ¹ì • ì ˆ ë²”ìœ„ë§Œ í•„í„°ë§
            start_v, end_v = test_verse_range
            filtered_verses = [v for v in chapter.verses if start_v <= v.verse <= end_v]

            if not filtered_verses:
                return {"ok": False, "error": f"ì ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {book} {start_chapter}ì¥ {start_v}-{end_v}ì ˆ"}

            # í…ŒìŠ¤íŠ¸ìš© Episode ê°ì²´ ìƒì„±
            test_chapter = Chapter(book=book, chapter=start_chapter, verses=filtered_verses)
            episode = Episode(
                episode_id=episode_id,
                book=book,
                start_chapter=start_chapter,
                end_chapter=start_chapter,
                chapters=[test_chapter],
                day_number=0
            )
            print(f"[BIBLE] í…ŒìŠ¤íŠ¸ ì—í”¼ì†Œë“œ ìƒì„±: {len(filtered_verses)}ê°œ ì ˆ", flush=True)
        else:
            # ì¼ë°˜ ì—í”¼ì†Œë“œ: Day ë²ˆí˜¸ë¡œ ì°¾ê¸°
            episodes = pipeline.generate_all_bible_episodes()
            episode = next((ep for ep in episodes if ep.day_number == day_number), None)

            if not episode:
                return {"ok": False, "error": f"Day {day_number} ì—í”¼ì†Œë“œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"}

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = os.path.join(tempfile.gettempdir(), f"bible_day_{day_number}")
        os.makedirs(temp_dir, exist_ok=True)

        # ========== 1. TTS ìƒì„± (ì²­í¬ë³„ ì‹¤ì œ duration ì¸¡ì •) ==========
        print(f"[BIBLE] 1. TTS ìƒì„± ì‹œì‘...", flush=True)

        # ì ˆë³„ TTS í…ìŠ¤íŠ¸ ì¶”ì¶œ (ì ˆ ë²ˆí˜¸ ì œì™¸, ë§ˆì¹¨í‘œ í¬í•¨)
        # â˜… ì¥ì´ ì‹œì‘í•  ë•Œ "ì°½ì„¸ê¸° 1ì¥." ì½ì–´ì£¼ê¸°
        tts_texts = []
        for chapter in episode.chapters:
            for i, verse in enumerate(chapter.verses):
                if i == 0:
                    # ì¥ì˜ ì²« ë²ˆì§¸ ì ˆ: "ì°½ì„¸ê¸° 1ì¥. íƒœì´ˆì— í•˜ë‚˜ë‹˜ì´..."
                    chapter_intro = f"{chapter.book} {chapter.chapter}ì¥."
                    tts_texts.append(f"{chapter_intro} {verse.tts_text}")
                else:
                    tts_texts.append(verse.tts_text)

        print(f"[BIBLE] TTS í…ìŠ¤íŠ¸: {len(tts_texts)}ê°œ ì ˆ (ì¥ ì œëª© í¬í•¨)", flush=True)

        # TTS ìŒì„± ì²˜ë¦¬
        audio_path = os.path.join(temp_dir, f"day_{day_number:03d}.mp3")

        if voice.startswith("chirp3:"):
            # â˜… Chirp 3 HD: ì²­í¬ë³„ TTS + ffprobeë¡œ ì‹¤ì œ duration ì¸¡ì •
            chirp3_config = parse_chirp3_voice(voice)
            tts_result = generate_bible_tts_with_durations(
                verse_texts=tts_texts,
                voice_name=chirp3_config["voice"]
            )
            if tts_result.get("ok"):
                verse_durations = tts_result.get("verse_durations", [])
                audio_duration = tts_result.get("total_duration", 0)
            else:
                error_msg = f"TTS ìƒì„± ì‹¤íŒ¨: {tts_result.get('error')}"
                update_episode_status(service, sheet_id, row_idx, "ì‹¤íŒ¨", error_message=error_msg)
                return {"ok": False, "error": error_msg}

        elif voice.startswith("gemini:"):
            # â˜… Gemini TTS: ì²­í¬ë³„ TTS + ffprobeë¡œ ì‹¤ì œ duration ì¸¡ì •
            gemini_config = parse_gemini_voice(voice)
            print(f"[BIBLE] Gemini TTS ì‚¬ìš©: {gemini_config['voice']} ({gemini_config['model']})", flush=True)

            tts_result = generate_bible_tts_with_durations_gemini(
                verse_texts=tts_texts,
                voice_name=gemini_config["voice"],
                model=gemini_config["model"]
            )
            if tts_result.get("ok"):
                verse_durations = tts_result.get("verse_durations", [])
                audio_duration = tts_result.get("total_duration", 0)
            else:
                error_msg = f"TTS ìƒì„± ì‹¤íŒ¨: {tts_result.get('error')}"
                update_episode_status(service, sheet_id, row_idx, "ì‹¤íŒ¨", error_message=error_msg)
                return {"ok": False, "error": error_msg}

        else:
            # ê¸°ì¡´ ë°©ì‹ í´ë°± (Google Cloud TTS)
            full_text = " ".join(tts_texts)
            from scripts.tts.google_tts import generate_google_tts
            tts_result = generate_google_tts(full_text, voice)

            if not tts_result.get("ok"):
                error_msg = f"TTS ìƒì„± ì‹¤íŒ¨: {tts_result.get('error')}"
                update_episode_status(service, sheet_id, row_idx, "ì‹¤íŒ¨", error_message=error_msg)
                return {"ok": False, "error": error_msg}

            # í´ë°±: ê¸€ììˆ˜ ë¹„ìœ¨ë¡œ duration ì¶”ì •
            audio_duration = tts_result.get("duration", len(full_text) / 15.0)
            total_chars = sum(len(t) for t in tts_texts)
            verse_durations = []
            for text in tts_texts:
                ratio = len(text) / total_chars if total_chars > 0 else 1.0 / len(tts_texts)
                verse_durations.append(audio_duration * ratio)

        # ì˜¤ë””ì˜¤ ì €ì¥
        audio_data = tts_result.get("audio_data")
        with open(audio_path, "wb") as f:
            f.write(audio_data)

        print(f"[BIBLE] TTS ì™„ë£Œ: {audio_duration:.1f}ì´ˆ, {len(verse_durations)}ê°œ ì ˆ duration ê³„ì‚°ë¨", flush=True)

        # ========== 2. ë°°ê²½ ì´ë¯¸ì§€ ==========
        print(f"[BIBLE] 2. ë°°ê²½ ì´ë¯¸ì§€ í™•ì¸...", flush=True)
        from scripts.bible_pipeline.background import get_background_path, generate_book_background

        background_path = get_background_path(episode.book)
        if not background_path:
            print(f"[BIBLE] ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±: {episode.book}", flush=True)
            bg_result = generate_book_background(episode.book)
            if bg_result.get("ok"):
                background_path = bg_result.get("image_path")
                print(f"[BIBLE] ë°°ê²½ ì´ë¯¸ì§€ ìƒì„± ì™„ë£Œ: {background_path}", flush=True)
            else:
                print(f"[BIBLE] ë°°ê²½ ìƒì„± ì‹¤íŒ¨, ê¸°ë³¸ ë°°ê²½ ì‚¬ìš©", flush=True)
                background_path = None
        else:
            print(f"[BIBLE] ê¸°ì¡´ ë°°ê²½ ì´ë¯¸ì§€ ì‚¬ìš©: {background_path}", flush=True)

        # ========== 3. ì¸ë„¤ì¼ ìƒì„± ==========
        print(f"[BIBLE] 3. ì¸ë„¤ì¼ ìƒì„±...", flush=True)
        from scripts.bible_pipeline.thumbnail import generate_episode_thumbnail

        thumb_result = generate_episode_thumbnail(episode)
        thumbnail_path = thumb_result.get("image_path") if thumb_result.get("ok") else None
        if thumbnail_path:
            print(f"[BIBLE] ì¸ë„¤ì¼ ìƒì„± ì™„ë£Œ: {thumbnail_path}", flush=True)
        else:
            print(f"[BIBLE] ì¸ë„¤ì¼ ìƒì„± ì‹¤íŒ¨: {thumb_result.get('error', 'Unknown')}", flush=True)

        # ========== 4. ì˜ìƒ ë Œë”ë§ ==========
        print(f"[BIBLE] 4. ì˜ìƒ ë Œë”ë§...", flush=True)
        from scripts.bible_pipeline.renderer import render_episode_video

        video_result = render_episode_video(
            episode=episode,
            audio_path=audio_path,
            verse_durations=verse_durations,
            output_dir=temp_dir,
            background_path=background_path,
            use_ass=True
        )

        if not video_result.get("ok"):
            error_msg = f"ì˜ìƒ ë Œë”ë§ ì‹¤íŒ¨: {video_result.get('error')}"
            update_episode_status(service, sheet_id, row_idx, "ì‹¤íŒ¨", error_message=error_msg)
            return {"ok": False, "error": error_msg}

        video_path = video_result.get("video_path")
        print(f"[BIBLE] ì˜ìƒ ìƒì„± ì™„ë£Œ: {video_path}", flush=True)

        # ========== 4.5. BGM ë¯¹ì‹± (calm ë¶„ìœ„ê¸°, 10% ë³¼ë¥¨) ==========
        print(f"[BIBLE] 4.5. BGM ë¯¹ì‹±...", flush=True)

        import glob
        import random

        script_dir = os.path.dirname(os.path.abspath(__file__))
        bgm_dir = os.path.join(script_dir, "static", "audio", "bgm")
        calm_bgms = glob.glob(os.path.join(bgm_dir, "calm_*.mp3"))

        if calm_bgms:
            bgm_path = random.choice(calm_bgms)
            bgm_output_path = video_path.replace(".mp4", "_bgm.mp4")

            print(f"[BIBLE] BGM íŒŒì¼: {os.path.basename(bgm_path)}", flush=True)

            if _mix_bgm_with_video(video_path, bgm_path, bgm_output_path, bgm_volume=0.10):
                # BGM ë¯¹ì‹± ì„±ê³µ - ê¸°ì¡´ íŒŒì¼ êµì²´
                os.replace(bgm_output_path, video_path)
                print(f"[BIBLE] BGM ë¯¹ì‹± ì™„ë£Œ (ë³¼ë¥¨ 10%)", flush=True)
            else:
                print(f"[BIBLE] BGM ë¯¹ì‹± ì‹¤íŒ¨ - ì›ë³¸ ì˜ìƒ ì‚¬ìš©", flush=True)
        else:
            print(f"[BIBLE] calm BGM íŒŒì¼ ì—†ìŒ - BGM ì—†ì´ ì§„í–‰", flush=True)

        # ========== 5. YouTube ì—…ë¡œë“œ ==========
        print(f"[BIBLE] 5. YouTube ì—…ë¡œë“œ...", flush=True)

        # â˜… SEO ìµœì í™”ëœ ì œëª©/ì„¤ëª… ìƒì„±
        from scripts.bible_pipeline.seo import generate_seo_title, generate_seo_description, validate_seo_title

        total_verses = sum(len(ch.verses) for ch in episode.chapters)
        estimated_minutes = int(audio_duration / 60) + 1  # ì‹¤ì œ ì˜¤ë””ì˜¤ ê¸¸ì´ ê¸°ì¤€

        # SEO ìµœì í™”ëœ ì œëª© ìƒì„± (ì‹œíŠ¸ ì œëª©ì´ ê¸°ë³¸ê°’ì¸ ê²½ìš°ì—ë§Œ)
        default_title_pattern = f"[100ì¼ ì„±ê²½í†µë…] Day {day_number}"
        if title.startswith(default_title_pattern) or title == default_title_pattern:
            seo_title = generate_seo_title(
                day_number=day_number,
                book=episode.book,
                start_chapter=episode.start_chapter,
                end_chapter=episode.end_chapter
            )
            print(f"[BIBLE] SEO ì œëª© ìƒì„±: {seo_title}", flush=True)
        else:
            # ì‚¬ìš©ìê°€ ì§ì ‘ ì…ë ¥í•œ ì œëª©ì€ ìœ ì§€
            seo_title = title
            print(f"[BIBLE] ì‚¬ìš©ì ì œëª© ìœ ì§€: {seo_title}", flush=True)

        # SEO ê²€ì¦
        title_validation = validate_seo_title(seo_title)
        if title_validation.get("warnings"):
            for warning in title_validation["warnings"]:
                print(f"[BIBLE] SEO ê²½ê³ : {warning}", flush=True)

        # SEO ìµœì í™”ëœ ì„¤ëª… ìƒì„±
        description = generate_seo_description(
            day_number=day_number,
            book=episode.book,
            start_chapter=episode.start_chapter,
            end_chapter=episode.end_chapter,
            total_verses=total_verses,
            estimated_minutes=estimated_minutes,
            playlist_url=None  # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ URLì€ ë³„ë„ ì¡°íšŒ í•„ìš”
        )

        # ì œëª© ë³€ìˆ˜ ì—…ë°ì´íŠ¸
        title = seo_title

        # ë‚´ë¶€ API í˜¸ì¶œë¡œ YouTube ì—…ë¡œë“œ
        import requests as req
        base_url = os.environ.get('RENDER_EXTERNAL_URL', 'http://127.0.0.1:10000')

        upload_payload = {
            "videoPath": video_path,
            "title": title,
            "description": description,
            "privacyStatus": visibility,
            "thumbnailPath": thumbnail_path,
        }

        if playlist_id:
            upload_payload["playlistId"] = playlist_id
        if publish_time:
            upload_payload["publish_at"] = publish_time
        if channel_id:
            upload_payload["channelId"] = channel_id

        upload_resp = req.post(f"{base_url}/api/youtube/upload", json=upload_payload, timeout=600)
        upload_result = upload_resp.json()

        if not upload_result.get("ok"):
            error_msg = f"YouTube ì—…ë¡œë“œ ì‹¤íŒ¨: {upload_result.get('error')}"
            update_episode_status(service, sheet_id, row_idx, "ì‹¤íŒ¨", error_message=error_msg)
            return {"ok": False, "error": error_msg}

        video_url = upload_result.get("videoUrl", "")
        print(f"[BIBLE] YouTube ì—…ë¡œë“œ ì™„ë£Œ: {video_url}", flush=True)

        # ========== 6. ì‹œíŠ¸ ì—…ë°ì´íŠ¸ ==========
        print(f"[BIBLE] 6. ì‹œíŠ¸ ì—…ë°ì´íŠ¸...", flush=True)
        elapsed_time = time_module.time() - start_time
        work_time_str = f"{elapsed_time / 60:.1f}ë¶„"

        update_episode_status(
            service, sheet_id, row_idx, "ì™„ë£Œ",
            video_url=video_url,
            work_time=work_time_str
        )

        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        print(f"[BIBLE] 7. ì„ì‹œ íŒŒì¼ ì •ë¦¬...", flush=True)
        try:
            import shutil
            shutil.rmtree(temp_dir, ignore_errors=True)
        except:
            pass

        print(f"[BIBLE] ========== íŒŒì´í”„ë¼ì¸ ì™„ë£Œ: Day {day_number} ({work_time_str}) ==========", flush=True)

        return {"ok": True, "video_url": video_url}

    except Exception as e:
        import traceback
        traceback.print_exc()
        error_msg = str(e)

        try:
            from scripts.bible_pipeline.sheets import update_episode_status
            update_episode_status(service, sheet_id, row_idx, "ì‹¤íŒ¨", error_message=error_msg)
        except:
            pass

        return {"ok": False, "error": error_msg}


@app.route('/api/bible/test-background', methods=['GET', 'POST'])
def api_bible_test_background():
    """
    ë°°ê²½ ì´ë¯¸ì§€ í…ŒìŠ¤íŠ¸ API - ì˜ìƒ ìƒì„± ì—†ì´ ë°°ê²½ë§Œ ë¹ ë¥´ê²Œ í™•ì¸

    ì‚¬ìš©ë²•:
    - GET /api/bible/test-background?book=ì°½ì„¸ê¸°
    - GET /api/bible/test-background?book=ë§ˆíƒœë³µìŒ&force=1

    Args:
        book: ì„±ê²½ ì±… ì´ë¦„ (ì˜ˆ: ì°½ì„¸ê¸°, ë§ˆíƒœë³µìŒ)
        force: 1ì´ë©´ ê¸°ì¡´ ì´ë¯¸ì§€ ì¬ìƒì„±
    """
    try:
        book = request.args.get('book', 'ì°½ì„¸ê¸°')
        force = request.args.get('force', '0') == '1'

        from scripts.bible_pipeline.background import generate_book_background, get_background_prompt

        # í”„ë¡¬í”„íŠ¸ í™•ì¸ìš©
        prompt = get_background_prompt(book)
        print(f"[BIBLE-BG-TEST] í”„ë¡¬í”„íŠ¸:\n{prompt[:500]}...")

        # ë°°ê²½ ì´ë¯¸ì§€ ìƒì„±
        result = generate_book_background(book, force_regenerate=force)

        if result.get("ok"):
            return jsonify({
                "ok": True,
                "book": book,
                "image_url": result.get("image_url"),
                "image_path": result.get("image_path"),
                "cached": result.get("cached", False),
                "prompt_preview": prompt[:300] + "..."
            })
        else:
            return jsonify({
                "ok": False,
                "book": book,
                "error": result.get("error")
            })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/bible/check-and-process', methods=['GET', 'POST'])
def api_bible_check_and_process():
    """
    ì„±ê²½í†µë… íŒŒì´í”„ë¼ì¸ - BIBLE ì‹œíŠ¸ì—ì„œ ëŒ€ê¸° ìƒíƒœì¸ ì—í”¼ì†Œë“œ ì²˜ë¦¬

    cron jobì—ì„œ í˜¸ì¶œ:
    - POST /api/bible/check-and-process

    BIBLE ì‹œíŠ¸ êµ¬ì¡°:
    - í–‰1: ì±„ë„ID | UCxxx
    - í–‰2: í—¤ë” (ì—í”¼ì†Œë“œ, ì±…, ì‹œì‘ì¥, ëì¥, ... ìƒíƒœ, ì˜ìƒURL, ...)
    - í–‰3~: ì—í”¼ì†Œë“œ ë°ì´í„° (106ê°œ)

    ìƒíƒœ='ëŒ€ê¸°'ì¸ í–‰ì„ ì°¾ì•„ íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
    """
    print(f"[BIBLE] ===== check-and-process í˜¸ì¶œë¨ =====")

    # ë™ì‹œ ì‹¤í–‰ ë°©ì§€
    if not pipeline_lock.acquire(blocking=False):
        print("[BIBLE] ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ - ìŠ¤í‚µ")
        return jsonify({
            "ok": True,
            "message": "ë‹¤ë¥¸ íŒŒì´í”„ë¼ì¸ì´ ì´ë¯¸ ì‹¤í–‰ ì¤‘ì…ë‹ˆë‹¤",
            "skipped": True
        })

    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        sheet_id = os.environ.get('AUTOMATION_SHEET_ID')
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # ëŒ€ê¸° ì¤‘ì¸ ì—í”¼ì†Œë“œ ì¡°íšŒ
        from scripts.bible_pipeline.sheets import get_pending_episodes

        pending = get_pending_episodes(service, sheet_id, limit=1)

        if not pending:
            print("[BIBLE] ëŒ€ê¸° ì¤‘ì¸ ì—í”¼ì†Œë“œ ì—†ìŒ")
            return jsonify({
                "ok": True,
                "message": "ì²˜ë¦¬í•  ì—í”¼ì†Œë“œê°€ ì—†ìŠµë‹ˆë‹¤",
                "processed": 0
            })

        episode_data = pending[0]
        row_idx = episode_data.get("row_idx")

        print(f"[BIBLE] ëŒ€ê¸° ì—í”¼ì†Œë“œ ë°œê²¬: {episode_data.get('ì—í”¼ì†Œë“œ')} (í–‰ {row_idx})")

        # ì±„ë„ ID ê°€ì ¸ì˜¤ê¸° (í–‰1ì—ì„œ)
        channel_id = ""
        try:
            result = service.spreadsheets().values().get(
                spreadsheetId=sheet_id,
                range="BIBLE!B1"
            ).execute()
            channel_id = result.get('values', [[]])[0][0] if result.get('values') else ""
        except:
            pass

        # íŒŒì´í”„ë¼ì¸ ì‹¤í–‰
        result = run_bible_episode_pipeline(
            service=service,
            sheet_id=sheet_id,
            row_idx=row_idx,
            episode_data=episode_data,
            channel_id=channel_id
        )

        if result.get("ok"):
            return jsonify({
                "ok": True,
                "message": f"Day {episode_data.get('ì—í”¼ì†Œë“œ')} ì²˜ë¦¬ ì™„ë£Œ",
                "video_url": result.get("video_url"),
                "processed": 1
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.get("error"),
                "processed": 0
            }), 500

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500

    finally:
        pipeline_lock.release()


# ============================================================================
# í˜ˆì˜ ì´ì„¸ê³„í¸ íŒŒì´í”„ë¼ì¸ API
# ============================================================================

@app.route('/api/isekai/create-sheet', methods=['GET', 'POST'])
def api_isekai_create_sheet():
    """
    í˜ˆì˜ì´ì„¸ê³„ ì‹œíŠ¸ ìƒì„±

    GET/POST /api/isekai/create-sheet?channel_id=UCxxx
    """
    from scripts.isekai_pipeline import create_isekai_sheet

    channel_id = request.args.get('channel_id') or request.json.get('channel_id', '') if request.is_json else ''
    result = create_isekai_sheet(channel_id=channel_id)

    status_code = 200 if result.get('ok') else 400
    return jsonify(result), status_code


@app.route('/api/isekai/sync-episode', methods=['POST'])
def api_isekai_sync_episode():
    """
    íŠ¹ì • ì—í”¼ì†Œë“œë¥¼ ì‹œíŠ¸ì— ë™ê¸°í™”

    POST /api/isekai/sync-episode
    {"episode": 1}

    outputs/isekai/EP001/ í´ë”ì˜ íŒŒì¼ë“¤ì„ ì½ì–´ ì‹œíŠ¸ì— ê¸°ë¡
    """
    from scripts.isekai_pipeline import sync_episode_from_files

    data = request.get_json() or {}
    episode = data.get('episode')

    if not episode:
        return jsonify({"ok": False, "error": "episode íŒŒë¼ë¯¸í„°ê°€ í•„ìš”í•©ë‹ˆë‹¤"}), 400

    try:
        episode_num = int(episode)
    except ValueError:
        return jsonify({"ok": False, "error": "episodeì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤"}), 400

    result = sync_episode_from_files(episode_num)
    status_code = 200 if result.get('ok') else 400
    return jsonify(result), status_code


@app.route('/api/isekai/sync-all', methods=['POST'])
def api_isekai_sync_all():
    """
    ëª¨ë“  ì—í”¼ì†Œë“œë¥¼ ì‹œíŠ¸ì— ë™ê¸°í™”

    POST /api/isekai/sync-all

    outputs/isekai/ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“  EP* í´ë”ë¥¼ ìŠ¤ìº”í•˜ì—¬ ì‹œíŠ¸ì— ë™ê¸°í™”
    """
    from scripts.isekai_pipeline import sync_all_episodes

    result = sync_all_episodes()
    status_code = 200 if result.get('ok') else 400
    return jsonify(result), status_code


@app.route('/api/isekai/push-episode', methods=['POST'])
def api_isekai_push_episode():
    """
    ì—í”¼ì†Œë“œ ë°ì´í„°ë¥¼ ì§ì ‘ ë°›ì•„ì„œ ì‹œíŠ¸ì— ê¸°ë¡

    POST /api/isekai/push-episode
    {
        "episode": 1,
        "title": "ì´ë°©ì¸ì˜ ëˆˆ",
        "summary": "ë¬´ì˜ì´ ì´ì„¸ê³„ì— ê¹¨ì–´ë‚˜ë‹¤...",
        "script": "ëŒ€ë³¸ ì „ë¬¸...",
        "youtube_title": "[í˜ˆì˜ ì´ì„¸ê³„í¸] ì œ1í™”...",
        "youtube_description": "ì„¤ëª…...",
        "thumbnail_text": "í˜ˆì˜ ì´ì„¸ê³„í¸\\nì œ1í™”\\nì´ë°©ì¸",
        "status": "ëŒ€ê¸°"
    }
    """
    from scripts.isekai_pipeline.sheets import (
        get_sheets_service, get_sheet_id, get_episode_by_number,
        add_episode, SHEET_NAME, _clean_script_for_tts
    )
    from scripts.isekai_pipeline.config import SHEET_HEADERS

    data = request.get_json() or {}
    episode = data.get('episode')

    if not episode:
        return jsonify({"ok": False, "error": "episode íŒŒë¼ë¯¸í„° í•„ìš”"}), 400

    try:
        episode_num = int(episode)
    except ValueError:
        return jsonify({"ok": False, "error": "episodeì€ ìˆ«ìì—¬ì•¼ í•©ë‹ˆë‹¤"}), 400

    service = get_sheets_service()
    if not service:
        return jsonify({"ok": False, "error": "Sheets ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}), 400

    sheet_id = get_sheet_id()
    if not sheet_id:
        return jsonify({"ok": False, "error": "AUTOMATION_SHEET_ID í•„ìš”"}), 400

    try:
        # ì—í”¼ì†Œë“œ í–‰ ì°¾ê¸° ë˜ëŠ” ìƒì„±
        existing = get_episode_by_number(episode_num)

        if existing:
            row_index = existing["_row_index"]
        else:
            add_result = add_episode(
                episode=episode_num,
                title=data.get("title", f"ì œ{episode_num}í™”"),
                summary=data.get("summary", ""),
            )
            if not add_result.get("ok"):
                return jsonify(add_result), 400
            row_index = add_result["row_index"]

        # í—¤ë” ì¡°íšŒ
        result = service.spreadsheets().values().get(
            spreadsheetId=sheet_id,
            range=f"{SHEET_NAME}!A2:AZ2"
        ).execute()
        headers = result.get('values', [[]])[0]
        col_map = {h: i for i, h in enumerate(headers)}

        # ì—…ë°ì´íŠ¸ ì¤€ë¹„
        updates = []

        def add_update(header: str, value):
            if header in col_map and value:
                col_letter = chr(ord('A') + col_map[header])
                updates.append({
                    "range": f"{SHEET_NAME}!{col_letter}{row_index}",
                    "values": [[str(value)]]
                })

        # ë°ì´í„° ë§¤í•‘
        add_update("title", data.get("title"))
        add_update("summary", data.get("summary"))
        add_update("part", data.get("part", 1))

        # ëŒ€ë³¸ (TTSìš© ì •ì œ)
        script = data.get("script", "")
        if script:
            try:
                script = _clean_script_for_tts(script)
            except:
                pass
            add_update("ëŒ€ë³¸", script)

        # ë©”íƒ€ë°ì´í„°
        add_update("ì œëª©(GPTìƒì„±)", data.get("youtube_title"))
        add_update("ì¸ë„¤ì¼ë¬¸êµ¬(ì…ë ¥)", data.get("thumbnail_text"))

        # ìƒíƒœ
        status = data.get("status", "ëŒ€ê¸°")
        add_update("ìƒíƒœ", status)

        # ë°°ì¹˜ ì—…ë°ì´íŠ¸ ì‹¤í–‰
        if updates:
            service.spreadsheets().values().batchUpdate(
                spreadsheetId=sheet_id,
                body={
                    "valueInputOption": "RAW",
                    "data": updates
                }
            ).execute()

        return jsonify({
            "ok": True,
            "episode": episode_num,
            "row_index": row_index,
            "fields_updated": len(updates),
            "status": status
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/isekai/push', methods=['GET'])
def isekai_push_page():
    """
    EP001 ì‹œíŠ¸ ì „ì†¡ í˜ì´ì§€

    ë¸Œë¼ìš°ì €ì—ì„œ https://drama-s2ns.onrender.com/isekai/push ì ‘ì†
    """
    html = '''<!DOCTYPE html>
<html>
<head>
    <meta charset="UTF-8">
    <title>EP001 ì‹œíŠ¸ ì „ì†¡</title>
    <style>
        body { font-family: sans-serif; max-width: 800px; margin: 50px auto; padding: 20px; }
        button { font-size: 24px; padding: 20px 40px; cursor: pointer; background: #4CAF50; color: white; border: none; border-radius: 8px; }
        button:hover { background: #45a049; }
        button:disabled { background: #ccc; cursor: not-allowed; }
        #result { margin-top: 20px; padding: 20px; background: #f5f5f5; border-radius: 8px; white-space: pre-wrap; }
        .success { color: green; }
        .error { color: red; }
    </style>
</head>
<body>
    <h1>ğŸ—¡ï¸ í˜ˆì˜ ì´ì„¸ê³„í¸ EP001</h1>
    <p><strong>ì œëª©:</strong> ì´ë°©ì¸</p>
    <p><strong>ëŒ€ë³¸:</strong> 26,079ì</p>
    <p><strong>ìƒíƒœ:</strong> ëŒ€ê¸° (ì˜ìƒ ìƒì„± ëŒ€ê¸°ì—´)</p>
    <br>
    <button id="pushBtn" onclick="pushToSheet()">ğŸ“¤ Google Sheetsì— ì „ì†¡</button>
    <div id="result"></div>
    <script>
    async function pushToSheet() {
        const btn = document.getElementById('pushBtn');
        const resultDiv = document.getElementById('result');
        btn.disabled = true;
        btn.textContent = 'ì „ì†¡ ì¤‘...';
        resultDiv.innerHTML = '';
        resultDiv.className = '';
        try {
            const response = await fetch('/api/isekai/push-ep001', { method: 'POST' });
            const data = await response.json();
            if (data.ok) {
                resultDiv.innerHTML = 'âœ… ì „ì†¡ ì„±ê³µ!\\n\\n' + JSON.stringify(data, null, 2);
                resultDiv.className = 'success';
                btn.textContent = 'âœ… ì™„ë£Œ!';
            } else {
                resultDiv.innerHTML = 'âŒ ì „ì†¡ ì‹¤íŒ¨\\n\\n' + JSON.stringify(data, null, 2);
                resultDiv.className = 'error';
                btn.disabled = false;
                btn.textContent = 'ğŸ“¤ ë‹¤ì‹œ ì‹œë„';
            }
        } catch (error) {
            resultDiv.innerHTML = 'âŒ ì˜¤ë¥˜: ' + error.message;
            resultDiv.className = 'error';
            btn.disabled = false;
            btn.textContent = 'ğŸ“¤ ë‹¤ì‹œ ì‹œë„';
        }
    }
    </script>
</body>
</html>'''
    return html


@app.route('/api/isekai/push-ep001', methods=['POST'])
def api_isekai_push_ep001():
    """EP001 ë°ì´í„°ë¥¼ ì‹œíŠ¸ì— ì „ì†¡ (íŒŒì¼ì—ì„œ ëŒ€ë³¸/ì´ë¯¸ì§€í”„ë¡¬í”„íŠ¸ ì½ê¸°)"""
    import json
    from scripts.isekai_pipeline.sheets import (
        get_sheets_service, get_sheet_id, get_episode_by_number,
        add_episode, SHEET_NAME
    )

    base_dir = os.path.dirname(__file__)

    # ëŒ€ë³¸ íŒŒì¼ ì½ê¸°
    script_path = os.path.join(base_dir, 'static', 'isekai', 'EP001_script.txt')
    try:
        with open(script_path, 'r', encoding='utf-8') as f:
            script_content = f.read()
    except Exception as e:
        return jsonify({"ok": False, "error": f"ëŒ€ë³¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨: {e}"}), 400

    # ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸° (static í´ë”ì—ì„œ)
    image_prompt_path = os.path.join(base_dir, 'static', 'isekai', 'EP001_image_prompts.json')
    image_prompt = ""
    try:
        with open(image_prompt_path, 'r', encoding='utf-8') as f:
            prompts_data = json.load(f)
            # main_image.prompt ì¶”ì¶œ
            image_prompt = prompts_data.get("main_image", {}).get("prompt", "")
    except Exception as e:
        print(f"[ISEKAI] ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    # ì”¬ ë°ì´í„° ì½ê¸° (BGM ì „í™˜, ì±•í„°ìš©)
    brief_path = os.path.join(base_dir, 'static', 'isekai', 'EP001_brief.json')
    scenes_json = ""
    cliffhanger = ""
    next_preview = ""
    try:
        with open(brief_path, 'r', encoding='utf-8') as f:
            brief_data = json.load(f)
            scenes = brief_data.get("scenes", [])
            if scenes:
                scenes_json = json.dumps(scenes, ensure_ascii=False)
            cliffhanger = brief_data.get("cliffhanger", "")
            next_preview = brief_data.get("next_preview", "")
    except Exception as e:
        print(f"[ISEKAI] ì”¬ ë°ì´í„° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    # ë©”íƒ€ë°ì´í„° íŒŒì¼ ì½ê¸° (YouTube ì„¤ëª…, íƒœê·¸, ì¸ë„¤ì¼ í›…)
    metadata_path = os.path.join(base_dir, 'static', 'isekai', 'EP001_metadata.json')
    youtube_title = ""
    youtube_description = ""
    youtube_tags = ""
    thumbnail_hook = ""
    try:
        with open(metadata_path, 'r', encoding='utf-8') as f:
            metadata = json.load(f)
            yt = metadata.get("youtube", {})
            youtube_title = yt.get("title", "")
            youtube_description = yt.get("description", "")
            tags = yt.get("tags", [])
            if tags:
                youtube_tags = json.dumps(tags, ensure_ascii=False)
            thumb = metadata.get("thumbnail", {})
            thumbnail_hook = thumb.get("hook_text", "")
    except Exception as e:
        print(f"[ISEKAI] ë©”íƒ€ë°ì´í„° íŒŒì¼ ì½ê¸° ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    # EP001 ë°ì´í„° (ì—ì´ì „íŠ¸ ìƒì„± ë©”íƒ€ë°ì´í„° í¬í•¨)
    ep001_data = {
        "episode": 1,
        "title": "ì´ë°©ì¸",
        "summary": "ë¬´ë¦¼ ìµœê°•ì˜ ê²€ê° ë¬´ì˜ì´ ì²œë§ˆêµì£¼ í˜ˆë§ˆì™€ì˜ ìµœì¢…ì „ ì¤‘ ì°¨ì› ê· ì—´ì— íœ©ì“¸ë ¤ ì´ì„¸ê³„ì— ë–¨ì–´ì§„ë‹¤. ëª¨ë“  ë‚´ê³µì„ ìƒê³  ë‚¯ì„  ì„¸ê³„ì—ì„œ ëˆˆì„ ëœ¬ ê·¸ëŠ”, ì–¸ì–´ë„ í†µí•˜ì§€ ì•ŠëŠ” ê³³ì—ì„œ ìƒì¡´ì„ ìœ„í•œ ì²«ê±¸ìŒì„ ë‚´ë”›ëŠ”ë‹¤.",
        "status": "ëŒ€ê¸°",
        "script": script_content,
        "image_prompt": image_prompt,
        "scenes": scenes_json,
        # ë©”íƒ€ë°ì´í„° ì—ì´ì „íŠ¸ ìƒì„± í•„ë“œ
        "youtube_title": youtube_title or "[í˜ˆì˜ ì´ì„¸ê³„í¸] ì œ1í™” - ì´ë°©ì¸ | ë¬´í˜‘ íŒíƒ€ì§€ ì˜¤ë””ì˜¤ë¶",
        "youtube_description": youtube_description,
        "youtube_tags": youtube_tags,
        "thumbnail_hook": thumbnail_hook,
        "cliffhanger": cliffhanger,
        "next_preview": next_preview,
        # ìë™í™” ê¸°ë³¸ê°’
        "ìŒì„±": "chirp3:Charon",
        "ê³µê°œì„¤ì •": "private",
    }

    service = get_sheets_service()
    if not service:
        return jsonify({"ok": False, "error": "Sheets ì„œë¹„ìŠ¤ ì—°ê²° ì‹¤íŒ¨"}), 400

    sheet_id = get_sheet_id()
    if not sheet_id:
        return jsonify({"ok": False, "error": "AUTOMATION_SHEET_ID í•„ìš”"}), 400

    try:
        existing = get_episode_by_number(1)

        if existing:
            row_index = existing["_row_index"]
        else:
            add_result = add_episode(
                episode=1,
                title=ep001_data["title"],
                summary=ep001_data["summary"],
            )
            if not add_result.get("ok"):
                return jsonify(add_result), 400
            row_index = add_result["row_index"]

        # í—¤ë” ì¡°íšŒ
        result = service.spreadsheets().values().get(
            spreadsheetId=sheet_id,
            range=f"{SHEET_NAME}!A2:AZ2"
        ).execute()
        headers = result.get('values', [[]])[0]
        col_map = {h: i for i, h in enumerate(headers)}

        updates = []
        def add_update(header, value):
            if header in col_map and value:
                col_letter = chr(ord('A') + col_map[header])
                updates.append({
                    "range": f"{SHEET_NAME}!{col_letter}{row_index}",
                    "values": [[str(value)]]
                })

        # ê¸°ë³¸ ì •ë³´
        add_update("title", ep001_data["title"])
        add_update("summary", ep001_data["summary"])
        add_update("scenes", ep001_data["scenes"])
        add_update("ëŒ€ë³¸", ep001_data["script"])
        add_update("image_prompt", ep001_data["image_prompt"])
        add_update("ìƒíƒœ", ep001_data["status"])

        # ë©”íƒ€ë°ì´í„° ì—ì´ì „íŠ¸ ìƒì„± í•„ë“œ
        add_update("youtube_title", ep001_data["youtube_title"])
        add_update("youtube_description", ep001_data["youtube_description"])
        add_update("youtube_tags", ep001_data["youtube_tags"])
        add_update("thumbnail_hook", ep001_data["thumbnail_hook"])
        add_update("cliffhanger", ep001_data["cliffhanger"])
        add_update("next_preview", ep001_data["next_preview"])

        # ìë™í™” ê¸°ë³¸ê°’
        add_update("ìŒì„±", ep001_data["ìŒì„±"])
        add_update("ê³µê°œì„¤ì •", ep001_data["ê³µê°œì„¤ì •"])

        if updates:
            service.spreadsheets().values().batchUpdate(
                spreadsheetId=sheet_id,
                body={"valueInputOption": "RAW", "data": updates}
            ).execute()

        return jsonify({
            "ok": True,
            "episode": 1,
            "row_index": row_index,
            "fields_updated": len(updates),
            "script_length": len(script_content),  # ì‹¤ì œ íŒŒì¼ì—ì„œ ì½ì€ ê¸€ììˆ˜
            "message": "EP001 ì „ì†¡ ì™„ë£Œ!"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ê¸°ì¡´ ì‹œíŠ¸ â†’ ìƒˆ ì‹œíŠ¸ ë§¤í•‘
MIGRATION_MAPPING = {
    "NEWS": {
        "source": "OPUS_INPUT_ECON",
        "header_map": {
            # ê¸°ì¡´ í—¤ë” â†’ ìƒˆ í—¤ë” (ë™ì¼í•˜ë©´ ìƒëµ)
            "run_id": "run_id",
            "selected_rank": "selected_rank",
            "category": "category",
            "issue_one_line": "issue_one_line",
            "core_points": "core_points",
            "brief": "brief",
            "thumbnail_copy": "thumbnail_copy",
            "opus_prompt_pack": "opus_prompt_pack",
            "status": "ìƒíƒœ",  # PENDING â†’ (ë¹ˆê°’), ìƒíƒœ ì—´ë¡œ ë§¤í•‘
            "created_at": None,  # ë¬´ì‹œ
            "selected": None,  # ë¬´ì‹œ
        },
        "status_map": {
            "PENDING": "",  # ëŒ€ê¸°ë¡œ ì“°ì§€ ì•ŠìŒ (ëŒ€ë³¸ì´ ì—†ìœ¼ë¯€ë¡œ)
            "WRITING": "",
            "DONE": "",
        }
    },
    "HISTORY": {
        "source": "HISTORY_OPUS_INPUT",
        "header_map": {
            "era": "era",
            "episode_slot": "episode_slot",
            "structure_role": "structure_role",
            "core_question": "core_question",
            "facts": "facts",
            "human_choices": "human_choices",
            "impact_candidates": "impact_candidates",
            "source_url": "source_url",
            "opus_prompt_pack": "opus_prompt_pack",
            "thumbnail_copy": "thumbnail_copy",
            "status": "ìƒíƒœ",
            "created_at": None,
        }
    },
    "MYSTERY": {
        "source": "MYSTERY_OPUS_INPUT",
        "header_map": {
            "run_id": None,  # ë¬´ì‹œ
            "episode": "episode",
            "category": "category",
            "title_en": "title_en",
            "title_ko": "title_ko",
            "wiki_url": "wiki_url",
            "summary": "summary",
            "full_content": "full_content",
            "opus_prompt": "opus_prompt",
            "status": "ìƒíƒœ",
            "created_at": None,
        }
    }
}


@app.route('/api/sheets/migrate-data', methods=['GET', 'POST'])
def api_migrate_sheet_data():
    """
    ê¸°ì¡´ ì‹œíŠ¸ ë°ì´í„°ë¥¼ ìƒˆ í†µí•© ì‹œíŠ¸ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

    ê¸°ì¡´ ì‹œíŠ¸:
    - OPUS_INPUT_ECON â†’ NEWS
    - HISTORY_OPUS_INPUT â†’ HISTORY
    - MYSTERY_OPUS_INPUT â†’ MYSTERY

    íŒŒë¼ë¯¸í„°:
    - sheets: ë§ˆì´ê·¸ë ˆì´ì…˜í•  ì‹œíŠ¸ (ì½¤ë§ˆ êµ¬ë¶„, ê¸°ë³¸: NEWS,HISTORY,MYSTERY)
    - dry_run: "1"ì´ë©´ ì‹¤ì œ ì“°ê¸° ì—†ì´ ë¯¸ë¦¬ë³´ê¸°ë§Œ

    ì˜ˆì‹œ:
    - GET /api/sheets/migrate-data
    - GET /api/sheets/migrate-data?sheets=NEWS&dry_run=1
    """
    print("[MIGRATE] ===== migrate-data í˜¸ì¶œë¨ =====")

    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        sheet_id = (
            os.environ.get('AUTOMATION_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        # íŒŒë¼ë¯¸í„°
        sheets_param = request.args.get('sheets', 'NEWS,HISTORY,MYSTERY')
        sheet_names = [s.strip().upper() for s in sheets_param.split(',')]
        dry_run = request.args.get('dry_run', '0') == '1'

        valid_sheets = [s for s in sheet_names if s in MIGRATION_MAPPING]
        if not valid_sheets:
            return jsonify({
                "ok": False,
                "error": f"ìœ íš¨í•œ ì‹œíŠ¸ê°€ ì—†ìŠµë‹ˆë‹¤. ê°€ëŠ¥í•œ ê°’: {list(MIGRATION_MAPPING.keys())}"
            }), 400

        print(f"[MIGRATE] ëŒ€ìƒ ì‹œíŠ¸: {valid_sheets}, dry_run: {dry_run}")

        results = []

        for target_sheet in valid_sheets:
            mapping = MIGRATION_MAPPING[target_sheet]
            source_sheet = mapping["source"]
            header_map = mapping["header_map"]

            try:
                # 1) ì†ŒìŠ¤ ì‹œíŠ¸ ë°ì´í„° ì½ê¸°
                source_range = f"{source_sheet}!A:Z"
                source_result = service.spreadsheets().values().get(
                    spreadsheetId=sheet_id,
                    range=source_range
                ).execute()
                source_rows = source_result.get('values', [])

                if len(source_rows) < 2:
                    results.append({
                        "sheet": target_sheet,
                        "source": source_sheet,
                        "status": "skipped",
                        "message": f"ì†ŒìŠ¤ ì‹œíŠ¸ '{source_sheet}'ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤"
                    })
                    continue

                source_headers = source_rows[0]
                source_data = source_rows[1:]

                print(f"[MIGRATE] {source_sheet}: {len(source_data)}ê°œ í–‰ ë°œê²¬")

                # 2) íƒ€ê²Ÿ ì‹œíŠ¸ í—¤ë” ì½ê¸°
                target_range = f"{target_sheet}!A1:Z2"
                target_result = service.spreadsheets().values().get(
                    spreadsheetId=sheet_id,
                    range=target_range
                ).execute()
                target_rows = target_result.get('values', [])

                if len(target_rows) < 2:
                    results.append({
                        "sheet": target_sheet,
                        "source": source_sheet,
                        "status": "error",
                        "message": f"íƒ€ê²Ÿ ì‹œíŠ¸ '{target_sheet}'ì˜ í—¤ë”ê°€ ì—†ìŠµë‹ˆë‹¤"
                    })
                    continue

                target_headers = target_rows[1]  # í–‰ 2ê°€ í—¤ë”

                # 3) ì†ŒìŠ¤ â†’ íƒ€ê²Ÿ ì¸ë±ìŠ¤ ë§¤í•‘ ìƒì„±
                source_idx = {h: i for i, h in enumerate(source_headers)}
                target_idx = {h: i for i, h in enumerate(target_headers)}

                # 4) ë°ì´í„° ë³€í™˜
                migrated_rows = []
                for source_row in source_data:
                    new_row = [''] * len(target_headers)

                    for src_header, tgt_header in header_map.items():
                        if tgt_header is None:
                            continue  # ë¬´ì‹œ
                        if src_header not in source_idx:
                            continue
                        if tgt_header not in target_idx:
                            continue

                        src_i = source_idx[src_header]
                        tgt_i = target_idx[tgt_header]

                        value = source_row[src_i] if src_i < len(source_row) else ''

                        # ìƒíƒœ ë§¤í•‘ (PENDING/WRITING/DONE â†’ ë¹ˆê°’)
                        if tgt_header == "ìƒíƒœ" and "status_map" in mapping:
                            value = mapping["status_map"].get(value, '')

                        new_row[tgt_i] = value

                    migrated_rows.append(new_row)

                print(f"[MIGRATE] {target_sheet}: {len(migrated_rows)}ê°œ í–‰ ë³€í™˜ ì™„ë£Œ")

                # 5) íƒ€ê²Ÿ ì‹œíŠ¸ì— ì“°ê¸° (dry_runì´ ì•„ë‹Œ ê²½ìš°)
                if not dry_run and migrated_rows:
                    # í–‰ 3ë¶€í„° ì“°ê¸°
                    write_range = f"{target_sheet}!A3"
                    service.spreadsheets().values().update(
                        spreadsheetId=sheet_id,
                        range=write_range,
                        valueInputOption="RAW",
                        body={"values": migrated_rows}
                    ).execute()
                    print(f"[MIGRATE] {target_sheet}: {len(migrated_rows)}ê°œ í–‰ ì“°ê¸° ì™„ë£Œ")

                results.append({
                    "sheet": target_sheet,
                    "source": source_sheet,
                    "status": "success" if not dry_run else "dry_run",
                    "rows_migrated": len(migrated_rows),
                    "message": f"{len(migrated_rows)}ê°œ í–‰ {'ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ' if not dry_run else 'ë¯¸ë¦¬ë³´ê¸°'}"
                })

            except Exception as e:
                results.append({
                    "sheet": target_sheet,
                    "source": mapping.get("source", "?"),
                    "status": "error",
                    "message": str(e)
                })
                print(f"[MIGRATE] {target_sheet} ì˜¤ë¥˜: {e}")

        total_migrated = sum(r.get("rows_migrated", 0) for r in results if r["status"] in ["success", "dry_run"])

        return jsonify({
            "ok": True,
            "dry_run": dry_run,
            "total_rows_migrated": total_migrated,
            "results": results,
            "message": f"{'[DRY RUN] ' if dry_run else ''}{total_migrated}ê°œ í–‰ ë§ˆì´ê·¸ë ˆì´ì…˜ {'ì˜ˆì •' if dry_run else 'ì™„ë£Œ'}"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/sheets/hide-old-sheets', methods=['GET', 'POST'])
def api_hide_old_sheets():
    """
    ê¸°ì¡´ ì‹œíŠ¸ ìˆ¨ê¸°ê¸° (ì‚­ì œí•˜ì§€ ì•ŠìŒ)

    ëŒ€ìƒ:
    - OPUS_INPUT_ECON
    - HISTORY_OPUS_INPUT
    - MYSTERY_OPUS_INPUT

    íŒŒë¼ë¯¸í„°:
    - action: "hide" (ìˆ¨ê¸°ê¸°, ê¸°ë³¸ê°’) ë˜ëŠ” "show" (ë‹¤ì‹œ ë³´ì´ê¸°)
    """
    print("[SHEETS] ===== hide-old-sheets í˜¸ì¶œë¨ =====")

    try:
        service = get_sheets_service_account()
        if not service:
            return jsonify({
                "ok": False,
                "error": "Google Sheets ì„œë¹„ìŠ¤ ê³„ì •ì´ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"
            }), 400

        sheet_id = (
            os.environ.get('AUTOMATION_SHEET_ID') or
            os.environ.get('NEWS_SHEET_ID')
        )
        if not sheet_id:
            return jsonify({
                "ok": False,
                "error": "AUTOMATION_SHEET_ID í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤"
            }), 400

        action = request.args.get('action', 'hide')
        hide = (action == 'hide')

        old_sheets = ["OPUS_INPUT_ECON", "HISTORY_OPUS_INPUT", "MYSTERY_OPUS_INPUT"]

        # ìŠ¤í”„ë ˆë“œì‹œíŠ¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        spreadsheet = service.spreadsheets().get(spreadsheetId=sheet_id).execute()
        sheet_info = {
            sheet['properties']['title']: sheet['properties']['sheetId']
            for sheet in spreadsheet.get('sheets', [])
        }

        results = []
        requests_body = []

        for sheet_name in old_sheets:
            if sheet_name not in sheet_info:
                results.append({
                    "sheet": sheet_name,
                    "status": "not_found",
                    "message": f"ì‹œíŠ¸ '{sheet_name}'ì„(ë¥¼) ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"
                })
                continue

            sheet_id_num = sheet_info[sheet_name]
            requests_body.append({
                "updateSheetProperties": {
                    "properties": {
                        "sheetId": sheet_id_num,
                        "hidden": hide
                    },
                    "fields": "hidden"
                }
            })
            results.append({
                "sheet": sheet_name,
                "status": "hidden" if hide else "visible",
                "message": f"ì‹œíŠ¸ '{sheet_name}' {'ìˆ¨ê¹€' if hide else 'í‘œì‹œ'} ì²˜ë¦¬"
            })

        if requests_body:
            service.spreadsheets().batchUpdate(
                spreadsheetId=sheet_id,
                body={"requests": requests_body}
            ).execute()

        return jsonify({
            "ok": True,
            "action": action,
            "results": results,
            "message": f"{len([r for r in results if r['status'] in ['hidden', 'visible']])}ê°œ ì‹œíŠ¸ {'ìˆ¨ê¹€' if hide else 'í‘œì‹œ'} ì²˜ë¦¬"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ============================================================
# Shorts íŒŒì´í”„ë¼ì¸ API (ì—°ì˜ˆ/ìŠ¤í¬ì¸ /êµ­ë½• ë‰´ìŠ¤ ì‡¼ì¸  ìë™ ìƒì„±)
# ============================================================

@app.route('/api/shorts/create-sheet', methods=['GET', 'POST'])
def api_shorts_create_sheet():
    """
    SHORTS ì‹œíŠ¸ ìƒì„±

    Query params:
        channel_id: YouTube ì±„ë„ ID (ì„ íƒ)
        force: 1ì´ë©´ ê¸°ì¡´ ì‹œíŠ¸ ì‚­ì œ í›„ ì¬ìƒì„±

    Returns:
        {"ok": True, "message": "SHORTS ì‹œíŠ¸ ìƒì„± ì™„ë£Œ"}
    """
    try:
        from scripts.shorts_pipeline import create_shorts_sheet, get_sheets_service, get_spreadsheet_id

        channel_id = request.args.get('channel_id', '')
        force = request.args.get('force', '0') == '1'

        service = get_sheets_service()
        spreadsheet_id = get_spreadsheet_id()

        created = create_shorts_sheet(
            service=service,
            spreadsheet_id=spreadsheet_id,
            channel_id=channel_id,
            force=force
        )

        if created:
            return jsonify({
                "ok": True,
                "message": "SHORTS ì‹œíŠ¸ ìƒì„± ì™„ë£Œ",
                "spreadsheet_url": f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/edit"
            })
        else:
            return jsonify({
                "ok": True,
                "message": "SHORTS ì‹œíŠ¸ê°€ ì´ë¯¸ ì¡´ì¬í•©ë‹ˆë‹¤",
                "spreadsheet_url": f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/edit"
            })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/shorts/collect-news', methods=['GET', 'POST'])
def api_shorts_collect_news():
    """
    ì—°ì˜ˆ/ìŠ¤í¬ì¸ /êµ­ë½• ë‰´ìŠ¤ ìˆ˜ì§‘ ë° SHORTS ì‹œíŠ¸ ì €ì¥

    Query params:
        max_items: ìˆ˜ì§‘í•  ìµœëŒ€ ë‰´ìŠ¤ ìˆ˜ (ê¸°ë³¸: 10)
        save: 0ì´ë©´ ì‹œíŠ¸ ì €ì¥ ì•ˆí•¨ (í…ŒìŠ¤íŠ¸ìš©)

    Returns:
        {"ok": True, "collected": 10, "saved": 8, "duplicates": 2}
    """
    try:
        from scripts.shorts_pipeline import run_news_collection

        max_items = int(request.args.get('max_items', '10'))
        save_to_sheet = request.args.get('save', '1') != '0'

        result = run_news_collection(
            max_items=max_items,
            save_to_sheet=save_to_sheet
        )

        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/shorts/youtube-collect', methods=['GET', 'POST'])
def api_shorts_youtube_collect():
    """
    YouTube íŠ¸ë Œë”© ì‡¼ì¸  ìˆ˜ì§‘ ë° SHORTS ì‹œíŠ¸ ì €ì¥

    Query params / JSON body:
        limit: ìˆ˜ì§‘í•  ìµœëŒ€ ì£¼ì œ ìˆ˜ (ê¸°ë³¸: 10)
        min_engagement: ìµœì†Œ ì°¸ì—¬ë„ ì ìˆ˜ (ê¸°ë³¸: 30)
        categories: ì¹´í…Œê³ ë¦¬ ëª©ë¡ (ê¸°ë³¸: ["ì—°ì˜ˆì¸"])
        save: 0ì´ë©´ ì‹œíŠ¸ ì €ì¥ ì•ˆí•¨ (í…ŒìŠ¤íŠ¸ìš©)

    Returns:
        {"ok": True, "collected": 5, "saved": 3, "topics": [...]}
    """
    try:
        from scripts.shorts_pipeline import run_youtube_collection

        # GET ë˜ëŠ” POSTì—ì„œ íŒŒë¼ë¯¸í„° ì¶”ì¶œ
        if request.is_json:
            data = request.get_json() or {}
        else:
            data = {}

        limit = int(data.get('limit') or request.args.get('limit', '10'))
        min_engagement = float(data.get('min_engagement') or request.args.get('min_engagement', '30'))
        categories = data.get('categories') or None
        save_to_sheet = str(data.get('save', request.args.get('save', '1'))) != '0'

        result = run_youtube_collection(
            max_items=limit,
            min_engagement=min_engagement,
            categories=categories,
            save_to_sheet=save_to_sheet
        )

        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/shorts/generate-script', methods=['POST'])
def api_shorts_generate_script():
    """
    ëŒ€ê¸° ìƒíƒœ ë‰´ìŠ¤ì— ëŒ€í•´ ëŒ€ë³¸ ìƒì„±

    Query params:
        limit: ì²˜ë¦¬í•  ìµœëŒ€ í–‰ ìˆ˜ (ê¸°ë³¸: 1)

    Returns:
        {"ok": True, "processed": 1, "results": [...]}
    """
    try:
        from scripts.shorts_pipeline import run_script_generation

        limit = int(request.args.get('limit', '1'))

        result = run_script_generation(limit=limit)

        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/shorts/check-and-process', methods=['GET', 'POST'])
def api_shorts_check_and_process():
    """
    Shorts íŒŒì´í”„ë¼ì¸ ì „ì²´ ì‹¤í–‰ (cron jobìš©)

    1. ë‰´ìŠ¤ ìˆ˜ì§‘ â†’ SHORTS ì‹œíŠ¸ ì €ì¥
    2. ëŒ€ê¸° ìƒíƒœ í–‰ì— ëŒ€í•´ ëŒ€ë³¸ ìƒì„±
    3. (ì˜µì…˜) ë¹„ë””ì˜¤ ìƒì„±: TTS â†’ ì´ë¯¸ì§€(4ì›Œì»¤) + ì¸ë„¤ì¼ ë³‘ë ¬ â†’ FFmpeg

    Query params:
        person: íŠ¹ì • ì¸ë¬¼ë§Œ ì²˜ë¦¬ (ì„ íƒ)
        collect: 0ì´ë©´ ë‰´ìŠ¤ ìˆ˜ì§‘ ê±´ë„ˆëœ€
        generate: 0ì´ë©´ ëŒ€ë³¸ ìƒì„± ê±´ë„ˆëœ€
        video: 1ì´ë©´ ë¹„ë””ì˜¤ê¹Œì§€ ìƒì„±
        limit: ì²˜ë¦¬í•  ìµœëŒ€ í–‰ ìˆ˜ (ê¸°ë³¸: 1)

    Returns:
        {"ok": True, "news_collection": {...}, "script_generation": {...}}
    """
    try:
        from scripts.shorts_pipeline import run_shorts_pipeline, get_sheets_service, get_spreadsheet_id, SHEET_NAME, read_pending_rows

        person = request.args.get('person')
        collect_news = request.args.get('collect', '1') != '0'
        generate_script = request.args.get('generate', '1') != '0'
        generate_video = request.args.get('video', '0') == '1'
        limit = int(request.args.get('limit', '1'))

        # ì§„ë‹¨ ì •ë³´ ìˆ˜ì§‘
        print(f"\n[SHORTS API] check-and-process ì‹œì‘")
        print(f"  - collect_news: {collect_news}")
        print(f"  - generate_script: {generate_script}")
        print(f"  - generate_video: {generate_video}")
        print(f"  - limit: {limit}")

        # ëŒ€ê¸° ìƒíƒœ í–‰ ë¯¸ë¦¬ í™•ì¸
        service = get_sheets_service()
        spreadsheet_id = get_spreadsheet_id()
        pending = read_pending_rows(service, spreadsheet_id, limit=10)
        print(f"[SHORTS API] ëŒ€ê¸° ìƒíƒœ í–‰: {len(pending)}ê°œ")
        for p in pending[:3]:
            print(f"  - í–‰ {p.get('row_number')}: {p.get('person', p.get('celebrity', ''))}")

        result = run_shorts_pipeline(
            person=person,
            collect_news=collect_news,
            generate_script=generate_script,
            generate_video=generate_video,
            limit=limit
        )

        # ì§„ë‹¨ ì •ë³´ ì¶”ê°€
        result["debug"] = {
            "pending_rows_found": len(pending),
            "spreadsheet_id": spreadsheet_id,
            "sheet_name": SHEET_NAME,
        }

        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/shorts/status', methods=['GET'])
def api_shorts_status():
    """
    Shorts íŒŒì´í”„ë¼ì¸ ìƒíƒœ í™•ì¸

    Returns:
        {"ok": True, "pending": 5, "processing": 1, "completed": 10}
    """
    try:
        from scripts.shorts_pipeline import get_sheets_service, get_spreadsheet_id, SHEET_NAME

        service = get_sheets_service()
        spreadsheet_id = get_spreadsheet_id()

        # ë°ì´í„° ì½ê¸°
        result = service.spreadsheets().values().get(
            spreadsheetId=spreadsheet_id,
            range=f"'{SHEET_NAME}'!A2:Z"
        ).execute()
        rows = result.get('values', [])

        if not rows:
            return jsonify({
                "ok": True,
                "pending": 0,
                "processing": 0,
                "completed": 0,
                "failed": 0,
                "total": 0,
                "spreadsheet_url": f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/edit"
            })

        # í—¤ë” ë§¤í•‘
        headers = rows[0] if rows else []
        status_col = headers.index("ìƒíƒœ") if "ìƒíƒœ" in headers else -1

        counts = {"ëŒ€ê¸°": 0, "ì¤€ë¹„": 0, "ì²˜ë¦¬ì¤‘": 0, "ì™„ë£Œ": 0, "ëŒ€ë³¸ì™„ë£Œ": 0, "ì‹¤íŒ¨": 0}
        sample_rows = []  # ëŒ€ê¸° ìƒíƒœ ìƒ˜í”Œ
        for i, row in enumerate(rows[1:], start=3):  # í—¤ë” ì œì™¸, ì‹¤ì œ í–‰ë²ˆí˜¸
            if status_col >= 0 and status_col < len(row):
                status = row[status_col]
                if status in counts:
                    counts[status] += 1
                # ëŒ€ê¸° ìƒíƒœ ìƒ˜í”Œ ì €ì¥ (ìµœëŒ€ 3ê°œ)
                if status == "ëŒ€ê¸°" and len(sample_rows) < 3:
                    person_col = headers.index("person") if "person" in headers else -1
                    person = row[person_col] if person_col >= 0 and person_col < len(row) else ""
                    sample_rows.append({"row": i, "person": person})

        return jsonify({
            "ok": True,
            "pending": counts["ëŒ€ê¸°"],
            "ready": counts["ì¤€ë¹„"],
            "processing": counts["ì²˜ë¦¬ì¤‘"],
            "script_done": counts["ëŒ€ë³¸ì™„ë£Œ"],
            "completed": counts["ì™„ë£Œ"],
            "failed": counts["ì‹¤íŒ¨"],
            "total": len(rows) - 1,
            "headers": headers,
            "status_col": status_col,
            "sample_pending": sample_rows,
            "spreadsheet_url": f"https://docs.google.com/spreadsheets/d/{spreadsheet_id}/edit"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ===== Shorts Viral Pipeline API =====

@app.route('/api/shorts/viral-pipeline', methods=['POST'])
def api_shorts_viral_pipeline():
    """
    ë°”ì´ëŸ´ ì ìˆ˜ ê¸°ë°˜ ìë™ ì‡¼ì¸  íŒŒì´í”„ë¼ì¸

    ìë™ìœ¼ë¡œ ìµœì ì˜ ë‰´ìŠ¤ë¥¼ ì„ ì •í•˜ê³  ëŒ“ê¸€ ê¸°ë°˜ ëŒ€ë³¸ì„ ìƒì„±í•©ë‹ˆë‹¤.

    íë¦„:
    1. RSSì—ì„œ ë‰´ìŠ¤ ìˆ˜ì§‘
    2. ë„¤ì´ë²„/ë‹¤ìŒ ëŒ“ê¸€ í¬ë¡¤ë§ â†’ ë°”ì´ëŸ´ ì ìˆ˜ ê³„ì‚°
    3. ê°€ì¥ ì ìˆ˜ ë†’ì€ ë‰´ìŠ¤ ì„ ì •
    4. ì‹¤ì œ ëŒ“ê¸€ì„ ë°˜ì˜í•œ ëŒ€ë³¸ ìƒì„±
    5. (ì˜µì…˜) ë¹„ë””ì˜¤ ìƒì„±

    Request JSON:
        {
            "min_score": 40,           # ìµœì†Œ ë°”ì´ëŸ´ ì ìˆ˜ (ê¸°ë³¸ 40)
            "categories": ["ì—°ì˜ˆì¸"],  # ìˆ˜ì§‘í•  ì¹´í…Œê³ ë¦¬ (ì„ íƒ)
            "generate_video": true,    # ë¹„ë””ì˜¤ ìƒì„± ì—¬ë¶€ (ê¸°ë³¸ true)
            "upload_youtube": false,   # YouTube ì—…ë¡œë“œ ì—¬ë¶€ (ê¸°ë³¸ false)
            "privacy_status": "private", # YouTube ê³µê°œ ì„¤ì •
            "channel_id": null,        # YouTube ì±„ë„ ID (ì„ íƒ)
            "save_to_sheet": true      # ì‹œíŠ¸ ì €ì¥ ì—¬ë¶€ (ê¸°ë³¸ true)
        }

    Returns:
        {
            "ok": true,
            "person": "ì•„ì´ìœ ",
            "issue_type": "ì—´ì• ",
            "viral_score": {
                "total_score": 75,
                "grade": "S",
                "components": {...}
            },
            "script_hints": {
                "debate_topic": "...",
                "hot_phrases": [...],
                ...
            },
            "script": {
                "title": "...",
                "total_chars": 350,
                "scenes": 5
            },
            "video": {
                "path": "/tmp/shorts_xxx/final.mp4",
                "duration": 45.5
            },
            "youtube": {
                "video_id": "...",
                "video_url": "https://www.youtube.com/watch?v=..."
            },
            "cost": 0.84
        }

    cURL ì˜ˆì‹œ:
        # ë¹„ë””ì˜¤ ìƒì„±ë§Œ
        curl -X POST https://drama-s2ns.onrender.com/api/shorts/viral-pipeline \\
          -H "Content-Type: application/json" \\
          -d '{"min_score": 40, "generate_video": true}'

        # ë¹„ë””ì˜¤ ìƒì„± + YouTube ì—…ë¡œë“œ
        curl -X POST https://drama-s2ns.onrender.com/api/shorts/viral-pipeline \\
          -H "Content-Type: application/json" \\
          -d '{"min_score": 40, "generate_video": true, "upload_youtube": true}'
    """
    try:
        from scripts.shorts_pipeline.run import run_viral_pipeline

        data = request.get_json() or {}

        min_score = data.get("min_score", 40)
        categories = data.get("categories")
        generate_video = data.get("generate_video", True)
        upload_youtube = data.get("upload_youtube", False)
        privacy_status = data.get("privacy_status", "private")
        channel_id = data.get("channel_id")
        save_to_sheet = data.get("save_to_sheet", True)

        print(f"[API] /api/shorts/viral-pipeline í˜¸ì¶œ")
        print(f"[API] íŒŒë¼ë¯¸í„°: min_score={min_score}, generate_video={generate_video}, upload_youtube={upload_youtube}")

        result = run_viral_pipeline(
            min_score=min_score,
            categories=categories,
            generate_video=generate_video,
            upload_youtube=upload_youtube,
            privacy_status=privacy_status,
            channel_id=channel_id,
            save_to_sheet=save_to_sheet
        )

        if result.get("ok"):
            return jsonify(result)
        else:
            return jsonify(result), 400

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


# ===== Shorts Agent API =====

@app.route('/api/shorts/agent-run', methods=['POST'])
def api_shorts_agent_run():
    """
    Supervisor Agentë¥¼ í†µí•œ ì‡¼ì¸  ìƒì„±

    Request JSON:
        {
            "topic": "BTS ì»´ë°± ì†Œì‹",
            "person": "BTS",
            "category": "ì—°ì˜ˆì¸",
            "issue_type": "ì»´ë°±",
            "skip_images": false
        }

    Returns:
        {
            "ok": true,
            "task_id": "abc123",
            "script": {...},
            "images": [...],
            "cost": 0.05,
            "duration": 30.5,
            "logs": [...]
        }
    """
    import asyncio

    try:
        data = request.get_json() or {}

        topic = data.get("topic", "")
        person = data.get("person", "")
        category = data.get("category", "ì—°ì˜ˆì¸")
        issue_type = data.get("issue_type", "ì´ìŠˆ")
        skip_images = data.get("skip_images", False)

        if not topic:
            return jsonify({"ok": False, "error": "topicì€ í•„ìˆ˜ì…ë‹ˆë‹¤"}), 400

        # ì—ì´ì „íŠ¸ ì„í¬íŠ¸ (ë™ì )
        import sys
        agents_dir = os.path.join(os.path.dirname(__file__), "scripts", "shorts_pipeline", "agents")
        if agents_dir not in sys.path:
            sys.path.insert(0, agents_dir)

        from supervisor import SupervisorAgent

        # Supervisor ì‹¤í–‰
        supervisor = SupervisorAgent()

        # asyncio ì´ë²¤íŠ¸ ë£¨í”„ ì²˜ë¦¬
        try:
            loop = asyncio.get_event_loop()
        except RuntimeError:
            loop = asyncio.new_event_loop()
            asyncio.set_event_loop(loop)

        result = loop.run_until_complete(
            supervisor.run(
                topic=topic,
                person=person or topic.split()[0],
                category=category,
                issue_type=issue_type,
                skip_images=skip_images,
            )
        )

        if result.success:
            return jsonify({
                "ok": True,
                "task_id": result.data.get("task_id"),
                "script": result.data.get("script"),
                "images": result.data.get("images"),
                "script_attempts": result.data.get("script_attempts"),
                "image_attempts": result.data.get("image_attempts"),
                "cost": result.cost,
                "duration": result.duration,
                "logs": result.data.get("logs", []),
            })
        else:
            return jsonify({
                "ok": False,
                "error": result.error,
                "logs": result.data.get("logs", []) if result.data else [],
            }), 500

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)}), 500


@app.route('/api/shorts/agent-status', methods=['GET'])
def api_shorts_agent_status():
    """
    Agent ì‹œìŠ¤í…œ ìƒíƒœ í™•ì¸

    Returns:
        {"ok": true, "agents": ["Supervisor", "ScriptAgent", ...], "ready": true}
    """
    try:
        import sys
        agents_dir = os.path.join(os.path.dirname(__file__), "scripts", "shorts_pipeline", "agents")
        if agents_dir not in sys.path:
            sys.path.insert(0, agents_dir)

        # ì—ì´ì „íŠ¸ ì„í¬íŠ¸ í…ŒìŠ¤íŠ¸
        from supervisor import SupervisorAgent
        from script_agent import ScriptAgent
        from image_agent import ImageAgent
        from review_agent import ReviewAgent

        return jsonify({
            "ok": True,
            "agents": ["SupervisorAgent", "ScriptAgent", "ImageAgent", "ReviewAgent"],
            "ready": True,
            "openai_configured": bool(os.environ.get("OPENAI_API_KEY")),
        })

    except ImportError as e:
        return jsonify({
            "ok": False,
            "error": f"Agent import failed: {e}",
            "ready": False,
        }), 500
    except Exception as e:
        return jsonify({"ok": False, "error": str(e)}), 500


# ===== AI Tools API (Claude ë³´ì¡° ë„êµ¬) =====

@app.route('/ai-tools')
def ai_tools_page():
    """AI Tools í˜ì´ì§€ ë Œë”ë§"""
    return render_template('ai-tools.html')


@app.route('/api/ai-tools/youtube', methods=['POST'])
def api_ai_tools_youtube():
    """YouTube ë¦¬ì„œì²˜: ê²€ìƒ‰, ìë§‰ ì¶”ì¶œ, ëŒ“ê¸€ ë¶„ì„"""
    try:
        data = request.get_json()
        query = data.get('query', '').strip()
        action = data.get('action', 'search')
        limit = data.get('limit', 10)

        if not query:
            return jsonify({"ok": False, "error": "ê²€ìƒ‰ì–´ë¥¼ ì…ë ¥í•˜ì„¸ìš”"})

        # YouTube URLì—ì„œ video ID ì¶”ì¶œ
        video_id = None
        if 'youtube.com/watch' in query or 'youtu.be/' in query:
            import re
            match = re.search(r'(?:v=|youtu\.be/)([a-zA-Z0-9_-]{11})', query)
            if match:
                video_id = match.group(1)

        result = {"ok": True}

        if action == 'search':
            # YouTube Data APIë¡œ ê²€ìƒ‰
            api_key = os.environ.get('YOUTUBE_API_KEY') or os.environ.get('YOUTUBE_API_KEY_2')
            if not api_key:
                return jsonify({"ok": False, "error": "YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"})

            import requests as req
            search_url = "https://www.googleapis.com/youtube/v3/search"
            params = {
                'part': 'snippet',
                'q': query,
                'type': 'video',
                'maxResults': min(limit, 50),
                'key': api_key,
                'regionCode': 'KR',
                'relevanceLanguage': 'ko'
            }

            resp = req.get(search_url, params=params, timeout=30)
            if resp.status_code != 200:
                return jsonify({"ok": False, "error": f"YouTube API ì˜¤ë¥˜: {resp.status_code}"})

            search_data = resp.json()
            videos = []

            for item in search_data.get('items', []):
                snippet = item.get('snippet', {})
                videos.append({
                    'id': item.get('id', {}).get('videoId'),
                    'title': snippet.get('title', ''),
                    'channel': snippet.get('channelTitle', ''),
                    'thumbnail': snippet.get('thumbnails', {}).get('medium', {}).get('url', ''),
                    'published': snippet.get('publishedAt', ''),
                    'description': snippet.get('description', '')[:200]
                })

            result['videos'] = videos

        elif action == 'transcript':
            # ìë§‰ ì¶”ì¶œ (youtube_transcript_api ì‚¬ìš©)
            target_id = video_id or query
            try:
                from youtube_transcript_api import YouTubeTranscriptApi

                # í•œêµ­ì–´ ìë§‰ ìš°ì„ , ì—†ìœ¼ë©´ ì˜ì–´, ì—†ìœ¼ë©´ ìë™ìƒì„±
                transcript_list = YouTubeTranscriptApi.list_transcripts(target_id)
                transcript = None

                try:
                    transcript = transcript_list.find_transcript(['ko'])
                except:
                    try:
                        transcript = transcript_list.find_transcript(['en'])
                    except:
                        try:
                            transcript = transcript_list.find_generated_transcript(['ko', 'en'])
                        except:
                            pass

                if transcript:
                    captions = transcript.fetch()
                    full_text = ' '.join([c['text'] for c in captions])
                    result['transcript'] = full_text
                    result['video_id'] = target_id
                else:
                    result['transcript'] = 'ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'

            except Exception as e:
                result['transcript'] = f'ìë§‰ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}'

        elif action == 'comments':
            # ëŒ“ê¸€ ë¶„ì„
            target_id = video_id or query
            api_key = os.environ.get('YOUTUBE_API_KEY') or os.environ.get('YOUTUBE_API_KEY_2')
            if not api_key:
                return jsonify({"ok": False, "error": "YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"})

            import requests as req
            comments_url = "https://www.googleapis.com/youtube/v3/commentThreads"
            params = {
                'part': 'snippet',
                'videoId': target_id,
                'maxResults': min(limit, 100),
                'order': 'relevance',
                'key': api_key
            }

            resp = req.get(comments_url, params=params, timeout=30)
            if resp.status_code != 200:
                return jsonify({"ok": False, "error": f"ëŒ“ê¸€ API ì˜¤ë¥˜: {resp.status_code}"})

            comments_data = resp.json()
            comments = []

            for item in comments_data.get('items', []):
                snippet = item.get('snippet', {}).get('topLevelComment', {}).get('snippet', {})
                comments.append({
                    'author': snippet.get('authorDisplayName', ''),
                    'text': snippet.get('textDisplay', ''),
                    'likes': snippet.get('likeCount', 0),
                    'published': snippet.get('publishedAt', '')
                })

            result['comments'] = comments
            result['video_id'] = target_id

        elif action == 'channel':
            # ì±„ë„ ë¶„ì„ (ì¶”í›„ êµ¬í˜„)
            result['channel_info'] = {'message': 'ì±„ë„ ë¶„ì„ ê¸°ëŠ¥ì€ ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.'}

        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/ai-tools/trend', methods=['POST'])
def api_ai_tools_trend():
    """íŠ¸ë Œë“œ ìŠ¤ìºë„ˆ: ë‰´ìŠ¤, ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ"""
    try:
        data = request.get_json()
        source = data.get('source', 'news')
        category = data.get('category', 'all')
        keyword = data.get('keyword', '')

        result = {"ok": True}

        if source == 'news':
            # Google News RSS ìˆ˜ì§‘
            import feedparser
            import requests as req

            # ì¹´í…Œê³ ë¦¬ë³„ RSS URL
            category_queries = {
                'all': 'ë‰´ìŠ¤',
                'economy': 'ê²½ì œ ê¸ˆìœµ ì£¼ì‹',
                'tech': 'ê¸°ìˆ  AI ë°˜ë„ì²´',
                'entertainment': 'ì—°ì˜ˆ ë“œë¼ë§ˆ ì˜í™”',
                'sports': 'ìŠ¤í¬ì¸  ì¶•êµ¬ ì•¼êµ¬'
            }

            search_query = keyword if keyword else category_queries.get(category, 'ë‰´ìŠ¤')
            encoded_query = requests.utils.quote(search_query)
            rss_url = f"https://news.google.com/rss/search?q={encoded_query}&hl=ko&gl=KR&ceid=KR:ko"

            feed = feedparser.parse(rss_url)

            news = []
            for entry in feed.entries[:20]:
                # ì¶œì²˜ ì¶”ì¶œ
                source_name = ''
                if ' - ' in entry.title:
                    parts = entry.title.rsplit(' - ', 1)
                    title = parts[0]
                    source_name = parts[1] if len(parts) > 1 else ''
                else:
                    title = entry.title

                news.append({
                    'title': title,
                    'source': source_name,
                    'link': entry.link,
                    'time': entry.get('published', ''),
                    'summary': entry.get('summary', '')[:200] if entry.get('summary') else ''
                })

            result['news'] = news

        elif source == 'search':
            # ê²€ìƒ‰ì–´ íŠ¸ë Œë“œ (Google Trends ë˜ëŠ” ë„¤ì´ë²„ ë°ì´í„°ë©)
            # ê°„ë‹¨íˆ ë„¤ì´ë²„ ì‹¤ì‹œê°„ ê²€ìƒ‰ì–´ ëŒ€ì•ˆìœ¼ë¡œ RSS ì‚¬ìš©
            import feedparser

            # ë‹¤ì–‘í•œ ì¹´í…Œê³ ë¦¬ ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            trends = []

            # ì¸ê¸° ë‰´ìŠ¤ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ
            rss_url = "https://news.google.com/rss?hl=ko&gl=KR&ceid=KR:ko"
            feed = feedparser.parse(rss_url)

            from collections import Counter
            words = Counter()

            for entry in feed.entries[:30]:
                title = entry.title.split(' - ')[0]
                # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (2ê¸€ì ì´ìƒ)
                for word in title.split():
                    if len(word) >= 2 and not word.isdigit():
                        words[word] += 1

            for word, count in words.most_common(20):
                trends.append({
                    'keyword': word,
                    'volume': f'{count}ê±´'
                })

            result['trends'] = trends

        elif source == 'social':
            # ì†Œì…œ ë¯¸ë””ì–´ íŠ¸ë Œë“œ (ì¶”í›„ êµ¬í˜„)
            result['social'] = {'message': 'ì†Œì…œ ë¯¸ë””ì–´ íŠ¸ë Œë“œëŠ” ì¤€ë¹„ ì¤‘ì…ë‹ˆë‹¤.'}

        return jsonify(result)

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/ai-tools/image-generate', methods=['POST'])
def api_ai_tools_image_generate():
    """ì´ë¯¸ì§€ ìƒì„±ê¸°: Gemini Imagen"""
    try:
        data = request.get_json()
        prompt = data.get('prompt', '').strip()
        style = data.get('style', 'realistic')
        ratio = data.get('ratio', '16:9')

        if not prompt:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ì„¤ëª…ì„ ì…ë ¥í•˜ì„¸ìš”"})

        # ìŠ¤íƒ€ì¼ë³„ í”„ë¡¬í”„íŠ¸ ìˆ˜ì •
        style_prompts = {
            'realistic': 'photorealistic, high detail, professional photography',
            'webtoon': 'Korean webtoon style, manhwa art style, clean lines, vibrant colors',
            'cinematic': 'cinematic lighting, movie scene, dramatic atmosphere, 4K',
            'illustration': 'digital illustration, artistic, colorful, detailed artwork',
            '3d': '3D render, Unreal Engine, octane render, high quality CGI'
        }

        style_suffix = style_prompts.get(style, '')
        full_prompt = f"{prompt}, {style_suffix}"

        # ë¹„ìœ¨ ì„¤ì •
        ratio_map = {
            '16:9': (1280, 720),
            '9:16': (720, 1280),
            '1:1': (1024, 1024),
            '4:3': (1024, 768)
        }
        width, height = ratio_map.get(ratio, (1280, 720))

        # Gemini Imagen í˜¸ì¶œ (ê¸°ì¡´ image.py ëª¨ë“ˆ í™œìš©)
        from image import generate_image_base64, GEMINI_FLASH

        image_data = generate_image_base64(
            prompt=full_prompt,
            width=width,
            height=height,
            model=GEMINI_FLASH
        )

        if image_data:
            # Base64 ì´ë¯¸ì§€ë¥¼ íŒŒì¼ë¡œ ì €ì¥
            import base64
            import uuid

            filename = f"generated_{uuid.uuid4().hex[:8]}.png"
            filepath = os.path.join("static", "generated", filename)
            os.makedirs(os.path.dirname(filepath), exist_ok=True)

            with open(filepath, 'wb') as f:
                f.write(base64.b64decode(image_data))

            image_url = f"/static/generated/{filename}"

            return jsonify({
                "ok": True,
                "image_url": image_url,
                "prompt_used": full_prompt
            })
        else:
            return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"})

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/ai-tools/vision', methods=['POST'])
def api_ai_tools_vision():
    """ì´ë¯¸ì§€ ë¶„ì„ê¸°: Gemini Vision"""
    try:
        # íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” URL
        if request.content_type and 'multipart/form-data' in request.content_type:
            file = request.files.get('file')
            prompt = request.form.get('prompt', 'ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.')

            if not file:
                return jsonify({"ok": False, "error": "íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”"})

            # íŒŒì¼ì„ base64ë¡œ ë³€í™˜
            import base64
            image_data = base64.b64encode(file.read()).decode('utf-8')
            image_url = f"data:{file.content_type};base64,{image_data}"

        else:
            data = request.get_json()
            url = data.get('url', '').strip()
            prompt = data.get('prompt', 'ì´ ì´ë¯¸ì§€ë¥¼ ìì„¸íˆ ë¶„ì„í•´ì£¼ì„¸ìš”.')

            if not url:
                return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ URLì„ ì…ë ¥í•˜ì„¸ìš”"})

            image_url = url

        # Gemini Vision API í˜¸ì¶œ
        import google.generativeai as genai

        api_key = os.environ.get('GOOGLE_API_KEY')
        if not api_key:
            return jsonify({"ok": False, "error": "Google API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"})

        genai.configure(api_key=api_key)
        model = genai.GenerativeModel('gemini-2.0-flash-exp')

        # ì´ë¯¸ì§€ ì¤€ë¹„
        if image_url.startswith('data:'):
            # Base64 ì´ë¯¸ì§€
            import base64
            header, data = image_url.split(',', 1)
            mime_type = header.split(';')[0].split(':')[1]
            image_bytes = base64.b64decode(data)

            image_part = {
                'mime_type': mime_type,
                'data': image_bytes
            }
        else:
            # URLì—ì„œ ì´ë¯¸ì§€ ë‹¤ìš´ë¡œë“œ
            import requests as req
            resp = req.get(image_url, timeout=30)
            if resp.status_code != 200:
                return jsonify({"ok": False, "error": "ì´ë¯¸ì§€ë¥¼ ë‹¤ìš´ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

            content_type = resp.headers.get('content-type', 'image/jpeg')
            image_part = {
                'mime_type': content_type.split(';')[0],
                'data': resp.content
            }

        # ë¶„ì„ ìš”ì²­
        response = model.generate_content([
            prompt,
            image_part
        ])

        analysis = response.text if response.text else "ë¶„ì„ ê²°ê³¼ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        return jsonify({
            "ok": True,
            "analysis": analysis,
            "image_url": image_url if not image_url.startswith('data:') else None
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/ai-tools/chat', methods=['POST'])
def api_ai_tools_chat():
    """ë„êµ¬ ê²°ê³¼ì— ëŒ€í•œ ì¶”ê°€ ëŒ€í™”"""
    try:
        data = request.get_json()
        message = data.get('message', '')
        context = data.get('context', '')
        history = data.get('history', [])

        if not message:
            return jsonify({"ok": False, "error": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"})

        # GPT-4o-minië¡œ ì‘ë‹µ ìƒì„±
        from openai import OpenAI
        client = OpenAI()

        messages = [
            {
                "role": "system",
                "content": """ë‹¹ì‹ ì€ AI ë„êµ¬ ê²°ê³¼ë¥¼ ë¶„ì„í•˜ê³  í™œìš©í•˜ëŠ” ê²ƒì„ ë•ëŠ” ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìê°€ ë„êµ¬(YouTube ê²€ìƒ‰, íŠ¸ë Œë“œ ë¶„ì„, ì´ë¯¸ì§€ ìƒì„± ë“±)ì˜ ê²°ê³¼ë¬¼ì— ëŒ€í•´ ì§ˆë¬¸í•˜ë©´,
í•´ë‹¹ ì»¨í…ìŠ¤íŠ¸ë¥¼ ë°”íƒ•ìœ¼ë¡œ ìœ ìš©í•œ ì¸ì‚¬ì´íŠ¸, ìš”ì•½, ì•„ì´ë””ì–´ë¥¼ ì œê³µí•˜ì„¸ìš”.

ì‘ë‹µì€ ê°„ê²°í•˜ê³  ì‹¤ìš©ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”. í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì„¸ìš”."""
            }
        ]

        # ì´ì „ ëŒ€í™” ì¶”ê°€
        for h in history[-6:]:
            messages.append({
                "role": h.get('role', 'user'),
                "content": h.get('content', '')
            })

        # í˜„ì¬ ì»¨í…ìŠ¤íŠ¸ì™€ ì§ˆë¬¸
        user_content = message
        if context:
            user_content = f"[ë„êµ¬ ê²°ê³¼ ì»¨í…ìŠ¤íŠ¸]\n{context[:2000]}\n\n[ì‚¬ìš©ì ì§ˆë¬¸]\n{message}"

        messages.append({"role": "user", "content": user_content})

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=messages,
            temperature=0.7,
            max_tokens=1000
        )

        assistant_response = response.choices[0].message.content

        return jsonify({
            "ok": True,
            "response": assistant_response
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


# ===== GPT Chat API (ê°€ì¡± ê³µìš© GPT) =====

# ë°ì´í„° ì €ì¥ ê²½ë¡œ
GPT_DATA_DIR = os.path.join(os.path.dirname(__file__), 'data', 'gpt_chat')
GPT_CONVERSATIONS_FILE = os.path.join(GPT_DATA_DIR, 'conversations.json')
GPT_USERS_FILE = os.path.join(GPT_DATA_DIR, 'users.json')

# ê¸°ë³¸ ì‚¬ìš©ì ëª©ë¡
DEFAULT_USERS = ["ì•„ë¹ ", "ì—„ë§ˆ", "ì¬í•˜", "í•˜ìœ¤"]

# ì‚¬ìš©ìë³„ í”„ë¡œí•„ (ë‚˜ì´, í•™ë…„ ë“±)
USER_PROFILES = {
    "ì¬í•˜": {
        "grade": "ì¤‘í•™êµ 2í•™ë…„",
        "age": 14,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI íŠœí„°ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ” ì‚¬ëŒì€ ì¤‘í•™êµ 2í•™ë…„ í•™ìƒì…ë‹ˆë‹¤.

ë‹µë³€ ì‹œ ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:
- ì¤‘í•™ìƒ ìˆ˜ì¤€ì— ë§ëŠ” ì–´íœ˜ì™€ ì„¤ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê°œë…ì„ ì„¤ëª…í•  ë•Œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”
- ìˆ˜í•™, ê³¼í•™, ì˜ì–´ ë“± í•™ì—… ì§ˆë¬¸ì—ëŠ” ë‹¨ê³„ë³„ë¡œ í’€ì´ ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”
- ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  ìŠ¤ìŠ¤ë¡œ ìƒê°í•´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ë˜ì ¸ì£¼ì„¸ìš”
- ê²©ë ¤ì™€ ì¹­ì°¬ì„ ì•„ë¼ì§€ ë§ˆì„¸ìš”"""
    },
    "í•˜ìœ¤": {
        "grade": "ì´ˆë“±í•™êµ 5í•™ë…„",
        "age": 11,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ì¬ë¯¸ìˆëŠ” AI ì„ ìƒë‹˜ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ” ì‚¬ëŒì€ ì´ˆë“±í•™êµ 5í•™ë…„ í•™ìƒì…ë‹ˆë‹¤.

ë‹µë³€ ì‹œ ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:
- ì´ˆë“±í•™ìƒë„ ì´í•´í•  ìˆ˜ ìˆëŠ” ì‰¬ìš´ ë§ë¡œ ì„¤ëª…í•˜ì„¸ìš”
- ë³µì¡í•œ ê°œë…ì€ ê·¸ë¦¼ì´ë‚˜ ë¹„ìœ ë¥¼ í™œìš©í•´ ì„¤ëª…í•˜ì„¸ìš” (ì˜ˆ: "ë§ˆì¹˜ ~ì²˜ëŸ¼")
- ê¸´ ë¬¸ì¥ë³´ë‹¤ ì§§ê³  ëª…í™•í•œ ë¬¸ì¥ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ì´ëª¨ì§€ë¥¼ ì ì ˆíˆ ì‚¬ìš©í•´ì„œ ì¬ë¯¸ìˆê²Œ ë‹µë³€í•˜ì„¸ìš” ğŸ˜Š
- í•™ìŠµì— í¥ë¯¸ë¥¼ ëŠë‚„ ìˆ˜ ìˆë„ë¡ ê²©ë ¤í•´ì£¼ì„¸ìš”
- ì–´ë ¤ìš´ í•œìì–´ë‚˜ ì˜ì–´ ë‹¨ì–´ëŠ” í”¼í•˜ê±°ë‚˜ ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- "ì˜í–ˆì–´!", "ëŒ€ë‹¨í•´!" ê°™ì€ ì¹­ì°¬ì„ ìì£¼ í•´ì£¼ì„¸ìš”"""
    },
    "ì—„ë§ˆ": {
        "grade": None,
        "age": None,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ” ì‚¬ëŒì€ ì¤‘í•™ìƒê³¼ ì´ˆë“±í•™ìƒ ìë…€ë¥¼ ë‘” ì—„ë§ˆì…ë‹ˆë‹¤.

ë‹µë³€ ì‹œ ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:
- ìë…€ í•™ì—… ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì•„ì´ë“¤ì—ê²Œ ì„¤ëª…í•˜ê¸° ì‰¬ìš´ ë°©ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- í•™ìŠµ ì§€ë„ì— ë„ì›€ì´ ë˜ëŠ” íŒì„ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”
- ë³µì¡í•œ ê°œë…ë„ ì•„ì´ë“¤ ëˆˆë†’ì´ì—ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”
- ê°€ì •ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìƒí™œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì•„ì´ë“¤ì˜ í•™ìŠµ ë™ê¸° ë¶€ì—¬ ë°©ë²•ë„ ì œì•ˆí•´ì£¼ì„¸ìš”"""
    },
    "ì•„ë¹ ": {
        "grade": None,
        "age": None,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ë©°, í•„ìš”ì‹œ ì½”ë“œë‚˜ ì˜ˆì‹œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì „ë¬¸ì ì¸ ë‚´ìš©ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ë˜, í•µì‹¬ì„ ë¹ ë¥´ê²Œ ì „ë‹¬í•˜ì„¸ìš”."""
    }
}

def get_system_prompt_for_user(user_id: str) -> str:
    """ì‚¬ìš©ìë³„ ë§ì¶¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
    if user_id in USER_PROFILES:
        return USER_PROFILES[user_id]["system_prompt"]

    # ê¸°ë³¸ í”„ë¡¬í”„íŠ¸
    return "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ë©°, í•„ìš”ì‹œ ì½”ë“œë‚˜ ì˜ˆì‹œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."

def ensure_gpt_data_dir():
    """GPT ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
    os.makedirs(GPT_DATA_DIR, exist_ok=True)

def load_gpt_users():
    """ì‚¬ìš©ì ëª©ë¡ ë¡œë“œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT user_id FROM gpt_users ORDER BY id")
        rows = cursor.fetchall()
        cursor.close()
        conn.close()

        if rows:
            return [row['user_id'] if isinstance(row, dict) else row[0] for row in rows]
        else:
            # ê¸°ë³¸ ì‚¬ìš©ì ì¶”ê°€
            save_gpt_users(DEFAULT_USERS)
            return DEFAULT_USERS.copy()
    except Exception as e:
        print(f"[GPT] ì‚¬ìš©ì ë¡œë“œ ì‹¤íŒ¨: {e}")
        return DEFAULT_USERS.copy()

def save_gpt_users(users):
    """ì‚¬ìš©ì ëª©ë¡ ì €ì¥ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        for user_id in users:
            if USE_POSTGRES:
                cursor.execute(
                    "INSERT INTO gpt_users (user_id) VALUES (%s) ON CONFLICT (user_id) DO NOTHING",
                    (user_id,)
                )
            else:
                cursor.execute(
                    "INSERT OR IGNORE INTO gpt_users (user_id) VALUES (?)",
                    (user_id,)
                )

        conn.commit()
        cursor.close()
        conn.close()
        print(f"[GPT] ì‚¬ìš©ì ì €ì¥ ì™„ë£Œ: {users}")
        return True
    except Exception as e:
        print(f"[GPT] ì‚¬ìš©ì ì €ì¥ ì‹¤íŒ¨: {e}")
        return False

def load_gpt_conversations_for_user(user_id: str):
    """íŠ¹ì • ì‚¬ìš©ìì˜ ëŒ€í™” ëª©ë¡ ë¡œë“œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        cursor.execute(
            """SELECT conversation_id, created_at, updated_at
               FROM gpt_conversations
               WHERE user_id = %s
               ORDER BY updated_at DESC""" if USE_POSTGRES else
            """SELECT conversation_id, created_at, updated_at
               FROM gpt_conversations
               WHERE user_id = ?
               ORDER BY updated_at DESC""",
            (user_id,)
        )
        convs = cursor.fetchall()

        result = {}
        for conv in convs:
            conv_id = conv['conversation_id'] if isinstance(conv, dict) else conv[0]

            # ë©”ì‹œì§€ ë¡œë“œ
            cursor.execute(
                """SELECT role, content, model, has_image, created_at
                   FROM gpt_messages
                   WHERE user_id = %s AND conversation_id = %s
                   ORDER BY created_at""" if USE_POSTGRES else
                """SELECT role, content, model, has_image, created_at
                   FROM gpt_messages
                   WHERE user_id = ? AND conversation_id = ?
                   ORDER BY created_at""",
                (user_id, conv_id)
            )
            messages = cursor.fetchall()

            result[conv_id] = {
                'created_at': (conv['created_at'] if isinstance(conv, dict) else conv[1]).isoformat() if hasattr(conv['created_at'] if isinstance(conv, dict) else conv[1], 'isoformat') else str(conv['created_at'] if isinstance(conv, dict) else conv[1]),
                'updated_at': (conv['updated_at'] if isinstance(conv, dict) else conv[2]).isoformat() if hasattr(conv['updated_at'] if isinstance(conv, dict) else conv[2], 'isoformat') else str(conv['updated_at'] if isinstance(conv, dict) else conv[2]),
                'messages': [
                    {
                        'role': msg['role'] if isinstance(msg, dict) else msg[0],
                        'content': msg['content'] if isinstance(msg, dict) else msg[1],
                        'model': msg['model'] if isinstance(msg, dict) else msg[2],
                        'has_image': bool(msg['has_image'] if isinstance(msg, dict) else msg[3]),
                        'timestamp': (msg['created_at'] if isinstance(msg, dict) else msg[4]).isoformat() if hasattr(msg['created_at'] if isinstance(msg, dict) else msg[4], 'isoformat') else str(msg['created_at'] if isinstance(msg, dict) else msg[4])
                    }
                    for msg in messages
                ]
            }

        cursor.close()
        conn.close()
        return result
    except Exception as e:
        print(f"[GPT] ëŒ€í™” ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {}

def save_gpt_message(user_id: str, conversation_id: str, role: str, content: str, model: str = None, has_image: bool = False):
    """ë‹¨ì¼ ë©”ì‹œì§€ ì €ì¥ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        # conversationì´ ì—†ìœ¼ë©´ ìƒì„±
        if USE_POSTGRES:
            cursor.execute(
                """INSERT INTO gpt_conversations (user_id, conversation_id)
                   VALUES (%s, %s)
                   ON CONFLICT (user_id, conversation_id)
                   DO UPDATE SET updated_at = CURRENT_TIMESTAMP""",
                (user_id, conversation_id)
            )
            cursor.execute(
                """INSERT INTO gpt_messages (user_id, conversation_id, role, content, model, has_image)
                   VALUES (%s, %s, %s, %s, %s, %s)""",
                (user_id, conversation_id, role, content, model, has_image)
            )
        else:
            cursor.execute(
                """INSERT OR REPLACE INTO gpt_conversations (user_id, conversation_id, updated_at)
                   VALUES (?, ?, CURRENT_TIMESTAMP)""",
                (user_id, conversation_id)
            )
            cursor.execute(
                """INSERT INTO gpt_messages (user_id, conversation_id, role, content, model, has_image)
                   VALUES (?, ?, ?, ?, ?, ?)""",
                (user_id, conversation_id, role, content, model, 1 if has_image else 0)
            )

        conn.commit()
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"[GPT] ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False

def delete_gpt_conversation(user_id: str, conversation_id: str):
    """ëŒ€í™” ì‚­ì œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute(
                "DELETE FROM gpt_messages WHERE user_id = %s AND conversation_id = %s",
                (user_id, conversation_id)
            )
            cursor.execute(
                "DELETE FROM gpt_conversations WHERE user_id = %s AND conversation_id = %s",
                (user_id, conversation_id)
            )
        else:
            cursor.execute(
                "DELETE FROM gpt_messages WHERE user_id = ? AND conversation_id = ?",
                (user_id, conversation_id)
            )
            cursor.execute(
                "DELETE FROM gpt_conversations WHERE user_id = ? AND conversation_id = ?",
                (user_id, conversation_id)
            )

        conn.commit()
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"[GPT] ëŒ€í™” ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False

def delete_gpt_user(user_id: str):
    """ì‚¬ìš©ì ì‚­ì œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if USE_POSTGRES:
            cursor.execute("DELETE FROM gpt_messages WHERE user_id = %s", (user_id,))
            cursor.execute("DELETE FROM gpt_conversations WHERE user_id = %s", (user_id,))
            cursor.execute("DELETE FROM gpt_users WHERE user_id = %s", (user_id,))
        else:
            cursor.execute("DELETE FROM gpt_messages WHERE user_id = ?", (user_id,))
            cursor.execute("DELETE FROM gpt_conversations WHERE user_id = ?", (user_id,))
            cursor.execute("DELETE FROM gpt_users WHERE user_id = ?", (user_id,))

        conn.commit()
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"[GPT] ì‚¬ìš©ì ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False

# í•˜ìœ„ í˜¸í™˜ìš© (ê¸°ì¡´ ì½”ë“œì—ì„œ ì‚¬ìš©)
def load_gpt_conversations():
    """ì „ì²´ ëŒ€í™” ë¡œë“œ - í•˜ìœ„ í˜¸í™˜ìš©"""
    return {}

def save_gpt_conversations(data):
    """ì „ì²´ ëŒ€í™” ì €ì¥ - í•˜ìœ„ í˜¸í™˜ìš© (ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
    return True

def analyze_question_complexity(message: str, has_image: bool = False) -> str:
    """ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ

    Returns:
        'gpt-5.2' for complex questions (ë¶„ì„, ì½”ë”©, ì°½ì‘)
        'gpt-4o' for medium questions (ì„¤ëª…, ë²ˆì—­, ì¤‘ê°„ ê¸¸ì´)
        'gpt-4o-mini' for simple questions (ì§§ì€ ëŒ€í™”, ë‹¨ìˆœ ì‚¬ì‹¤)
    """
    # ì´ë¯¸ì§€ê°€ ìˆìœ¼ë©´ Vision ëª¨ë¸ í•„ìš”
    if has_image:
        return 'gpt-4o'  # GPT-4oëŠ” Vision ì§€ì›

    # ë³µì¡í•œ ì§ˆë¬¸ íŒ¨í„´ â†’ GPT-5.2
    complex_patterns = [
        # ì½”ë”©/í”„ë¡œê·¸ë˜ë°
        'ì½”ë“œ', 'code', 'í”„ë¡œê·¸ë˜ë°', 'python', 'javascript', 'java', 'c++',
        'í•¨ìˆ˜', 'function', 'í´ë˜ìŠ¤', 'class', 'ì•Œê³ ë¦¬ì¦˜', 'êµ¬í˜„', 'implement',
        'ë²„ê·¸', 'debug', 'ì—ëŸ¬', 'error', 'API', 'ë°ì´í„°ë² ì´ìŠ¤', 'SQL',
        # ë¶„ì„/ì¶”ë¡ 
        'ë¶„ì„', 'analyze', 'ë¹„êµ', 'compare', 'ì¥ë‹¨ì ', 'ì°¨ì´ì ', 'ì „ëµ', 'strategy',
        # ì°½ì‘/ì‘ë¬¸
        'ì‘ì„±í•´', 'write', 'ë§Œë“¤ì–´ì¤˜', 'create', 'ê¸°íš', 'ìŠ¤í† ë¦¬', 'story',
        'ëŒ€ë³¸', 'script', 'ì—ì„¸ì´', 'essay', 'ë³´ê³ ì„œ', 'report',
        # ìˆ˜í•™/ê³¼í•™ (ë³µì¡)
        'ì¦ëª…', 'prove', 'í†µê³„', 'statistics', 'í™•ë¥ ', 'probability',
        # ê¸´ ì„¤ëª…
        'ìì„¸íˆ', 'ìƒì„¸íˆ', 'detailed', 'ìš”ì•½', 'summarize',
    ]

    # ì¤‘ê°„ ë³µì¡ë„ íŒ¨í„´ â†’ GPT-4o
    medium_patterns = [
        # ì„¤ëª… ìš”ì²­
        'ì„¤ëª…í•´', 'explain', 'ì•Œë ¤ì¤˜', 'ê°€ë¥´ì³', 'ì–´ë–»ê²Œ', 'how',
        # ë²ˆì—­
        'ë²ˆì—­', 'translate', 'ì˜ì–´ë¡œ', 'í•œêµ­ì–´ë¡œ', 'in english',
        # ê°œë…/ì •ì˜ (ê¸´ ì„¤ëª… í•„ìš”)
        'ê°œë…', 'concept', 'ì›ë¦¬', 'principle',
        # ì™œ/ì´ìœ 
        'ì™œ', 'why', 'ì›ì¸', 'ì´ìœ ',
        # ìˆ˜í•™/ê³¼í•™ (ê¸°ë³¸)
        'ê³„ì‚°', 'calculate', 'ê³µì‹', 'formula', 'ìˆ˜í•™', 'ê³¼í•™',
    ]

    # ê°„ë‹¨í•œ ì§ˆë¬¸ íŒ¨í„´ â†’ GPT-4o-mini (ê°€ì¥ ë¹ ë¦„)
    simple_patterns = [
        # ë‹¨ìˆœ ì‚¬ì‹¤
        'ë­ì•¼', 'ë­”ê°€ìš”', 'ë¬´ì—‡', 'what is', 'ì •ì˜', 'ì˜ë¯¸',
        # ë‚ ì”¨/ì‹œê°„
        'ë‚ ì”¨', 'weather', 'ì‹œê°„', 'time', 'ì˜¤ëŠ˜',
        # ì§§ì€ ëŒ€í™”
        'ì•ˆë…•', 'hello', 'hi', 'ê³ ë§ˆì›Œ', 'thanks', 'ë„¤', 'ì•„ë‹ˆ',
        'ì˜ê°€', 'bye', 'ì¢‹ì•„', 'ì‹«ì–´', 'ë§ì•„', 'í‹€ë ¤',
        # ë‹¨ìˆœ ì§ˆë¬¸
        'ëª‡', 'ì–¸ì œ', 'when', 'ì–´ë””', 'where', 'ëˆ„êµ¬', 'who',
        # ì˜ˆ/ì•„ë‹ˆì˜¤ ì§ˆë¬¸
        'ë§ì•„?', 'ë ê¹Œ?', 'ìˆì–´?', 'ì—†ì–´?',
    ]

    message_lower = message.lower()

    # ë³µì¡í•œ íŒ¨í„´ í™•ì¸ â†’ GPT-5.2
    for pattern in complex_patterns:
        if pattern in message_lower:
            return 'gpt-5.2'

    # ì¤‘ê°„ ë³µì¡ë„ íŒ¨í„´ í™•ì¸ â†’ GPT-4o
    for pattern in medium_patterns:
        if pattern in message_lower:
            return 'gpt-4o'

    # ê°„ë‹¨í•œ íŒ¨í„´ í™•ì¸ â†’ GPT-4o-mini
    for pattern in simple_patterns:
        if pattern in message_lower:
            return 'gpt-4o-mini'

    # ë©”ì‹œì§€ ê¸¸ì´ ê¸°ë°˜ íŒë‹¨
    if len(message) > 200:
        return 'gpt-5.2'  # ê¸´ ì§ˆë¬¸ â†’ ë³µì¡í•  ê°€ëŠ¥ì„±
    elif len(message) > 50:
        return 'gpt-4o'   # ì¤‘ê°„ ê¸¸ì´ â†’ ì¤‘ê°„ ë³µì¡ë„
    else:
        return 'gpt-4o-mini'  # ì§§ì€ ì§ˆë¬¸ â†’ ê°„ë‹¨

    # ê¸°ë³¸ê°’
    return 'gpt-4o'


@app.route('/gpt-chat')
def gpt_chat_page():
    """GPT Chat í˜ì´ì§€ ë Œë”ë§"""
    return render_template('gpt-chat.html')


@app.route('/api/gpt/chat', methods=['POST'])
def api_gpt_chat():
    """GPT Chat API - ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ìë™ ëª¨ë¸ ë¼ìš°íŒ…"""
    try:
        data = request.get_json() or {}
        message = data.get('message', '').strip()
        model_preference = data.get('model', 'auto')  # 'auto', 'gpt-5.2', 'gpt-4o', 'gpt-4o-mini'
        history = data.get('history', [])
        user_id = data.get('user_id', 'default')
        conversation_id = data.get('conversation_id')
        has_image = data.get('has_image', False)
        image_base64 = data.get('image')

        if not message and not image_base64:
            return jsonify({"ok": False, "error": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"})

        # ëª¨ë¸ ì„ íƒ
        if model_preference == 'auto':
            selected_model = analyze_question_complexity(message, has_image or bool(image_base64))
        else:
            selected_model = model_preference

        print(f"[GPT] ëª¨ë¸ ì„ íƒ: {selected_model} (preference: {model_preference}, user: {user_id}, has_image: {bool(image_base64)})")

        # ì‚¬ìš©ìë³„ ë§ì¶¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
        system_prompt = get_system_prompt_for_user(user_id)

        # ëŒ€í™” íˆìŠ¤í† ë¦¬ êµ¬ì„±
        messages = [
            {
                "role": "system",
                "content": system_prompt
            }
        ]

        # ì´ì „ ëŒ€í™” ì¶”ê°€ (ìµœê·¼ 10ê°œ)
        for h in history[-10:]:
            messages.append({
                "role": h.get('role', 'user'),
                "content": h.get('content', '')
            })

        # í˜„ì¬ ë©”ì‹œì§€ êµ¬ì„±
        if image_base64 and selected_model == 'gpt-4o':
            # Vision API ì‚¬ìš© (GPT-4o)
            user_content = [
                {"type": "text", "text": message or "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."}
            ]

            # ì´ë¯¸ì§€ ì¶”ê°€
            if image_base64.startswith('data:'):
                # data URL í˜•ì‹
                user_content.append({
                    "type": "image_url",
                    "image_url": {"url": image_base64}
                })
            else:
                # base64ë§Œ ìˆëŠ” ê²½ìš°
                user_content.append({
                    "type": "image_url",
                    "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}
                })

            messages.append({"role": "user", "content": user_content})

            # GPT-4o Vision í˜¸ì¶œ
            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.7,
                max_tokens=4000
            )

            assistant_response = response.choices[0].message.content
            model_used = "gpt-4o"

        elif selected_model == 'gpt-5.2':
            # GPT-5.2 Responses API ì‚¬ìš©
            messages.append({"role": "user", "content": message})

            # Responses API í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            input_messages = []
            for msg in messages:
                input_messages.append({
                    "role": msg["role"],
                    "content": [{"type": "input_text", "text": msg["content"]}]
                })

            response = client.responses.create(
                model="gpt-5.2",
                input=input_messages,
                temperature=0.7
            )

            # ì‘ë‹µ ì¶”ì¶œ
            if getattr(response, "output_text", None):
                assistant_response = response.output_text.strip()
            else:
                text_chunks = []
                for item in getattr(response, "output", []) or []:
                    for content in getattr(item, "content", []) or []:
                        if getattr(content, "type", "") == "text":
                            text_chunks.append(getattr(content, "text", ""))
                assistant_response = "\n".join(text_chunks).strip()

            model_used = "gpt-5.2"

        else:
            # GPT-4o / GPT-4o-mini Chat Completions API ì‚¬ìš©
            messages.append({"role": "user", "content": message})

            # gpt-4o-miniëŠ” ë¹ ë¥¸ ì‘ë‹µì„ ìœ„í•´ max_tokens ì¤„ì„
            max_tokens = 2000 if selected_model == 'gpt-4o-mini' else 4000

            response = client.chat.completions.create(
                model=selected_model,  # 'gpt-4o' ë˜ëŠ” 'gpt-4o-mini'
                messages=messages,
                temperature=0.7,
                max_tokens=max_tokens
            )

            assistant_response = response.choices[0].message.content
            model_used = selected_model

        # ëŒ€í™” ì €ì¥ (PostgreSQL)
        if conversation_id:
            try:
                # ì‚¬ìš©ì ë©”ì‹œì§€ ì €ì¥
                save_gpt_message(user_id, conversation_id, 'user', message, None, bool(image_base64))
                # ì–´ì‹œìŠ¤í„´íŠ¸ ì‘ë‹µ ì €ì¥
                save_gpt_message(user_id, conversation_id, 'assistant', assistant_response, model_used, False)
            except Exception as e:
                print(f"[GPT] ëŒ€í™” ì €ì¥ ì˜¤ë¥˜: {e}")

        return jsonify({
            "ok": True,
            "response": assistant_response,
            "model_used": model_used,
            "complexity": "complex" if model_used == "gpt-5.2" else "simple"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/gpt/conversations', methods=['GET'])
def api_gpt_get_conversations():
    """ì‚¬ìš©ìë³„ ëŒ€í™” ëª©ë¡ ì¡°íšŒ (PostgreSQL)"""
    try:
        user_id = request.args.get('user_id', 'default')
        user_convs = load_gpt_conversations_for_user(user_id)

        # ëª©ë¡ í˜•íƒœë¡œ ë³€í™˜
        result = []
        for conv_id, conv_data in user_convs.items():
            # ì²« ë²ˆì§¸ ì‚¬ìš©ì ë©”ì‹œì§€ë¥¼ ì œëª©ìœ¼ë¡œ ì‚¬ìš©
            title = "ìƒˆ ëŒ€í™”"
            for msg in conv_data.get('messages', []):
                if msg.get('role') == 'user':
                    title = msg.get('content', '')[:50] + ('...' if len(msg.get('content', '')) > 50 else '')
                    break

            result.append({
                'id': conv_id,
                'title': title,
                'created_at': conv_data.get('created_at'),
                'updated_at': conv_data.get('updated_at'),
                'message_count': len(conv_data.get('messages', []))
            })

        # ìµœì‹ ìˆœ ì •ë ¬
        result.sort(key=lambda x: x.get('updated_at', ''), reverse=True)

        return jsonify({"ok": True, "conversations": result})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/gpt/conversations/<conversation_id>', methods=['GET'])
def api_gpt_get_conversation(conversation_id):
    """íŠ¹ì • ëŒ€í™” ì¡°íšŒ (PostgreSQL)"""
    try:
        user_id = request.args.get('user_id', 'default')
        user_convs = load_gpt_conversations_for_user(user_id)
        conv_data = user_convs.get(conversation_id)

        if not conv_data:
            return jsonify({"ok": False, "error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

        return jsonify({
            "ok": True,
            "conversation": {
                'id': conversation_id,
                'messages': conv_data.get('messages', []),
                'created_at': conv_data.get('created_at'),
                'updated_at': conv_data.get('updated_at')
            }
        })

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/gpt/conversations/<conversation_id>', methods=['DELETE'])
def api_gpt_delete_conversation(conversation_id):
    """ëŒ€í™” ì‚­ì œ (PostgreSQL)"""
    try:
        user_id = request.args.get('user_id', 'default')

        if delete_gpt_conversation(user_id, conversation_id):
            return jsonify({"ok": True})

        return jsonify({"ok": False, "error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/gpt/users', methods=['GET'])
def api_gpt_get_users():
    """ë“±ë¡ëœ ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ (PostgreSQL)"""
    try:
        users = load_gpt_users()

        result = []
        for user_id in users:
            user_convs = load_gpt_conversations_for_user(user_id)
            total_messages = sum(len(c.get('messages', [])) for c in user_convs.values())
            result.append({
                'id': user_id,
                'conversation_count': len(user_convs),
                'total_messages': total_messages
            })

        return jsonify({"ok": True, "users": result})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/gpt/users', methods=['POST'])
def api_gpt_add_user():
    """ì‚¬ìš©ì ì¶”ê°€"""
    try:
        data = request.get_json() or {}
        user_name = data.get('name', '').strip()

        if not user_name:
            return jsonify({"ok": False, "error": "ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"})

        users = load_gpt_users()

        if user_name in users:
            return jsonify({"ok": False, "error": "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤"})

        users.append(user_name)
        save_gpt_users(users)

        return jsonify({"ok": True, "users": users})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@app.route('/api/gpt/users/<user_id>', methods=['DELETE'])
def api_gpt_delete_user(user_id):
    """ì‚¬ìš©ì ì‚­ì œ (ëŒ€í™” ê¸°ë¡ë„ í•¨ê»˜ ì‚­ì œ) - PostgreSQL"""
    try:
        users = load_gpt_users()

        if user_id not in users:
            return jsonify({"ok": False, "error": "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

        # ì‚¬ìš©ì ë° ëŒ€í™” ê¸°ë¡ ì‚­ì œ (PostgreSQL)
        delete_gpt_user(user_id)

        # ì—…ë°ì´íŠ¸ëœ ì‚¬ìš©ì ëª©ë¡ ë°˜í™˜
        users = load_gpt_users()
        return jsonify({"ok": True, "users": users})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


# ===== Fontconfig ì„¤ì • (ì¼ë³¸ì–´ í°íŠ¸ ì¸ì‹ìš©) =====
def setup_fontconfig():
    """í”„ë¡œì íŠ¸ fonts ë””ë ‰í† ë¦¬ë¥¼ fontconfigì— ë“±ë¡"""
    try:
        import subprocess
        script_dir = os.path.dirname(os.path.abspath(__file__))
        fonts_dir = os.path.join(script_dir, "fonts")

        # fontconfig ì„¤ì • íŒŒì¼ ìƒì„±
        config_dir = os.path.expanduser("~/.config/fontconfig")
        os.makedirs(config_dir, exist_ok=True)

        fonts_conf = os.path.join(config_dir, "fonts.conf")
        config_content = f'''<?xml version="1.0"?>
<!DOCTYPE fontconfig SYSTEM "fonts.dtd">
<fontconfig>
  <dir>{fonts_dir}</dir>
</fontconfig>'''

        with open(fonts_conf, 'w') as f:
            f.write(config_content)

        # fontconfig ìºì‹œ ì—…ë°ì´íŠ¸
        subprocess.run(['fc-cache', '-f'], capture_output=True)
        print(f"[FONTCONFIG] ì„¤ì • ì™„ë£Œ: {fonts_dir}")
    except Exception as e:
        print(f"[FONTCONFIG] ì„¤ì • ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

# ì„œë²„ ì‹œì‘ ì‹œ fontconfig ì„¤ì •
setup_fontconfig()

# ===== Render ë°°í¬ë¥¼ ìœ„í•œ ì„¤ì • =====
if __name__ == "__main__":
    port = int(os.environ.get("PORT", 5059))
    app.run(host="0.0.0.0", port=port, debug=False)
