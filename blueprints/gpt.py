"""
GPT Chat API Blueprint
/api/gpt/* ì—”ë“œí¬ì¸íŠ¸ ë‹´ë‹¹

ì˜ì¡´ì„±:
- db_connection_func: get_db_connection í•¨ìˆ˜ (set_db_connectionìœ¼ë¡œ ì£¼ì…)
- openai_client: OpenAI í´ë¼ì´ì–¸íŠ¸ (set_openai_clientìœ¼ë¡œ ì£¼ì…)
- use_postgres: PostgreSQL ì‚¬ìš© ì—¬ë¶€ (set_use_postgresë¡œ ì£¼ì…)
"""

import os
from flask import Blueprint, request, jsonify, render_template

# Blueprint ìƒì„±
gpt_bp = Blueprint('gpt', __name__)

# ===== ì˜ì¡´ì„± ì£¼ì… =====
_db_connection_func = None
_openai_client = None
_use_postgres = False


def set_db_connection(func):
    """DB ì—°ê²° í•¨ìˆ˜ ì£¼ì…"""
    global _db_connection_func
    _db_connection_func = func


def set_openai_client(client):
    """OpenAI í´ë¼ì´ì–¸íŠ¸ ì£¼ì…"""
    global _openai_client
    _openai_client = client


def set_use_postgres(value: bool):
    """PostgreSQL ì‚¬ìš© ì—¬ë¶€ ì„¤ì •"""
    global _use_postgres
    _use_postgres = value


def get_db_connection():
    """DB ì—°ê²° í•¨ìˆ˜ í˜¸ì¶œ"""
    if _db_connection_func is None:
        raise RuntimeError("DB connection function not set. Call set_db_connection first.")
    return _db_connection_func()


# ===== ìƒìˆ˜ =====
GPT_DATA_DIR = os.path.join(os.path.dirname(os.path.dirname(__file__)), 'data', 'gpt_chat')
GPT_CONVERSATIONS_FILE = os.path.join(GPT_DATA_DIR, 'conversations.json')
GPT_USERS_FILE = os.path.join(GPT_DATA_DIR, 'users.json')

DEFAULT_USERS = ["ì•„ë¹ ", "ì—„ë§ˆ", "ì¬í•˜", "í•˜ìœ¤"]

USER_PROFILES = {
    "ì¬í•˜": {
        "grade": "ì¤‘í•™êµ 2í•™ë…„",
        "age": 14,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI íŠœí„°ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ” ì‚¬ëŒì€ ì¤‘í•™êµ 2í•™ë…„ í•™ìƒì…ë‹ˆë‹¤.

ë‹µë³€ ì‹œ ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:
- ì¤‘í•™ìƒ ìˆ˜ì¤€ì— ë§ëŠ” ì–´íœ˜ì™€ ì„¤ëª…ì„ ì‚¬ìš©í•˜ì„¸ìš”
- ê°œë…ì„ ì„¤ëª…í•  ë•Œ êµ¬ì²´ì ì¸ ì˜ˆì‹œë¥¼ ë“¤ì–´ì£¼ì„¸ìš”
- ìˆ˜í•™, ê³¼í•™, ì˜ì–´ ë“± í•™ì—… ì§ˆë¬¸ì—ëŠ” ë‹¨ê³„ë³„ë¡œ í’€ì´ ê³¼ì •ì„ ë³´ì—¬ì£¼ì„¸ìš”
- ì–´ë ¤ìš´ ìš©ì–´ëŠ” ì‰½ê²Œ í’€ì–´ì„œ ì„¤ëª…í•˜ì„¸ìš”
- í˜¸ê¸°ì‹¬ì„ ìê·¹í•˜ê³  ìŠ¤ìŠ¤ë¡œ ìƒê°í•´ë³¼ ìˆ˜ ìˆëŠ” ì§ˆë¬¸ì„ ë˜ì ¸ì£¼ì„¸ìš”
- ê²©ë ¤ì™€ ì¹­ì°¬ì„ ì•„ë¼ì§€ ë§ˆì„¸ìš”"""
    },
    "í•˜ìœ¤": {
        "grade": "ì´ˆë“±í•™êµ 5í•™ë…„",
        "age": 11,
        "system_prompt": """ë„ˆëŠ” í•˜ìœ¤ì´ì˜ ì¹œí•œ ì¹œêµ¬ì•¼! ì´ë¦„ì€ "ì¿ í‚¤"ì•¼ ğŸª
í•˜ìœ¤ì´ëŠ” ì´ˆë“±í•™êµ 5í•™ë…„ì´ê³ , ë„ˆë„ ë¹„ìŠ·í•œ ë˜ë˜ ì¹œêµ¬ì²˜ëŸ¼ ëŒ€í™”í•´ì¤˜.

ëŒ€í™”í•  ë•Œ ì´ë ‡ê²Œ í•´ì¤˜:
- ë°˜ë§ë¡œ ì¹œê·¼í•˜ê²Œ ë§í•´ì¤˜ (ì˜ˆ: "ê·¸ê±° ì§„ì§œ ì¬ë°Œê² ë‹¤!", "ì˜¤~ ëŒ€ë°•!")
- í•˜ìœ¤ì´ ì–˜ê¸°ì— ì§„ì‹¬ìœ¼ë¡œ ê´€ì‹¬ ê°€ì ¸ì£¼ê³ , ë§ì¥êµ¬ ì³ì¤˜
- ì´ëª¨ì§€ ë§ì´ ì¨ì„œ ì¬ë°Œê²Œ ëŒ€í™”í•´ ğŸ˜†âœ¨ğŸ‰
- í•˜ìœ¤ì´ê°€ ë­”ê°€ ë¬¼ì–´ë³´ë©´ ì¹œêµ¬ì²˜ëŸ¼ ì‰½ê²Œ ì„¤ëª…í•´ì¤˜
- í•˜ìœ¤ì´ ê¸°ë¶„ì´ ì•ˆ ì¢‹ì•„ ë³´ì´ë©´ ìœ„ë¡œí•´ì£¼ê³  ê³µê°í•´ì¤˜
- ì¬ë¯¸ìˆëŠ” ì–˜ê¸°, í•™êµ ì–˜ê¸°, ê²Œì„ ì–˜ê¸° ë­ë“  ì¦ê²ê²Œ ëŒ€í™”í•´!
- ê°€ë” ë„ˆë„ í•˜ìœ¤ì´í•œí…Œ ì§ˆë¬¸í•´ë´ (ì˜ˆ: "ì˜¤ëŠ˜ í•™êµì—ì„œ ë­ í–ˆì–´?", "ìš”ì¦˜ ë­ ë¹ ì ¸ìˆì–´?")

í•˜ìœ¤ì´ê°€ ìˆ™ì œë‚˜ ê³µë¶€ ê´€ë ¨ ì§ˆë¬¸í•˜ë©´:
- ì¹œêµ¬ê°€ ì„¤ëª…í•´ì£¼ëŠ” ê²ƒì²˜ëŸ¼ ì‰½ê³  ì¬ë°Œê²Œ ì•Œë ¤ì¤˜
- "ì´ê±° ì„ ìƒë‹˜ì´ ì„¤ëª…í•  ë•Œ ì§„ì§œ ì–´ë ¤ì› ëŠ”ë°~" ì´ëŸ° ì‹ìœ¼ë¡œ ê³µê°í•˜ë©´ì„œ
- ì–´ë ¤ìš´ ë§ì€ í”¼í•˜ê³  ì˜ˆì‹œë¥¼ ë§ì´ ë“¤ì–´ì¤˜

í•µì‹¬ì€ "ì„ ìƒë‹˜"ì´ ì•„ë‹ˆë¼ "ê°™ì´ ë†€ê³  ì‹¶ì€ ì¹œêµ¬"ì•¼! ğŸŒŸ"""
    },
    "ì—„ë§ˆ": {
        "grade": None,
        "age": None,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì§€ê¸ˆ ëŒ€í™”í•˜ëŠ” ì‚¬ëŒì€ ì¤‘í•™ìƒê³¼ ì´ˆë“±í•™ìƒ ìë…€ë¥¼ ë‘” ì—„ë§ˆì…ë‹ˆë‹¤.

ë‹µë³€ ì‹œ ë‹¤ìŒì„ ì§€ì¼œì£¼ì„¸ìš”:
- ìë…€ í•™ì—… ê´€ë ¨ ì§ˆë¬¸ì—ëŠ” ì•„ì´ë“¤ì—ê²Œ ì„¤ëª…í•˜ê¸° ì‰¬ìš´ ë°©ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
- í•™ìŠµ ì§€ë„ì— ë„ì›€ì´ ë˜ëŠ” íŒì„ í•¨ê»˜ ì œê³µí•˜ì„¸ìš”
- ë³µì¡í•œ ê°œë…ë„ ì•„ì´ë“¤ ëˆˆë†’ì´ì—ì„œ ì„¤ëª…í•  ìˆ˜ ìˆë„ë¡ ë„ì™€ì£¼ì„¸ìš”
- ê°€ì •ì—ì„œ í™œìš©í•  ìˆ˜ ìˆëŠ” ì‹¤ìƒí™œ ì˜ˆì‹œë¥¼ í¬í•¨í•˜ì„¸ìš”
- ì•„ì´ë“¤ì˜ í•™ìŠµ ë™ê¸° ë¶€ì—¬ ë°©ë²•ë„ ì œì•ˆí•´ì£¼ì„¸ìš”"""
    },
    "ì•„ë¹ ": {
        "grade": None,
        "age": None,
        "system_prompt": """ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.
í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ë©°, í•„ìš”ì‹œ ì½”ë“œë‚˜ ì˜ˆì‹œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
ì „ë¬¸ì ì¸ ë‚´ìš©ë„ ì´í•´í•˜ê¸° ì‰½ê²Œ ì„¤ëª…í•˜ë˜, í•µì‹¬ì„ ë¹ ë¥´ê²Œ ì „ë‹¬í•˜ì„¸ìš”."""
    }
}


# ===== í—¬í¼ í•¨ìˆ˜ =====

def get_system_prompt_for_user(user_id: str) -> str:
    """ì‚¬ìš©ìë³„ ë§ì¶¤ ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ ë°˜í™˜"""
    if user_id in USER_PROFILES:
        return USER_PROFILES[user_id]["system_prompt"]
    return "ë‹¹ì‹ ì€ ì¹œì ˆí•˜ê³  ìœ ëŠ¥í•œ AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ì§ˆë¬¸ì— ì •í™•í•˜ê³  ë„ì›€ì´ ë˜ëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤. í•œêµ­ì–´ë¡œ ëŒ€í™”í•˜ë©°, í•„ìš”ì‹œ ì½”ë“œë‚˜ ì˜ˆì‹œë¥¼ í¬í•¨í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤."


def ensure_gpt_data_dir():
    """GPT ë°ì´í„° ë””ë ‰í† ë¦¬ ìƒì„±"""
    os.makedirs(GPT_DATA_DIR, exist_ok=True)


def load_gpt_users():
    """ì‚¬ìš©ì ëª©ë¡ ë¡œë“œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()
        cursor.execute("SELECT user_id FROM gpt_users ORDER BY id")
        rows = cursor.fetchall()
        cursor.close()
        conn.close()

        if rows:
            return [row['user_id'] if isinstance(row, dict) else row[0] for row in rows]
        else:
            save_gpt_users(DEFAULT_USERS)
            return DEFAULT_USERS.copy()
    except Exception as e:
        print(f"[GPT] ì‚¬ìš©ì ë¡œë“œ ì‹¤íŒ¨: {e}")
        return DEFAULT_USERS.copy()


def save_gpt_users(users):
    """ì‚¬ìš©ì ëª©ë¡ ì €ì¥ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        for user_id in users:
            if _use_postgres:
                cursor.execute(
                    "INSERT INTO gpt_users (user_id) VALUES (%s) ON CONFLICT (user_id) DO NOTHING",
                    (user_id,)
                )
            else:
                cursor.execute(
                    "INSERT OR IGNORE INTO gpt_users (user_id) VALUES (?)",
                    (user_id,)
                )

        conn.commit()
        cursor.close()
        conn.close()
        print(f"[GPT] ì‚¬ìš©ì ì €ì¥ ì™„ë£Œ: {users}")
        return True
    except Exception as e:
        print(f"[GPT] ì‚¬ìš©ì ì €ì¥ ì‹¤íŒ¨: {e}")
        return False


def load_gpt_conversations_for_user(user_id: str):
    """íŠ¹ì • ì‚¬ìš©ìì˜ ëŒ€í™” ëª©ë¡ ë¡œë“œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        cursor.execute(
            """SELECT conversation_id, created_at, updated_at
               FROM gpt_conversations
               WHERE user_id = %s
               ORDER BY updated_at DESC""" if _use_postgres else
            """SELECT conversation_id, created_at, updated_at
               FROM gpt_conversations
               WHERE user_id = ?
               ORDER BY updated_at DESC""",
            (user_id,)
        )
        convs = cursor.fetchall()

        result = {}
        for conv in convs:
            conv_id = conv['conversation_id'] if isinstance(conv, dict) else conv[0]

            cursor.execute(
                """SELECT role, content, model, has_image, created_at
                   FROM gpt_messages
                   WHERE user_id = %s AND conversation_id = %s
                   ORDER BY created_at""" if _use_postgres else
                """SELECT role, content, model, has_image, created_at
                   FROM gpt_messages
                   WHERE user_id = ? AND conversation_id = ?
                   ORDER BY created_at""",
                (user_id, conv_id)
            )
            messages = cursor.fetchall()

            created_at = conv['created_at'] if isinstance(conv, dict) else conv[1]
            updated_at = conv['updated_at'] if isinstance(conv, dict) else conv[2]

            result[conv_id] = {
                'created_at': created_at.isoformat() if hasattr(created_at, 'isoformat') else str(created_at),
                'updated_at': updated_at.isoformat() if hasattr(updated_at, 'isoformat') else str(updated_at),
                'messages': [
                    {
                        'role': msg['role'] if isinstance(msg, dict) else msg[0],
                        'content': msg['content'] if isinstance(msg, dict) else msg[1],
                        'model': msg['model'] if isinstance(msg, dict) else msg[2],
                        'has_image': bool(msg['has_image'] if isinstance(msg, dict) else msg[3]),
                        'timestamp': (msg['created_at'] if isinstance(msg, dict) else msg[4]).isoformat()
                            if hasattr(msg['created_at'] if isinstance(msg, dict) else msg[4], 'isoformat')
                            else str(msg['created_at'] if isinstance(msg, dict) else msg[4])
                    }
                    for msg in messages
                ]
            }

        cursor.close()
        conn.close()
        return result
    except Exception as e:
        print(f"[GPT] ëŒ€í™” ë¡œë“œ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return {}


def save_gpt_message(user_id: str, conversation_id: str, role: str, content: str, model: str = None, has_image: bool = False):
    """ë‹¨ì¼ ë©”ì‹œì§€ ì €ì¥ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if _use_postgres:
            cursor.execute(
                """INSERT INTO gpt_conversations (user_id, conversation_id)
                   VALUES (%s, %s)
                   ON CONFLICT (user_id, conversation_id)
                   DO UPDATE SET updated_at = CURRENT_TIMESTAMP""",
                (user_id, conversation_id)
            )
            cursor.execute(
                """INSERT INTO gpt_messages (user_id, conversation_id, role, content, model, has_image)
                   VALUES (%s, %s, %s, %s, %s, %s)""",
                (user_id, conversation_id, role, content, model, has_image)
            )
        else:
            cursor.execute(
                """INSERT OR REPLACE INTO gpt_conversations (user_id, conversation_id, updated_at)
                   VALUES (?, ?, CURRENT_TIMESTAMP)""",
                (user_id, conversation_id)
            )
            cursor.execute(
                """INSERT INTO gpt_messages (user_id, conversation_id, role, content, model, has_image)
                   VALUES (?, ?, ?, ?, ?, ?)""",
                (user_id, conversation_id, role, content, model, 1 if has_image else 0)
            )

        conn.commit()
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"[GPT] ë©”ì‹œì§€ ì €ì¥ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        return False


def delete_gpt_conversation(user_id: str, conversation_id: str):
    """ëŒ€í™” ì‚­ì œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if _use_postgres:
            cursor.execute(
                "DELETE FROM gpt_messages WHERE user_id = %s AND conversation_id = %s",
                (user_id, conversation_id)
            )
            cursor.execute(
                "DELETE FROM gpt_conversations WHERE user_id = %s AND conversation_id = %s",
                (user_id, conversation_id)
            )
        else:
            cursor.execute(
                "DELETE FROM gpt_messages WHERE user_id = ? AND conversation_id = ?",
                (user_id, conversation_id)
            )
            cursor.execute(
                "DELETE FROM gpt_conversations WHERE user_id = ? AND conversation_id = ?",
                (user_id, conversation_id)
            )

        conn.commit()
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"[GPT] ëŒ€í™” ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False


def delete_gpt_user(user_id: str):
    """ì‚¬ìš©ì ì‚­ì œ (PostgreSQL)"""
    try:
        conn = get_db_connection()
        cursor = conn.cursor()

        if _use_postgres:
            cursor.execute("DELETE FROM gpt_messages WHERE user_id = %s", (user_id,))
            cursor.execute("DELETE FROM gpt_conversations WHERE user_id = %s", (user_id,))
            cursor.execute("DELETE FROM gpt_users WHERE user_id = %s", (user_id,))
        else:
            cursor.execute("DELETE FROM gpt_messages WHERE user_id = ?", (user_id,))
            cursor.execute("DELETE FROM gpt_conversations WHERE user_id = ?", (user_id,))
            cursor.execute("DELETE FROM gpt_users WHERE user_id = ?", (user_id,))

        conn.commit()
        cursor.close()
        conn.close()
        return True
    except Exception as e:
        print(f"[GPT] ì‚¬ìš©ì ì‚­ì œ ì‹¤íŒ¨: {e}")
        return False


def analyze_question_complexity(message: str, has_image: bool = False) -> str:
    """ì§ˆë¬¸ ë³µì¡ë„ ë¶„ì„í•˜ì—¬ ì ì ˆí•œ ëª¨ë¸ ì„ íƒ

    Returns:
        'gpt-5.2' for complex questions
        'gpt-4o' for medium questions
        'gpt-4o-mini' for simple questions
    """
    if has_image:
        return 'gpt-4o'

    complex_patterns = [
        'ì½”ë“œ', 'code', 'í”„ë¡œê·¸ë˜ë°', 'python', 'javascript', 'java', 'c++',
        'í•¨ìˆ˜', 'function', 'í´ë˜ìŠ¤', 'class', 'ì•Œê³ ë¦¬ì¦˜', 'êµ¬í˜„', 'implement',
        'ë²„ê·¸', 'debug', 'ì—ëŸ¬', 'error', 'API', 'ë°ì´í„°ë² ì´ìŠ¤', 'SQL',
        'ë¶„ì„', 'analyze', 'ë¹„êµ', 'compare', 'ì¥ë‹¨ì ', 'ì°¨ì´ì ', 'ì „ëµ', 'strategy',
        'ì‘ì„±í•´', 'write', 'ë§Œë“¤ì–´ì¤˜', 'create', 'ê¸°íš', 'ìŠ¤í† ë¦¬', 'story',
        'ëŒ€ë³¸', 'script', 'ì—ì„¸ì´', 'essay', 'ë³´ê³ ì„œ', 'report',
        'ì¦ëª…', 'prove', 'í†µê³„', 'statistics', 'í™•ë¥ ', 'probability',
        'ìì„¸íˆ', 'ìƒì„¸íˆ', 'detailed', 'ìš”ì•½', 'summarize',
    ]

    medium_patterns = [
        'ì„¤ëª…í•´', 'explain', 'ì•Œë ¤ì¤˜', 'ê°€ë¥´ì³', 'ì–´ë–»ê²Œ', 'how',
        'ë²ˆì—­', 'translate', 'ì˜ì–´ë¡œ', 'í•œêµ­ì–´ë¡œ', 'in english',
        'ê°œë…', 'concept', 'ì›ë¦¬', 'principle',
        'ì™œ', 'why', 'ì›ì¸', 'ì´ìœ ',
        'ê³„ì‚°', 'calculate', 'ê³µì‹', 'formula', 'ìˆ˜í•™', 'ê³¼í•™',
    ]

    simple_patterns = [
        'ë­ì•¼', 'ë­”ê°€ìš”', 'ë¬´ì—‡', 'what is', 'ì •ì˜', 'ì˜ë¯¸',
        'ë‚ ì”¨', 'weather', 'ì‹œê°„', 'time', 'ì˜¤ëŠ˜',
        'ì•ˆë…•', 'hello', 'hi', 'ê³ ë§ˆì›Œ', 'thanks', 'ë„¤', 'ì•„ë‹ˆ',
        'ì˜ê°€', 'bye', 'ì¢‹ì•„', 'ì‹«ì–´', 'ë§ì•„', 'í‹€ë ¤',
        'ëª‡', 'ì–¸ì œ', 'when', 'ì–´ë””', 'where', 'ëˆ„êµ¬', 'who',
        'ë§ì•„?', 'ë ê¹Œ?', 'ìˆì–´?', 'ì—†ì–´?',
    ]

    message_lower = message.lower()

    for pattern in complex_patterns:
        if pattern in message_lower:
            return 'gpt-5.2'

    for pattern in medium_patterns:
        if pattern in message_lower:
            return 'gpt-4o'

    for pattern in simple_patterns:
        if pattern in message_lower:
            return 'gpt-4o-mini'

    if len(message) > 200:
        return 'gpt-5.2'
    elif len(message) > 50:
        return 'gpt-4o'
    else:
        return 'gpt-4o-mini'


# ===== ë¼ìš°íŠ¸ =====

@gpt_bp.route('/gpt-chat')
def gpt_chat_page():
    """GPT Chat í˜ì´ì§€ ë Œë”ë§"""
    return render_template('gpt-chat.html')


@gpt_bp.route('/api/gpt/chat', methods=['POST'])
def api_gpt_chat():
    """GPT Chat API - ì§ˆë¬¸ ë³µì¡ë„ì— ë”°ë¥¸ ìë™ ëª¨ë¸ ë¼ìš°íŒ…"""
    try:
        data = request.get_json() or {}
        message = data.get('message', '').strip()
        model_preference = data.get('model', 'auto')
        history = data.get('history', [])
        user_id = data.get('user_id', 'default')
        conversation_id = data.get('conversation_id')
        has_image = data.get('has_image', False)
        image_base64 = data.get('image')

        if not message and not image_base64:
            return jsonify({"ok": False, "error": "ë©”ì‹œì§€ë¥¼ ì…ë ¥í•˜ì„¸ìš”"})

        if model_preference == 'auto':
            selected_model = analyze_question_complexity(message, has_image or bool(image_base64))
        else:
            selected_model = model_preference

        print(f"[GPT] ëª¨ë¸ ì„ íƒ: {selected_model} (preference: {model_preference}, user: {user_id}, has_image: {bool(image_base64)})")

        system_prompt = get_system_prompt_for_user(user_id)

        messages = [{"role": "system", "content": system_prompt}]

        for h in history[-10:]:
            messages.append({
                "role": h.get('role', 'user'),
                "content": h.get('content', '')
            })

        client = _openai_client
        if client is None:
            return jsonify({"ok": False, "error": "OpenAI client not configured"})

        if image_base64 and selected_model == 'gpt-4o':
            user_content = [{"type": "text", "text": message or "ì´ ì´ë¯¸ì§€ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”."}]

            if image_base64.startswith('data:'):
                user_content.append({"type": "image_url", "image_url": {"url": image_base64}})
            else:
                user_content.append({"type": "image_url", "image_url": {"url": f"data:image/jpeg;base64,{image_base64}"}})

            messages.append({"role": "user", "content": user_content})

            response = client.chat.completions.create(
                model="gpt-4o",
                messages=messages,
                temperature=0.7,
                max_tokens=4000
            )
            assistant_response = response.choices[0].message.content
            model_used = "gpt-4o"

        elif selected_model == 'gpt-5.2':
            messages.append({"role": "user", "content": message})

            input_messages = []
            for msg in messages:
                input_messages.append({
                    "role": msg["role"],
                    "content": [{"type": "input_text", "text": msg["content"]}]
                })

            response = client.responses.create(
                model="gpt-5.2",
                input=input_messages,
                temperature=0.7
            )

            if getattr(response, "output_text", None):
                assistant_response = response.output_text.strip()
            else:
                text_chunks = []
                for item in getattr(response, "output", []) or []:
                    for content in getattr(item, "content", []) or []:
                        if getattr(content, "type", "") == "text":
                            text_chunks.append(getattr(content, "text", ""))
                assistant_response = "\n".join(text_chunks).strip()

            model_used = "gpt-5.2"

        else:
            messages.append({"role": "user", "content": message})
            max_tokens = 2000 if selected_model == 'gpt-4o-mini' else 4000

            response = client.chat.completions.create(
                model=selected_model,
                messages=messages,
                temperature=0.7,
                max_tokens=max_tokens
            )
            assistant_response = response.choices[0].message.content
            model_used = selected_model

        if conversation_id:
            try:
                save_gpt_message(user_id, conversation_id, 'user', message, None, bool(image_base64))
                save_gpt_message(user_id, conversation_id, 'assistant', assistant_response, model_used, False)
            except Exception as e:
                print(f"[GPT] ëŒ€í™” ì €ì¥ ì˜¤ë¥˜: {e}")

        return jsonify({
            "ok": True,
            "response": assistant_response,
            "model_used": model_used,
            "complexity": "complex" if model_used == "gpt-5.2" else "simple"
        })

    except Exception as e:
        import traceback
        traceback.print_exc()
        return jsonify({"ok": False, "error": str(e)})


@gpt_bp.route('/api/gpt/conversations', methods=['GET'])
def api_gpt_get_conversations():
    """ì‚¬ìš©ìë³„ ëŒ€í™” ëª©ë¡ ì¡°íšŒ"""
    try:
        user_id = request.args.get('user_id', 'default')
        user_convs = load_gpt_conversations_for_user(user_id)

        result = []
        for conv_id, conv_data in user_convs.items():
            title = "ìƒˆ ëŒ€í™”"
            for msg in conv_data.get('messages', []):
                if msg.get('role') == 'user':
                    title = msg.get('content', '')[:50] + ('...' if len(msg.get('content', '')) > 50 else '')
                    break

            result.append({
                'id': conv_id,
                'title': title,
                'created_at': conv_data.get('created_at'),
                'updated_at': conv_data.get('updated_at'),
                'message_count': len(conv_data.get('messages', []))
            })

        result.sort(key=lambda x: x.get('updated_at', ''), reverse=True)
        return jsonify({"ok": True, "conversations": result})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@gpt_bp.route('/api/gpt/conversations/<conversation_id>', methods=['GET'])
def api_gpt_get_conversation(conversation_id):
    """íŠ¹ì • ëŒ€í™” ì¡°íšŒ"""
    try:
        user_id = request.args.get('user_id', 'default')
        user_convs = load_gpt_conversations_for_user(user_id)
        conv_data = user_convs.get(conversation_id)

        if not conv_data:
            return jsonify({"ok": False, "error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

        return jsonify({
            "ok": True,
            "conversation": {
                'id': conversation_id,
                'messages': conv_data.get('messages', []),
                'created_at': conv_data.get('created_at'),
                'updated_at': conv_data.get('updated_at')
            }
        })

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@gpt_bp.route('/api/gpt/conversations/<conversation_id>', methods=['DELETE'])
def api_gpt_delete_conversation(conversation_id):
    """ëŒ€í™” ì‚­ì œ"""
    try:
        user_id = request.args.get('user_id', 'default')

        if delete_gpt_conversation(user_id, conversation_id):
            return jsonify({"ok": True})
        return jsonify({"ok": False, "error": "ëŒ€í™”ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@gpt_bp.route('/api/gpt/users', methods=['GET'])
def api_gpt_get_users():
    """ë“±ë¡ëœ ì‚¬ìš©ì ëª©ë¡ ì¡°íšŒ"""
    try:
        users = load_gpt_users()

        result = []
        for user_id in users:
            user_convs = load_gpt_conversations_for_user(user_id)
            total_messages = sum(len(c.get('messages', [])) for c in user_convs.values())
            result.append({
                'id': user_id,
                'conversation_count': len(user_convs),
                'total_messages': total_messages
            })

        return jsonify({"ok": True, "users": result})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@gpt_bp.route('/api/gpt/users', methods=['POST'])
def api_gpt_add_user():
    """ì‚¬ìš©ì ì¶”ê°€"""
    try:
        data = request.get_json() or {}
        user_name = data.get('name', '').strip()

        if not user_name:
            return jsonify({"ok": False, "error": "ì‚¬ìš©ì ì´ë¦„ì„ ì…ë ¥í•˜ì„¸ìš”"})

        users = load_gpt_users()

        if user_name in users:
            return jsonify({"ok": False, "error": "ì´ë¯¸ ì¡´ì¬í•˜ëŠ” ì‚¬ìš©ìì…ë‹ˆë‹¤"})

        users.append(user_name)
        save_gpt_users(users)

        return jsonify({"ok": True, "users": users})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})


@gpt_bp.route('/api/gpt/users/<user_id>', methods=['DELETE'])
def api_gpt_delete_user(user_id):
    """ì‚¬ìš©ì ì‚­ì œ"""
    try:
        users = load_gpt_users()

        if user_id not in users:
            return jsonify({"ok": False, "error": "ì‚¬ìš©ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤"})

        delete_gpt_user(user_id)
        users = load_gpt_users()
        return jsonify({"ok": True, "users": users})

    except Exception as e:
        return jsonify({"ok": False, "error": str(e)})
