"""
TubeLens Server - YouTube Analytics Tool
YouTube Data API v3ë¥¼ ì‚¬ìš©í•œ ì˜ìƒ ë¶„ì„ ë„êµ¬
"""

from flask import Blueprint, render_template, request, jsonify
import os
import re
import math
import subprocess
import tempfile
import base64
import json
import shutil
from datetime import datetime, timedelta
from typing import Dict, Any, List, Optional
import requests
import google.generativeai as genai
from openai import OpenAI

tubelens_bp = Blueprint('tubelens', __name__)

# YouTube Data API Base URL
YOUTUBE_API_BASE = "https://www.googleapis.com/youtube/v3"


def get_youtube_api_key() -> Optional[str]:
    """í™˜ê²½ ë³€ìˆ˜ì—ì„œ YouTube API í‚¤ ê°€ì ¸ì˜¤ê¸°"""
    return os.getenv("YOUTUBE_API_KEY")


def make_youtube_request(endpoint: str, params: Dict[str, Any], api_key: str = None) -> Dict[str, Any]:
    """YouTube API ìš”ì²­ ìˆ˜í–‰"""
    if not api_key:
        api_key = get_youtube_api_key()

    if not api_key:
        raise ValueError("YouTube API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    params['key'] = api_key
    url = f"{YOUTUBE_API_BASE}/{endpoint}"

    response = requests.get(url, params=params, timeout=30)
    response.raise_for_status()

    return response.json()


def parse_duration(duration: str) -> int:
    """ISO 8601 durationì„ ì´ˆë¡œ ë³€í™˜ (PT4M13S -> 253)"""
    if not duration:
        return 0

    match = re.match(r'PT(?:(\d+)H)?(?:(\d+)M)?(?:(\d+)S)?', duration)
    if not match:
        return 0

    hours = int(match.group(1) or 0)
    minutes = int(match.group(2) or 0)
    seconds = int(match.group(3) or 0)

    return hours * 3600 + minutes * 60 + seconds


def format_duration(seconds: int) -> str:
    """ì´ˆë¥¼ MM:SS ë˜ëŠ” HH:MM:SS í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    if seconds < 3600:
        return f"{seconds // 60}:{seconds % 60:02d}"
    else:
        hours = seconds // 3600
        minutes = (seconds % 3600) // 60
        secs = seconds % 60
        return f"{hours}:{minutes:02d}:{secs:02d}"


def format_number(num: int) -> str:
    """ìˆ«ìë¥¼ í•œêµ­ì–´ í˜•ì‹ìœ¼ë¡œ ë³€í™˜ (1000 -> 1ì²œ)"""
    if num >= 100000000:
        return f"{num / 100000000:.1f}ì–µ"
    elif num >= 10000:
        return f"{num / 10000:.1f}ë§Œ"
    elif num >= 1000:
        return f"{num / 1000:.1f}ì²œ"
    return str(num)


def calculate_cii(view_count: int, subscriber_count: int, like_count: int, comment_count: int) -> Dict[str, Any]:
    """CII (Channel Impact Index) ê³„ì‚°"""
    if subscriber_count == 0:
        subscriber_count = 1

    # ì±„ë„ ê¸°ì—¬ë„: ì¡°íšŒìˆ˜ / êµ¬ë…ììˆ˜ * 100
    contribution_value = (view_count / subscriber_count) * 100

    # ì„±ê³¼ë„ ë°°ìœ¨: ì¡°íšŒìˆ˜ / êµ¬ë…ììˆ˜
    performance_value = view_count / subscriber_count

    # ì°¸ì—¬ìœ¨: (ì¢‹ì•„ìš” + ëŒ“ê¸€) / ì¡°íšŒìˆ˜ * 100
    engagement_rate = 0
    if view_count > 0:
        engagement_rate = ((like_count + comment_count) / view_count) * 100

    # CII ì ìˆ˜ ê³„ì‚°
    cii_score = min(100, (contribution_value * 0.4 + performance_value * 30 + engagement_rate * 10))

    # CII ë“±ê¸‰ ê²°ì •
    if cii_score >= 80:
        cii_grade = "Great!!"
    elif cii_score >= 60:
        cii_grade = "Good"
    elif cii_score >= 40:
        cii_grade = "Soso"
    elif cii_score >= 20:
        cii_grade = "Not bad"
    else:
        cii_grade = "Bad"

    return {
        "contributionValue": round(contribution_value, 2),
        "performanceValue": round(performance_value, 2),
        "engagementRate": round(engagement_rate, 4),
        "ciiScore": round(cii_score, 2),
        "cii": cii_grade
    }


def get_time_filter(time_frame: str) -> Optional[str]:
    """ì‹œê°„ í•„í„° ê³„ì‚°"""
    if not time_frame or time_frame == "":
        return None

    now = datetime.utcnow()

    time_deltas = {
        "hour": timedelta(hours=1),
        "day": timedelta(days=1),
        "week": timedelta(weeks=1),
        "month": timedelta(days=30),
        "3months": timedelta(days=90),
        "6months": timedelta(days=180),
        "year": timedelta(days=365),
    }

    if time_frame in time_deltas:
        published_after = now - time_deltas[time_frame]
        return published_after.strftime("%Y-%m-%dT%H:%M:%SZ")

    return None


def extract_video_id(url: str) -> Optional[str]:
    """YouTube URLì—ì„œ ë¹„ë””ì˜¤ ID ì¶”ì¶œ"""
    patterns = [
        r'(?:v=|/v/|youtu\.be/)([a-zA-Z0-9_-]{11})',
        r'(?:embed/)([a-zA-Z0-9_-]{11})',
        r'(?:shorts/)([a-zA-Z0-9_-]{11})',
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)

    # URLì´ ì•„ë‹Œ ID ìì²´ì¸ ê²½ìš°
    if re.match(r'^[a-zA-Z0-9_-]{11}$', url):
        return url

    return None


def extract_channel_id(url: str) -> Optional[str]:
    """YouTube URLì—ì„œ ì±„ë„ ID ì¶”ì¶œ"""
    patterns = [
        r'(?:channel/)([a-zA-Z0-9_-]+)',
        r'(?:user/)([a-zA-Z0-9_-]+)',
        r'(?:c/)([a-zA-Z0-9_-]+)',
        r'(?:@)([a-zA-Z0-9_-]+)',
    ]

    for pattern in patterns:
        match = re.search(pattern, url)
        if match:
            return match.group(1)

    return None


def get_channel_info(channel_id: str, api_key: str) -> Dict[str, Any]:
    """ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°"""
    try:
        data = make_youtube_request("channels", {
            "id": channel_id,
            "part": "snippet,statistics,contentDetails"
        }, api_key)

        if not data.get("items"):
            return {}

        item = data["items"][0]
        snippet = item.get("snippet", {})
        statistics = item.get("statistics", {})
        content_details = item.get("contentDetails", {})

        return {
            "channelId": channel_id,
            "channelTitle": snippet.get("title", ""),
            "subscriberCount": int(statistics.get("subscriberCount", 0)),
            "videoCount": int(statistics.get("videoCount", 0)),
            "viewCount": int(statistics.get("viewCount", 0)),
            "uploadPlaylist": content_details.get("relatedPlaylists", {}).get("uploads", ""),
            "thumbnailUrl": snippet.get("thumbnails", {}).get("default", {}).get("url", ""),
            "description": snippet.get("description", ""),
            "country": snippet.get("country", ""),
            "publishedAt": snippet.get("publishedAt", ""),
        }
    except Exception as e:
        print(f"ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")
        return {}


def get_video_details(video_ids: List[str], api_key: str) -> List[Dict[str, Any]]:
    """ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (ì±„ë„ ì •ë³´ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ìµœì í™”)"""
    if not video_ids:
        return []

    # 1ë‹¨ê³„: ë¹„ë””ì˜¤ ì •ë³´ 50ê°œì”© ë°°ì¹˜ë¡œ ìˆ˜ì§‘
    video_items = []
    for i in range(0, len(video_ids), 50):
        batch_ids = video_ids[i:i+50]
        try:
            data = make_youtube_request("videos", {
                "id": ",".join(batch_ids),
                "part": "snippet,statistics,contentDetails"
            }, api_key)
            video_items.extend(data.get("items", []))
        except Exception as e:
            print(f"ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    # 2ë‹¨ê³„: ëª¨ë“  ê³ ìœ  ì±„ë„ ID ìˆ˜ì§‘
    channel_ids = list(set([
        item.get("snippet", {}).get("channelId", "")
        for item in video_items
        if item.get("snippet", {}).get("channelId")
    ]))

    # 3ë‹¨ê³„: ì±„ë„ ì •ë³´ ë°°ì¹˜ë¡œ ê°€ì ¸ì˜¤ê¸° (N+1 ë¬¸ì œ í•´ê²°)
    channel_map = {}
    for i in range(0, len(channel_ids), 50):
        batch_channel_ids = channel_ids[i:i+50]
        try:
            channels_data = make_youtube_request("channels", {
                "part": "statistics",
                "id": ",".join(batch_channel_ids)
            }, api_key)
            for ch in channels_data.get("items", []):
                channel_map[ch["id"]] = {
                    "subscriberCount": int(ch["statistics"].get("subscriberCount", 0)),
                    "videoCount": int(ch["statistics"].get("videoCount", 0))
                }
        except Exception as e:
            print(f"ì±„ë„ ì •ë³´ ë°°ì¹˜ ê°€ì ¸ì˜¤ê¸° ì‹¤íŒ¨: {e}")

    # 4ë‹¨ê³„: ë¹„ë””ì˜¤ ë°ì´í„° ì¡°í•©
    all_videos = []
    for item in video_items:
        video_id = item.get("id")
        snippet = item.get("snippet", {})
        statistics = item.get("statistics", {})
        content_details = item.get("contentDetails", {})

        channel_id = snippet.get("channelId", "")
        channel_info = channel_map.get(channel_id, {"subscriberCount": 0, "videoCount": 0})

        duration_seconds = parse_duration(content_details.get("duration", ""))
        published_at = snippet.get("publishedAt", "")

        view_count = int(statistics.get("viewCount", 0))
        like_count = int(statistics.get("likeCount", 0))
        comment_count = int(statistics.get("commentCount", 0))
        subscriber_count = channel_info.get("subscriberCount", 0)

        cii_data = calculate_cii(view_count, subscriber_count, like_count, comment_count)

        all_videos.append({
            "videoId": video_id,
            "title": snippet.get("title", ""),
            "description": snippet.get("description", ""),
            "thumbnail": snippet.get("thumbnails", {}).get("high", {}).get("url", ""),
            "channelId": channel_id,
            "channelTitle": snippet.get("channelTitle", ""),
            "publishedAt": published_at[:10] if published_at else "",
            "publishedAtRaw": published_at,
            "duration": format_duration(duration_seconds),
            "durationSeconds": duration_seconds,
            "viewCount": view_count,
            "likeCount": like_count,
            "commentCount": comment_count,
            "subscriberCount": subscriber_count,
            "totalVideos": channel_info.get("videoCount", 0),
            "categoryId": snippet.get("categoryId", ""),
            **cii_data
        })

    return all_videos


# ===== API ë¼ìš°íŠ¸ =====

@tubelens_bp.route('/tubelens')
def tubelens_page():
    """TubeLens ë©”ì¸ í˜ì´ì§€"""
    return render_template('tubelens.html')


@tubelens_bp.route('/api/tubelens/search', methods=['POST'])
def api_search():
    """í‚¤ì›Œë“œë¡œ ì˜ìƒ ê²€ìƒ‰"""
    try:
        data = request.get_json()

        keyword = data.get("keyword", "")
        max_results = min(int(data.get("maxResults", 50)), 500)
        time_frame = data.get("timeFrame", "")
        region_code = data.get("regionCode", "KR")
        video_type = data.get("videoType", "all")
        is_views_sort = data.get("isViewsSort", True)
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
        search_params = {
            "part": "snippet",
            "type": "video",
            "maxResults": min(max_results, 50),
            "regionCode": region_code,
            "order": "viewCount" if is_views_sort else "date",
        }

        if keyword:
            search_params["q"] = keyword

        # ì‹œê°„ í•„í„°
        published_after = get_time_filter(time_frame)
        if published_after:
            search_params["publishedAfter"] = published_after

        # ì»¤ìŠ¤í…€ ë‚ ì§œ í•„í„°
        if time_frame == "custom":
            start_date = data.get("startDate")
            end_date = data.get("endDate")
            if start_date:
                search_params["publishedAfter"] = f"{start_date}T00:00:00Z"
            if end_date:
                search_params["publishedBefore"] = f"{end_date}T23:59:59Z"

        # ì˜ìƒ íƒ€ì… í•„í„° (ì‡¼ì¸ /ë¡±í¼)
        if video_type == "shorts":
            search_params["videoDuration"] = "short"
        elif video_type.startswith("longform"):
            search_params["videoDuration"] = "medium"

        # ê²€ìƒ‰ ì‹¤í–‰ (í˜ì´ì§€ë„¤ì´ì…˜ìœ¼ë¡œ ìµœëŒ€ max_resultsê¹Œì§€)
        all_video_ids = []
        next_page_token = None

        while len(all_video_ids) < max_results:
            if next_page_token:
                search_params["pageToken"] = next_page_token

            search_data = make_youtube_request("search", search_params, api_key)

            video_ids = [
                item["id"]["videoId"]
                for item in search_data.get("items", [])
                if item.get("id", {}).get("videoId")
            ]
            all_video_ids.extend(video_ids)

            next_page_token = search_data.get("nextPageToken")
            if not next_page_token:
                break

        # ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        videos = get_video_details(all_video_ids[:max_results], api_key)

        # ì˜ìƒ ê¸¸ì´ í•„í„°ë§
        if video_type == "shorts":
            videos = [v for v in videos if v["durationSeconds"] <= 60]
        elif video_type == "longform_4_20":
            videos = [v for v in videos if 240 <= v["durationSeconds"] <= 1200]
        elif video_type == "longform_20_plus":
            videos = [v for v in videos if v["durationSeconds"] > 1200]

        # ì¸ë±ìŠ¤ ì¶”ê°€
        for i, video in enumerate(videos):
            video["index"] = i + 1

        return jsonify({
            "success": True,
            "data": videos,
            "message": f"{len(videos)}ê°œ ì˜ìƒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/analyze', methods=['POST'])
def api_analyze():
    """URLë¡œ ì˜ìƒ/ì±„ë„ ë¶„ì„"""
    try:
        data = request.get_json()
        url = data.get("url", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ë¹„ë””ì˜¤ ID ì¶”ì¶œ ì‹œë„
        video_id = extract_video_id(url)
        if video_id:
            videos = get_video_details([video_id], api_key)
            if videos:
                videos[0]["index"] = 1
                return jsonify({
                    "success": True,
                    "data": videos,
                    "message": "ì˜ìƒ ë¶„ì„ ì™„ë£Œ"
                })

        # ì±„ë„ ID ì¶”ì¶œ ì‹œë„
        channel_id = extract_channel_id(url)
        if channel_id:
            # ì±„ë„ í•¸ë“¤(@username)ì¸ ê²½ìš° ì‹¤ì œ ì±„ë„ ID ì¡°íšŒ
            if not channel_id.startswith("UC"):
                search_data = make_youtube_request("search", {
                    "part": "snippet",
                    "type": "channel",
                    "q": channel_id,
                    "maxResults": 1
                }, api_key)

                if search_data.get("items"):
                    channel_id = search_data["items"][0]["id"]["channelId"]

            channel_info = get_channel_info(channel_id, api_key)
            if channel_info:
                return jsonify({
                    "success": True,
                    "data": [channel_info],
                    "type": "channel",
                    "message": "ì±„ë„ ë¶„ì„ ì™„ë£Œ"
                })

        return jsonify({"success": False, "message": "ìœ íš¨í•œ YouTube URLì´ ì•„ë‹™ë‹ˆë‹¤."}), 400

    except Exception as e:
        print(f"ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/channel-search', methods=['POST'])
def api_channel_search():
    """ì±„ë„ ê²€ìƒ‰"""
    try:
        data = request.get_json()
        channel_name = data.get("channelName", "")
        region_code = data.get("regionCode", "KR")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not channel_name:
            return jsonify({"success": False, "message": "ì±„ë„ëª…ì„ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì±„ë„ ê²€ìƒ‰
        search_data = make_youtube_request("search", {
            "part": "snippet",
            "type": "channel",
            "q": channel_name,
            "maxResults": 10,
            "regionCode": region_code
        }, api_key)

        channels = []
        for item in search_data.get("items", []):
            channel_id = item["id"]["channelId"]
            channel_info = get_channel_info(channel_id, api_key)

            if channel_info:
                # ì •í™• ì¼ì¹˜ ì—¬ë¶€ í™•ì¸
                is_exact_match = channel_info["channelTitle"].lower() == channel_name.lower()
                channel_info["isExactMatch"] = is_exact_match
                channels.append(channel_info)

        # ì •í™• ì¼ì¹˜ ë¨¼ì €, ê·¸ ë‹¤ìŒ êµ¬ë…ì ìˆ˜ ìˆœ
        channels.sort(key=lambda x: (-x.get("isExactMatch", False), -x.get("subscriberCount", 0)))

        return jsonify({
            "success": True,
            "data": channels,
            "message": f"{len(channels)}ê°œ ì±„ë„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"ì±„ë„ ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/channel-videos', methods=['POST'])
def api_channel_videos():
    """ì±„ë„ì˜ ì˜ìƒ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°"""
    try:
        data = request.get_json()
        channel_id = data.get("channelId", "")
        upload_playlist = data.get("uploadPlaylist", "")
        max_results = min(int(data.get("maxResults", 50)), 500)
        video_type = data.get("videoType", "all")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not channel_id:
            return jsonify({"success": False, "message": "ì±„ë„ IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ IDê°€ ì—†ìœ¼ë©´ ì±„ë„ ì •ë³´ì—ì„œ ê°€ì ¸ì˜¤ê¸°
        if not upload_playlist:
            channel_info = get_channel_info(channel_id, api_key)
            upload_playlist = channel_info.get("uploadPlaylist", "")

        if not upload_playlist:
            return jsonify({"success": False, "message": "ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400

        # í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ì—ì„œ ì˜ìƒ ID ê°€ì ¸ì˜¤ê¸°
        all_video_ids = []
        next_page_token = None

        while len(all_video_ids) < max_results:
            params = {
                "part": "contentDetails",
                "playlistId": upload_playlist,
                "maxResults": 50
            }

            if next_page_token:
                params["pageToken"] = next_page_token

            playlist_data = make_youtube_request("playlistItems", params, api_key)

            video_ids = [
                item["contentDetails"]["videoId"]
                for item in playlist_data.get("items", [])
            ]
            all_video_ids.extend(video_ids)

            next_page_token = playlist_data.get("nextPageToken")
            if not next_page_token:
                break

        # ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        videos = get_video_details(all_video_ids[:max_results], api_key)

        # ì˜ìƒ íƒ€ì… í•„í„°ë§
        if video_type == "shorts":
            videos = [v for v in videos if v["durationSeconds"] <= 60]
        elif video_type == "longform":
            videos = [v for v in videos if v["durationSeconds"] > 60]

        # ì¸ë±ìŠ¤ ì¶”ê°€
        for i, video in enumerate(videos):
            video["index"] = i + 1

        return jsonify({
            "success": True,
            "data": videos,
            "message": f"{len(videos)}ê°œ ì˜ìƒì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"ì±„ë„ ì˜ìƒ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/filter', methods=['POST'])
def api_filter():
    """ê²°ê³¼ í•„í„°ë§"""
    try:
        data = request.get_json()
        results = data.get("results", [])
        filters = data.get("filters", {})

        filtered = results.copy()

        # CII í•„í„°
        cii_filters = []
        if filters.get("ciiGreat"):
            cii_filters.append("Great!!")
        if filters.get("ciiGood"):
            cii_filters.append("Good")
        if filters.get("ciiSoso"):
            cii_filters.append("Soso")

        if cii_filters:
            filtered = [v for v in filtered if v.get("cii") in cii_filters]

        # ì¡°íšŒìˆ˜ í•„í„°
        view_count_min = filters.get("viewCount")
        if view_count_min:
            filtered = [v for v in filtered if v.get("viewCount", 0) >= int(view_count_min)]

        # êµ¬ë…ììˆ˜ í•„í„° (ì´í•˜)
        subscriber_max = filters.get("subscriberCount")
        if subscriber_max:
            filtered = [v for v in filtered if v.get("subscriberCount", 0) <= int(subscriber_max)]

        # ì˜ìƒ ê¸¸ì´ í•„í„°
        if filters.get("durationFilterActive"):
            duration_minutes = filters.get("durationFilterMinutes", 0)
            duration_condition = filters.get("durationFilterCondition", "ì´ìƒ")
            duration_seconds = duration_minutes * 60

            if duration_condition == "ì´ìƒ":
                filtered = [v for v in filtered if v.get("durationSeconds", 0) >= duration_seconds]
            else:
                filtered = [v for v in filtered if v.get("durationSeconds", 0) <= duration_seconds]

        # ì¸ë±ìŠ¤ ì¬ì¡°ì •
        for i, video in enumerate(filtered):
            video["index"] = i + 1

        return jsonify({
            "success": True,
            "data": filtered,
            "message": f"í•„í„° ì ìš© ì™„ë£Œ - {len(filtered)}ê°œ ê²°ê³¼"
        })

    except Exception as e:
        print(f"í•„í„° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


# YouTube ì¹´í…Œê³ ë¦¬ ëª©ë¡ (í•œêµ­ ê¸°ì¤€)
YOUTUBE_CATEGORIES = {
    "1": "ì˜í™”/ì• ë‹ˆë©”ì´ì…˜",
    "2": "ìë™ì°¨",
    "10": "ìŒì•…",
    "15": "ë™ë¬¼",
    "17": "ìŠ¤í¬ì¸ ",
    "19": "ì—¬í–‰/ì´ë²¤íŠ¸",
    "20": "ê²Œì„",
    "22": "ì¸ë¬¼/ë¸”ë¡œê·¸",
    "23": "ì½”ë¯¸ë””",
    "24": "ì—”í„°í…Œì¸ë¨¼íŠ¸",
    "25": "ë‰´ìŠ¤/ì •ì¹˜",
    "26": "ë…¸í•˜ìš°/ìŠ¤íƒ€ì¼",
    "27": "êµìœ¡",
    "28": "ê³¼í•™ê¸°ìˆ ",
    "29": "ë¹„ì˜ë¦¬/ì‚¬íšŒìš´ë™"
}


@tubelens_bp.route('/api/tubelens/trending', methods=['POST'])
def api_trending():
    """íŠ¸ë Œë”©(ì¸ê¸°) ì˜ìƒ ê°€ì ¸ì˜¤ê¸°"""
    try:
        data = request.get_json()
        region_code = data.get("regionCode", "KR")
        category_id = data.get("categoryId", "")
        max_results = min(int(data.get("maxResults", 50)), 50)
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # íŠ¸ë Œë”© ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
        params = {
            "part": "snippet,statistics,contentDetails",
            "chart": "mostPopular",
            "regionCode": region_code,
            "maxResults": max_results
        }

        if category_id:
            params["videoCategoryId"] = category_id

        videos_data = make_youtube_request("videos", params, api_key)

        # ì±„ë„ ì •ë³´ ì¼ê´„ ì¡°íšŒ
        channel_ids = list(set([
            item["snippet"]["channelId"]
            for item in videos_data.get("items", [])
        ]))

        channel_map = {}
        if channel_ids:
            for i in range(0, len(channel_ids), 50):
                batch_ids = channel_ids[i:i+50]
                channels_data = make_youtube_request("channels", {
                    "part": "statistics",
                    "id": ",".join(batch_ids)
                }, api_key)

                for ch in channels_data.get("items", []):
                    channel_map[ch["id"]] = {
                        "subscriberCount": int(ch["statistics"].get("subscriberCount", 0)),
                        "videoCount": int(ch["statistics"].get("videoCount", 0))
                    }

        # ê²°ê³¼ ê°€ê³µ
        videos = []
        for idx, item in enumerate(videos_data.get("items", [])):
            video_id = item["id"]
            snippet = item.get("snippet", {})
            statistics = item.get("statistics", {})
            content_details = item.get("contentDetails", {})

            channel_id = snippet.get("channelId", "")
            channel_info = channel_map.get(channel_id, {"subscriberCount": 0, "videoCount": 0})

            duration_seconds = parse_duration(content_details.get("duration", ""))
            view_count = int(statistics.get("viewCount", 0))
            like_count = int(statistics.get("likeCount", 0))
            comment_count = int(statistics.get("commentCount", 0))
            subscriber_count = channel_info["subscriberCount"]

            cii_data = calculate_cii(view_count, subscriber_count, like_count, comment_count)

            videos.append({
                "index": idx + 1,
                "videoId": video_id,
                "title": snippet.get("title", ""),
                "description": snippet.get("description", ""),
                "thumbnail": snippet.get("thumbnails", {}).get("high", {}).get("url", ""),
                "channelId": channel_id,
                "channelTitle": snippet.get("channelTitle", ""),
                "publishedAt": snippet.get("publishedAt", "")[:10],
                "duration": format_duration(duration_seconds),
                "durationSeconds": duration_seconds,
                "viewCount": view_count,
                "likeCount": like_count,
                "commentCount": comment_count,
                "subscriberCount": subscriber_count,
                "totalVideos": channel_info["videoCount"],
                "categoryId": snippet.get("categoryId", ""),
                **cii_data
            })

        return jsonify({
            "success": True,
            "data": videos,
            "message": f"ì¸ê¸° ì˜ìƒ {len(videos)}ê°œë¥¼ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"íŠ¸ë Œë”© ì˜ìƒ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/categories', methods=['GET'])
def api_categories():
    """YouTube ì¹´í…Œê³ ë¦¬ ëª©ë¡ ë°˜í™˜"""
    categories = [
        {"id": k, "name": v}
        for k, v in YOUTUBE_CATEGORIES.items()
    ]
    return jsonify({
        "success": True,
        "data": categories
    })


def calculate_rising_score(video: Dict[str, Any]) -> Dict[str, Any]:
    """
    ì§„ì§œ ê¸‰ìƒìŠ¹ ì ìˆ˜ ê³„ì‚° - ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ + êµ¬ë…ì ëŒ€ë¹„ ì„±ê³¼

    ì ìˆ˜ ìš”ì†Œ:
    1. ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ (views_per_hour) - ìµœê·¼ ì˜ìƒì¼ìˆ˜ë¡ ë†’ì€ ê°€ì¹˜
    2. êµ¬ë…ì ëŒ€ë¹„ ë°°ìœ¨ (performance_value)
    3. ì‹ ì„ ë„ ë³´ë„ˆìŠ¤ (72ì‹œê°„ ì´ë‚´ ì˜ìƒì— ê°€ì¤‘ì¹˜)
    4. ì°¸ì—¬ìœ¨ ë³´ë„ˆìŠ¤ (ì¢‹ì•„ìš”+ëŒ“ê¸€ ë¹„ìœ¨)
    """
    view_count = video.get("viewCount", 0)
    subscriber_count = video.get("subscriberCount", 1) or 1
    like_count = video.get("likeCount", 0)
    comment_count = video.get("commentCount", 0)
    published_at_raw = video.get("publishedAtRaw", "")

    # ì—…ë¡œë“œ í›„ ê²½ê³¼ ì‹œê°„ (ì‹œê°„ ë‹¨ìœ„)
    hours_since_upload = 1  # ìµœì†Œ 1ì‹œê°„
    if published_at_raw:
        try:
            from datetime import datetime
            published_dt = datetime.fromisoformat(published_at_raw.replace("Z", "+00:00"))
            now = datetime.now(published_dt.tzinfo) if published_dt.tzinfo else datetime.utcnow()
            hours_since_upload = max(1, (now - published_dt.replace(tzinfo=None)).total_seconds() / 3600)
        except:
            hours_since_upload = 24  # ê¸°ë³¸ê°’

    # 1. ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜
    views_per_hour = view_count / hours_since_upload

    # 2. ì¼ì¼ í‰ê·  ì¡°íšŒìˆ˜
    views_per_day = views_per_hour * 24

    # 3. êµ¬ë…ì ëŒ€ë¹„ ë°°ìœ¨
    performance_value = view_count / subscriber_count

    # 4. ì‹ ì„ ë„ ë³´ë„ˆìŠ¤ (72ì‹œê°„ ì´ë‚´: 1.5ë°°, 168ì‹œê°„(1ì£¼) ì´ë‚´: 1.2ë°°)
    freshness_bonus = 1.0
    if hours_since_upload <= 72:
        freshness_bonus = 1.5
    elif hours_since_upload <= 168:
        freshness_bonus = 1.2

    # 5. ì°¸ì—¬ìœ¨ (ì¢‹ì•„ìš”+ëŒ“ê¸€ / ì¡°íšŒìˆ˜)
    engagement_rate = 0
    if view_count > 0:
        engagement_rate = (like_count + comment_count) / view_count * 100

    # 6. ì°¸ì—¬ìœ¨ ë³´ë„ˆìŠ¤ (3% ì´ìƒì´ë©´ ì¶”ê°€ ì ìˆ˜)
    engagement_bonus = 1.0
    if engagement_rate >= 5:
        engagement_bonus = 1.3
    elif engagement_rate >= 3:
        engagement_bonus = 1.15

    # ê¸‰ìƒìŠ¹ ì ìˆ˜ ê³„ì‚° (0-100 ìŠ¤ì¼€ì¼)
    # ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ê°€ ë†’ê³  + êµ¬ë…ì ëŒ€ë¹„ ì„±ê³¼ê°€ ì¢‹ê³  + ì‹ ì„ í•˜ê³  + ì°¸ì—¬ìœ¨ ë†’ìœ¼ë©´ ê¸‰ìƒìŠ¹
    rising_score = min(100, (
        (views_per_hour ** 0.5) * 2 +  # ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ (ì œê³±ê·¼ìœ¼ë¡œ ìŠ¤ì¼€ì¼ ì¡°ì •)
        performance_value * 10 +        # êµ¬ë…ì ëŒ€ë¹„ ë°°ìœ¨
        engagement_rate * 5             # ì°¸ì—¬ìœ¨
    ) * freshness_bonus * engagement_bonus)

    # ê¸‰ìƒìŠ¹ ë“±ê¸‰
    if rising_score >= 70:
        rising_grade = "ğŸ”¥ í­ë°œ"
    elif rising_score >= 50:
        rising_grade = "ğŸš€ ê¸‰ìƒìŠ¹"
    elif rising_score >= 30:
        rising_grade = "ğŸ“ˆ ìƒìŠ¹ì¤‘"
    else:
        rising_grade = "â¡ï¸ ë³´í†µ"

    # ê²°ê³¼ì— ì¶”ê°€ ì •ë³´ í¬í•¨
    video["viewsPerHour"] = round(views_per_hour, 1)
    video["viewsPerDay"] = round(views_per_day, 0)
    video["hoursSinceUpload"] = round(hours_since_upload, 1)
    video["risingScore"] = round(rising_score, 1)
    video["risingGrade"] = rising_grade
    video["freshnessBonus"] = freshness_bonus
    video["engagementBonus"] = engagement_bonus

    return video


@tubelens_bp.route('/api/tubelens/rising', methods=['POST'])
def api_rising():
    """ê¸‰ìƒìŠ¹ ì˜ìƒ ë°œêµ´ (ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ + êµ¬ë…ì ëŒ€ë¹„ ì„±ê³¼ ê¸°ë°˜)"""
    try:
        data = request.get_json()
        region_code = data.get("regionCode", "KR")
        max_subscribers = int(data.get("maxSubscribers", 100000))  # êµ¬ë…ì ìƒí•œ
        time_frame = data.get("timeFrame", "week")
        category_id = data.get("categoryId", "")
        video_type = data.get("videoType", "all")  # all, shorts, long
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)
        exclude_categories = data.get("excludeCategories", [])  # ì œì™¸í•  ì¹´í…Œê³ ë¦¬

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì‹œê°„ í•„í„° ê³„ì‚°
        published_after = get_time_filter(time_frame)

        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° - date ìˆœìœ¼ë¡œ ê²€ìƒ‰í•˜ì—¬ ìµœì‹  ì˜ìƒ ìœ„ì£¼ë¡œ ìˆ˜ì§‘
        search_params = {
            "part": "snippet",
            "type": "video",
            "maxResults": 50,
            "regionCode": region_code,
            "order": "date",  # ìµœì‹ ìˆœìœ¼ë¡œ ë³€ê²½ (ê¸‰ìƒìŠ¹ì€ ìµœì‹  ì˜ìƒì—ì„œ ì°¾ì•„ì•¼ í•¨)
        }

        if published_after:
            search_params["publishedAfter"] = published_after

        if category_id:
            search_params["videoCategoryId"] = category_id

        # ì˜ìƒ íƒ€ì… í•„í„°
        if video_type == "shorts":
            search_params["videoDuration"] = "short"
        elif video_type == "long":
            search_params["videoDuration"] = "medium"

        # ì—¬ëŸ¬ í˜ì´ì§€ì—ì„œ ì˜ìƒ ìˆ˜ì§‘ (ìµœëŒ€ 300ê°œ)
        all_video_ids = []
        next_page_token = None

        for _ in range(6):  # ìµœëŒ€ 300ê°œ ìˆ˜ì§‘
            if next_page_token:
                search_params["pageToken"] = next_page_token

            search_data = make_youtube_request("search", search_params, api_key)

            video_ids = [
                item["id"]["videoId"]
                for item in search_data.get("items", [])
                if item.get("id", {}).get("videoId")
            ]
            all_video_ids.extend(video_ids)

            next_page_token = search_data.get("nextPageToken")
            if not next_page_token:
                break

        # ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        videos = get_video_details(all_video_ids, api_key)

        # ê¸‰ìƒìŠ¹ í•„í„°ë§ ë° ì ìˆ˜ ê³„ì‚°
        rising_videos = []
        for video in videos:
            subscriber_count = video.get("subscriberCount", 0)
            category_id_str = str(video.get("categoryId", ""))

            # êµ¬ë…ì ìƒí•œ ì²´í¬
            if subscriber_count > max_subscribers:
                continue

            # ì œì™¸ ì¹´í…Œê³ ë¦¬ ì²´í¬
            if category_id_str in exclude_categories:
                continue

            # ìµœì†Œ ì¡°íšŒìˆ˜ ì²´í¬ (ë…¸ì´ì¦ˆ ì œê±°)
            if video.get("viewCount", 0) < 1000:
                continue

            # ê¸‰ìƒìŠ¹ ì ìˆ˜ ê³„ì‚°
            video = calculate_rising_score(video)

            # ê¸‰ìƒìŠ¹ ì ìˆ˜ 25 ì´ìƒë§Œ í¬í•¨
            if video.get("risingScore", 0) >= 25:
                rising_videos.append(video)

        # ê¸‰ìƒìŠ¹ ì ìˆ˜ ê¸°ì¤€ ì •ë ¬
        rising_videos.sort(key=lambda x: x.get("risingScore", 0), reverse=True)

        # ìƒìœ„ 50ê°œë§Œ
        rising_videos = rising_videos[:50]

        # ì¸ë±ìŠ¤ ì¬í• ë‹¹
        for idx, video in enumerate(rising_videos):
            video["index"] = idx + 1

        return jsonify({
            "success": True,
            "data": rising_videos,
            "message": f"ê¸‰ìƒìŠ¹ ì˜ìƒ {len(rising_videos)}ê°œë¥¼ ë°œêµ´í–ˆìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"ê¸‰ìƒìŠ¹ ì˜ìƒ ë°œêµ´ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/comments', methods=['POST'])
def api_comments():
    """ì˜ìƒ ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°"""
    try:
        data = request.get_json()
        video_id = data.get("videoId", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not video_id:
            return jsonify({"success": False, "message": "ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        comments_data = make_youtube_request("commentThreads", {
            "part": "snippet",
            "videoId": video_id,
            "order": "relevance",
            "maxResults": 20
        }, api_key)

        comments = []
        for item in comments_data.get("items", []):
            comment = item["snippet"]["topLevelComment"]["snippet"]
            comments.append({
                "author": comment.get("authorDisplayName", ""),
                "authorImage": comment.get("authorProfileImageUrl", ""),
                "text": comment.get("textDisplay", ""),
                "likeCount": comment.get("likeCount", 0),
                "publishedAt": comment.get("publishedAt", "")
            })

        return jsonify({
            "success": True,
            "data": comments,
            "message": f"{len(comments)}ê°œ ëŒ“ê¸€ì„ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/analyzer', methods=['POST'])
def api_analyzer():
    """ì½˜í…ì¸  ë¶„ì„ê¸° - í‚¤ì›Œë“œ+í•„í„°ë¡œ í„°ì§„ ì˜ìƒ ì°¾ê¸°"""
    try:
        data = request.get_json()

        keyword = data.get("keyword", "")
        region_code = data.get("regionCode", "JP")
        relevance_language = data.get("relevanceLanguage", "")
        time_frame = data.get("timeFrame", "week")
        duration = data.get("duration", "long")
        min_views = int(data.get("minViews", 10000))
        max_results = min(int(data.get("maxResults", 25)), 100)
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not keyword:
            return jsonify({"success": False, "message": "ê²€ìƒ‰ í‚¤ì›Œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •
        search_params = {
            "part": "snippet",
            "type": "video",
            "maxResults": 50,
            "regionCode": region_code,
            "order": "viewCount",
            "q": keyword,
        }

        # ì–¸ì–´ í•„í„°
        if relevance_language:
            search_params["relevanceLanguage"] = relevance_language

        # ì‹œê°„ í•„í„°
        published_after = get_time_filter(time_frame)
        if published_after:
            search_params["publishedAfter"] = published_after

        # ì˜ìƒ ê¸¸ì´ í•„í„°
        if duration == "short":
            search_params["videoDuration"] = "short"
        elif duration in ["medium", "long"]:
            search_params["videoDuration"] = "medium" if duration == "medium" else "long"

        # ê²€ìƒ‰ ì‹¤í–‰ (ì—¬ëŸ¬ í˜ì´ì§€)
        all_video_ids = []
        next_page_token = None
        fetch_count = 0
        max_fetch = 4  # ìµœëŒ€ 4ë²ˆ í˜ì´ì§€ë„¤ì´ì…˜ (200ê°œ)

        while len(all_video_ids) < max_results * 2 and fetch_count < max_fetch:
            if next_page_token:
                search_params["pageToken"] = next_page_token

            search_data = make_youtube_request("search", search_params, api_key)

            video_ids = [
                item["id"]["videoId"]
                for item in search_data.get("items", [])
                if item.get("id", {}).get("videoId")
            ]
            all_video_ids.extend(video_ids)

            next_page_token = search_data.get("nextPageToken")
            if not next_page_token:
                break
            fetch_count += 1

        # ë¹„ë””ì˜¤ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        videos = get_video_details(all_video_ids, api_key)

        # ì˜ìƒ ê¸¸ì´ í•„í„°ë§
        if duration == "short":
            videos = [v for v in videos if v["durationSeconds"] <= 60]
        elif duration == "medium":
            videos = [v for v in videos if 240 <= v["durationSeconds"] <= 1200]
        elif duration == "long":
            videos = [v for v in videos if v["durationSeconds"] > 1200]

        # ì¡°íšŒìˆ˜ í•„í„°ë§
        videos = [v for v in videos if v["viewCount"] >= min_views]

        # ì¡°íšŒìˆ˜ ìˆœ ì •ë ¬
        videos.sort(key=lambda x: x["viewCount"], reverse=True)

        # ê²°ê³¼ ì œí•œ
        videos = videos[:max_results]

        # ì¸ë±ìŠ¤ ì¶”ê°€
        for i, video in enumerate(videos):
            video["index"] = i + 1

        return jsonify({
            "success": True,
            "data": videos,
            "message": f"ì½˜í…ì¸  ë¶„ì„ ì™„ë£Œ: {len(videos)}ê°œ ì˜ìƒ"
        })

    except Exception as e:
        print(f"ì½˜í…ì¸  ë¶„ì„ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


# ===== AI ë¶„ì„ API =====

@tubelens_bp.route('/api/tubelens/analyze-titles', methods=['POST'])
def api_analyze_titles():
    """AIë¡œ ì œëª© íŒ¨í„´ ë¶„ì„ - í´ë¦­ ìœ ë°œ ìš”ì†Œ íŒŒì•…"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()
        titles = data.get("titles", [])  # [{title, viewCount, subscriberCount, ...}]

        if not titles:
            return jsonify({"success": False, "message": "ë¶„ì„í•  ì œëª©ì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        if len(titles) > 20:
            titles = titles[:20]  # ìµœëŒ€ 20ê°œ

        # OpenAI API í‚¤ í™•ì¸
        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        client = OpenAI(api_key=openai_api_key)

        # ì œëª© ë°ì´í„° ì¤€ë¹„
        titles_text = "\n".join([
            f"{i+1}. \"{t.get('title', '')}\" (ì¡°íšŒìˆ˜: {t.get('viewCount', 0):,}, êµ¬ë…ì: {t.get('subscriberCount', 0):,})"
            for i, t in enumerate(titles)
        ])

        prompt = f"""ë‹¤ìŒ YouTube ì˜ìƒ ì œëª©ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ì´ ì˜ìƒë“¤ì€ êµ¬ë…ì ëŒ€ë¹„ ë†’ì€ ì¡°íšŒìˆ˜ë¥¼ ê¸°ë¡í•œ ê¸‰ìƒìŠ¹ ì˜ìƒë“¤ì…ë‹ˆë‹¤.

{titles_text}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
  "common_patterns": ["ê³µí†µ íŒ¨í„´ 1", "ê³µí†µ íŒ¨í„´ 2", ...],
  "click_triggers": ["í´ë¦­ ìœ ë°œ ìš”ì†Œ 1", "í´ë¦­ ìœ ë°œ ìš”ì†Œ 2", ...],
  "emotional_hooks": ["ê°ì • ìê·¹ í‘œí˜„ 1", "ê°ì • ìê·¹ í‘œí˜„ 2", ...],
  "title_structures": ["ì œëª© êµ¬ì¡° íŒ¨í„´ 1", "ì œëª© êµ¬ì¡° íŒ¨í„´ 2", ...],
  "recommended_keywords": ["ì¶”ì²œ í‚¤ì›Œë“œ 1", "ì¶”ì²œ í‚¤ì›Œë“œ 2", ...],
  "title_suggestions": [
    {{"template": "ì œëª© í…œí”Œë¦¿ 1", "example": "ì˜ˆì‹œ ì œëª© 1"}},
    {{"template": "ì œëª© í…œí”Œë¦¿ 2", "example": "ì˜ˆì‹œ ì œëª© 2"}},
    {{"template": "ì œëª© í…œí”Œë¦¿ 3", "example": "ì˜ˆì‹œ ì œëª© 3"}}
  ],
  "summary": "ì „ì²´ ë¶„ì„ ìš”ì•½ (2-3ë¬¸ì¥)"
}}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ YouTube ì½˜í…ì¸  ë§ˆì¼€íŒ… ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì œëª© íŒ¨í„´ ë¶„ì„ì„ í†µí•´ í´ë¦­ë¥ ì„ ë†’ì´ëŠ” ì¸ì‚¬ì´íŠ¸ë¥¼ ì œê³µí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        analysis = json.loads(result_text)

        return jsonify({
            "success": True,
            "data": analysis,
            "message": "ì œëª© íŒ¨í„´ ë¶„ì„ ì™„ë£Œ"
        })

    except json.JSONDecodeError as e:
        print(f"ì œëª© ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"ì œëª© ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/generate-ideas', methods=['POST'])
def api_generate_ideas():
    """íŠ¸ë Œë”© ì˜ìƒ ê¸°ë°˜ ëŒ€ë³¸ ì£¼ì œ/ì•„ì´ë””ì–´ ìƒì„±"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()
        videos = data.get("videos", [])  # [{title, description, ...}]
        target_category = data.get("targetCategory", "")  # ì›í•˜ëŠ” ì¹´í…Œê³ ë¦¬
        content_style = data.get("contentStyle", "story")  # story, news, education

        if not videos:
            return jsonify({"success": False, "message": "ì°¸ê³ í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        if len(videos) > 10:
            videos = videos[:10]

        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        client = OpenAI(api_key=openai_api_key)

        # ì˜ìƒ ì •ë³´ ì¤€ë¹„
        videos_text = "\n".join([
            f"{i+1}. ì œëª©: \"{v.get('title', '')}\"\n   ì„¤ëª…: {v.get('description', '')[:200]}..."
            for i, v in enumerate(videos)
        ])

        style_guide = {
            "story": "ê°ë™ì ì¸ ìŠ¤í† ë¦¬í…”ë§, ì¸ê°„ë¯¸ ìˆëŠ” ì´ì•¼ê¸°",
            "news": "ì‹œì‚¬/ë‰´ìŠ¤ í˜•ì‹, íŒ©íŠ¸ ê¸°ë°˜",
            "education": "êµìœ¡/ì •ë³´ ì „ë‹¬ í˜•ì‹",
            "entertainment": "ì¬ë¯¸ìˆê³  í¥ë¯¸ë¡œìš´ ì½˜í…ì¸ "
        }

        prompt = f"""ë‹¤ìŒ YouTube ì¸ê¸°/ê¸‰ìƒìŠ¹ ì˜ìƒë“¤ì„ ì°¸ê³ í•˜ì—¬ ìƒˆë¡œìš´ ì½˜í…ì¸  ì•„ì´ë””ì–´ë¥¼ ìƒì„±í•´ì£¼ì„¸ìš”.

ì°¸ê³  ì˜ìƒ:
{videos_text}

ì½˜í…ì¸  ìŠ¤íƒ€ì¼: {style_guide.get(content_style, content_style)}
{f'íƒ€ê²Ÿ ì¹´í…Œê³ ë¦¬: {target_category}' if target_category else ''}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ 5ê°œì˜ ì½˜í…ì¸  ì•„ì´ë””ì–´ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
  "trend_analysis": "í˜„ì¬ íŠ¸ë Œë“œ ë¶„ì„ (2-3ë¬¸ì¥)",
  "ideas": [
    {{
      "title": "ì¶”ì²œ ì œëª©",
      "hook": "ì˜ìƒ ì‹œì‘ í›… (ì²« 5ì´ˆ)",
      "outline": "ëŒ€ë³¸ ê°œìš” (3-5ë¬¸ì¥)",
      "target_emotion": "íƒ€ê²Ÿ ê°ì • (í˜¸ê¸°ì‹¬/ê³µê°/ë¶„ë…¸/ê°ë™ ë“±)",
      "viral_potential": "ë°”ì´ëŸ´ ê°€ëŠ¥ì„± (ìƒ/ì¤‘/í•˜)",
      "similar_to": "ì°¸ê³ í•œ ì›ë³¸ ì˜ìƒ ë²ˆí˜¸"
    }}
  ],
  "keywords": ["ì¶”ì²œ í‚¤ì›Œë“œ 1", "ì¶”ì²œ í‚¤ì›Œë“œ 2", ...],
  "avoid": ["í”¼í•´ì•¼ í•  ìš”ì†Œ 1", "í”¼í•´ì•¼ í•  ìš”ì†Œ 2", ...]
}}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. ì°¸ì‹ í•˜ê³  í•œêµ­ ì‹œì²­ìì—ê²Œ ì–´í•„í•  ìˆ˜ ìˆëŠ” ì•„ì´ë””ì–´ë¡œ ì œì•ˆí•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ YouTube ì½˜í…ì¸  ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤. íŠ¸ë Œë“œë¥¼ ë¶„ì„í•˜ê³  ë°”ì´ëŸ´ ê°€ëŠ¥ì„±ì´ ë†’ì€ ì½˜í…ì¸  ì•„ì´ë””ì–´ë¥¼ ì œì•ˆí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,
            max_tokens=3000
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        ideas = json.loads(result_text)

        return jsonify({
            "success": True,
            "data": ideas,
            "message": f"{len(ideas.get('ideas', []))}ê°œì˜ ì½˜í…ì¸  ì•„ì´ë””ì–´ê°€ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        })

    except json.JSONDecodeError as e:
        print(f"ì•„ì´ë””ì–´ ìƒì„± JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"ì•„ì´ë””ì–´ ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/analyze-thumbnails', methods=['POST'])
def api_analyze_thumbnails():
    """ì¸ë„¤ì¼ íŒ¨í„´ ë¶„ì„ (URL ê¸°ë°˜)"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()
        videos = data.get("videos", [])  # [{title, thumbnail, viewCount, ...}]

        if not videos:
            return jsonify({"success": False, "message": "ë¶„ì„í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        if len(videos) > 10:
            videos = videos[:10]

        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        client = OpenAI(api_key=openai_api_key)

        # GPT-5.1 Responses APIìš© input êµ¬ì„±
        system_prompt = "ë‹¹ì‹ ì€ YouTube ì¸ë„¤ì¼ ë””ìì¸ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. í´ë¦­ë¥ ì„ ë†’ì´ëŠ” ì¸ë„¤ì¼ íŒ¨í„´ì„ ë¶„ì„í•©ë‹ˆë‹¤."

        user_content = [
            {"type": "input_text", "text": """ë‹¤ìŒ YouTube ì¸ë„¤ì¼ë“¤ì„ ë¶„ì„í•´ì£¼ì„¸ìš”. ì´ ì˜ìƒë“¤ì€ ë†’ì€ ì„±ê³¼ë¥¼ ê¸°ë¡í•œ ê¸‰ìƒìŠ¹ ì˜ìƒë“¤ì…ë‹ˆë‹¤.

ê° ì¸ë„¤ì¼ì˜ ê³µí†µ íŒ¨í„´ê³¼ í´ë¦­ì„ ìœ ë°œí•˜ëŠ” ìš”ì†Œë¥¼ ë¶„ì„í•˜ê³ , ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:

{
  "common_elements": ["ê³µí†µ ìš”ì†Œ 1", "ê³µí†µ ìš”ì†Œ 2", ...],
  "color_patterns": ["ìƒ‰ìƒ íŒ¨í„´ 1", "ìƒ‰ìƒ íŒ¨í„´ 2", ...],
  "text_usage": ["í…ìŠ¤íŠ¸ ì‚¬ìš© íŒ¨í„´ 1", "í…ìŠ¤íŠ¸ ì‚¬ìš© íŒ¨í„´ 2", ...],
  "face_expressions": ["í‘œì •/ì¸ë¬¼ íŒ¨í„´ 1", "í‘œì •/ì¸ë¬¼ íŒ¨í„´ 2", ...],
  "composition": ["êµ¬ë„ íŒ¨í„´ 1", "êµ¬ë„ íŒ¨í„´ 2", ...],
  "recommendations": [
    {"tip": "ì¶”ì²œ 1", "reason": "ì´ìœ  1"},
    {"tip": "ì¶”ì²œ 2", "reason": "ì´ìœ  2"},
    {"tip": "ì¶”ì²œ 3", "reason": "ì´ìœ  3"}
  ],
  "summary": "ì „ì²´ ë¶„ì„ ìš”ì•½ (2-3ë¬¸ì¥)"
}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""}
        ]

        # ì¸ë„¤ì¼ ì´ë¯¸ì§€ ì¶”ê°€ (GPT-5.1 í˜•ì‹)
        for i, v in enumerate(videos[:6]):  # ìµœëŒ€ 6ê°œ ì´ë¯¸ì§€
            thumbnail_url = v.get("thumbnail", "")
            if thumbnail_url:
                user_content.append({"type": "input_image", "image_url": thumbnail_url})
                user_content.append({"type": "input_text", "text": f"[ì˜ìƒ {i+1}] ì œëª©: {v.get('title', '')} (ì¡°íšŒìˆ˜: {v.get('viewCount', 0):,})"})

        response = client.responses.create(
            model="gpt-5.1",
            input=[
                {"role": "system", "content": [{"type": "input_text", "text": system_prompt}]},
                {"role": "user", "content": user_content}
            ],
            temperature=0.7
        )

        # GPT-5.1 ì‘ë‹µ ì¶”ì¶œ
        if getattr(response, "output_text", None):
            result_text = response.output_text.strip()
        else:
            text_chunks = []
            for item in getattr(response, "output", []) or []:
                for content_item in getattr(item, "content", []) or []:
                    if getattr(content_item, "type", "") == "text":
                        text_chunks.append(getattr(content_item, "text", ""))
            result_text = "\n".join(text_chunks).strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        analysis = json.loads(result_text)

        return jsonify({
            "success": True,
            "data": analysis,
            "message": "ì¸ë„¤ì¼ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ"
        })

    except json.JSONDecodeError as e:
        print(f"ì¸ë„¤ì¼ ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"ì¸ë„¤ì¼ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/config', methods=['GET'])
def api_get_config():
    """ì„œë²„ì— ì €ì¥ëœ API í‚¤ í™•ì¸ (ë§ˆìŠ¤í‚¹ëœ í˜•íƒœë¡œ)"""
    youtube_key = os.getenv("YOUTUBE_API_KEY", "")

    has_youtube_key = bool(youtube_key)
    masked_key = ""
    if youtube_key:
        masked_key = youtube_key[:8] + "â€¢â€¢â€¢â€¢â€¢â€¢â€¢â€¢" + youtube_key[-4:] if len(youtube_key) > 12 else "â€¢â€¢â€¢â€¢"

    return jsonify({
        "success": True,
        "data": {
            "hasYouTubeKey": has_youtube_key,
            "maskedKey": masked_key
        }
    })


# ===== ì‹ ê·œ ê¸°ëŠ¥: ê²½ìŸ ì±„ë„ ë¹„êµ =====

@tubelens_bp.route('/api/tubelens/compare-channels', methods=['POST'])
def api_compare_channels():
    """ì—¬ëŸ¬ ì±„ë„ ë¹„êµ ë¶„ì„"""
    try:
        data = request.get_json()
        channel_ids = data.get("channelIds", [])  # ì±„ë„ ID ë¦¬ìŠ¤íŠ¸
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not channel_ids or len(channel_ids) < 2:
            return jsonify({"success": False, "message": "ë¹„êµí•  ì±„ë„ì„ 2ê°œ ì´ìƒ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        if len(channel_ids) > 5:
            channel_ids = channel_ids[:5]  # ìµœëŒ€ 5ê°œ

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì±„ë„ ì •ë³´ ì¼ê´„ ì¡°íšŒ
        channels_data = make_youtube_request("channels", {
            "part": "snippet,statistics,contentDetails,brandingSettings",
            "id": ",".join(channel_ids)
        }, api_key)

        channels = []
        for ch in channels_data.get("items", []):
            stats = ch.get("statistics", {})
            snippet = ch.get("snippet", {})

            # ìµœê·¼ 10ê°œ ì˜ìƒ ì„±ê³¼ ë¶„ì„
            upload_playlist = ch.get("contentDetails", {}).get("relatedPlaylists", {}).get("uploads", "")
            recent_videos = []
            avg_views = 0
            avg_likes = 0
            avg_comments = 0

            if upload_playlist:
                playlist_data = make_youtube_request("playlistItems", {
                    "part": "contentDetails",
                    "playlistId": upload_playlist,
                    "maxResults": 10
                }, api_key)

                video_ids = [item["contentDetails"]["videoId"] for item in playlist_data.get("items", [])]

                if video_ids:
                    videos_data = make_youtube_request("videos", {
                        "part": "statistics,snippet",
                        "id": ",".join(video_ids)
                    }, api_key)

                    for vid in videos_data.get("items", []):
                        vid_stats = vid.get("statistics", {})
                        recent_videos.append({
                            "title": vid.get("snippet", {}).get("title", ""),
                            "viewCount": int(vid_stats.get("viewCount", 0)),
                            "likeCount": int(vid_stats.get("likeCount", 0)),
                            "commentCount": int(vid_stats.get("commentCount", 0))
                        })

                    if recent_videos:
                        avg_views = sum(v["viewCount"] for v in recent_videos) // len(recent_videos)
                        avg_likes = sum(v["likeCount"] for v in recent_videos) // len(recent_videos)
                        avg_comments = sum(v["commentCount"] for v in recent_videos) // len(recent_videos)

            subscriber_count = int(stats.get("subscriberCount", 0))
            view_count = int(stats.get("viewCount", 0))
            video_count = int(stats.get("videoCount", 0))

            # ì˜ìƒë‹¹ í‰ê·  ì¡°íšŒìˆ˜
            avg_views_per_video = view_count // video_count if video_count > 0 else 0

            channels.append({
                "channelId": ch.get("id"),
                "channelTitle": snippet.get("title", ""),
                "thumbnail": snippet.get("thumbnails", {}).get("default", {}).get("url", ""),
                "description": snippet.get("description", "")[:200],
                "subscriberCount": subscriber_count,
                "viewCount": view_count,
                "videoCount": video_count,
                "avgViewsPerVideo": avg_views_per_video,
                "recentAvgViews": avg_views,
                "recentAvgLikes": avg_likes,
                "recentAvgComments": avg_comments,
                "engagementRate": round((avg_likes + avg_comments) / avg_views * 100, 2) if avg_views > 0 else 0,
                "recentVideos": recent_videos[:5],
                "country": snippet.get("country", ""),
                "publishedAt": snippet.get("publishedAt", "")[:10]
            })

        # êµ¬ë…ììˆ˜ ê¸°ì¤€ ì •ë ¬
        channels.sort(key=lambda x: x["subscriberCount"], reverse=True)

        return jsonify({
            "success": True,
            "data": channels,
            "message": f"{len(channels)}ê°œ ì±„ë„ ë¹„êµ ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"ì±„ë„ ë¹„êµ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


# ===== ì‹ ê·œ ê¸°ëŠ¥: ì œëª© A/B í…ŒìŠ¤íŠ¸ ì œì•ˆ =====

@tubelens_bp.route('/api/tubelens/suggest-titles', methods=['POST'])
def api_suggest_titles():
    """AIë¡œ ëŒ€ì•ˆ ì œëª© ìƒì„± (A/B í…ŒìŠ¤íŠ¸ìš©)"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()
        original_title = data.get("title", "")
        description = data.get("description", "")
        target_audience = data.get("targetAudience", "general")  # general, young, senior

        if not original_title:
            return jsonify({"success": False, "message": "ì›ë³¸ ì œëª©ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        client = OpenAI(api_key=openai_api_key)

        audience_guide = {
            "general": "ì¼ë°˜ ëŒ€ì¤‘",
            "young": "10-30ëŒ€ ì Šì€ ì¸µ",
            "senior": "40-60ëŒ€ ì¤‘ì¥ë…„ì¸µ"
        }

        prompt = f"""ë‹¤ìŒ YouTube ì˜ìƒ ì œëª©ì˜ ëŒ€ì•ˆì„ 5ê°œ ìƒì„±í•´ì£¼ì„¸ìš”.

ì›ë³¸ ì œëª©: {original_title}
{f'ì˜ìƒ ì„¤ëª…: {description[:300]}...' if description else ''}
íƒ€ê²Ÿ ì‹œì²­ì: {audience_guide.get(target_audience, "ì¼ë°˜ ëŒ€ì¤‘")}

ê° ëŒ€ì•ˆì€ ë‹¤ë¥¸ ì ‘ê·¼ë²•ì„ ì‚¬ìš©í•´ì£¼ì„¸ìš”:
1. í˜¸ê¸°ì‹¬ ìœ ë°œí˜• (ì§ˆë¬¸/ì˜ë¬¸)
2. ìˆ«ì/ë¦¬ìŠ¤íŠ¸í˜• (êµ¬ì²´ì  ìˆ˜ì¹˜)
3. ê°ì • ìê·¹í˜• (ë†€ë¼ì›€/ì¶©ê²©)
4. ì§ì ‘ í™”ë²•í˜• (ì‹œì²­ìì—ê²Œ ë§í•˜ë“¯)
5. íŠ¸ë Œë“œ í‚¤ì›Œë“œí˜• (ê²€ìƒ‰ ìµœì í™”)

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "suggestions": [
    {{
      "type": "í˜¸ê¸°ì‹¬ ìœ ë°œí˜•",
      "title": "ëŒ€ì•ˆ ì œëª©",
      "reason": "ì´ ì œëª©ì´ íš¨ê³¼ì ì¸ ì´ìœ "
    }}
  ],
  "analysis": "ì›ë³¸ ì œëª© ë¶„ì„ (ê°•ì /ì•½ì )"
}}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ YouTube ì œëª© ìµœì í™” ì „ë¬¸ê°€ì…ë‹ˆë‹¤. CTRì„ ë†’ì´ëŠ” ì œëª©ì„ ì œì•ˆí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.8,
            max_tokens=2000
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        suggestions = json.loads(result_text)

        return jsonify({
            "success": True,
            "data": suggestions,
            "message": "5ê°œì˜ ëŒ€ì•ˆ ì œëª©ì´ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤."
        })

    except json.JSONDecodeError as e:
        print(f"ì œëª© ì œì•ˆ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"ì œëª© ì œì•ˆ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


# ===== ì‹ ê·œ ê¸°ëŠ¥: ëŒ“ê¸€ ê°ì„± ë¶„ì„ =====

@tubelens_bp.route('/api/tubelens/analyze-sentiment', methods=['POST'])
def api_analyze_sentiment():
    """ëŒ“ê¸€ ê°ì„± ë¶„ì„"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()
        video_id = data.get("videoId", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not video_id:
            return jsonify({"success": False, "message": "ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "YouTube API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        # ëŒ“ê¸€ ê°€ì ¸ì˜¤ê¸°
        comments_data = make_youtube_request("commentThreads", {
            "part": "snippet",
            "videoId": video_id,
            "order": "relevance",
            "maxResults": 50
        }, api_key)

        comments = []
        for item in comments_data.get("items", []):
            comment = item["snippet"]["topLevelComment"]["snippet"]
            comments.append({
                "text": comment.get("textDisplay", ""),
                "likeCount": comment.get("likeCount", 0)
            })

        if not comments:
            return jsonify({
                "success": True,
                "data": {
                    "summary": "ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤.",
                    "sentiment": {"positive": 0, "neutral": 0, "negative": 0},
                    "keywords": [],
                    "suggestions": []
                },
                "message": "ëŒ“ê¸€ì´ ì—†ìŠµë‹ˆë‹¤."
            })

        # AI ë¶„ì„
        client = OpenAI(api_key=openai_api_key)

        comments_text = "\n".join([f"- {c['text'][:200]}" for c in comments[:30]])

        prompt = f"""ë‹¤ìŒ YouTube ì˜ìƒ ëŒ“ê¸€ë“¤ì˜ ê°ì„±ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.

ëŒ“ê¸€ ëª©ë¡:
{comments_text}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
  "sentiment": {{
    "positive": ê¸ì • ëŒ“ê¸€ ë¹„ìœ¨ (0-100),
    "neutral": ì¤‘ë¦½ ëŒ“ê¸€ ë¹„ìœ¨ (0-100),
    "negative": ë¶€ì • ëŒ“ê¸€ ë¹„ìœ¨ (0-100)
  }},
  "summary": "ì „ì²´ ëŒ“ê¸€ ë¶„ìœ„ê¸° ìš”ì•½ (2-3ë¬¸ì¥)",
  "keywords": ["ìì£¼ ì–¸ê¸‰ëœ í‚¤ì›Œë“œ 1", "í‚¤ì›Œë“œ 2", ...],
  "positive_points": ["ì‹œì²­ìë“¤ì´ ì¢‹ì•„í•˜ëŠ” ì  1", "ì  2", ...],
  "negative_points": ["ì‹œì²­ìë“¤ì´ ì•„ì‰¬ì›Œí•˜ëŠ” ì  1", "ì  2", ...],
  "suggestions": ["ê°œì„  ì œì•ˆ 1", "ì œì•ˆ 2", ...],
  "sample_comments": {{
    "positive": "ëŒ€í‘œ ê¸ì • ëŒ“ê¸€",
    "negative": "ëŒ€í‘œ ë¶€ì • ëŒ“ê¸€ (ìˆëŠ” ê²½ìš°)"
  }}
}}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ ì†Œì…œ ë¯¸ë””ì–´ ê°ì„± ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        analysis = json.loads(result_text)
        analysis["totalComments"] = len(comments)

        return jsonify({
            "success": True,
            "data": analysis,
            "message": f"{len(comments)}ê°œ ëŒ“ê¸€ ê°ì„± ë¶„ì„ ì™„ë£Œ"
        })

    except json.JSONDecodeError as e:
        print(f"ê°ì„± ë¶„ì„ JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"ê°ì„± ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


# ===== ì‹ ê·œ ê¸°ëŠ¥: íƒœê·¸ ë¶„ì„ =====

@tubelens_bp.route('/api/tubelens/analyze-tags', methods=['POST'])
def api_analyze_tags():
    """ì¸ê¸° ì˜ìƒë“¤ì˜ íƒœê·¸/í•´ì‹œíƒœê·¸ íŒ¨í„´ ë¶„ì„"""
    try:
        import json
        from collections import Counter

        data = request.get_json()
        video_ids = data.get("videoIds", [])
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not video_ids:
            return jsonify({"success": False, "message": "ë¶„ì„í•  ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        if len(video_ids) > 20:
            video_ids = video_ids[:20]

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸° (íƒœê·¸ í¬í•¨)
        videos_data = make_youtube_request("videos", {
            "part": "snippet,statistics",
            "id": ",".join(video_ids)
        }, api_key)

        all_tags = []
        all_hashtags = []
        video_tag_data = []

        for item in videos_data.get("items", []):
            snippet = item.get("snippet", {})
            stats = item.get("statistics", {})

            tags = snippet.get("tags", [])
            title = snippet.get("title", "")
            description = snippet.get("description", "")

            # ì œëª©ê³¼ ì„¤ëª…ì—ì„œ í•´ì‹œíƒœê·¸ ì¶”ì¶œ
            import re
            hashtags_in_title = re.findall(r'#(\w+)', title)
            hashtags_in_desc = re.findall(r'#(\w+)', description)
            hashtags = list(set(hashtags_in_title + hashtags_in_desc))

            all_tags.extend(tags)
            all_hashtags.extend(hashtags)

            video_tag_data.append({
                "title": title,
                "viewCount": int(stats.get("viewCount", 0)),
                "tags": tags[:10],
                "hashtags": hashtags[:5]
            })

        # íƒœê·¸ ë¹ˆë„ ë¶„ì„
        tag_counter = Counter(all_tags)
        hashtag_counter = Counter(all_hashtags)

        # ê°€ì¥ ë§ì´ ì‚¬ìš©ëœ íƒœê·¸
        top_tags = [{"tag": tag, "count": count} for tag, count in tag_counter.most_common(20)]
        top_hashtags = [{"hashtag": ht, "count": count} for ht, count in hashtag_counter.most_common(10)]

        # íƒœê·¸ ê¸¸ì´ ë¶„ì„
        avg_tag_count = len(all_tags) / len(video_ids) if video_ids else 0
        avg_tag_length = sum(len(t) for t in all_tags) / len(all_tags) if all_tags else 0

        return jsonify({
            "success": True,
            "data": {
                "topTags": top_tags,
                "topHashtags": top_hashtags,
                "totalTagsAnalyzed": len(all_tags),
                "totalHashtagsAnalyzed": len(all_hashtags),
                "avgTagsPerVideo": round(avg_tag_count, 1),
                "avgTagLength": round(avg_tag_length, 1),
                "videoTagData": video_tag_data,
                "recommendations": [
                    f"í‰ê·  {round(avg_tag_count)}ê°œì˜ íƒœê·¸ ì‚¬ìš© ê¶Œì¥",
                    f"ì¸ê¸° íƒœê·¸: {', '.join([t['tag'] for t in top_tags[:5]])}",
                    f"ì¸ê¸° í•´ì‹œíƒœê·¸: {', '.join(['#' + h['hashtag'] for h in top_hashtags[:3]])}" if top_hashtags else "í•´ì‹œíƒœê·¸ í™œìš© ê¶Œì¥"
                ]
            },
            "message": f"{len(video_ids)}ê°œ ì˜ìƒì˜ íƒœê·¸ ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"íƒœê·¸ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


# ===== ì‹ ê·œ ê¸°ëŠ¥: í‚¤ì›Œë“œ íŠ¸ë Œë“œ (YouTube ê²€ìƒ‰ ê¸°ë°˜) =====

# ===== ì‹ ê·œ ê¸°ëŠ¥: í†µí•© ì˜ìƒ ì ìˆ˜ ê³„ì‚° =====

def calculate_seo_score(title: str, description: str, tags: List[str] = None) -> Dict[str, Any]:
    """SEO ì ìˆ˜ ê³„ì‚° - ì œëª©, ì„¤ëª…, íƒœê·¸ ìµœì í™” ë¶„ì„"""
    score = 0
    details = []

    # ì œëª© ë¶„ì„ (ìµœëŒ€ 40ì )
    title_len = len(title)
    if 30 <= title_len <= 60:
        score += 20
        details.append("âœ… ì œëª© ê¸¸ì´ ì ì ˆ (30-60ì)")
    elif 20 <= title_len <= 70:
        score += 10
        details.append("âš ï¸ ì œëª© ê¸¸ì´ ë³´í†µ")
    else:
        details.append("âŒ ì œëª© ë„ˆë¬´ ì§§ê±°ë‚˜ ê¹€")

    # ì œëª©ì— ìˆ«ì í¬í•¨ (í´ë¦­ë¥  í–¥ìƒ)
    import re
    if re.search(r'\d+', title):
        score += 10
        details.append("âœ… ìˆ«ì í¬í•¨ (í´ë¦­ë¥  â†‘)")

    # ì œëª©ì— ê°ì • í‘œí˜„ í¬í•¨
    emotion_words = ['ì¶©ê²©', 'ë†€ë¼ìš´', 'ëŒ€ë°•', 'ê°ë™', 'ì‹¤í™”', 'ê²½ì•…', 'ë¹„ë°€', 'ë°˜ì „', 'ìµœì´ˆ', 'ë“œë””ì–´']
    if any(word in title for word in emotion_words):
        score += 10
        details.append("âœ… ê°ì • ìœ ë°œ í‚¤ì›Œë“œ í¬í•¨")

    # ì„¤ëª…ë€ ë¶„ì„ (ìµœëŒ€ 30ì )
    desc_len = len(description) if description else 0
    if desc_len >= 500:
        score += 15
        details.append("âœ… ì„¤ëª…ë€ ì¶©ë¶„íˆ ì‘ì„±ë¨")
    elif desc_len >= 200:
        score += 8
        details.append("âš ï¸ ì„¤ëª…ë€ ë³´í†µ")
    else:
        details.append("âŒ ì„¤ëª…ë€ ë„ˆë¬´ ì§§ìŒ")

    # ì„¤ëª…ì— íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨
    if description and re.search(r'\d{1,2}:\d{2}', description):
        score += 10
        details.append("âœ… íƒ€ì„ìŠ¤íƒ¬í”„ í¬í•¨")

    # í•´ì‹œíƒœê·¸ ë¶„ì„
    hashtags = re.findall(r'#\w+', title + (description or ''))
    if 3 <= len(hashtags) <= 10:
        score += 5
        details.append("âœ… í•´ì‹œíƒœê·¸ ì ì ˆ")
    elif len(hashtags) > 0:
        score += 2
        details.append("âš ï¸ í•´ì‹œíƒœê·¸ ë¶€ì¡±í•˜ê±°ë‚˜ ê³¼ë‹¤")

    # íƒœê·¸ ë¶„ì„ (ìµœëŒ€ 30ì )
    if tags:
        if len(tags) >= 10:
            score += 15
            details.append("âœ… íƒœê·¸ ì¶©ë¶„íˆ ì„¤ì •ë¨")
        elif len(tags) >= 5:
            score += 8
            details.append("âš ï¸ íƒœê·¸ ë³´í†µ")
        else:
            details.append("âŒ íƒœê·¸ ë¶€ì¡±")

        # íƒœê·¸ ê¸¸ì´ ë‹¤ì–‘ì„±
        tag_lengths = [len(t) for t in tags]
        if min(tag_lengths, default=0) < 10 and max(tag_lengths, default=0) > 15:
            score += 10
            details.append("âœ… íƒœê·¸ ê¸¸ì´ ë‹¤ì–‘í•¨")
    else:
        score += 5  # íƒœê·¸ ì •ë³´ ì—†ìœ¼ë©´ ê¸°ë³¸ì 

    # ë“±ê¸‰ ê²°ì •
    if score >= 80:
        grade = "A+"
    elif score >= 65:
        grade = "A"
    elif score >= 50:
        grade = "B"
    elif score >= 35:
        grade = "C"
    else:
        grade = "D"

    return {
        "score": min(100, score),
        "grade": grade,
        "details": details
    }


def calculate_viral_score(video: Dict[str, Any]) -> Dict[str, Any]:
    """ë°”ì´ëŸ´ ì˜ˆì¸¡ ì ìˆ˜ ê³„ì‚° - ì¡°íšŒìˆ˜ ê°€ì†ë„, ì°¸ì—¬ìœ¨, êµ¬ë…ì ëŒ€ë¹„ ì„±ê³¼ ì¢…í•©"""
    view_count = video.get("viewCount", 0)
    like_count = video.get("likeCount", 0)
    comment_count = video.get("commentCount", 0)
    subscriber_count = video.get("subscriberCount", 1) or 1
    hours_since_upload = video.get("hoursSinceUpload", 24)

    if hours_since_upload == 0:
        hours_since_upload = 1

    score = 0
    factors = []

    # 1. ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜ (ê°€ì†ë„) - ìµœëŒ€ 30ì 
    views_per_hour = view_count / hours_since_upload
    if views_per_hour >= 10000:
        score += 30
        factors.append(("ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜", "ğŸ”¥ í­ë°œì ", views_per_hour))
    elif views_per_hour >= 1000:
        score += 20
        factors.append(("ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜", "ğŸš€ ë†’ìŒ", views_per_hour))
    elif views_per_hour >= 100:
        score += 10
        factors.append(("ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜", "ğŸ“ˆ ë³´í†µ", views_per_hour))
    else:
        factors.append(("ì‹œê°„ë‹¹ ì¡°íšŒìˆ˜", "â¡ï¸ ë‚®ìŒ", views_per_hour))

    # 2. êµ¬ë…ì ëŒ€ë¹„ ì„±ê³¼ - ìµœëŒ€ 25ì 
    performance = view_count / subscriber_count
    if performance >= 5:
        score += 25
        factors.append(("êµ¬ë…ì ëŒ€ë¹„", "ğŸ”¥ 5ë°° ì´ìƒ", performance))
    elif performance >= 2:
        score += 18
        factors.append(("êµ¬ë…ì ëŒ€ë¹„", "âœ… 2ë°° ì´ìƒ", performance))
    elif performance >= 1:
        score += 10
        factors.append(("êµ¬ë…ì ëŒ€ë¹„", "ğŸ“Š 1ë°° ì´ìƒ", performance))
    else:
        factors.append(("êµ¬ë…ì ëŒ€ë¹„", "â¡ï¸ 1ë°° ë¯¸ë§Œ", performance))

    # 3. ì°¸ì—¬ìœ¨ - ìµœëŒ€ 25ì 
    engagement_rate = 0
    if view_count > 0:
        engagement_rate = ((like_count + comment_count) / view_count) * 100

    if engagement_rate >= 10:
        score += 25
        factors.append(("ì°¸ì—¬ìœ¨", "ğŸ”¥ ë§¤ìš° ë†’ìŒ", f"{engagement_rate:.1f}%"))
    elif engagement_rate >= 5:
        score += 18
        factors.append(("ì°¸ì—¬ìœ¨", "âœ… ë†’ìŒ", f"{engagement_rate:.1f}%"))
    elif engagement_rate >= 2:
        score += 10
        factors.append(("ì°¸ì—¬ìœ¨", "ğŸ“Š ë³´í†µ", f"{engagement_rate:.1f}%"))
    else:
        factors.append(("ì°¸ì—¬ìœ¨", "â¡ï¸ ë‚®ìŒ", f"{engagement_rate:.1f}%"))

    # 4. ì¢‹ì•„ìš”/ëŒ“ê¸€ ë¹„ìœ¨ - ìµœëŒ€ 10ì 
    if comment_count > 0:
        like_comment_ratio = like_count / comment_count
        if 5 <= like_comment_ratio <= 50:
            score += 10
            factors.append(("ì¢‹ì•„ìš”/ëŒ“ê¸€ ë¹„ìœ¨", "âœ… ê±´ê°•í•¨", like_comment_ratio))
        elif like_comment_ratio > 50:
            score += 5
            factors.append(("ì¢‹ì•„ìš”/ëŒ“ê¸€ ë¹„ìœ¨", "âš ï¸ ëŒ“ê¸€ ë¶€ì¡±", like_comment_ratio))

    # 5. ì‹ ì„ ë„ ë³´ë„ˆìŠ¤ - ìµœëŒ€ 10ì 
    if hours_since_upload <= 24:
        score += 10
        factors.append(("ì‹ ì„ ë„", "ğŸ†• 24ì‹œê°„ ì´ë‚´", f"{hours_since_upload:.0f}h"))
    elif hours_since_upload <= 72:
        score += 5
        factors.append(("ì‹ ì„ ë„", "ğŸ“… 3ì¼ ì´ë‚´", f"{hours_since_upload:.0f}h"))

    # ë“±ê¸‰ ê²°ì •
    if score >= 80:
        grade = "ğŸ”¥ ë°”ì´ëŸ´ í™•ì‹¤"
    elif score >= 60:
        grade = "ğŸš€ ë°”ì´ëŸ´ ê°€ëŠ¥ì„± ë†’ìŒ"
    elif score >= 40:
        grade = "ğŸ“ˆ ì„±ì¥ ì¤‘"
    else:
        grade = "â¡ï¸ ë³´í†µ"

    return {
        "viralScore": min(100, score),
        "viralGrade": grade,
        "viralFactors": factors
    }


@tubelens_bp.route('/api/tubelens/upload-pattern', methods=['POST'])
def api_upload_pattern():
    """ì±„ë„ì˜ ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„ - ìš”ì¼/ì‹œê°„ëŒ€ë³„ ì„±ê³¼"""
    try:
        data = request.get_json()
        channel_id = data.get("channelId", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not channel_id:
            return jsonify({"success": False, "message": "ì±„ë„ IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì±„ë„ì˜ ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ ê°€ì ¸ì˜¤ê¸°
        channel_info = get_channel_info(channel_id, api_key)
        upload_playlist = channel_info.get("uploadPlaylist", "")

        if not upload_playlist:
            return jsonify({"success": False, "message": "ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400

        # ìµœê·¼ 50ê°œ ì˜ìƒ ê°€ì ¸ì˜¤ê¸°
        playlist_data = make_youtube_request("playlistItems", {
            "part": "contentDetails",
            "playlistId": upload_playlist,
            "maxResults": 50
        }, api_key)

        video_ids = [item["contentDetails"]["videoId"] for item in playlist_data.get("items", [])]

        if not video_ids:
            return jsonify({"success": False, "message": "ì˜ìƒì´ ì—†ìŠµë‹ˆë‹¤."}), 400

        # ì˜ìƒ ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        videos_data = make_youtube_request("videos", {
            "part": "snippet,statistics,contentDetails",
            "id": ",".join(video_ids)
        }, api_key)

        # ìš”ì¼ë³„ ë¶„ì„
        day_stats = {0: [], 1: [], 2: [], 3: [], 4: [], 5: [], 6: []}  # ì›”~ì¼
        day_names = ["ì›”", "í™”", "ìˆ˜", "ëª©", "ê¸ˆ", "í† ", "ì¼"]

        # ì‹œê°„ëŒ€ë³„ ë¶„ì„
        hour_stats = {h: [] for h in range(24)}

        # ì˜ìƒ ê¸¸ì´ë³„ ì„±ê³¼
        duration_stats = {"short": [], "medium": [], "long": []}  # ~10ë¶„, 10~30ë¶„, 30ë¶„+

        # ì œëª© ê¸¸ì´ë³„ ì„±ê³¼
        title_length_stats = {"short": [], "medium": [], "long": []}  # ~30ì, 30~50ì, 50ì+

        for vid in videos_data.get("items", []):
            snippet = vid.get("snippet", {})
            stats = vid.get("statistics", {})
            content = vid.get("contentDetails", {})

            published_at = snippet.get("publishedAt", "")
            view_count = int(stats.get("viewCount", 0))

            if published_at:
                from datetime import datetime
                dt = datetime.fromisoformat(published_at.replace("Z", "+00:00"))
                weekday = dt.weekday()
                hour = dt.hour

                day_stats[weekday].append(view_count)
                hour_stats[hour].append(view_count)

            # ì˜ìƒ ê¸¸ì´ ë¶„ì„
            duration_seconds = parse_duration(content.get("duration", ""))
            if duration_seconds <= 600:  # 10ë¶„ ì´í•˜
                duration_stats["short"].append(view_count)
            elif duration_seconds <= 1800:  # 30ë¶„ ì´í•˜
                duration_stats["medium"].append(view_count)
            else:
                duration_stats["long"].append(view_count)

            # ì œëª© ê¸¸ì´ ë¶„ì„
            title = snippet.get("title", "")
            title_len = len(title)
            if title_len <= 30:
                title_length_stats["short"].append(view_count)
            elif title_len <= 50:
                title_length_stats["medium"].append(view_count)
            else:
                title_length_stats["long"].append(view_count)

        # ìš”ì¼ë³„ í‰ê·  ê³„ì‚°
        day_avg = []
        best_day = {"name": "", "avg": 0}
        for i in range(7):
            views = day_stats[i]
            avg = sum(views) / len(views) if views else 0
            day_avg.append({"day": day_names[i], "avgViews": round(avg), "videoCount": len(views)})
            if avg > best_day["avg"]:
                best_day = {"name": day_names[i], "avg": avg}

        # ì‹œê°„ëŒ€ë³„ í‰ê·  (6ì‹œê°„ ë‹¨ìœ„ë¡œ ê·¸ë£¹í•‘)
        time_periods = [
            {"name": "ìƒˆë²½ (0-6ì‹œ)", "hours": list(range(0, 6))},
            {"name": "ì˜¤ì „ (6-12ì‹œ)", "hours": list(range(6, 12))},
            {"name": "ì˜¤í›„ (12-18ì‹œ)", "hours": list(range(12, 18))},
            {"name": "ì €ë… (18-24ì‹œ)", "hours": list(range(18, 24))}
        ]

        time_avg = []
        best_time = {"name": "", "avg": 0}
        for period in time_periods:
            views = []
            for h in period["hours"]:
                views.extend(hour_stats[h])
            avg = sum(views) / len(views) if views else 0
            time_avg.append({"period": period["name"], "avgViews": round(avg), "videoCount": len(views)})
            if avg > best_time["avg"]:
                best_time = {"name": period["name"], "avg": avg}

        # ì˜ìƒ ê¸¸ì´ë³„ í‰ê· 
        duration_avg = {}
        duration_labels = {"short": "10ë¶„ ì´í•˜", "medium": "10-30ë¶„", "long": "30ë¶„ ì´ìƒ"}
        best_duration = {"name": "", "avg": 0}
        for key, views in duration_stats.items():
            avg = sum(views) / len(views) if views else 0
            duration_avg[key] = {"label": duration_labels[key], "avgViews": round(avg), "videoCount": len(views)}
            if avg > best_duration["avg"]:
                best_duration = {"name": duration_labels[key], "avg": avg}

        # ì œëª© ê¸¸ì´ë³„ í‰ê· 
        title_avg = {}
        title_labels = {"short": "30ì ì´í•˜", "medium": "30-50ì", "long": "50ì ì´ìƒ"}
        best_title_len = {"name": "", "avg": 0}
        for key, views in title_length_stats.items():
            avg = sum(views) / len(views) if views else 0
            title_avg[key] = {"label": title_labels[key], "avgViews": round(avg), "videoCount": len(views)}
            if avg > best_title_len["avg"]:
                best_title_len = {"name": title_labels[key], "avg": avg}

        return jsonify({
            "success": True,
            "data": {
                "channelTitle": channel_info.get("channelTitle", ""),
                "analyzedVideos": len(video_ids),
                "dayPattern": {
                    "data": day_avg,
                    "bestDay": best_day["name"],
                    "recommendation": f"'{best_day['name']}ìš”ì¼'ì— ì—…ë¡œë“œí•˜ë©´ í‰ê·  {format_number(int(best_day['avg']))}íšŒ ì¡°íšŒìˆ˜ ê¸°ëŒ€"
                },
                "timePattern": {
                    "data": time_avg,
                    "bestTime": best_time["name"],
                    "recommendation": f"'{best_time['name']}'ì— ì—…ë¡œë“œí•˜ë©´ í‰ê·  {format_number(int(best_time['avg']))}íšŒ ì¡°íšŒìˆ˜ ê¸°ëŒ€"
                },
                "durationPattern": {
                    "data": duration_avg,
                    "bestDuration": best_duration["name"],
                    "recommendation": f"'{best_duration['name']}' ì˜ìƒì´ í‰ê·  {format_number(int(best_duration['avg']))}íšŒë¡œ ê°€ì¥ ì¢‹ì€ ì„±ê³¼"
                },
                "titleLengthPattern": {
                    "data": title_avg,
                    "bestTitleLength": best_title_len["name"],
                    "recommendation": f"'{best_title_len['name']}' ì œëª©ì´ í‰ê·  {format_number(int(best_title_len['avg']))}íšŒë¡œ ê°€ì¥ ì¢‹ì€ ì„±ê³¼"
                }
            },
            "message": "ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"ì—…ë¡œë“œ íŒ¨í„´ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/video-score', methods=['POST'])
def api_video_score():
    """ì˜ìƒ ì¢…í•© ì ìˆ˜ ê³„ì‚° - SEO + ë°”ì´ëŸ´ ì˜ˆì¸¡ í†µí•©"""
    try:
        data = request.get_json()
        video_id = data.get("videoId", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not video_id:
            return jsonify({"success": False, "message": "ë¹„ë””ì˜¤ IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì˜ìƒ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        videos_data = make_youtube_request("videos", {
            "part": "snippet,statistics,contentDetails",
            "id": video_id
        }, api_key)

        if not videos_data.get("items"):
            return jsonify({"success": False, "message": "ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400

        video = videos_data["items"][0]
        snippet = video.get("snippet", {})
        stats = video.get("statistics", {})
        content = video.get("contentDetails", {})

        # ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        channel_id = snippet.get("channelId", "")
        channel_info = get_channel_info(channel_id, api_key) if channel_id else {}

        # ì—…ë¡œë“œ ì‹œê°„ ê³„ì‚°
        published_at = snippet.get("publishedAt", "")
        hours_since_upload = 24
        if published_at:
            try:
                from datetime import datetime
                published_dt = datetime.fromisoformat(published_at.replace("Z", "+00:00"))
                now = datetime.now(published_dt.tzinfo) if published_dt.tzinfo else datetime.utcnow()
                hours_since_upload = max(1, (now - published_dt.replace(tzinfo=None)).total_seconds() / 3600)
            except:
                pass

        video_data = {
            "viewCount": int(stats.get("viewCount", 0)),
            "likeCount": int(stats.get("likeCount", 0)),
            "commentCount": int(stats.get("commentCount", 0)),
            "subscriberCount": channel_info.get("subscriberCount", 0),
            "hoursSinceUpload": hours_since_upload
        }

        # SEO ì ìˆ˜ ê³„ì‚°
        tags = snippet.get("tags", [])
        seo_result = calculate_seo_score(
            snippet.get("title", ""),
            snippet.get("description", ""),
            tags
        )

        # ë°”ì´ëŸ´ ì ìˆ˜ ê³„ì‚°
        viral_result = calculate_viral_score(video_data)

        # ì¢…í•© ì ìˆ˜ (SEO 40% + ë°”ì´ëŸ´ 60%)
        total_score = seo_result["score"] * 0.4 + viral_result["viralScore"] * 0.6

        if total_score >= 80:
            total_grade = "ğŸ† Së“±ê¸‰"
        elif total_score >= 65:
            total_grade = "â­ Aë“±ê¸‰"
        elif total_score >= 50:
            total_grade = "âœ… Bë“±ê¸‰"
        elif total_score >= 35:
            total_grade = "ğŸ“Š Cë“±ê¸‰"
        else:
            total_grade = "â¡ï¸ Dë“±ê¸‰"

        return jsonify({
            "success": True,
            "data": {
                "videoId": video_id,
                "title": snippet.get("title", ""),
                "thumbnail": snippet.get("thumbnails", {}).get("high", {}).get("url", ""),
                "seo": seo_result,
                "viral": viral_result,
                "totalScore": round(total_score, 1),
                "totalGrade": total_grade,
                "stats": video_data
            },
            "message": "ì˜ìƒ ì¢…í•© ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"ì˜ìƒ ì ìˆ˜ ê³„ì‚° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/similar-channels', methods=['POST'])
def api_similar_channels():
    """ìœ ì‚¬ ì±„ë„ ì°¾ê¸° - ë¹„ìŠ·í•œ ì£¼ì œ/ê·œëª¨ì˜ ì±„ë„ ë°œêµ´"""
    try:
        data = request.get_json()
        channel_id = data.get("channelId", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not channel_id:
            return jsonify({"success": False, "message": "ì±„ë„ IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì›ë³¸ ì±„ë„ ì •ë³´
        base_channel = get_channel_info(channel_id, api_key)
        if not base_channel:
            return jsonify({"success": False, "message": "ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 400

        base_subs = base_channel.get("subscriberCount", 0)
        channel_title = base_channel.get("channelTitle", "")

        # ì±„ë„ í‚¤ì›Œë“œë¡œ ìœ ì‚¬ ì±„ë„ ê²€ìƒ‰
        search_data = make_youtube_request("search", {
            "part": "snippet",
            "q": channel_title,
            "type": "channel",
            "maxResults": 20,
            "regionCode": "KR"
        }, api_key)

        similar_channels = []
        for item in search_data.get("items", []):
            found_channel_id = item["id"]["channelId"]
            if found_channel_id == channel_id:  # ìê¸° ìì‹  ì œì™¸
                continue

            ch_info = get_channel_info(found_channel_id, api_key)
            if not ch_info:
                continue

            ch_subs = ch_info.get("subscriberCount", 0)

            # êµ¬ë…ì ìˆ˜ ìœ ì‚¬ë„ ê³„ì‚° (0.1ë°° ~ 10ë°° ë²”ìœ„)
            if base_subs > 0 and ch_subs > 0:
                ratio = ch_subs / base_subs if ch_subs > base_subs else base_subs / ch_subs
                if ratio <= 10:  # 10ë°° ì´ë‚´ë§Œ
                    similarity = max(0, 100 - (ratio - 1) * 10)  # ë¹„ìœ¨ì´ ê°€ê¹Œìš¸ìˆ˜ë¡ ë†’ì€ ì ìˆ˜

                    similar_channels.append({
                        "channelId": found_channel_id,
                        "channelTitle": ch_info.get("channelTitle", ""),
                        "thumbnail": ch_info.get("thumbnailUrl", ""),
                        "subscriberCount": ch_subs,
                        "videoCount": ch_info.get("videoCount", 0),
                        "viewCount": ch_info.get("viewCount", 0),
                        "similarity": round(similarity, 1),
                        "sizeRatio": f"{ch_subs / base_subs:.1f}x" if base_subs > 0 else "N/A"
                    })

        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        similar_channels.sort(key=lambda x: x["similarity"], reverse=True)

        return jsonify({
            "success": True,
            "data": {
                "baseChannel": {
                    "channelId": channel_id,
                    "channelTitle": channel_title,
                    "subscriberCount": base_subs
                },
                "similarChannels": similar_channels[:10]
            },
            "message": f"{len(similar_channels[:10])}ê°œì˜ ìœ ì‚¬ ì±„ë„ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤."
        })

    except Exception as e:
        print(f"ìœ ì‚¬ ì±„ë„ ì°¾ê¸° ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/generate-description', methods=['POST'])
def api_generate_description():
    """AIë¡œ ìµœì í™”ëœ ì„¤ëª…ë€ í…œí”Œë¦¿ ìƒì„±"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()
        title = data.get("title", "")
        category = data.get("category", "general")  # general, news, story, education
        include_sections = data.get("includeSections", ["timestamps", "links", "hashtags"])

        if not title:
            return jsonify({"success": False, "message": "ì˜ìƒ ì œëª©ì´ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        client = OpenAI(api_key=openai_api_key)

        sections_guide = {
            "timestamps": "- ì±•í„°ë³„ íƒ€ì„ìŠ¤íƒ¬í”„ (00:00 í˜•ì‹)",
            "links": "- ê´€ë ¨ ë§í¬ ì„¹ì…˜",
            "hashtags": "- SEOìš© í•´ì‹œíƒœê·¸ (3-5ê°œ)",
            "cta": "- êµ¬ë…/ì¢‹ì•„ìš” CTA",
            "credits": "- ì¶œì²˜/í¬ë ˆë”§ ì„¹ì…˜"
        }

        selected_sections = "\n".join([sections_guide.get(s, "") for s in include_sections if s in sections_guide])

        category_style = {
            "general": "ì¼ë°˜ì ì¸ ìœ íŠœë¸Œ ì˜ìƒ",
            "news": "ë‰´ìŠ¤/ì‹œì‚¬ ì½˜í…ì¸  (ì •ë³´ ì „ë‹¬ ì¤‘ì‹¬)",
            "story": "ìŠ¤í† ë¦¬í…”ë§ ì½˜í…ì¸  (ê°ì„±ì , ëª°ì…í˜•)",
            "education": "êµìœ¡/ì •ë³´ ì½˜í…ì¸  (í•™ìŠµ ëª©ì )"
        }

        prompt = f"""ë‹¤ìŒ YouTube ì˜ìƒ ì œëª©ì— ë§ëŠ” ìµœì í™”ëœ ì„¤ëª…ë€ í…œí”Œë¦¿ì„ ìƒì„±í•´ì£¼ì„¸ìš”.

ì˜ìƒ ì œëª©: {title}
ì½˜í…ì¸  ìŠ¤íƒ€ì¼: {category_style.get(category, "ì¼ë°˜ì ì¸ ìœ íŠœë¸Œ ì˜ìƒ")}

í¬í•¨í•  ì„¹ì…˜:
{selected_sections}

ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
{{
  "description": "ì™„ì„±ëœ ì„¤ëª…ë€ í…ìŠ¤íŠ¸ (ì‹¤ì œë¡œ ë°”ë¡œ ì‚¬ìš© ê°€ëŠ¥í•œ í˜•íƒœ)",
  "hookLine": "ì²« ì¤„ì— ë“¤ì–´ê°ˆ í›… (ê²€ìƒ‰ ê²°ê³¼ì— ë…¸ì¶œë˜ëŠ” ë¶€ë¶„)",
  "tips": ["ì„¤ëª…ë€ ì‘ì„± íŒ 1", "íŒ 2", ...]
}}

í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”. ì„¤ëª…ë€ì€ ìµœì†Œ 500ì ì´ìƒìœ¼ë¡œ ì‘ì„±í•˜ê³ , ê²€ìƒ‰ ìµœì í™”ë¥¼ ê³ ë ¤í•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ YouTube SEO ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ê²€ìƒ‰ ìµœì í™”ì™€ ì‹œì²­ì ì°¸ì—¬ë¥¼ ë†’ì´ëŠ” ì„¤ëª…ë€ì„ ì‘ì„±í•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        result = json.loads(result_text)

        return jsonify({
            "success": True,
            "data": result,
            "message": "ì„¤ëª…ë€ í…œí”Œë¦¿ ìƒì„± ì™„ë£Œ"
        })

    except json.JSONDecodeError as e:
        print(f"ì„¤ëª…ë€ ìƒì„± JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"ì„¤ëª…ë€ ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/keyword-trend', methods=['POST'])
def api_keyword_trend():
    """í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ - ê¸°ê°„ë³„ ì˜ìƒ ìˆ˜ì™€ í‰ê·  ì¡°íšŒìˆ˜ ë¹„êµ"""
    try:
        data = request.get_json()
        keyword = data.get("keyword", "")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not keyword:
            return jsonify({"success": False, "message": "í‚¤ì›Œë“œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]

        if not api_key:
            api_key = get_youtube_api_key()

        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ê¸°ê°„ë³„ ê²€ìƒ‰ (ìµœê·¼ 7ì¼, 30ì¼, 90ì¼)
        periods = [
            {"name": "7ì¼", "days": 7},
            {"name": "30ì¼", "days": 30},
            {"name": "90ì¼", "days": 90}
        ]

        trend_data = []

        for period in periods:
            published_after = get_time_filter("day" if period["days"] == 1 else
                                              "week" if period["days"] == 7 else
                                              "month" if period["days"] == 30 else
                                              "3months")

            search_result = make_youtube_request("search", {
                "part": "snippet",
                "q": keyword,
                "type": "video",
                "maxResults": 20,
                "order": "date",
                "publishedAfter": published_after,
                "regionCode": "KR"
            }, api_key)

            video_count = len(search_result.get("items", []))

            # ì¡°íšŒìˆ˜ ë¶„ì„
            avg_views = 0
            if video_count > 0:
                video_ids = [item["id"]["videoId"] for item in search_result.get("items", [])]
                videos_data = make_youtube_request("videos", {
                    "part": "statistics",
                    "id": ",".join(video_ids)
                }, api_key)

                total_views = sum(int(v.get("statistics", {}).get("viewCount", 0))
                                  for v in videos_data.get("items", []))
                avg_views = total_views // video_count if video_count > 0 else 0

            trend_data.append({
                "period": period["name"],
                "days": period["days"],
                "videoCount": video_count,
                "avgViews": avg_views,
                "videosPerDay": round(video_count / period["days"], 2)
            })

        # íŠ¸ë Œë“œ ë¶„ì„
        recent = trend_data[0]  # 7ì¼
        older = trend_data[2]   # 90ì¼

        trend_direction = "ìƒìŠ¹" if recent["videosPerDay"] > older["videosPerDay"] * 0.9 else "í•˜ë½"
        trend_strength = "ê°•í•¨" if abs(recent["videosPerDay"] - older["videosPerDay"]) > older["videosPerDay"] * 0.3 else "ë³´í†µ"

        return jsonify({
            "success": True,
            "data": {
                "keyword": keyword,
                "trendData": trend_data,
                "trendDirection": trend_direction,
                "trendStrength": trend_strength,
                "recommendation": f"'{keyword}' í‚¤ì›Œë“œëŠ” í˜„ì¬ {trend_direction} ì¶”ì„¸ì…ë‹ˆë‹¤. " +
                                 (f"ê²½ìŸì´ {'ì¹˜ì—´' if recent['videosPerDay'] > 3 else 'ë³´í†µ'} í•˜ë©°, " +
                                  f"í‰ê·  ì¡°íšŒìˆ˜ëŠ” {recent['avgViews']:,}íšŒ ì…ë‹ˆë‹¤.")
            },
            "message": f"'{keyword}' í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"í‚¤ì›Œë“œ íŠ¸ë Œë“œ ë¶„ì„ ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/generate-ai-plan', methods=['POST'])
def api_generate_ai_plan():
    """AI ì½˜í…ì¸  ê¸°íš ìƒì„± - ë–¡ìƒ ì˜ìƒ ë¶„ì„ ë° ê¸°íš ì œì•ˆ"""
    try:
        import json
        from openai import OpenAI

        data = request.get_json()

        video_id = data.get("videoId", "")
        title = data.get("title", "")
        description = data.get("description", "")[:1000]  # ìµœëŒ€ 1000ì
        channel_title = data.get("channelTitle", "")
        view_count = int(data.get("viewCount", 0))
        subscriber_count = int(data.get("subscriberCount", 1))
        like_count = int(data.get("likeCount", 0))
        comment_count = int(data.get("commentCount", 0))
        performance_value = float(data.get("performanceValue", 0))
        duration = data.get("duration", "")
        published_at = data.get("publishedAt", "")

        if not title:
            return jsonify({"success": False, "message": "ì˜ìƒ ì •ë³´ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        openai_api_key = os.getenv("OPENAI_API_KEY", "")
        if not openai_api_key:
            return jsonify({"success": False, "message": "OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."}), 400

        client = OpenAI(api_key=openai_api_key)

        # ì„±ê³¼ ë¶„ì„
        performance_desc = ""
        if performance_value >= 100:
            performance_desc = f"ğŸ”¥ ì‹ ì˜ ê°„íƒ! êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ ë¬´ë ¤ {int(performance_value)}ë°°ì…ë‹ˆë‹¤!"
        elif performance_value >= 50:
            performance_desc = f"ğŸš€ ê³ ì„±ê³¼ ì˜ìƒ! êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ {int(performance_value)}ë°°ì…ë‹ˆë‹¤."
        elif performance_value >= 10:
            performance_desc = f"ğŸ‘ í‰ê·  ì´ìƒì˜ ì„±ê³¼! êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ {int(performance_value)}ë°°ì…ë‹ˆë‹¤."
        else:
            performance_desc = f"ğŸ“Š êµ¬ë…ì ëŒ€ë¹„ ì¡°íšŒìˆ˜ê°€ {performance_value:.2f}ë°°ì…ë‹ˆë‹¤."

        prompt = f"""ë‹¤ìŒì€ YouTubeì—ì„œ ë†’ì€ ì„±ê³¼ë¥¼ ê¸°ë¡í•œ ì˜ìƒì…ë‹ˆë‹¤. ì´ ì˜ìƒì„ ë¶„ì„í•˜ê³  ì½˜í…ì¸  ê¸°íš ì œì•ˆì„ í•´ì£¼ì„¸ìš”.

=== ì˜ìƒ ì •ë³´ ===
ì œëª©: {title}
ì±„ë„: {channel_title}
ì¡°íšŒìˆ˜: {view_count:,}
êµ¬ë…ì ìˆ˜: {subscriber_count:,}
ì„±ê³¼ë„ ë°°ìœ¨: {performance_value:.2f}ë°° ({performance_desc})
ì¢‹ì•„ìš”: {like_count:,}
ëŒ“ê¸€ ìˆ˜: {comment_count:,}
ì˜ìƒ ê¸¸ì´: {duration}
ê²Œì‹œì¼: {published_at}
URL: https://www.youtube.com/watch?v={video_id}

=== ì˜ìƒ ì„¤ëª… ===
{description or '(ì—†ìŒ)'}

=== ë¶„ì„ ìš”ì²­ ===
ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„ ê²°ê³¼ë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
{{
  "successFactors": [
    "ì´ ì˜ìƒì´ í„°ì§„ í•µì‹¬ ìš”ì¸ 1",
    "ì´ ì˜ìƒì´ í„°ì§„ í•µì‹¬ ìš”ì¸ 2",
    "ì´ ì˜ìƒì´ í„°ì§„ í•µì‹¬ ìš”ì¸ 3"
  ],
  "suggestedTitles": [
    "ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ì˜ ì œëª© ì œì•ˆ 1",
    "ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ì˜ ì œëª© ì œì•ˆ 2",
    "ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ì˜ ì œëª© ì œì•ˆ 3"
  ],
  "thumbnailIdeas": [
    "í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì¸ë„¤ì¼ ë¬¸êµ¬ 1",
    "í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì¸ë„¤ì¼ ë¬¸êµ¬ 2"
  ],
  "hookScript": "ì´ˆë°˜ 30ì´ˆ í›„í‚¹ì„ ìœ„í•œ ë©˜íŠ¸ ì˜ˆì‹œ (3-5ë¬¸ì¥)",
  "contentIdeas": [
    "ì´ ì˜ìƒì„ ì°¸ê³ í•œ ê´€ë ¨ ì½˜í…ì¸  ì•„ì´ë””ì–´ 1",
    "ì´ ì˜ìƒì„ ì°¸ê³ í•œ ê´€ë ¨ ì½˜í…ì¸  ì•„ì´ë””ì–´ 2",
    "ì´ ì˜ìƒì„ ì°¸ê³ í•œ ê´€ë ¨ ì½˜í…ì¸  ì•„ì´ë””ì–´ 3"
  ]
}}

í•œêµ­ì–´ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”. êµ¬ì²´ì ì´ê³  ì‹¤ì œë¡œ í™œìš© ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": "ë‹¹ì‹ ì€ YouTube ì½˜í…ì¸  ê¸°íš ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ë–¡ìƒ ì˜ìƒì˜ ì„±ê³µ ìš”ì¸ì„ ë¶„ì„í•˜ê³ , ìœ ì‚¬í•œ ì„±ê³¼ë¥¼ ë‚¼ ìˆ˜ ìˆëŠ” ì½˜í…ì¸  ê¸°íšì„ ì œì•ˆí•©ë‹ˆë‹¤."},
                {"role": "user", "content": prompt}
            ],
            temperature=0.7,
            max_tokens=2000
        )

        result_text = response.choices[0].message.content.strip()

        # JSON íŒŒì‹±
        if "```json" in result_text:
            result_text = result_text.split("```json")[1].split("```")[0].strip()
        elif "```" in result_text:
            result_text = result_text.split("```")[1].split("```")[0].strip()

        plan_data = json.loads(result_text)

        # í”„ë¡¬í”„íŠ¸ë„ í•¨ê»˜ ë°˜í™˜ (Geminiìš©)
        gemini_prompt = f"""ë‹¤ìŒì€ YouTubeì—ì„œ êµ¬ë…ì ëŒ€ë¹„ {int(performance_value)}ë°°ì˜ ì¡°íšŒìˆ˜ë¥¼ ê¸°ë¡í•œ ë–¡ìƒ ì˜ìƒì…ë‹ˆë‹¤.

=== ì˜ìƒ ì •ë³´ ===
ì œëª©: {title}
ì±„ë„: {channel_title}
ì¡°íšŒìˆ˜: {view_count:,}
êµ¬ë…ì ìˆ˜: {subscriber_count:,}
ì„±ê³¼ë„ ë°°ìœ¨: {performance_value:.2f}ë°°
ì¢‹ì•„ìš”: {like_count:,}
ëŒ“ê¸€ ìˆ˜: {comment_count:,}
ì˜ìƒ ê¸¸ì´: {duration}
URL: https://www.youtube.com/watch?v={video_id}

=== ì˜ìƒ ì„¤ëª… ===
{description or '(ì—†ìŒ)'}

=== ë¶„ì„ ìš”ì²­ ===
ì´ ì˜ìƒì´ í„°ì§„ ì´ìœ ë¥¼ ë¶„ì„í•˜ê³ , ë‹¤ìŒì„ ì œê³µí•´ì£¼ì„¸ìš”:

1. ì´ ì˜ìƒì´ í„°ì§„ 3ê°€ì§€ í•µì‹¬ ìš”ì¸
2. ë¹„ìŠ·í•œ ìŠ¤íƒ€ì¼ì˜ ì œëª© 3ê°œ ì œì•ˆ
3. í´ë¦­ì„ ìœ ë„í•˜ëŠ” ì¸ë„¤ì¼ ë¬¸êµ¬ 2ê°œ
4. ì´ˆë°˜ 30ì´ˆ í›„í‚¹ì„ ìœ„í•œ ë©˜íŠ¸ ì˜ˆì‹œ
5. ì´ ì˜ìƒì„ ì°¸ê³ í•œ ê´€ë ¨ ì½˜í…ì¸  ì•„ì´ë””ì–´ 3ê°œ"""

        plan_data["prompt"] = gemini_prompt

        return jsonify({
            "success": True,
            "data": plan_data,
            "message": "AI ì½˜í…ì¸  ê¸°íš ìƒì„± ì™„ë£Œ"
        })

    except json.JSONDecodeError as e:
        print(f"AI ê¸°íš JSON íŒŒì‹± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": "ë¶„ì„ ê²°ê³¼ íŒŒì‹± ì‹¤íŒ¨"}), 500
    except Exception as e:
        print(f"AI ê¸°íš ìƒì„± ì˜¤ë¥˜: {e}")
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/transcript', methods=['POST'])
def api_get_transcript():
    """YouTube ì˜ìƒ ëŒ€ë³¸(ìë§‰) ì¶”ì¶œ API - youtube-transcript-api v1.0+ í˜¸í™˜"""
    try:
        from youtube_transcript_api import YouTubeTranscriptApi

        data = request.get_json()
        video_id = data.get("videoId", "")
        language_codes = data.get("languages", ["ko", "ja", "en", "zh-Hans", "zh-Hant"])
        include_auto = data.get("includeAuto", True)

        if not video_id:
            return jsonify({"success": False, "message": "videoIdê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì˜ìƒ IDì—ì„œ URL íŒŒë¼ë¯¸í„° ì œê±°
        if "&" in video_id:
            video_id = video_id.split("&")[0]

        # YouTubeTranscriptApi ì¸ìŠ¤í„´ìŠ¤ ìƒì„± (v1.0+ API)
        ytt_api = YouTubeTranscriptApi()

        transcript_result = None
        used_language = None
        is_auto_generated = False

        try:
            # ìë§‰ ëª©ë¡ ì¡°íšŒ (v1.0+: .list() ë©”ì„œë“œ ì‚¬ìš©)
            transcript_list = ytt_api.list(video_id)

            # 1. ìˆ˜ë™ ìë§‰ ìš°ì„  ì‹œë„
            for lang_code in language_codes:
                try:
                    transcript = transcript_list.find_transcript([lang_code])
                    if not transcript.is_generated:
                        transcript_result = transcript.fetch()
                        used_language = lang_code
                        is_auto_generated = False
                        break
                except Exception:
                    continue

            # 2. ìë™ ìƒì„± ìë§‰ ì‹œë„
            if transcript_result is None and include_auto:
                for lang_code in language_codes:
                    try:
                        transcript = transcript_list.find_transcript([lang_code])
                        if transcript.is_generated:
                            transcript_result = transcript.fetch()
                            used_language = lang_code
                            is_auto_generated = True
                            break
                    except Exception:
                        continue

            # 3. ë²ˆì—­ ìë§‰ ì‹œë„
            if transcript_result is None:
                try:
                    en_transcript = transcript_list.find_transcript(['en'])
                    for target_lang in ['ko', 'ja']:
                        try:
                            translated = en_transcript.translate(target_lang)
                            transcript_result = translated.fetch()
                            used_language = f"enâ†’{target_lang}"
                            is_auto_generated = en_transcript.is_generated
                            break
                        except Exception:
                            continue
                except Exception:
                    pass

            # 4. ì•„ë¬´ ìë§‰ì´ë‚˜ ê°€ì ¸ì˜¤ê¸°
            if transcript_result is None:
                try:
                    for transcript in transcript_list:
                        transcript_result = transcript.fetch()
                        used_language = transcript.language_code
                        is_auto_generated = transcript.is_generated
                        break
                except Exception:
                    pass

        except Exception as e:
            error_msg = str(e).lower()
            if "disabled" in error_msg:
                return jsonify({
                    "success": False,
                    "message": "ì´ ì˜ìƒì€ ìë§‰ì´ ë¹„í™œì„±í™”ë˜ì–´ ìˆìŠµë‹ˆë‹¤.",
                    "errorType": "disabled"
                }), 400
            elif "unavailable" in error_msg or "not exist" in error_msg:
                return jsonify({
                    "success": False,
                    "message": "ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                    "errorType": "unavailable"
                }), 400
            elif "no transcript" in error_msg:
                return jsonify({
                    "success": False,
                    "message": "ì´ ì˜ìƒì—ëŠ” ìë§‰ì´ ì—†ìŠµë‹ˆë‹¤.",
                    "errorType": "not_found"
                }), 400
            else:
                raise

        if transcript_result is None:
            return jsonify({
                "success": False,
                "message": "ìë§‰ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "errorType": "not_found"
            }), 400

        # v1.0+ FetchedTranscript ê°ì²´ ì²˜ë¦¬
        full_text = ""
        segments = []

        # snippets ì†ì„± ë˜ëŠ” ì§ì ‘ ì´í„°ë ˆì´ì…˜
        items = getattr(transcript_result, 'snippets', None) or transcript_result

        for entry in items:
            # FetchedTranscriptSnippet ê°ì²´ ë˜ëŠ” dict ì²˜ë¦¬
            if hasattr(entry, 'text'):
                text = entry.text.strip()
                start = entry.start
                duration = entry.duration
            else:
                text = entry.get("text", "").strip()
                start = entry.get("start", 0)
                duration = entry.get("duration", 0)

            if text and not (text.startswith("[") and text.endswith("]")):
                segments.append({
                    "text": text,
                    "start": round(start, 2),
                    "duration": round(duration, 2)
                })
                full_text += text + " "

        full_text = full_text.strip()

        # ì–¸ì–´ ì •ë³´ (FetchedTranscriptì—ì„œ ê°€ì ¸ì˜¤ê¸°)
        if hasattr(transcript_result, 'language_code') and transcript_result.language_code:
            used_language = transcript_result.language_code
        if hasattr(transcript_result, 'is_generated'):
            is_auto_generated = transcript_result.is_generated

        char_count = len(full_text.replace(" ", ""))
        estimated_minutes = round(char_count / 300, 1)

        return jsonify({
            "success": True,
            "data": {
                "videoId": video_id,
                "language": used_language,
                "isAutoGenerated": is_auto_generated,
                "fullText": full_text,
                "segments": segments,
                "charCount": char_count,
                "estimatedMinutes": estimated_minutes,
                "segmentCount": len(segments)
            },
            "message": f"ìë§‰ ì¶”ì¶œ ì™„ë£Œ ({used_language}, {'ìë™ìƒì„±' if is_auto_generated else 'ìˆ˜ë™'})"
        })

    except Exception as e:
        print(f"ëŒ€ë³¸ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "message": f"ëŒ€ë³¸ ì¶”ì¶œ ì‹¤íŒ¨: {str(e)}"}), 500


# ===== ë¸”ë£¨ì˜¤ì…˜ ì¹´í…Œê³ ë¦¬ ë°œêµ´ =====

def extract_keywords_from_videos(videos: List[Dict[str, Any]]) -> List[str]:
    """ì˜ìƒ ì œëª©ì—ì„œ í‚¤ì›Œë“œ ì¶”ì¶œ (GPT ì—†ì´ ê°„ë‹¨í•œ ë°©ì‹)"""
    import re
    from collections import Counter

    all_words = []
    stop_words = {'the', 'a', 'an', 'is', 'are', 'was', 'were', 'be', 'been',
                  'being', 'have', 'has', 'had', 'do', 'does', 'did', 'will',
                  'would', 'could', 'should', 'may', 'might', 'must', 'shall',
                  'can', 'need', 'dare', 'ought', 'used', 'to', 'of', 'in',
                  'for', 'on', 'with', 'at', 'by', 'from', 'as', 'into',
                  'through', 'during', 'before', 'after', 'above', 'below',
                  'between', 'under', 'again', 'further', 'then', 'once',
                  'here', 'there', 'when', 'where', 'why', 'how', 'all',
                  'each', 'few', 'more', 'most', 'other', 'some', 'such',
                  'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than',
                  'too', 'very', 'just', 'and', 'but', 'if', 'or', 'because',
                  'until', 'while', 'this', 'that', 'these', 'those', 'i',
                  'me', 'my', 'myself', 'we', 'our', 'ours', 'you', 'your',
                  'he', 'him', 'his', 'she', 'her', 'it', 'its', 'they',
                  'them', 'their', 'what', 'which', 'who', 'whom', 'shorts',
                  'video', 'new', 'official', 'full', '|', '-', '#', 'ep',
                  'episode', 'part', 'vol', 'vs', '&', 'feat', 'ft'}

    for video in videos:
        title = video.get('title', '').lower()
        # íŠ¹ìˆ˜ë¬¸ì ì œê±°í•˜ê³  ë‹¨ì–´ ì¶”ì¶œ
        words = re.findall(r'[a-zê°€-í£]+', title)
        for word in words:
            if len(word) > 2 and word not in stop_words:
                all_words.append(word)

    # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ìƒìœ„ í‚¤ì›Œë“œ
    word_counts = Counter(all_words)
    top_keywords = [word for word, count in word_counts.most_common(20) if count >= 2]

    return top_keywords


# í•´ì™¸ì—ì„œ ì¸ê¸° ìˆëŠ” ë‹ˆì¹˜ í‚¤ì›Œë“œ (ë¸”ë£¨ì˜¤ì…˜ í›„ë³´)
NICHE_KEYWORDS = {
    "US": [
        "stoicism", "adhd tips", "dopamine detox", "carnivore diet",
        "home gym", "biohacking", "sleep optimization", "cold plunge",
        "thrift flip", "van life", "tiny house", "off grid",
        "ai tools", "chatgpt tutorial", "midjourney", "stable diffusion",
        "true crime", "unsolved mystery", "creepypasta", "iceberg explained",
        "satisfying", "asmr", "oddly satisfying", "relaxing",
        "financial freedom", "side hustle", "passive income", "dropshipping",
        "manga recap", "anime recap", "manhwa", "webtoon",
        "90s nostalgia", "liminal spaces", "analog horror", "arg",
        "silent vlog", "study with me", "clean with me", "day in my life"
    ],
    "JP": [
        "vtuber", "hololive", "nijisanji", "voiceroid",
        "isekai", "narou", "light novel", "manga spoiler",
        "retro game", "famicom", "super famicom", "arcade",
        "japanese asmr", "ear cleaning", "whispering",
        "japan travel", "tokyo walk", "kyoto tour", "osaka food",
        "idol", "jpop", "city pop", "anime song",
        "otaku", "figure", "gunpla", "cosplay",
        "ramen", "sushi", "bento", "japanese cooking"
    ],
    "GB": [
        "british comedy", "uk drill", "grime",
        "premier league", "football highlights", "match analysis",
        "royal family", "british history", "castle tour",
        "pub culture", "british food", "full english",
        "london vlog", "uk travel", "scotland",
        "british slang", "cockney", "accent challenge"
    ],
    "DE": [
        "german lesson", "deutsch lernen", "german culture",
        "bundesliga", "german football",
        "german engineering", "made in germany",
        "berlin", "munich", "oktoberfest",
        "german history", "ww2 documentary", "cold war"
    ],
    "BR": [
        "funk brasileiro", "sertanejo", "pagode",
        "futebol brasileiro", "flamengo", "corinthians",
        "novela", "brazilian drama", "reality show",
        "brazil travel", "rio", "amazon",
        "brazilian food", "feijoada", "churrasco"
    ],
    "IN": [
        "bollywood", "south indian", "tollywood",
        "cricket", "ipl", "india match",
        "indian cooking", "curry recipe", "biryani",
        "indian wedding", "mehndi", "sangeet",
        "yoga", "meditation", "ayurveda",
        "indian history", "mythology", "mahabharata"
    ]
}


def calculate_blueocean_score(foreign_data: Dict, korea_data: Dict) -> float:
    """ë¸”ë£¨ì˜¤ì…˜ ì ìˆ˜ ê³„ì‚°

    ë¸”ë£¨ì˜¤ì…˜ = í•´ì™¸ì—ì„œ ì¸ê¸° ìˆì§€ë§Œ í•œêµ­ì—ì„œ ê²½ìŸì´ ì ì€ ì‹œì¥

    ì ìˆ˜ êµ¬ì„±:
    - í•´ì™¸ ì¸ê¸°ë„ (40ì ): í•´ì™¸ í‰ê·  ì¡°íšŒìˆ˜ê°€ ë†’ì„ìˆ˜ë¡ +
    - í•œêµ­ í¬ì†Œì„± (60ì ): í•œêµ­ ì±„ë„ì´ ì ê³ , ì¡°íšŒìˆ˜ë„ ë‚®ì„ìˆ˜ë¡ +

    í•µì‹¬: í•œêµ­ì— ì´ë¯¸ ë§ì€ ì±„ë„ì´ ìˆê³  ì¡°íšŒìˆ˜ë„ ë†’ìœ¼ë©´ ë ˆë“œì˜¤ì…˜ (ë‚®ì€ ì ìˆ˜)
    """
    foreign_avg_views = foreign_data.get('avg_views', 0)
    korea_channel_count = korea_data.get('channel_count', 0)
    korea_avg_views = korea_data.get('avg_views', 0)

    # 1. í•´ì™¸ ì¸ê¸°ë„ ì ìˆ˜ (0-40ì )
    if foreign_avg_views >= 10_000_000:  # 1000ë§Œ ì´ìƒ
        popularity_score = 40
    elif foreign_avg_views >= 1_000_000:  # 100ë§Œ ì´ìƒ
        popularity_score = 30
    elif foreign_avg_views >= 100_000:  # 10ë§Œ ì´ìƒ
        popularity_score = 20
    else:
        popularity_score = 10

    # 2. í•œêµ­ í¬ì†Œì„± ì ìˆ˜ (0-60ì )
    # ì‹œì‘: 60ì ì—ì„œ ì±„ë„ìˆ˜ì™€ ì¡°íšŒìˆ˜ì— ë”°ë¼ ê°ì 
    scarcity_score = 60

    # 2-1. ì±„ë„ ìˆ˜ ê°ì  (ìµœëŒ€ -30ì )
    if korea_channel_count >= 50:
        scarcity_score -= 30  # 50ê°œ ì´ìƒ = ë ˆë“œì˜¤ì…˜
    elif korea_channel_count >= 30:
        scarcity_score -= 25
    elif korea_channel_count >= 20:
        scarcity_score -= 20
    elif korea_channel_count >= 10:
        scarcity_score -= 15
    elif korea_channel_count >= 5:
        scarcity_score -= 5

    # 2-2. í•œêµ­ í‰ê·  ì¡°íšŒìˆ˜ ê°ì  (ìµœëŒ€ -30ì )
    # í•œêµ­ì—ì„œ ì´ë¯¸ ë†’ì€ ì¡°íšŒìˆ˜ = ë ˆë“œì˜¤ì…˜
    if korea_avg_views >= 100_000_000:  # 1ì–µ ì´ìƒ
        scarcity_score -= 30
    elif korea_avg_views >= 50_000_000:  # 5000ë§Œ ì´ìƒ
        scarcity_score -= 25
    elif korea_avg_views >= 10_000_000:  # 1000ë§Œ ì´ìƒ
        scarcity_score -= 20
    elif korea_avg_views >= 1_000_000:  # 100ë§Œ ì´ìƒ
        scarcity_score -= 10
    elif korea_avg_views >= 100_000:  # 10ë§Œ ì´ìƒ
        scarcity_score -= 5

    scarcity_score = max(0, scarcity_score)

    final_score = popularity_score + scarcity_score
    return round(final_score, 2)


@tubelens_bp.route('/api/tubelens/blueocean', methods=['POST'])
def api_blueocean():
    """ë¸”ë£¨ì˜¤ì…˜ ì¹´í…Œê³ ë¦¬ ë°œêµ´ API

    í•´ì™¸ì—ì„œ ì¸ê¸°ìˆì§€ë§Œ í•œêµ­ì— ì•„ì§ ì—†ëŠ” ì¹´í…Œê³ ë¦¬ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
    """
    try:
        data = request.get_json()

        foreign_regions = data.get("foreignRegions", ["US"])  # ë¶„ì„í•  í•´ì™¸ êµ­ê°€
        video_type = data.get("videoType", "all")  # shorts, longform, all
        category_id = data.get("categoryId", "")  # YouTube ì¹´í…Œê³ ë¦¬
        max_results = min(int(data.get("maxResults", 50)), 100)
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]
        if not api_key:
            api_key = get_youtube_api_key()
        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        results = []

        for region in foreign_regions:
            # 1. í•´ì™¸ íŠ¸ë Œë”© ì˜ìƒ ìˆ˜ì§‘
            try:
                trending_params = {
                    "part": "snippet",
                    "chart": "mostPopular",
                    "regionCode": region,
                    "maxResults": max_results
                }
                if category_id:
                    trending_params["videoCategoryId"] = category_id

                trending_data = make_youtube_request("videos", trending_params, api_key)
                foreign_video_ids = [item["id"] for item in trending_data.get("items", [])]

                if not foreign_video_ids:
                    continue

                # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                foreign_videos = get_video_details(foreign_video_ids, api_key)

                # ì˜ìƒ íƒ€ì… í•„í„°ë§
                if video_type == "shorts":
                    foreign_videos = [v for v in foreign_videos if v["durationSeconds"] <= 60]
                elif video_type == "longform":
                    foreign_videos = [v for v in foreign_videos if v["durationSeconds"] > 60]

                if not foreign_videos:
                    continue

                # 2. í‚¤ì›Œë“œ ì¶”ì¶œ (íŠ¸ë Œë”©ì—ì„œ + ë‹ˆì¹˜ í‚¤ì›Œë“œ)
                extracted_keywords = extract_keywords_from_videos(foreign_videos)
                niche_keywords = NICHE_KEYWORDS.get(region, [])

                # ë‹ˆì¹˜ í‚¤ì›Œë“œì—ì„œ ëœë¤ 10ê°œ ì„ íƒ + ì¶”ì¶œ í‚¤ì›Œë“œ 5ê°œ
                import random
                selected_niche = random.sample(niche_keywords, min(10, len(niche_keywords))) if niche_keywords else []
                keywords = list(set(extracted_keywords[:5] + selected_niche))

                # í•´ì™¸ í†µê³„
                foreign_avg_views = sum(v["viewCount"] for v in foreign_videos) / len(foreign_videos)
                foreign_total_views = sum(v["viewCount"] for v in foreign_videos)

                # 3. ê° í‚¤ì›Œë“œì— ëŒ€í•´ í•´ì™¸/í•œêµ­ ê²€ìƒ‰ ë¹„êµ
                for keyword in keywords[:15]:  # ìƒìœ„ 15ê°œ í‚¤ì›Œë“œ
                    try:
                        # í•´ì™¸ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰ (ë‹ˆì¹˜ í‚¤ì›Œë“œìš©)
                        foreign_search_params = {
                            "part": "snippet",
                            "type": "video",
                            "q": keyword,
                            "regionCode": region,
                            "maxResults": 20,
                            "order": "viewCount"
                        }
                        if video_type == "shorts":
                            foreign_search_params["videoDuration"] = "short"
                        elif video_type == "longform":
                            foreign_search_params["videoDuration"] = "medium"

                        foreign_search = make_youtube_request("search", foreign_search_params, api_key)
                        foreign_search_ids = [item["id"]["videoId"] for item in foreign_search.get("items", [])
                                              if item.get("id", {}).get("videoId")]

                        # í•´ì™¸ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼ ìƒì„¸ ì •ë³´
                        foreign_keyword_videos = []
                        foreign_keyword_avg = 0
                        if foreign_search_ids:
                            foreign_keyword_videos = get_video_details(foreign_search_ids[:10], api_key)
                            if foreign_keyword_videos:
                                foreign_keyword_avg = sum(v["viewCount"] for v in foreign_keyword_videos) / len(foreign_keyword_videos)

                        # í•´ì™¸ì—ì„œ ì¸ê¸° ì—†ìœ¼ë©´ ìŠ¤í‚µ
                        if foreign_keyword_avg < 100000:  # 10ë§Œ ë¯¸ë§Œì´ë©´ ìŠ¤í‚µ
                            continue

                        # í•œêµ­ ê²€ìƒ‰
                        korea_search_params = {
                            "part": "snippet",
                            "type": "video",
                            "q": keyword,
                            "regionCode": "KR",
                            "maxResults": 50,
                            "order": "viewCount"
                        }

                        if video_type == "shorts":
                            korea_search_params["videoDuration"] = "short"
                        elif video_type == "longform":
                            korea_search_params["videoDuration"] = "medium"

                        korea_search = make_youtube_request("search", korea_search_params, api_key)
                        korea_items = korea_search.get("items", [])

                        # í•œêµ­ ì±„ë„ ìˆ˜ (ê³ ìœ  ì±„ë„)
                        korea_channels = set()
                        korea_video_ids = []
                        for item in korea_items:
                            if item.get("id", {}).get("videoId"):
                                korea_video_ids.append(item["id"]["videoId"])
                                korea_channels.add(item["snippet"]["channelId"])

                        # í•œêµ­ ì˜ìƒ ìƒì„¸ ì •ë³´
                        korea_videos = []
                        korea_avg_views = 0
                        if korea_video_ids:
                            korea_videos = get_video_details(korea_video_ids[:20], api_key)
                            if korea_videos:
                                korea_avg_views = sum(v["viewCount"] for v in korea_videos) / len(korea_videos)

                        # 4. ë¸”ë£¨ì˜¤ì…˜ ì ìˆ˜ ê³„ì‚°
                        foreign_data = {
                            "avg_views": foreign_keyword_avg,
                            "video_count": len(foreign_keyword_videos)
                        }
                        korea_data = {
                            "channel_count": len(korea_channels),
                            "video_count": len(korea_videos),
                            "avg_views": korea_avg_views
                        }

                        score = calculate_blueocean_score(foreign_data, korea_data)

                        # ë¸”ë£¨ì˜¤ì…˜ íŒì • (ì ìˆ˜ 30 ì´ìƒì´ë©´ í‘œì‹œ)
                        if score >= 30:
                            # ëŒ€í‘œ ì˜ìƒ ì„ íƒ (í•´ì™¸ í‚¤ì›Œë“œ ê²€ìƒ‰ ê²°ê³¼)
                            sample_videos = foreign_keyword_videos[:3]

                            results.append({
                                "keyword": keyword,
                                "region": region,
                                "blueoceanScore": score,
                                "foreignStats": {
                                    "avgViews": int(foreign_keyword_avg),
                                    "videoCount": len(foreign_keyword_videos),
                                    "totalViews": int(sum(v["viewCount"] for v in foreign_keyword_videos)) if foreign_keyword_videos else 0
                                },
                                "koreaStats": {
                                    "channelCount": len(korea_channels),
                                    "videoCount": len(korea_videos),
                                    "avgViews": int(korea_avg_views)
                                },
                                "sampleVideos": [{
                                    "videoId": v["videoId"],
                                    "title": v["title"],
                                    "thumbnail": v["thumbnail"],
                                    "viewCount": v["viewCount"],
                                    "channelTitle": v["channelTitle"]
                                } for v in sample_videos],
                                "recommendation": get_blueocean_recommendation(score, len(korea_channels))
                            })

                    except Exception as e:
                        print(f"í‚¤ì›Œë“œ '{keyword}' ë¶„ì„ ì‹¤íŒ¨: {e}")
                        continue

            except Exception as e:
                print(f"ì§€ì—­ '{region}' íŠ¸ë Œë”© ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                continue

        # ì ìˆ˜ ìˆœìœ¼ë¡œ ì •ë ¬
        results.sort(key=lambda x: x["blueoceanScore"], reverse=True)

        # ì¤‘ë³µ í‚¤ì›Œë“œ ì œê±° (ê°€ì¥ ë†’ì€ ì ìˆ˜ë§Œ ìœ ì§€)
        seen_keywords = set()
        unique_results = []
        for r in results:
            if r["keyword"] not in seen_keywords:
                seen_keywords.add(r["keyword"])
                unique_results.append(r)

        return jsonify({
            "success": True,
            "data": unique_results[:20],  # ìƒìœ„ 20ê°œ
            "message": f"ë¸”ë£¨ì˜¤ì…˜ ì¹´í…Œê³ ë¦¬ {len(unique_results)}ê°œ ë°œêµ´ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"ë¸”ë£¨ì˜¤ì…˜ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "message": str(e)}), 500


def get_blueocean_recommendation(score: float, korea_channels: int) -> str:
    """ë¸”ë£¨ì˜¤ì…˜ ì ìˆ˜ì— ë”°ë¥¸ ì¶”ì²œ ë©”ì‹œì§€"""
    if score >= 80:
        return "ğŸ”¥ ì´ˆë¸”ë£¨ì˜¤ì…˜! ì§€ê¸ˆ ë°”ë¡œ ì‹œì‘í•˜ì„¸ìš”"
    elif score >= 60:
        return "ğŸ’ ë§¤ìš° ìœ ë§! ì„ ì  íš¨ê³¼ ê¸°ëŒ€"
    elif score >= 40:
        return "âœ¨ ìœ ë§! ì°¨ë³„í™” ì „ëµ í•„ìš”"
    elif score >= 30:
        if korea_channels < 5:
            return "ğŸŒ± ì§„ì… ê°€ëŠ¥! í•œêµ­ ì±„ë„ ê±°ì˜ ì—†ìŒ"
        else:
            return "ğŸ“Š ê²€í†  í•„ìš”! ê²½ìŸ ë¶„ì„ ê¶Œì¥"
    else:
        return "âš ï¸ ë ˆë“œì˜¤ì…˜ ê°€ëŠ¥ì„±"


@tubelens_bp.route('/api/tubelens/blueocean-deep', methods=['POST'])
def api_blueocean_deep():
    """ë¸”ë£¨ì˜¤ì…˜ ì‹¬ì¸µ ë¶„ì„ API

    íŠ¹ì • í‚¤ì›Œë“œì— ëŒ€í•´ ë” ìƒì„¸í•œ ë¶„ì„ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
    """
    try:
        data = request.get_json()

        keyword = data.get("keyword", "")
        foreign_region = data.get("foreignRegion", "US")
        video_type = data.get("videoType", "all")
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not keyword:
            return jsonify({"success": False, "message": "í‚¤ì›Œë“œê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]
        if not api_key:
            api_key = get_youtube_api_key()
        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # í•´ì™¸ ê²€ìƒ‰
        foreign_params = {
            "part": "snippet",
            "type": "video",
            "q": keyword,
            "regionCode": foreign_region,
            "maxResults": 50,
            "order": "viewCount"
        }
        if video_type == "shorts":
            foreign_params["videoDuration"] = "short"
        elif video_type == "longform":
            foreign_params["videoDuration"] = "medium"

        foreign_search = make_youtube_request("search", foreign_params, api_key)
        foreign_video_ids = [item["id"]["videoId"] for item in foreign_search.get("items", [])
                           if item.get("id", {}).get("videoId")]
        foreign_videos = get_video_details(foreign_video_ids, api_key) if foreign_video_ids else []

        # í•œêµ­ ê²€ìƒ‰
        korea_params = foreign_params.copy()
        korea_params["regionCode"] = "KR"

        korea_search = make_youtube_request("search", korea_params, api_key)
        korea_video_ids = [item["id"]["videoId"] for item in korea_search.get("items", [])
                         if item.get("id", {}).get("videoId")]
        korea_videos = get_video_details(korea_video_ids, api_key) if korea_video_ids else []

        # ì±„ë„ ë¶„ì„
        foreign_channels = {}
        for v in foreign_videos:
            ch_id = v["channelId"]
            if ch_id not in foreign_channels:
                foreign_channels[ch_id] = {
                    "title": v["channelTitle"],
                    "subscribers": v["subscriberCount"],
                    "videos": []
                }
            foreign_channels[ch_id]["videos"].append(v)

        korea_channels = {}
        for v in korea_videos:
            ch_id = v["channelId"]
            if ch_id not in korea_channels:
                korea_channels[ch_id] = {
                    "title": v["channelTitle"],
                    "subscribers": v["subscriberCount"],
                    "videos": []
                }
            korea_channels[ch_id]["videos"].append(v)

        # í†µê³„ ê³„ì‚°
        foreign_stats = {
            "totalVideos": len(foreign_videos),
            "totalChannels": len(foreign_channels),
            "avgViews": int(sum(v["viewCount"] for v in foreign_videos) / len(foreign_videos)) if foreign_videos else 0,
            "maxViews": max((v["viewCount"] for v in foreign_videos), default=0),
            "avgSubscribers": int(sum(v["subscriberCount"] for v in foreign_videos) / len(foreign_videos)) if foreign_videos else 0,
            "topVideos": sorted(foreign_videos, key=lambda x: x["viewCount"], reverse=True)[:5]
        }

        korea_stats = {
            "totalVideos": len(korea_videos),
            "totalChannels": len(korea_channels),
            "avgViews": int(sum(v["viewCount"] for v in korea_videos) / len(korea_videos)) if korea_videos else 0,
            "maxViews": max((v["viewCount"] for v in korea_videos), default=0),
            "avgSubscribers": int(sum(v["subscriberCount"] for v in korea_videos) / len(korea_videos)) if korea_videos else 0,
            "topVideos": sorted(korea_videos, key=lambda x: x["viewCount"], reverse=True)[:5]
        }

        # ë¸”ë£¨ì˜¤ì…˜ ì ìˆ˜
        score = calculate_blueocean_score(
            {"avg_views": foreign_stats["avgViews"], "video_count": foreign_stats["totalVideos"]},
            {"channel_count": korea_stats["totalChannels"], "video_count": korea_stats["totalVideos"],
             "avg_views": korea_stats["avgViews"]}
        )

        # ê²½ìŸ ë¶„ì„
        competition_level = "ë‚®ìŒ" if korea_stats["totalChannels"] < 10 else "ì¤‘ê°„" if korea_stats["totalChannels"] < 30 else "ë†’ìŒ"

        return jsonify({
            "success": True,
            "data": {
                "keyword": keyword,
                "foreignRegion": foreign_region,
                "videoType": video_type,
                "blueoceanScore": score,
                "recommendation": get_blueocean_recommendation(score, korea_stats["totalChannels"]),
                "competitionLevel": competition_level,
                "foreignStats": foreign_stats,
                "koreaStats": korea_stats,
                "gap": {
                    "viewsGap": foreign_stats["avgViews"] - korea_stats["avgViews"],
                    "channelGap": foreign_stats["totalChannels"] - korea_stats["totalChannels"],
                    "opportunityScore": round((foreign_stats["avgViews"] / max(korea_stats["avgViews"], 1)) *
                                             (1 / max(korea_stats["totalChannels"], 1)) * 100, 2)
                }
            },
            "message": f"'{keyword}' ì‹¬ì¸µ ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"ë¸”ë£¨ì˜¤ì…˜ ì‹¬ì¸µ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "message": str(e)}), 500


@tubelens_bp.route('/api/tubelens/my-channel-analysis', methods=['POST'])
def api_my_channel_analysis():
    """ë‚´ ì±„ë„ ê²½ìŸë ¥ ë¶„ì„ API

    ë‚´ ì±„ë„ì´ ë¸”ë£¨ì˜¤ì…˜ì¸ì§€ ë ˆë“œì˜¤ì…˜ì¸ì§€ ë¶„ì„í•˜ê³ ,
    ìƒìœ„ ê²½ìŸ ì±„ë„ê³¼ ë¹„êµí•©ë‹ˆë‹¤.
    """
    try:
        data = request.get_json()

        channel_input = data.get("channelInput", "")  # ì±„ë„ URL ë˜ëŠ” ID
        api_keys = data.get("apiKeys", [])
        current_api_key_index = data.get("currentApiKeyIndex", 0)

        if not channel_input:
            return jsonify({"success": False, "message": "ì±„ë„ URL ë˜ëŠ” IDê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # API í‚¤ ì„ íƒ
        api_key = None
        if api_keys and len(api_keys) > current_api_key_index:
            api_key = api_keys[current_api_key_index]
        if not api_key:
            api_key = get_youtube_api_key()
        if not api_key:
            return jsonify({"success": False, "message": "API í‚¤ê°€ í•„ìš”í•©ë‹ˆë‹¤."}), 400

        # ì±„ë„ ID ì¶”ì¶œ
        channel_id = None
        if "youtube.com" in channel_input or "youtu.be" in channel_input:
            # URLì—ì„œ ì±„ë„ ID ì¶”ì¶œ
            if "/@" in channel_input:
                # í•¸ë“¤ í˜•ì‹: youtube.com/@channelhandle
                handle = channel_input.split("/@")[1].split("/")[0].split("?")[0]
                # í•¸ë“¤ë¡œ ì±„ë„ ê²€ìƒ‰
                search_result = make_youtube_request("search", {
                    "part": "snippet",
                    "type": "channel",
                    "q": handle,
                    "maxResults": 1
                }, api_key)
                if search_result.get("items"):
                    channel_id = search_result["items"][0]["snippet"]["channelId"]
            elif "/channel/" in channel_input:
                channel_id = channel_input.split("/channel/")[1].split("/")[0].split("?")[0]
            elif "/c/" in channel_input:
                custom_name = channel_input.split("/c/")[1].split("/")[0].split("?")[0]
                search_result = make_youtube_request("search", {
                    "part": "snippet",
                    "type": "channel",
                    "q": custom_name,
                    "maxResults": 1
                }, api_key)
                if search_result.get("items"):
                    channel_id = search_result["items"][0]["snippet"]["channelId"]
        else:
            # ì§ì ‘ ID ë˜ëŠ” ì´ë¦„ìœ¼ë¡œ ê²€ìƒ‰
            if channel_input.startswith("UC"):
                channel_id = channel_input
            else:
                search_result = make_youtube_request("search", {
                    "part": "snippet",
                    "type": "channel",
                    "q": channel_input,
                    "maxResults": 1
                }, api_key)
                if search_result.get("items"):
                    channel_id = search_result["items"][0]["snippet"]["channelId"]

        if not channel_id:
            return jsonify({"success": False, "message": "ì±„ë„ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        # 1. ë‚´ ì±„ë„ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
        channel_info = make_youtube_request("channels", {
            "part": "snippet,statistics,brandingSettings",
            "id": channel_id
        }, api_key)

        if not channel_info.get("items"):
            return jsonify({"success": False, "message": "ì±„ë„ ì •ë³´ë¥¼ ê°€ì ¸ì˜¬ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."}), 404

        my_channel = channel_info["items"][0]
        my_stats = {
            "channelId": channel_id,
            "title": my_channel["snippet"]["title"],
            "description": my_channel["snippet"].get("description", ""),
            "thumbnail": my_channel["snippet"]["thumbnails"]["default"]["url"],
            "subscriberCount": int(my_channel["statistics"].get("subscriberCount", 0)),
            "videoCount": int(my_channel["statistics"].get("videoCount", 0)),
            "viewCount": int(my_channel["statistics"].get("viewCount", 0)),
            "country": my_channel["snippet"].get("country", "KR")
        }

        # 2. ë‚´ ì±„ë„ì˜ ìµœê·¼ ì˜ìƒ ê°€ì ¸ì˜¤ê¸° (í‚¤ì›Œë“œ ì¶”ì¶œìš©)
        playlist_id = "UU" + channel_id[2:]  # ì—…ë¡œë“œ í”Œë ˆì´ë¦¬ìŠ¤íŠ¸
        playlist_items = make_youtube_request("playlistItems", {
            "part": "snippet",
            "playlistId": playlist_id,
            "maxResults": 20
        }, api_key)

        my_video_ids = [item["snippet"]["resourceId"]["videoId"]
                       for item in playlist_items.get("items", [])
                       if item["snippet"]["resourceId"]["kind"] == "youtube#video"]

        my_videos = get_video_details(my_video_ids, api_key) if my_video_ids else []

        # ë‚´ ì±„ë„ í‰ê·  ì¡°íšŒìˆ˜
        my_avg_views = sum(v["viewCount"] for v in my_videos) / len(my_videos) if my_videos else 0
        my_max_views = max((v["viewCount"] for v in my_videos), default=0)

        # 3. í‚¤ì›Œë“œ ì¶”ì¶œ (ì¹´í…Œê³ ë¦¬ íŒŒì•…)
        import re
        from collections import Counter

        all_words = []
        for video in my_videos:
            title = video.get('title', '').lower()
            # í•œê¸€ ë‹¨ì–´ë„ ì¶”ì¶œ
            words = re.findall(r'[a-zê°€-í£]{2,}', title)
            all_words.extend(words)

        # ë¶ˆìš©ì–´ ì œê±°
        stop_words = {'the', 'and', 'for', 'are', 'but', 'not', 'you', 'all',
                      'can', 'her', 'was', 'one', 'our', 'out', 'this', 'that',
                      'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ë˜ì„œ', 'ê·¸ëŸ°ë°', 'ì´ê²ƒ', 'ì €ê²ƒ', 'ìš°ë¦¬',
                      'ì˜¤ëŠ˜', 'ì§€ê¸ˆ', 'ì˜ìƒ', 'ì±„ë„', 'êµ¬ë…', 'ì¢‹ì•„ìš”', 'ì‹œì²­'}
        filtered_words = [w for w in all_words if w not in stop_words]
        word_counts = Counter(filtered_words)
        top_keywords = [word for word, count in word_counts.most_common(5)]

        # ì¹´í…Œê³ ë¦¬ ê°ì§€ (ë‰´ìŠ¤ í‚¤ì›Œë“œ ì²´í¬)
        news_keywords = {'ë‰´ìŠ¤', 'news', 'ì†ë³´', 'ì •ì¹˜', 'ê²½ì œ', 'ì‚¬íšŒ', 'ì´ìŠˆ', 'ë…¼ë€',
                         'ëŒ€í†µë ¹', 'êµ­íšŒ', 'ì •ë¶€', 'ì¥ê´€', 'ê¸°ì', 'ë³´ë„', 'ì·¨ì¬'}
        is_news = bool(set(filtered_words) & news_keywords)
        detected_category = "ë‰´ìŠ¤/ì‹œì‚¬" if is_news else "ì¼ë°˜"

        # 4. ê²½ìŸ ì±„ë„ ê²€ìƒ‰ (í•œêµ­ì—ì„œ ê°™ì€ ì¹´í…Œê³ ë¦¬)
        search_query = " ".join(top_keywords[:3]) if top_keywords else my_stats["title"]

        competitor_search = make_youtube_request("search", {
            "part": "snippet",
            "type": "channel",
            "q": search_query,
            "regionCode": "KR",
            "maxResults": 20,
            "order": "relevance"
        }, api_key)

        competitor_ids = [item["snippet"]["channelId"]
                         for item in competitor_search.get("items", [])
                         if item["snippet"]["channelId"] != channel_id][:10]

        # ê²½ìŸ ì±„ë„ ìƒì„¸ ì •ë³´
        competitors = []
        if competitor_ids:
            comp_info = make_youtube_request("channels", {
                "part": "snippet,statistics",
                "id": ",".join(competitor_ids)
            }, api_key)

            for ch in comp_info.get("items", []):
                comp_channel_id = ch["id"]
                # ê²½ìŸ ì±„ë„ì˜ ìµœê·¼ ì˜ìƒ ì¡°íšŒìˆ˜ ê°€ì ¸ì˜¤ê¸°
                comp_playlist_id = "UU" + comp_channel_id[2:]
                comp_playlist = make_youtube_request("playlistItems", {
                    "part": "snippet",
                    "playlistId": comp_playlist_id,
                    "maxResults": 10
                }, api_key)
                comp_video_ids = [item["snippet"]["resourceId"]["videoId"]
                                  for item in comp_playlist.get("items", [])
                                  if item["snippet"]["resourceId"]["kind"] == "youtube#video"]
                comp_videos = get_video_details(comp_video_ids[:5], api_key) if comp_video_ids else []
                comp_avg_views = sum(v["viewCount"] for v in comp_videos) / len(comp_videos) if comp_videos else 0

                # ì±„ë„ ìƒì„±ì¼ íŒŒì‹±
                published_at = ch["snippet"].get("publishedAt", "")
                created_date = published_at[:10] if published_at else "ì•Œ ìˆ˜ ì—†ìŒ"

                # ì—…ë¡œë“œ ì£¼ê¸° ê³„ì‚° (ìµœê·¼ 10ê°œ ì˜ìƒ ê¸°ì¤€)
                upload_frequency = "ì•Œ ìˆ˜ ì—†ìŒ"
                if len(comp_videos) >= 2:
                    from datetime import datetime
                    dates = []
                    for v in comp_videos:
                        try:
                            d = datetime.fromisoformat(v["publishedAt"].replace("Z", "+00:00"))
                            dates.append(d)
                        except:
                            pass
                    if len(dates) >= 2:
                        dates.sort(reverse=True)
                        total_days = (dates[0] - dates[-1]).days
                        if total_days > 0:
                            avg_days = total_days / (len(dates) - 1)
                            if avg_days <= 1:
                                upload_frequency = "ë§¤ì¼"
                            elif avg_days <= 3:
                                upload_frequency = f"ì£¼ {int(7/avg_days)}íšŒ"
                            elif avg_days <= 7:
                                upload_frequency = "ì£¼ 1íšŒ"
                            elif avg_days <= 14:
                                upload_frequency = "2ì£¼ 1íšŒ"
                            elif avg_days <= 30:
                                upload_frequency = "ì›” 1íšŒ"
                            else:
                                upload_frequency = f"{int(avg_days)}ì¼ë§ˆë‹¤"

                competitors.append({
                    "channelId": comp_channel_id,
                    "title": ch["snippet"]["title"],
                    "thumbnail": ch["snippet"]["thumbnails"]["default"]["url"],
                    "subscriberCount": int(ch["statistics"].get("subscriberCount", 0)),
                    "videoCount": int(ch["statistics"].get("videoCount", 0)),
                    "viewCount": int(ch["statistics"].get("viewCount", 0)),
                    "avgRecentViews": int(comp_avg_views),
                    "createdDate": created_date,
                    "uploadFrequency": upload_frequency,
                    "topVideo": comp_videos[0] if comp_videos else None
                })

        # êµ¬ë…ì ìˆœìœ¼ë¡œ ì •ë ¬
        competitors.sort(key=lambda x: x["subscriberCount"], reverse=True)

        # 5. ê²½ìŸë ¥ ë¶„ì„
        total_competitor_subs = sum(c["subscriberCount"] for c in competitors)
        avg_competitor_subs = total_competitor_subs / len(competitors) if competitors else 0
        avg_competitor_views = sum(c["avgRecentViews"] for c in competitors) / len(competitors) if competitors else 0

        # ë‚´ ìœ„ì¹˜ (ìˆœìœ„)
        my_rank = 1
        for comp in competitors:
            if comp["subscriberCount"] > my_stats["subscriberCount"]:
                my_rank += 1

        # ê²½ìŸ ê°•ë„ ì ìˆ˜ (0-100, ë†’ì„ìˆ˜ë¡ ê²½ìŸ ì¹˜ì—´)
        competition_intensity = 0

        # ê²½ìŸ ì±„ë„ ìˆ˜ì— ë”°ë¥¸ ì ìˆ˜
        if len(competitors) >= 10:
            competition_intensity += 30
        elif len(competitors) >= 5:
            competition_intensity += 20
        else:
            competition_intensity += 10

        # ìƒìœ„ ì±„ë„ êµ¬ë…ì ìˆ˜ì— ë”°ë¥¸ ì ìˆ˜
        if competitors and competitors[0]["subscriberCount"] >= 1000000:
            competition_intensity += 30
        elif competitors and competitors[0]["subscriberCount"] >= 100000:
            competition_intensity += 20
        elif competitors and competitors[0]["subscriberCount"] >= 10000:
            competition_intensity += 10

        # í‰ê·  ì¡°íšŒìˆ˜ ê²©ì°¨ì— ë”°ë¥¸ ì ìˆ˜
        if avg_competitor_views > 0 and my_avg_views > 0:
            view_ratio = avg_competitor_views / my_avg_views
            if view_ratio >= 10:
                competition_intensity += 40
            elif view_ratio >= 5:
                competition_intensity += 30
            elif view_ratio >= 2:
                competition_intensity += 20
            else:
                competition_intensity += 10

        competition_intensity = min(100, competition_intensity)

        # ì‹œì¥ ìƒíƒœ íŒì •
        if competition_intensity >= 70:
            market_status = "ë ˆë“œì˜¤ì…˜"
            market_color = "#dc2626"
            market_advice = "ê²½ìŸì´ ë§¤ìš° ì¹˜ì—´í•©ë‹ˆë‹¤. ì°¨ë³„í™”ëœ ì½˜í…ì¸  ì „ëµì´ í•„ìš”í•©ë‹ˆë‹¤."
        elif competition_intensity >= 50:
            market_status = "ê²½ìŸ ì‹œì¥"
            market_color = "#f59e0b"
            market_advice = "ì ë‹¹í•œ ê²½ìŸì´ ìˆìŠµë‹ˆë‹¤. ë‹ˆì¹˜í•œ ì£¼ì œë¡œ ì°¨ë³„í™”í•˜ì„¸ìš”."
        elif competition_intensity >= 30:
            market_status = "ì„±ì¥ ì‹œì¥"
            market_color = "#10b981"
            market_advice = "ì„±ì¥ ê°€ëŠ¥ì„±ì´ ìˆìŠµë‹ˆë‹¤. ê¾¸ì¤€í•œ ì—…ë¡œë“œê°€ ì¤‘ìš”í•©ë‹ˆë‹¤."
        else:
            market_status = "ë¸”ë£¨ì˜¤ì…˜"
            market_color = "#0ea5e9"
            market_advice = "ê²½ìŸì´ ì ìŠµë‹ˆë‹¤. ì„ ì  íš¨ê³¼ë¥¼ ë…¸ë ¤ë³´ì„¸ìš”!"

        # 6. ì„±ì¥ íŒ ìƒì„±
        growth_tips = []
        if my_avg_views < avg_competitor_views:
            growth_tips.append({
                "type": "ì¡°íšŒìˆ˜",
                "tip": f"í‰ê·  ì¡°íšŒìˆ˜ê°€ ê²½ìŸ ì±„ë„ ëŒ€ë¹„ ë‚®ìŠµë‹ˆë‹¤. ì œëª©ê³¼ ì¸ë„¤ì¼ ìµœì í™”ë¥¼ ê³ ë ¤í•˜ì„¸ìš”.",
                "myValue": int(my_avg_views),
                "avgValue": int(avg_competitor_views)
            })
        if my_stats["subscriberCount"] < avg_competitor_subs:
            growth_tips.append({
                "type": "êµ¬ë…ì",
                "tip": f"êµ¬ë… ìœ ë„ CTAë¥¼ ì˜ìƒì— ì¶”ê°€í•˜ê³ , ì»¤ë®¤ë‹ˆí‹° íƒ­ì„ í™œìš©í•˜ì„¸ìš”.",
                "myValue": my_stats["subscriberCount"],
                "avgValue": int(avg_competitor_subs)
            })

        # 7. ì„±ì¥ ì˜ˆì¸¡ (ê²½ìŸ ì±„ë„ ë°ì´í„° ê¸°ë°˜)
        growth_prediction = {
            "disclaimer": "ê²½ìŸ ì±„ë„ ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ì˜ˆì¸¡ì´ë©°, ì‹¤ì œ ê²°ê³¼ëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
            "scenarios": []
        }

        # ì—…ë¡œë“œ ì£¼ê¸°ë³„ ì„±ê³¼ ë¶„ì„
        frequency_performance = {}
        for comp in competitors:
            freq = comp.get("uploadFrequency", "ì•Œ ìˆ˜ ì—†ìŒ")
            if freq != "ì•Œ ìˆ˜ ì—†ìŒ" and comp["avgRecentViews"] > 0:
                if freq not in frequency_performance:
                    frequency_performance[freq] = []
                frequency_performance[freq].append({
                    "views": comp["avgRecentViews"],
                    "subs": comp["subscriberCount"]
                })

        # ê° ì‹œë‚˜ë¦¬ì˜¤ì— ëŒ€í•œ ì˜ˆì¸¡
        scenarios = [
            {"frequency": "ë§¤ì¼", "videos_per_month": 30},
            {"frequency": "ì£¼ 3íšŒ", "videos_per_month": 12},
            {"frequency": "ì£¼ 1íšŒ", "videos_per_month": 4},
        ]

        for scenario in scenarios:
            # ë¹„ìŠ·í•œ ì—…ë¡œë“œ ì£¼ê¸° ì±„ë„ë“¤ì˜ í‰ê·  ì¡°íšŒìˆ˜ ì°¾ê¸°
            matching_perfs = []
            for freq, perfs in frequency_performance.items():
                if "ë§¤ì¼" in freq and "ë§¤ì¼" in scenario["frequency"]:
                    matching_perfs.extend(perfs)
                elif "ì£¼" in freq and "ì£¼" in scenario["frequency"]:
                    matching_perfs.extend(perfs)

            # ì—†ìœ¼ë©´ ì „ì²´ í‰ê·  ì‚¬ìš©
            if not matching_perfs:
                expected_views = int(avg_competitor_views * 0.7)  # ê²½ìŸì í‰ê· ì˜ 70%ë¡œ ë³´ìˆ˜ì  ì˜ˆì¸¡
            else:
                expected_views = int(sum(p["views"] for p in matching_perfs) / len(matching_perfs) * 0.7)

            # ì›”ê°„ ì˜ˆìƒ ì¡°íšŒìˆ˜
            monthly_views = expected_views * scenario["videos_per_month"]

            # êµ¬ë… ì „í™˜ìœ¨ (ì—…ê³„ í‰ê·  1-2%)
            conversion_rate = 0.015
            monthly_new_subs = int(monthly_views * conversion_rate)

            # ëª©í‘œ ë„ë‹¬ ì˜ˆì¸¡ (10ë§Œ êµ¬ë…ì)
            current_subs = my_stats["subscriberCount"]
            target_subs = 100000
            if monthly_new_subs > 0:
                months_to_100k = max(0, (target_subs - current_subs) / monthly_new_subs)
            else:
                months_to_100k = -1  # ê³„ì‚° ë¶ˆê°€

            growth_prediction["scenarios"].append({
                "frequency": scenario["frequency"],
                "videosPerMonth": scenario["videos_per_month"],
                "expectedViewsPerVideo": expected_views,
                "monthlyViews": monthly_views,
                "monthlyNewSubs": monthly_new_subs,
                "monthsTo100k": round(months_to_100k, 1) if months_to_100k >= 0 else "ê³„ì‚° ë¶ˆê°€",
                "yearlyViews": monthly_views * 12,
                "yearlyNewSubs": monthly_new_subs * 12
            })

        # í˜„ì¬ ì±„ë„ê³¼ ìƒìœ„ ì±„ë„ ë¹„êµ
        if competitors:
            top_channel = competitors[0]
            growth_prediction["comparison"] = {
                "topChannelName": top_channel["title"],
                "topChannelSubs": top_channel["subscriberCount"],
                "topChannelViews": top_channel["avgRecentViews"],
                "topChannelFrequency": top_channel.get("uploadFrequency", "ì•Œ ìˆ˜ ì—†ìŒ"),
                "viewsGap": top_channel["avgRecentViews"] - int(my_avg_views),
                "subsGap": top_channel["subscriberCount"] - my_stats["subscriberCount"]
            }

        return jsonify({
            "success": True,
            "data": {
                "myChannel": {
                    **my_stats,
                    "avgRecentViews": int(my_avg_views),
                    "maxRecentViews": int(my_max_views),
                    "recentVideos": my_videos[:5]
                },
                "detectedCategory": detected_category,
                "topKeywords": top_keywords,
                "searchQuery": search_query,
                "competitors": competitors[:10],
                "analysis": {
                    "competitionIntensity": competition_intensity,
                    "marketStatus": market_status,
                    "marketColor": market_color,
                    "marketAdvice": market_advice,
                    "myRank": my_rank,
                    "totalCompetitors": len(competitors),
                    "avgCompetitorSubs": int(avg_competitor_subs),
                    "avgCompetitorViews": int(avg_competitor_views)
                },
                "growthTips": growth_tips,
                "growthPrediction": growth_prediction
            },
            "message": f"'{my_stats['title']}' ì±„ë„ ë¶„ì„ ì™„ë£Œ"
        })

    except Exception as e:
        print(f"ì±„ë„ ë¶„ì„ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "message": str(e)}), 500


# =====================================================
# YouTube Shorts â†’ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„± API
# =====================================================

def download_shorts_video(video_id: str, output_dir: str) -> tuple:
    """yt-dlp Python ë¼ì´ë¸ŒëŸ¬ë¦¬ë¡œ YouTube Shorts ë‹¤ìš´ë¡œë“œ

    Returns:
        tuple: (video_path, error_message)
               ì„±ê³µ ì‹œ: (ê²½ë¡œ, None)
               ì‹¤íŒ¨ ì‹œ: (None, ì—ëŸ¬ë©”ì‹œì§€)
    """
    output_template = os.path.join(output_dir, f"{video_id}.%(ext)s")
    cookies_file = None

    try:
        import yt_dlp

        base_opts = {
            'format': 'best[height<=1080]',
            'outtmpl': output_template,
            'noplaylist': True,
            'quiet': True,
            'no_warnings': True,
            'geo_bypass': True,
            'socket_timeout': 30,
        }

        url = f"https://www.youtube.com/shorts/{video_id}"

        # YouTube ì¿ í‚¤ ì„¤ì • (í™˜ê²½ë³€ìˆ˜ì—ì„œ ì½ê¸°)
        youtube_cookies = os.getenv("YOUTUBE_COOKIES", "")
        if youtube_cookies:
            cookies_file = os.path.join(output_dir, "cookies.txt")
            with open(cookies_file, "w") as f:
                f.write(youtube_cookies)
            cookie_lines = youtube_cookies.strip().split('\n')
            print(f"[SHORTS] ì¿ í‚¤ íŒŒì¼ ì¤€ë¹„: {len(cookie_lines)}ì¤„")

        # ë‹¤ì–‘í•œ í´ë¼ì´ì–¸íŠ¸ ì „ëµ ì‹œë„
        strategies = [
            # ì „ëµ 1: iOS í´ë¼ì´ì–¸íŠ¸ (ì¿ í‚¤ ì—†ì´)
            {
                'name': 'iOS',
                'opts': {
                    **base_opts,
                    'extractor_args': {'youtube': {'player_client': ['ios']}},
                    'http_headers': {'User-Agent': 'com.google.ios.youtube/19.09.3 (iPhone14,3; U; CPU iOS 17_4 like Mac OS X)'},
                }
            },
            # ì „ëµ 2: TV Embed í´ë¼ì´ì–¸íŠ¸ (ë´‡ ê°ì§€ ìš°íšŒì— íš¨ê³¼ì )
            {
                'name': 'TV Embed',
                'opts': {
                    **base_opts,
                    'extractor_args': {'youtube': {'player_client': ['tv_embedded']}},
                }
            },
            # ì „ëµ 3: Android í´ë¼ì´ì–¸íŠ¸
            {
                'name': 'Android',
                'opts': {
                    **base_opts,
                    'extractor_args': {'youtube': {'player_client': ['android']}},
                    'http_headers': {'User-Agent': 'com.google.android.youtube/19.09.37 (Linux; U; Android 12; Pixel 6)'},
                }
            },
            # ì „ëµ 4: Mobile Web í´ë¼ì´ì–¸íŠ¸
            {
                'name': 'Mobile Web',
                'opts': {
                    **base_opts,
                    'extractor_args': {'youtube': {'player_client': ['mweb']}},
                    'http_headers': {'User-Agent': 'Mozilla/5.0 (iPhone; CPU iPhone OS 17_4 like Mac OS X) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.4 Mobile/15E148 Safari/604.1'},
                }
            },
        ]

        # ì¿ í‚¤ê°€ ìˆìœ¼ë©´ ì¿ í‚¤ ë²„ì „ ì „ëµë„ ì¶”ê°€
        if cookies_file:
            strategies.append({
                'name': 'Web + Cookies',
                'opts': {
                    **base_opts,
                    'cookiefile': cookies_file,
                    'extractor_args': {'youtube': {'player_client': ['web']}},
                }
            })
            strategies.append({
                'name': 'iOS + Cookies',
                'opts': {
                    **base_opts,
                    'cookiefile': cookies_file,
                    'extractor_args': {'youtube': {'player_client': ['ios']}},
                }
            })

        for strategy in strategies:
            print(f"[SHORTS] ë‹¤ìš´ë¡œë“œ ì‹œë„ ({strategy['name']}): {url}")
            try:
                with yt_dlp.YoutubeDL(strategy['opts']) as ydl:
                    info = ydl.extract_info(url, download=True)
                    if info:
                        for ext in ['mp4', 'webm', 'mkv']:
                            check_path = os.path.join(output_dir, f"{video_id}.{ext}")
                            if os.path.exists(check_path):
                                print(f"[SHORTS] {strategy['name']} í´ë¼ì´ì–¸íŠ¸ë¡œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ!")
                                return (check_path, None)
            except Exception as e:
                error_msg = str(e)
                # ë´‡ ê°ì§€ê°€ ì•„ë‹Œ ë‹¤ë¥¸ ì—ëŸ¬ë©´ ë°”ë¡œ ë°˜í™˜
                if "Sign in to confirm" not in error_msg and "bot" not in error_msg.lower():
                    if "Private video" in error_msg:
                        return (None, "ë¹„ê³µê°œ ì˜ìƒì…ë‹ˆë‹¤")
                    elif "Video unavailable" in error_msg:
                        return (None, "ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
                    elif "age" in error_msg.lower():
                        return (None, "ì—°ë ¹ ì œí•œ ì˜ìƒì…ë‹ˆë‹¤")
                print(f"[SHORTS] {strategy['name']} ì‹¤íŒ¨: {error_msg[:80]}...")

        # íŒŒì¼ ê²€ìƒ‰ (ë‹¤ìš´ë¡œë“œë˜ì—ˆì§€ë§Œ ê°ì§€ ëª»í•œ ê²½ìš°)
        import glob
        files = glob.glob(os.path.join(output_dir, f"{video_id}.*"))
        video_files = [f for f in files if f.endswith(('.mp4', '.webm', '.mkv'))]
        if video_files:
            print(f"[SHORTS] ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {video_files[0]}")
            return (video_files[0], None)

        # Fallback: cobalt.tools API ì‚¬ìš©
        print(f"[SHORTS] yt-dlp ì‹¤íŒ¨, cobalt.tools APIë¡œ ì‹œë„...")
        try:
            import requests

            # YouTube í‘œì¤€ URL í˜•ì‹ìœ¼ë¡œ ë³€í™˜
            youtube_url = f"https://www.youtube.com/watch?v={video_id}"

            cobalt_response = requests.post(
                "https://api.cobalt.tools/",
                headers={
                    "Accept": "application/json",
                    "Content-Type": "application/json",
                },
                json={
                    "url": youtube_url,
                    "videoQuality": "720",
                    "filenameStyle": "basic",
                },
                timeout=30
            )

            print(f"[SHORTS] cobalt.tools ì‘ë‹µ: {cobalt_response.status_code}")

            if cobalt_response.status_code == 200:
                cobalt_data = cobalt_response.json()
                print(f"[SHORTS] cobalt.tools ë°ì´í„°: status={cobalt_data.get('status')}")

                if cobalt_data.get("status") in ["tunnel", "redirect", "stream"]:
                    download_url = cobalt_data.get("url")
                    if download_url:
                        print(f"[SHORTS] cobalt.toolsì—ì„œ ë‹¤ìš´ë¡œë“œ URL íšë“")
                        # íŒŒì¼ ë‹¤ìš´ë¡œë“œ
                        video_response = requests.get(download_url, timeout=120, stream=True)
                        if video_response.status_code == 200:
                            output_path = os.path.join(output_dir, f"{video_id}.mp4")
                            with open(output_path, "wb") as f:
                                for chunk in video_response.iter_content(chunk_size=8192):
                                    f.write(chunk)
                            if os.path.exists(output_path) and os.path.getsize(output_path) > 1000:
                                print(f"[SHORTS] cobalt.toolsë¡œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
                                return (output_path, None)
                elif cobalt_data.get("status") == "error":
                    error_info = cobalt_data.get("error", {})
                    print(f"[SHORTS] cobalt.tools ì—ëŸ¬: {error_info}")
                elif cobalt_data.get("status") == "picker":
                    # ì—¬ëŸ¬ ìŠ¤íŠ¸ë¦¼ ì„ íƒ í•„ìš”í•œ ê²½ìš°
                    picker = cobalt_data.get("picker", [])
                    if picker:
                        download_url = picker[0].get("url")
                        if download_url:
                            print(f"[SHORTS] cobalt.tools pickerì—ì„œ ì²« ë²ˆì§¸ ì˜µì…˜ ì„ íƒ")
                            video_response = requests.get(download_url, timeout=120, stream=True)
                            if video_response.status_code == 200:
                                output_path = os.path.join(output_dir, f"{video_id}.mp4")
                                with open(output_path, "wb") as f:
                                    for chunk in video_response.iter_content(chunk_size=8192):
                                        f.write(chunk)
                                if os.path.exists(output_path) and os.path.getsize(output_path) > 1000:
                                    print(f"[SHORTS] cobalt.toolsë¡œ ë‹¤ìš´ë¡œë“œ ì™„ë£Œ: {output_path}")
                                    return (output_path, None)
            else:
                # ì—ëŸ¬ ì‘ë‹µ ë‚´ìš© ë¡œê¹…
                try:
                    error_body = cobalt_response.json()
                    print(f"[SHORTS] cobalt.tools ì—ëŸ¬ ì‘ë‹µ: {error_body}")
                except:
                    print(f"[SHORTS] cobalt.tools ì—ëŸ¬: {cobalt_response.status_code}, {cobalt_response.text[:200]}")
        except Exception as cobalt_error:
            print(f"[SHORTS] cobalt.tools ì‹¤íŒ¨: {cobalt_error}")

        print(f"[SHORTS] ëª¨ë“  ë‹¤ìš´ë¡œë“œ ì „ëµ ì‹¤íŒ¨")
        return (None, "YouTube ë´‡ ê°ì§€ë¡œ ëª¨ë“  ë‹¤ìš´ë¡œë“œ ë°©ì‹ì´ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ì£¼ì„¸ìš”.")

    except Exception as e:
        error_str = str(e)
        print(f"[SHORTS] ë‹¤ìš´ë¡œë“œ ì˜¤ë¥˜: {error_str}")
        import traceback
        traceback.print_exc()

        # ì—ëŸ¬ íƒ€ì…ì— ë”°ë¥¸ ë©”ì‹œì§€ ë¶„ë¥˜
        if "Sign in to confirm" in error_str or "bot" in error_str.lower():
            return (None, "YouTube ë´‡ ê°ì§€ë¡œ ì°¨ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤. YOUTUBE_COOKIES í™˜ê²½ë³€ìˆ˜ë¥¼ ì—…ë°ì´íŠ¸í•´ì£¼ì„¸ìš”.")
        elif "Private video" in error_str:
            return (None, "ë¹„ê³µê°œ ì˜ìƒì…ë‹ˆë‹¤")
        elif "Video unavailable" in error_str:
            return (None, "ì˜ìƒì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤")
        elif "age" in error_str.lower():
            return (None, "ì—°ë ¹ ì œí•œ ì˜ìƒì…ë‹ˆë‹¤. ë¡œê·¸ì¸ì´ í•„ìš”í•©ë‹ˆë‹¤.")
        else:
            return (None, f"ë‹¤ìš´ë¡œë“œ ì‹¤íŒ¨: {error_str[:100]}")


def extract_frames_by_scene(video_path: str, output_dir: str, threshold: float = 0.3) -> List[Dict[str, Any]]:
    """FFmpegë¡œ ì”¬ ë³€ê²½ ê°ì§€í•˜ì—¬ í”„ë ˆì„ ì¶”ì¶œ (ì”¬ ê¸°ë°˜)"""
    frames = []

    try:
        # ì˜ìƒ ê¸¸ì´ í™•ì¸
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "json", video_path
        ]
        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
        probe_data = json.loads(probe_result.stdout)
        duration = float(probe_data.get("format", {}).get("duration", 60))

        print(f"[SHORTS] ì˜ìƒ ê¸¸ì´: {duration:.1f}ì´ˆ, ì”¬ ê°ì§€ ì„ê³„ê°’: {threshold}")

        # ì²« í”„ë ˆì„ì€ í•­ìƒ í¬í•¨
        first_frame_path = os.path.join(output_dir, "frame_000.jpg")
        cmd_first = [
            "ffmpeg", "-y",
            "-ss", "0",
            "-i", video_path,
            "-vframes", "1",
            "-q:v", "2",
            first_frame_path
        ]
        subprocess.run(cmd_first, capture_output=True, text=True, timeout=30)

        if os.path.exists(first_frame_path):
            frames.append({
                "index": 0,
                "time": 0.0,
                "path": first_frame_path
            })

        # ì”¬ ë³€ê²½ ê°ì§€í•˜ì—¬ í”„ë ˆì„ ì¶”ì¶œ
        # select í•„í„°: ì”¬ ë³€í™”ê°€ threshold ì´ìƒì¼ ë•Œë§Œ í”„ë ˆì„ ì„ íƒ
        # showinfo í•„í„°: íƒ€ì„ìŠ¤íƒ¬í”„ ì •ë³´ ì¶œë ¥
        scene_frames_pattern = os.path.join(output_dir, "scene_%03d.jpg")

        cmd = [
            "ffmpeg", "-y",
            "-i", video_path,
            "-vf", f"select='gt(scene,{threshold})',showinfo",
            "-vsync", "vfr",
            "-q:v", "2",
            scene_frames_pattern
        ]

        result = subprocess.run(cmd, capture_output=True, text=True, timeout=120)

        # showinfo ì¶œë ¥ì—ì„œ íƒ€ì„ìŠ¤íƒ¬í”„ ì¶”ì¶œ
        # í˜•ì‹: [Parsed_showinfo_1 @ 0x...] n:   1 pts:  12345 pts_time:3.456
        import re
        timestamps = []
        for line in result.stderr.split('\n'):
            match = re.search(r'pts_time:(\d+\.?\d*)', line)
            if match:
                timestamps.append(float(match.group(1)))

        # ì¶”ì¶œëœ ì”¬ í”„ë ˆì„ë“¤ ì •ë¦¬
        frame_index = 1
        for i, ts in enumerate(timestamps):
            scene_path = os.path.join(output_dir, f"scene_{i+1:03d}.jpg")
            if os.path.exists(scene_path):
                # íŒŒì¼ëª… í†µì¼
                new_path = os.path.join(output_dir, f"frame_{frame_index:03d}.jpg")
                os.rename(scene_path, new_path)
                frames.append({
                    "index": frame_index,
                    "time": round(ts, 1),
                    "path": new_path
                })
                frame_index += 1

        # ì”¬ì´ ê±°ì˜ ì—†ëŠ” ê²½ìš° (ë‹¨ì¼ ì”¬ ì˜ìƒ) ì¤‘ê°„ í”„ë ˆì„ ì¶”ê°€
        if len(frames) < 3 and duration > 10:
            print(f"[SHORTS] ì”¬ ë³€í™” ì ìŒ, ì¶”ê°€ í”„ë ˆì„ ìƒ˜í”Œë§...")
            mid_times = [duration * 0.33, duration * 0.66]
            for t in mid_times:
                extra_path = os.path.join(output_dir, f"frame_{frame_index:03d}.jpg")
                cmd_extra = [
                    "ffmpeg", "-y",
                    "-ss", str(t),
                    "-i", video_path,
                    "-vframes", "1",
                    "-q:v", "2",
                    extra_path
                ]
                subprocess.run(cmd_extra, capture_output=True, text=True, timeout=30)
                if os.path.exists(extra_path):
                    frames.append({
                        "index": frame_index,
                        "time": round(t, 1),
                        "path": extra_path
                    })
                    frame_index += 1

        # ì‹œê°„ìˆœ ì •ë ¬
        frames.sort(key=lambda x: x["time"])
        for i, f in enumerate(frames):
            f["index"] = i

        print(f"[SHORTS] ì”¬ ê¸°ë°˜ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {len(frames)}ê°œ")
        return frames

    except Exception as e:
        print(f"[SHORTS] í”„ë ˆì„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return frames


def extract_frames_by_interval(video_path: str, output_dir: str, interval: int = 5) -> List[Dict[str, Any]]:
    """FFmpegë¡œ Nì´ˆ ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ (ì‹œê°„ ê¸°ë°˜)"""
    frames = []

    try:
        # ì˜ìƒ ê¸¸ì´ í™•ì¸
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "json", video_path
        ]
        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
        probe_data = json.loads(probe_result.stdout)
        duration = float(probe_data.get("format", {}).get("duration", 60))

        print(f"[SHORTS] ì˜ìƒ ê¸¸ì´: {duration:.1f}ì´ˆ, ê°„ê²©: {interval}ì´ˆ")

        # Nì´ˆ ê°„ê²©ìœ¼ë¡œ í”„ë ˆì„ ì¶”ì¶œ
        current_time = 0
        frame_index = 0

        while current_time < duration:
            frame_path = os.path.join(output_dir, f"frame_{frame_index:03d}.jpg")

            cmd = [
                "ffmpeg", "-y",
                "-ss", str(current_time),
                "-i", video_path,
                "-vframes", "1",
                "-q:v", "2",
                frame_path
            ]

            subprocess.run(cmd, capture_output=True, text=True, timeout=30)

            if os.path.exists(frame_path):
                frames.append({
                    "index": frame_index,
                    "time": current_time,
                    "path": frame_path
                })
                frame_index += 1

            current_time += interval

        print(f"[SHORTS] ì‹œê°„ ê¸°ë°˜ í”„ë ˆì„ ì¶”ì¶œ ì™„ë£Œ: {len(frames)}ê°œ")
        return frames

    except Exception as e:
        print(f"[SHORTS] í”„ë ˆì„ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
        return frames


def analyze_frame_with_gemini(frame_path: str) -> Optional[str]:
    """OpenRouter Gemini Visionìœ¼ë¡œ í”„ë ˆì„ ë¶„ì„"""
    try:
        import requests
        import PIL.Image
        import io

        # OpenRouter API í‚¤ ì„¤ì •
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            print("[SHORTS] OpenRouter API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤")
            return None

        # ì´ë¯¸ì§€ ë¡œë“œ ë° base64 ì¸ì½”ë”©
        image = PIL.Image.open(frame_path)

        with open(frame_path, "rb") as f:
            image_bytes = f.read()
        image_base64 = base64.b64encode(image_bytes).decode('utf-8')

        # ì´ë¯¸ì§€ í¬ë§· ê°ì§€
        img_format = image.format or 'PNG'
        mime_type = f"image/{img_format.lower()}"
        if img_format.upper() == 'JPG':
            mime_type = 'image/jpeg'

        prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì´ë¯¸ì§€ ìƒì„± AIì— ì‚¬ìš©í•  í”„ë¡¬í”„íŠ¸ë¥¼ ë§Œë“¤ì–´ì£¼ì„¸ìš”.

ë‹¤ìŒ ìš”ì†Œë“¤ì„ í¬í•¨í•´ì£¼ì„¸ìš”:
- ì£¼ìš” í”¼ì‚¬ì²´ (ì‚¬ëŒ, ë¬¼ì²´, ì¥ë©´)
- ë°°ê²½ ë° í™˜ê²½
- ì¡°ëª… ìŠ¤íƒ€ì¼
- ìƒ‰ê° ë° ë¶„ìœ„ê¸°
- ì¹´ë©”ë¼ ì•µê¸€/êµ¬ë„

ì‘ë‹µ í˜•ì‹: ì˜ì–´ë¡œ ëœ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ë§Œ ì¶œë ¥ (ì„¤ëª… ì—†ì´)
ì˜ˆì‹œ: "Young woman in casual outfit, urban cafe background, natural window lighting, warm color palette, medium shot, candid moment"
"""

        # OpenRouter API í˜¸ì¶œ
        response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "google/gemini-2.0-flash-001",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{mime_type};base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 500,
                "temperature": 0.7
            },
            timeout=30
        )

        if response.status_code == 200:
            response_data = response.json()
            content = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")
            if content:
                return content.strip()

        print(f"[SHORTS] OpenRouter API ì˜¤ë¥˜: {response.status_code} - {response.text}")
        return None

    except Exception as e:
        print(f"[SHORTS] OpenRouter ë¶„ì„ ì˜¤ë¥˜: {e}")
        return None


def refine_prompt_with_gpt(raw_prompt: str, context: str = "") -> Optional[str]:
    """GPTë¡œ í”„ë¡¬í”„íŠ¸ ì •ì œ (ì„ íƒì )"""
    try:
        client = OpenAI()

        system_prompt = """You are an expert at creating image generation prompts.
Refine the given prompt to be more specific and effective for AI image generation.
Keep it concise (under 100 words) and in English.
Focus on visual elements, style, lighting, and composition.
Output only the refined prompt, nothing else."""

        response = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role": "system", "content": system_prompt},
                {"role": "user", "content": f"Refine this prompt:\n{raw_prompt}\n\nContext: {context}"}
            ],
            temperature=0.7,
            max_tokens=200
        )

        if response.choices:
            return response.choices[0].message.content.strip()

        return raw_prompt

    except Exception as e:
        print(f"[SHORTS] GPT ì •ì œ ì˜¤ë¥˜: {e}")
        return raw_prompt


@tubelens_bp.route('/api/tubelens/shorts-to-prompts', methods=['POST'])
def shorts_to_prompts():
    """YouTube Shorts URLì„ ë¶„ì„í•˜ì—¬ ì”¬ë³„ ì´ë¯¸ì§€ í”„ë¡¬í”„íŠ¸ ìƒì„±

    Request:
        {
            "url": "https://youtube.com/shorts/xxx",
            "mode": "scene",  // "scene" (ì”¬ ê¸°ë°˜, ê¸°ë³¸ê°’) ë˜ëŠ” "interval" (ì‹œê°„ ê¸°ë°˜)
            "interval": 5,    // ì‹œê°„ ê¸°ë°˜ ëª¨ë“œì¼ ë•Œ ì´ˆ ë‹¨ìœ„ (ê¸°ë³¸ê°’: 5)
            "threshold": 0.3, // ì”¬ ê¸°ë°˜ ëª¨ë“œì¼ ë•Œ ê°ì§€ ë¯¼ê°ë„ (0.1~0.5, ë‚®ì„ìˆ˜ë¡ ë¯¼ê°)
            "refine": false   // GPTë¡œ í”„ë¡¬í”„íŠ¸ ì •ì œ ì—¬ë¶€ (ê¸°ë³¸ê°’: false)
        }

    Response:
        {
            "success": true,
            "videoId": "xxx",
            "duration": 58,
            "mode": "scene",
            "prompts": [
                {"time": 0, "prompt": "..."},
                {"time": 3.5, "prompt": "..."}
            ]
        }
    """
    temp_dir = None

    try:
        data = request.get_json() or {}
        url = data.get("url", "")
        mode = data.get("mode", "scene")  # ê¸°ë³¸ê°’: ì”¬ ê¸°ë°˜
        interval = int(data.get("interval", 5))
        threshold = float(data.get("threshold", 0.3))
        refine = data.get("refine", False)

        # íŒŒë¼ë¯¸í„° ì œí•œ
        interval = max(2, min(30, interval))
        threshold = max(0.1, min(0.5, threshold))

        # Video ID ì¶”ì¶œ
        video_id = extract_video_id(url)
        if not video_id:
            return jsonify({
                "success": False,
                "message": "ìœ íš¨í•œ YouTube Shorts URLì´ ì•„ë‹™ë‹ˆë‹¤"
            }), 400

        print(f"[SHORTS] ë¶„ì„ ì‹œì‘: {video_id}, ëª¨ë“œ: {mode}")

        # ì„ì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
        temp_dir = tempfile.mkdtemp(prefix="shorts_")

        # 1. ì˜ìƒ ë‹¤ìš´ë¡œë“œ
        print(f"[SHORTS] ì˜ìƒ ë‹¤ìš´ë¡œë“œ ì¤‘...")
        video_path, download_error = download_shorts_video(video_id, temp_dir)

        if not video_path:
            return jsonify({
                "success": False,
                "message": download_error or "ì˜ìƒ ë‹¤ìš´ë¡œë“œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."
            }), 400

        # 2. í”„ë ˆì„ ì¶”ì¶œ (ëª¨ë“œì— ë”°ë¼ ë‹¤ë¥¸ ë°©ì‹ ì‚¬ìš©)
        print(f"[SHORTS] í”„ë ˆì„ ì¶”ì¶œ ì¤‘... (ëª¨ë“œ: {mode})")
        if mode == "interval":
            frames = extract_frames_by_interval(video_path, temp_dir, interval)
        else:
            frames = extract_frames_by_scene(video_path, temp_dir, threshold)

        if not frames:
            return jsonify({
                "success": False,
                "message": "í”„ë ˆì„ ì¶”ì¶œì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"
            }), 500

        # 3. ê° í”„ë ˆì„ ë¶„ì„
        print(f"[SHORTS] {len(frames)}ê°œ í”„ë ˆì„ ë¶„ì„ ì¤‘...")
        prompts = []

        for frame in frames:
            print(f"[SHORTS] í”„ë ˆì„ {frame['index']} ë¶„ì„ ì¤‘ ({frame['time']}ì´ˆ)...")

            raw_prompt = analyze_frame_with_gemini(frame["path"])

            if raw_prompt:
                # GPTë¡œ ì •ì œ (ì˜µì…˜)
                if refine:
                    final_prompt = refine_prompt_with_gpt(raw_prompt)
                else:
                    final_prompt = raw_prompt

                prompts.append({
                    "time": frame["time"],
                    "prompt": final_prompt
                })
            else:
                prompts.append({
                    "time": frame["time"],
                    "prompt": "[ë¶„ì„ ì‹¤íŒ¨]"
                })

        # ì˜ìƒ ê¸¸ì´ ê³„ì‚°
        probe_cmd = [
            "ffprobe", "-v", "error",
            "-show_entries", "format=duration",
            "-of", "json", video_path
        ]
        probe_result = subprocess.run(probe_cmd, capture_output=True, text=True, timeout=30)
        probe_data = json.loads(probe_result.stdout)
        duration = float(probe_data.get("format", {}).get("duration", 0))

        print(f"[SHORTS] ë¶„ì„ ì™„ë£Œ: {len(prompts)}ê°œ í”„ë¡¬í”„íŠ¸ ìƒì„±")

        return jsonify({
            "success": True,
            "videoId": video_id,
            "duration": round(duration, 1),
            "mode": mode,
            "frameCount": len(prompts),
            "prompts": prompts
        })

    except Exception as e:
        print(f"[SHORTS] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({
            "success": False,
            "message": str(e)
        }), 500

    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_dir and os.path.exists(temp_dir):
            try:
                shutil.rmtree(temp_dir)
            except Exception as cleanup_error:
                print(f"[SHORTS] ì„ì‹œ íŒŒì¼ ì •ë¦¬ ì‹¤íŒ¨: {cleanup_error}")


@tubelens_bp.route('/tubelens/shorts-prompt-generator')
def shorts_prompt_generator_page():
    """Shorts í”„ë¡¬í”„íŠ¸ ìƒì„±ê¸° í˜ì´ì§€"""
    return render_template('tubelens/shorts_prompt_generator.html')


@tubelens_bp.route('/api/tubelens/image-to-prompt', methods=['POST'])
def image_to_prompt():
    """ì´ë¯¸ì§€ë¥¼ ë¶„ì„í•˜ì—¬ ì„¸ë°€í•œ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ ìƒì„±

    Request:
        multipart/form-data with 'image' file
        ë˜ëŠ” JSON with 'image_base64' (base64 encoded image)

    Response:
        {
            "success": true,
            "prompt": "...",
            "analysis": {
                "subject": "...",
                "background": "...",
                "lighting": "...",
                "camera": "...",
                "color": "...",
                "mood": "...",
                "style": "..."
            }
        }
    """
    try:
        import PIL.Image
        import io
        import requests

        # OpenRouter API í‚¤ í™•ì¸
        api_key = os.getenv("OPENROUTER_API_KEY")
        if not api_key:
            return jsonify({"success": False, "message": "OpenRouter API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤"}), 500

        # ì´ë¯¸ì§€ ë¡œë“œ (íŒŒì¼ ì—…ë¡œë“œ ë˜ëŠ” base64)
        image = None
        image_base64 = None

        if request.files and 'image' in request.files:
            file = request.files['image']
            if file.filename:
                image_bytes = file.read()
                image = PIL.Image.open(io.BytesIO(image_bytes))
                image_base64 = base64.b64encode(image_bytes).decode('utf-8')
        elif request.is_json:
            data = request.get_json()
            if data.get('image_base64'):
                image_base64 = data['image_base64']
                image_data = base64.b64decode(image_base64)
                image = PIL.Image.open(io.BytesIO(image_data))

        if not image or not image_base64:
            return jsonify({"success": False, "message": "ì´ë¯¸ì§€ë¥¼ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”"}), 400

        # ì´ë¯¸ì§€ í¬ë§· ê°ì§€
        img_format = image.format or 'PNG'
        mime_type = f"image/{img_format.lower()}"
        if img_format.upper() == 'JPG':
            mime_type = 'image/jpeg'

        print(f"[IMAGE-PROMPT] ì´ë¯¸ì§€ ë¶„ì„ ì‹œì‘: {image.size}, í¬ë§·: {mime_type}")

        analysis_prompt = """ì´ ì´ë¯¸ì§€ë¥¼ ì „ë¬¸ ì‚¬ì§„ì‘ê°€/ì˜ìƒ ê°ë…ì˜ ê´€ì ì—ì„œ ë§¤ìš° ì„¸ë°€í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”.

ë‹¤ìŒ í•­ëª©ë“¤ì„ ê°ê° ìƒì„¸í•˜ê²Œ ë¶„ì„í•´ì£¼ì„¸ìš”:

1. **í”¼ì‚¬ì²´ (Subject)**
   - ì£¼ìš” í”¼ì‚¬ì²´ (ì‚¬ëŒ, ë¬¼ì²´, ë™ë¬¼ ë“±)
   - ìì„¸, í‘œì •, ë™ì‘
   - ì˜ìƒ, ì•¡ì„¸ì„œë¦¬, ì†Œí’ˆ

2. **ë°°ê²½ (Background)**
   - ì¥ì†Œ/í™˜ê²½ (ì‹¤ë‚´/ì‹¤ì™¸, êµ¬ì²´ì  ì¥ì†Œ)
   - ë°°ê²½ ìš”ì†Œë“¤
   - ì‹¬ë„(DOF) - ë°°ê²½ íë¦¼ ì •ë„

3. **ì¡°ëª… (Lighting)**
   - ê´‘ì› ìœ í˜• (ìì—°ê´‘, ì¸ê³µì¡°ëª…, ìŠ¤íŠœë””ì˜¤ ë“±)
   - ì¡°ëª… ë°©í–¥ (ì •ë©´ê´‘, ì¸¡ê´‘, ì—­ê´‘, ë¦¼ë¼ì´íŠ¸ ë“±)
   - ì¡°ëª… ê°•ë„ (í•˜ë“œë¼ì´íŠ¸, ì†Œí”„íŠ¸ë¼ì´íŠ¸)
   - ê·¸ë¦¼ì íŠ¹ì„±

4. **ì¹´ë©”ë¼/êµ¬ë„ (Camera)**
   - ì¹´ë©”ë¼ ì•µê¸€ (ì•„ì´ë ˆë²¨, í•˜ì´ì•µê¸€, ë¡œìš°ì•µê¸€, ë²„ë“œì•„ì´ ë“±)
   - ìƒ· íƒ€ì… (í´ë¡œì¦ˆì—…, ë¯¸ë””ì—„ìƒ·, í’€ìƒ·, ì™€ì´ë“œìƒ· ë“±)
   - êµ¬ë„ (ì‚¼ë“±ë¶„ë²•, ì¤‘ì•™ë°°ì¹˜, ëŒ€ì¹­, ë¦¬ë”©ë¼ì¸ ë“±)
   - ì´ˆì ê±°ë¦¬ ëŠë‚Œ (ê´‘ê°, í‘œì¤€, ë§ì›)

5. **ìƒ‰ê° (Color)**
   - ì „ì²´ì ì¸ ìƒ‰ì¡° (ì›œí†¤, ì¿¨í†¤, ë‰´íŠ¸ëŸ´)
   - ì£¼ìš” ìƒ‰ìƒë“¤
   - ì±„ë„, ëŒ€ë¹„
   - ìƒ‰ìƒ ê·¸ë ˆì´ë”© ìŠ¤íƒ€ì¼

6. **ë¶„ìœ„ê¸°/ê°ì • (Mood)**
   - ì „ì²´ì ì¸ ë¶„ìœ„ê¸°
   - ì „ë‹¬í•˜ëŠ” ê°ì •
   - ìŠ¤í† ë¦¬/ë‚´ëŸ¬í‹°ë¸Œ

7. **ìŠ¤íƒ€ì¼ (Style)**
   - ì‚¬ì§„/ì˜ìƒ ìŠ¤íƒ€ì¼ (ì‹œë„¤ë§ˆí‹±, ë‹¤íë©˜í„°ë¦¬, íŒ¨ì…˜, í¬íŠ¸ë ˆì´íŠ¸ ë“±)
   - ì‹œëŒ€/íŠ¸ë Œë“œ
   - ì°¸ê³ í•  ë§Œí•œ ì‘ê°€/ê°ë… ìŠ¤íƒ€ì¼

ì‘ë‹µì€ ë°˜ë“œì‹œ ì•„ë˜ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì¶œë ¥í•´ì£¼ì„¸ìš” (ë‹¤ë¥¸ í…ìŠ¤íŠ¸ ì—†ì´):
{
  "subject": "í”¼ì‚¬ì²´ ì„¤ëª…",
  "background": "ë°°ê²½ ì„¤ëª…",
  "lighting": "ì¡°ëª… ì„¤ëª…",
  "camera": "ì¹´ë©”ë¼/êµ¬ë„ ì„¤ëª…",
  "color": "ìƒ‰ê° ì„¤ëª…",
  "mood": "ë¶„ìœ„ê¸°/ê°ì • ì„¤ëª…",
  "style": "ìŠ¤íƒ€ì¼ ì„¤ëª…",
  "prompt_ko": "í•œêµ­ì–´ ì´ë¯¸ì§€ ìƒì„± í”„ë¡¬í”„íŠ¸ (ìœ„ ë¶„ì„ì„ ë°”íƒ•ìœ¼ë¡œ)",
  "prompt_en": "English image generation prompt (based on above analysis)"
}"""

        # OpenRouter API í˜¸ì¶œ
        openrouter_response = requests.post(
            "https://openrouter.ai/api/v1/chat/completions",
            headers={
                "Authorization": f"Bearer {api_key}",
                "Content-Type": "application/json"
            },
            json={
                "model": "google/gemini-2.0-flash-001",
                "messages": [
                    {
                        "role": "user",
                        "content": [
                            {"type": "text", "text": analysis_prompt},
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:{mime_type};base64,{image_base64}"
                                }
                            }
                        ]
                    }
                ],
                "max_tokens": 2000,
                "temperature": 0.7
            },
            timeout=60
        )

        if openrouter_response.status_code != 200:
            error_msg = openrouter_response.text
            print(f"[IMAGE-PROMPT] OpenRouter API ì˜¤ë¥˜: {error_msg}")
            return jsonify({"success": False, "message": f"OpenRouter API ì˜¤ë¥˜: {error_msg}"}), 500

        response_data = openrouter_response.json()
        response_text = response_data.get("choices", [{}])[0].get("message", {}).get("content", "")

        if not response_text:
            return jsonify({"success": False, "message": "ì´ë¯¸ì§€ ë¶„ì„ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤"}), 500

        # JSON íŒŒì‹±
        response_text = response_text.strip()

        # JSON ë¸”ë¡ ì¶”ì¶œ (```json ... ``` í˜•íƒœì¼ ê²½ìš°)
        if "```json" in response_text:
            response_text = response_text.split("```json")[1].split("```")[0].strip()
        elif "```" in response_text:
            response_text = response_text.split("```")[1].split("```")[0].strip()

        try:
            analysis = json.loads(response_text)
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ ë°˜í™˜
            print(f"[IMAGE-PROMPT] JSON íŒŒì‹± ì‹¤íŒ¨, ì›ë³¸ í…ìŠ¤íŠ¸ ë°˜í™˜")
            return jsonify({
                "success": True,
                "prompt": response_text,
                "analysis": None,
                "raw_response": response_text
            })

        print(f"[IMAGE-PROMPT] ë¶„ì„ ì™„ë£Œ")

        return jsonify({
            "success": True,
            "prompt": analysis.get("prompt_en", ""),
            "prompt_ko": analysis.get("prompt_ko", ""),
            "analysis": {
                "subject": analysis.get("subject", ""),
                "background": analysis.get("background", ""),
                "lighting": analysis.get("lighting", ""),
                "camera": analysis.get("camera", ""),
                "color": analysis.get("color", ""),
                "mood": analysis.get("mood", ""),
                "style": analysis.get("style", "")
            }
        })

    except Exception as e:
        print(f"[IMAGE-PROMPT] ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()
        return jsonify({"success": False, "message": str(e)}), 500
